{
    "q": [
        {
            "docid": "53953041_7",
            "document": "Predictive coding . Expectations about the precision (or inverse variance) of incoming sensory input are crucial for effectively minimizing prediction error in that the expected precision of a given prediction error can inform confidence in that error, which influences the extent to which the error is weighted in updating predictions (Feldman & Friston, 2010). Given that the world we live in is loaded with statistical noise, precision expectations must be represented as part of the brain\u2019s generative models, and they should be able to flexibly adapt to changing contexts. For instance, the expected precision of visual prediction errors likely varies between dawn and dusk, such that greater conditional confidence is assigned to errors in broad daylight than errors in prediction at nightfall (Hohwy, 2012). It has recently been proposed that such weighting of prediction errors in proportion to their estimated precision is, in essence, attention (Friston, 2009), and that the process of devoting attention may be neurobiologically accomplished by ascending reticular activating systems (ARAS) optimizing the \u201cgain\u201d of prediction error units.",
            "score": 140.70773327350616
        },
        {
            "docid": "684801_4",
            "document": "Andy Clark . In contrast to traditional models of cognition, which often posit the one-way flow of sensory information from the periphery towards more remote areas of the brain, Clark has suggested a two-way \"cascade of cortical processing\" underlying perception, action, and learning. The concept of predictive processing lies at the heart of this view, wherein top-down predictions attempt to correctly guess or \"explain away\" bottom-up sensory information in an iterative, hierarchical manner. Discrepancies between the expected signal and actual signal, in essence the \"prediction error,\" travel upward to help refine the accuracy of future predictions. Interactions between forward flow of error (conveyed by \"error units\") and backward flow of prediction are dynamic, with attention playing a key role in weighting the relative influence of either at each level of the cascade (dopamine is mentioned as \"one possible mechanism for encoding precision\" with regard to error units). Action (or action-oriented predictive processing) also plays an important role in Clark's account as another means by which the brain can reduce prediction error by directly influencing the environment. To this, he adds that \"personal, affective, and hedonic\" factors would be implicated along with the minimization of prediction error, creating a more nuanced model for the relationship between action and perception.",
            "score": 142.59615862369537
        },
        {
            "docid": "37438_37",
            "document": "Complex system . Complexity theory is rooted in chaos theory, which in turn has its origins more than a century ago in the work of the French mathematician Henri Poincar\u00e9. Chaos is sometimes viewed as extremely complicated information, rather than as an absence of order. Chaotic systems remain deterministic, though their long-term behavior can be difficult to predict with any accuracy. With perfect knowledge of the initial conditions and of the relevant equations describing the chaotic system's behavior, one can theoretically make perfectly accurate predictions about the future of the system, though in practice this is impossible to do with arbitrary accuracy. Ilya Prigogine argued that complexity is non-deterministic, and gives no way whatsoever to precisely predict the future.",
            "score": 77.91012525558472
        },
        {
            "docid": "14639492_9",
            "document": "Erich Schr\u00f6ger . In December 2008, Schr\u00f6ger won a one-million-Euro, five-year Reinhart Koselleck Project Grant by the DFG. The main research issue of this project was the mechanism of predictive modeling in audition. Specifically, Schr\u00f6ger investigated how automatic predictions about upcoming auditory events can be generated on the basis of regular environmental stimulation. Due to this mechanism, for example, incoming acoustic stimuli can be processed with astonishing speed as when comprehending spoken language or localizing moving sounds. Likewise, the specific processing of self-induced auditory stimuli\u2014stimuli that a person creates by means of its own behavior\u2014can be explained by the principles of predictive modeling. In order to optimize a predictive model, the information processing system calculates predictive errors as the difference between the prediction and the actual stimulus signal.",
            "score": 95.0556092262268
        },
        {
            "docid": "53953041_9",
            "document": "Predictive coding . Evaluating the empirical evidence that suggests a neurologically plausible basis for predictive coding is a broad and varied task. For one thing, and according to the model, predictive coding occurs at every iterative step in the perceptual and cognitive processes; accordingly, manifestations of predictive coding in the brain include genetics, specific cytoarchitecture of cells, systemic networks of neurons, and whole brain analyses. Due to this range of specificity, different methods of investigating the neural mechanisms of predictive coding have been applied, where available; more generally, however, and at least as it relates to humans, there are significant methodological limitations to investigating the potential evidence and much of the work is based on computational modeling of microcircuits in the brain. Notwithstanding, there has been substantial [theoretical] work that has been applied to understanding predictive coding mechanisms in the brain. This section will focus on specific evidence as it relates to the predictive coding phenomenon, rather than analogues, such as homeostasis (which are, nonetheless, integral to our overall understanding of Bayesian inference but already supported heavily; see Clark, 2012 for a review).",
            "score": 134.71316373348236
        },
        {
            "docid": "53953041_15",
            "document": "Predictive coding . The empirical evidence for predictive coding is most robust for perceptual processing. As early as 1999, Rao and Ballard proposed a hierarchical visual processing model in which higher-order visual cortical area sends down predictions and the feedforward connections carry the residual errors between the predictions and the actual lower-level activities (Rao and Ballard, 1999). According to this model, each level in the hierarchical model network (except the lowest level, which represents the image) attempts to predict the responses at the next lower level via feedback connections, and the error signal is used to correct the estimate of the input signal at each level concurrently (Rao and Ballard, 1999). Emberson et al. established the top-down modulation in infants using a cross-modal audiovisual omission paradigm, determining that even infant brains have expectation about future sensory input that is carried downstream from visual cortices and are capable of expectation-based feedback (Emberson et al., 2015). Functional near-infrared spectroscopy (fNIRS) data showed that infant occipital cortex responded to unexpected visual omission (with no visual information input) but not to expected visual omission. These results establish that in a hierarchically organized perception system, higher-order neurons send down predictions to lower-order neurons, which in turn sends back up the prediction error signal.",
            "score": 149.35449349880219
        },
        {
            "docid": "53953041_5",
            "document": "Predictive coding . Most of the research literature in the field has been about sensory perception, particularly vision, which is more easily conceptualized. However, the predictive coding framework could also be applied to different neural systems. Taking the sensory system as an example, the brain solves the seemingly intractable problem of modelling distal causes of sensory input through a version of Bayesian inference. It does this by modelling predictions of lower-level sensory inputs via backward connections from relatively higher levels in a cortical hierarchy (Clark, 2013).  Constrained by the statistical regularities of the outside world (and certain evolutionarily prepared predictions), the brain encodes top-down generative models at various temporal and spatial scales in order to predict and effectively suppress sensory inputs rising up from lower levels. A comparison between predictions (priors) and sensory input (likelihood) yields a difference measure (e.g. prediction error, free energy, or surprise) which, if it is sufficiently large beyond the levels of expected statistical noise, will cause the generative model to update so that it better predicts sensory input in the future.",
            "score": 154.0489171743393
        },
        {
            "docid": "41197921_19",
            "document": "Verbal overshadowing . According to the recoding interference hypothesis, verbalizing non-verbal memory makes the visual representations less accurate. The recoding interference hypothesis predicts that verbal overshadowing will occur more readily if participants generate less accurate verbal descriptions. A computational model detected core processing principles of the recoding interference hypothesis to simulate facial recognition and it reproduced these behavioral phenomena as well as verbal overshadowing, providing an account as to why target description accuracy does not linearly predict recognition accuracy. The study addressed the replicability issues in verbal overshadowing. Hatano et al. (2015) stated, \"Our hypothesis is that this is due to (a) the use of single-trial testing methods, (b) individual differences, and (c) relatively uncontrolled extraneous variables (e.g., how many distinctive facial features the target and distractors share)\" (p.\u00a04). The study found that verbalization changed the nature of representations, rather than shifting the types of processing. Then, this recoded representation was used for (or affected) subsequent visual recognition and resulted in a failure in computing item-specific information. The phenomena from the study are predictable from the recoding interference hypothesis. It is explained as followed by the authors: The researchers found that generated verbal descriptions affected not just the polarity (familiarity) values of \"old\" items but also those of \"new\" items, as a function of how accurately the descriptions captured the distractor faces. This was the reason why target description accuracy in isolation does not necessarily predict the effect size of verbal overshadowing in a linear fashion. The model links verbal and visual code as in the face recognition model. Verbal descriptions predicted recognition impairment and indicated that theory about interference in the memory domain is potentially useful when discussing the verbalization effect on non-verbal recognition. The study also noted that it did not consider whether this account can be extended to the visual imagery domain beyond facial recognition.",
            "score": 109.95362710952759
        },
        {
            "docid": "53953041_19",
            "document": "Predictive coding . As a mechanistic theory, predictive coding has not been mapped out physiologically on the neuronal level. One of the biggest challenges to the theory has been the imprecision of exactly how prediction error minimization works (Kogo & Trengove, 2015). In some studies, the increase in BOLD signal has been interpreted as error signal while in others it indicates changes in the input representation (Kogo & Trengove, 2015). A crucial question that needs to be addressed is what exactly constitutes error signal and how it is computed at each level of information processing (Bastos et al., 2012). Another challenge that has been posed is predictive coding\u2019s computational tractability. According to Kwisthout and Rooij, the subcomputation in each level of the predictive coding framework potentially hides a computationally intractable problem, which amounts to \u201cintractable hurdles\u201d that computational modelers have yet to overcome (Kwisthout & Rooij, 2013). Ransom and Fazelpour (2015) indicate \"Three Problems for the Predictive Coding Theory of Attention\".",
            "score": 106.9367538690567
        },
        {
            "docid": "6060077_6",
            "document": "Flash lag illusion . A recent study tries to reconcile these different approaches by approaching perception as an inference mechanism aiming at describing what is happening at the present time. In particular, it could extend the motion extrapolation hypothesis by weighting this prediction by the precision of the current information. Thus, the corrected position of the moving target is calculated by combining the sensory flux with the internal representation of the trajectory, both of which exist in the form of probability distributions. To manipulate the trajectory is to change the precision and therefore the relative weight of these two information when they are optimally combined in order to know where an object is at the present time. For an object that moves predictably, the neural network can infer its most probable position taking into account this processing time. For the flash, however, this prediction can not be established because its appearance is unpredictable. Thus, while the two targets are aligned on the retina at the time of the flash, the position of the moving object is anticipated by the brain to compensate for the processing time: it is this differentiated treatment that causes the flash-lag effect. Moreover, this could also explain related phenomena such as motion reversal.",
            "score": 115.0083498954773
        },
        {
            "docid": "53953041_8",
            "document": "Predictive coding . The same principle of prediction error minimization has been used to provide an account of behavior in which motor actions are not commands but descending proprioceptive predictions. In this scheme of active inference, classical reflex arcs are coordinated so as to selectively sample sensory input in ways that better fulfill predictions, thereby minimizing proprioceptive prediction errors (Friston, 2009). Indeed, Adams et al. (2013) review evidence suggesting that this view of hierarchical predictive coding in the motor system provides a principled and neurally plausible framework for explaining the agranular organization of the motor cortex. This view suggests that \u201cperceptual and motor systems should not be regarded as separate but instead as a single active inference machine that tries to predict its sensory input in all domains: visual, auditory, somatosensory, interoceptive and, in the case of the motor system, proprioceptive\u201d (Adams, Shipp, & Friston, 2013).",
            "score": 113.05886805057526
        },
        {
            "docid": "54842715_43",
            "document": "Interoception . The EPIC model proposes a method of understanding the brain\u2019s response to stimuli contrary to the classic \"stimulus-response\" model. The classical view of information processing is that when a peripheral stimulus provided information to the central nervous system, it was processed in the brain, and a response was elicited. The EPIC model deviates from this and proposes that the brain is involved in a process of active inference, that is, assiduously making predictions about situations based on previous experiences. These predictions, when coupled with incoming sensory signals, allow the brain to compute a prediction error. Interoceptive prediction errors signal the occurrence of discrepancies within the body, which the brain attempts to minimize. This can be done by 1) modifying the predictions through brain-related pathways, 2) altering the body position/location in order to better align incoming sensory signals with the prediction, or 3) altering the brain\u2019s method of receiving incoming stimuli. Interoceptive prediction error signals are a key component of many theories of interoceptive dysfunction in physical and mental health.",
            "score": 155.3931279182434
        },
        {
            "docid": "1434444_61",
            "document": "Autoregressive model . The question of how to interpret the measured forecasting accuracy arises\u2014for example, what is a \"high\" (bad) or a \"low\" (good) value for the mean squared prediction error? There are two possible points of comparison. First, the forecasting accuracy of an alternative model, estimated under different modeling assumptions or different estimation techniques, can be used for comparison purposes. Second, the out-of-sample accuracy measure can be compared to the same measure computed for the in-sample data points (that were used for parameter estimation) for which enough prior data values are available (that is, dropping the first \"p\" data points, for which \"p\" prior data points are not available). Since the model was estimated specifically to fit the in-sample points as well as possible, it will usually be the case that the out-of-sample predictive performance will be poorer than the in-sample predictive performance. But if the predictive quality deteriorates out-of-sample by \"not very much\" (which is not precisely definable), then the forecaster may be satisfied with the performance.",
            "score": 72.57851576805115
        },
        {
            "docid": "53953041_13",
            "document": "Predictive coding . \u201c...prediction neurons... in deep layers of agranular cortex drive active inference by sending sensory predictions via projections ...to supragranular layers of dysgranular and granular sensory cortices. Prediction-error neurons \u2026.in the supragranular layers of granular cortex compute the difference between the predicted and received sensory signal, and send prediction-error signals via projections...back to the deep layers of agranular cortical regions. Precision cells \u2026 tune the gain on predictions and prediction error dynamically, thereby giving these signals reduced (or, in some cases, greater) weight depending on the relative confidence in the descending predictions or the reliability of incoming sensory signals.\u201d (Barrett & Simmons, 2015)",
            "score": 90.29471445083618
        },
        {
            "docid": "25140_29",
            "document": "Perception . Philosopher Andy Clark explains that perception, although it occurs quickly, is not simply a bottom-up process (where minute details are put together to form larger wholes). Instead, our brains use what he calls 'predictive coding'. It starts with very broad constraints and expectations for the state of the world, and as expectations are met, it makes more detailed predictions (errors lead to new predictions, or learning processes). Clark says this research has various implications; not only can there be no completely \"unbiased, unfiltered\" perception, but this means that there is a great deal of feedback between perception and expectation (perceptual experiences often shape our beliefs, but those perceptions were based on existing beliefs). Indeed, predictive coding provides an account where this type of feedback assists in stabilizing our inference-making process about the physical world, such as with perceptual constancy examples.",
            "score": 157.30202877521515
        },
        {
            "docid": "3771060_2",
            "document": "Accuracy paradox . The accuracy paradox for predictive analytics states that predictive models with a given level of accuracy may have greater predictive power than models with higher accuracy. It may be better to avoid the accuracy metric in favor of other metrics such as precision and recall.",
            "score": 58.715941190719604
        },
        {
            "docid": "2426547_5",
            "document": "Affective forecasting . Affective forecasting can be divided into four components: predictions about emotional valence (i.e. positive or negative), the specific emotions experienced, their duration, and their intensity. While errors may occur in all four components, research overwhelmingly indicates that the two areas most prone to bias, usually in the form of overestimation, are duration and intensity. Immune neglect is a form of impact bias in response to negative events, in which people fail to predict how much their psychological immune system will hasten their recovery. On average, people are fairly accurate about predicting which emotions they will feel in response to future events. However, some studies indicate that predicting specific emotions in response to more complex social events leads to greater inaccuracy. For example, one study found that while many women who imagine encountering gender harassment predict feelings of anger, in reality, a much higher proportion report feelings of fear. Other research suggests that accuracy in affective forecasting is greater for positive affect than negative affect, suggesting an overall tendency to overreact to perceived negative events. Gilbert and Wilson posit that this is a result of our psychological immune system.",
            "score": 100.03718602657318
        },
        {
            "docid": "16839353_3",
            "document": "Super Crunchers . With examples such as predicting gestation period more precisely than Naegele's rule, predicting the box office success of films, Orley Ashenfelter's work predicting the price of Bordeaux wine based on weather data, collecting data on the effectiveness of teaching methods such as DISTAR, choosing baseball players based on statistics (Sabermetrics), and A/B testing to determine the most effective advertisements, Ayres explains how statistical evidence can be used as a supplement or substitute for human intuition.",
            "score": 72.22214770317078
        },
        {
            "docid": "2426547_26",
            "document": "Affective forecasting . Another problem that can arise with affective forecasting is that people tend to misremember their past predictions. Meyvis, Ratner, and Levav predicted that people forget how they predicted an experience would be beforehand, and thought their predictions were the same as their actual emotions. Because of this, people do not realize that they made a mistake in their predictions, and will then continue to misforecast similar situations in the future. Meyvis et al. ran five studies to test whether or not this is true. They found in all of their studies, when people were asked to recall their previous predictions they instead write how they currently feel about the situation. This shows that they do not remember how they thought they would feel, and makes it impossible for them to learn from this event for future experiences.",
            "score": 106.92803025245667
        },
        {
            "docid": "1983931_5",
            "document": "Predictive power . Another example of predictive power is the prediction of Einstein's general theory of relativity that the path of light would bend in the presence of a strong gravitational field. This was experimentally verified by an expedition to Sobral in Brazil and the Atlantic island of Pr\u00edncipe to measure star positions during the solar eclipse of May 29, 1919, when observations made by the astrophysicist Arthur Eddington seemed to confirm Einstein's predictions. Although the measurements have been criticized by some as utilizing flawed methodology, modern reanalysis of the data suggests that Eddington's analysis of the data was accurate. Later, more precise measurements taken by radio interferometry confirmed the predictions to a high degree of accuracy.",
            "score": 68.9930567741394
        },
        {
            "docid": "228051_6",
            "document": "Intrapersonal communication . Jones and Fernyhough cite other evidence for this hypothesis that inner speech is essentially like any other action. They mention that schizophrenics suffering auditory verbal hallucinations (AVH) need only open their mouths in order to disrupt the voices in their heads. To try and explain more about how inner speech works, but also what goes wrong with AVH patients, Jones and Fernyhough adapt what is known as the \"forward model\" of motor control, which uses the idea of \"efferent copies\". In a forward model of motor control, the mind generates movement unconsciously. While information is sent to the necessary body parts, the mind basically faxes a copy of that same information to other areas of the brain. This \"efferent\" copy could then be used to make predictions about upcoming movements. If the actual sensations match predictions, we experience the feeling of agency. If there is a mismatch between the body and its predicted position, perhaps due to obstructions or other cognitive disruption, no feeling of agency occurs. Jones and Fernyhough believe that the forward model might explain AVH and inner speech. Perhaps, if inner speech is a normal action, then the malfunction in schizophrenic patients is not the fact that actions (i.e. voices) are occurring at all. Instead, it may be that they are experiencing normal, inner speech, but the \"generation of the predictive efferent copy\" is malfunctioning. Without an efferent copy, motor commands are judged as alien (i.e. one does not feel like they caused the action). This could also explain why an open mouth stops the experience of alien voices: When the patient opens their mouth, the inner speech motor movements are not planned in the first place.",
            "score": 126.71678256988525
        },
        {
            "docid": "2426547_6",
            "document": "Affective forecasting . While affective forecasts take place in the present moment, researchers also investigate its future outcomes. That is, they analyze forecasting as a two-step process, encompassing a current prediction as well as a future event. Breaking down the present and future stages allow researchers to measure accuracy, as well as tease out how errors occur. Gilbert and Wilson, for example, categorize errors based on which component they affect and when they enter the forecasting process. In the present phase of affective forecasting, forecasters bring to mind a mental representation of the future event and predict how they will respond emotionally to it. The future phase includes the initial emotional response to the onset of the event, as well as subsequent emotional outcomes, for example, the fading of the initial feeling.",
            "score": 58.60653233528137
        },
        {
            "docid": "25043252_17",
            "document": "Musical syntax . The violation of these automatically made predictions lead to the observation of so-called ERPs (event related potential, a stereotyped electrophysiological response to an internal or external stimulus). Two forms of ERPs can be detected in the context of processing music. One is the MMN (mismatch negativity), which has first been investigated only with physical deviants like frequency, sound intensity, timbre deviants (referred to as phMMN) and could now also be shown for changes of abstract auditory features like tone pitches (referred to as afMMN). The other one is the so-called ERAN (early right anterior negativity), which can be elicited by syntactic irregularities in music. Both the ERAN and the MMN are ERPs indicating a mismatch between predictions based on regularities and actually experienced acoustic information. As for a long time it seemed to be, that the ERAN is a special variant of the MMN, the question arises, why they are told apart today. There are several differences between the MMN and the ERAN found in the last years:",
            "score": 102.56490790843964
        },
        {
            "docid": "53953041_6",
            "document": "Predictive coding . If, instead, the model accurately predicts driving sensory signals, activity at higher levels cancels out activity at lower levels, and the posterior probability of the model is increased. Thus, predictive coding inverts the conventional view of perception as a mostly bottom-up process, suggesting that it is largely constrained by prior predictions, where signals from the external world only shape perception to the extent that they are propagated up the cortical hierarchy in the form of prediction error.",
            "score": 111.31089401245117
        },
        {
            "docid": "29354346_8",
            "document": "Change deafness . Additional studies of change deafness have generated evidence in support of the prediction that undetected changes are successfully encoded at the sensory level in the auditory cortex, but do not trigger later change-related cortical responses that would produce conscious perception of change. EEG analysis during a change-detection task using changes in pitch revealed that responses previously shown to be involved with sensory extraction of pitch information increased during both detected and undetected pitch changes in auditory input, however only in cases where the pitch change was detected were later processing stages triggered, originating from hierarchically higher non-sensory brain regions. These findings suggest that change deafness does not arise from a deficit in initial sensory encoding of changed stimulus features in auditory cortex but occurs at a higher level of stimulus processing in auditory cortex, resulting in a failure to trigger auditory change detection mechanisms.",
            "score": 119.66991019248962
        },
        {
            "docid": "43218024_14",
            "document": "Evaluation of binary classifiers . In addition to sensitivity and specificity, the performance of a binary classification test can be measured with positive predictive value (PPV), also known as precision, and negative predictive value (NPV). The positive prediction value answers the question \"If the test result is \"positive\", how well does that \"predict\" an actual presence of disease?\". It is calculated as TP/(TP + FP); that is, it is the proportion of true positives out of all positive results. The negative prediction value is the same, but for negatives, naturally.",
            "score": 59.0655415058136
        },
        {
            "docid": "26565579_50",
            "document": "Neuroscience of free will . Multivariate pattern analysis using EEG has suggested that an evidence based perceptual decision model may be applicable to free will decisions. It was found that decisions could be predicted by neural activity immediately after stimulus perception. Furthermore, when the participant was unable to determine the nature of the stimulus the recent decision history predicted the neural activity (decision). The starting point of evidence accumulation was in effect shifted towards a previous choice (suggesting a priming bias). Another study has found that subliminally priming a participant for a particular decision outcome (showing a cue for 13ms) could be used to influence free decision outcomes. Likewise, it has been found that decision history alone can be used to predict future decisions. The prediction capacities of the Soon et al. (2008) experiment were successfully replicated using a linear SVM model based on participant decision history alone (without any brain activity data). Despite this, a recent study has sought to confirm the applicability of a perceptual decision model to free will decisions. When shown a masked and therefore invisible stimulus, participants were asked to either guess between a category or make a free decision for a particular category. Multivariate pattern analysis using fMRI could be trained on \"free decision\" data to successfully predict \"guess decisions\", and trained on \"guess data\" in order to predict \"free decisions\" (in the precuneus and cuneus region).",
            "score": 121.05202448368073
        },
        {
            "docid": "53953041_2",
            "document": "Predictive coding . Predictive coding models suggest that the brain is constantly generating and updating hypotheses that predict sensory input at varying levels of abstraction. This framework is in contrast to the view that the brain integrates exteroceptive information through a predominantly feedforward process, with feedback connections playing a more minor role in cortical processing.",
            "score": 129.64277935028076
        },
        {
            "docid": "1352020_6",
            "document": "Fudge factor . However, in project management it's common to build a certain error margin into the \"predicted\" \"resource cost\" of a project to make predictions more realistic: there are many unforeseen factors that may delay a project or make it more costly, but very few factors that could result in it being delivered \"before\" time or \"under\" the calculated budget ... so to some degree, \"unexpected\" overruns are to be expected, even if their precise nature can't be predicted in advance. Experienced planners may know that a certain type of project will tend to overrun by a certain percentage of its calculated resource requirements, and may multiply the \"ideal\" calculations by a safety margin to produce a more realistic estimate, and this margin may sometimes be referred to as a fudge factor.  However, when planning ahead for \"expected\" unpredictabilities, these \"error margins\" are usually assigned other, more specific names : for instance in warehouse stock control, where a certain amount of stock is expected to disappear naturally through damage, pilfering or other unexplained problems, the discrepancy is referred to as shrinkage.",
            "score": 66.67771863937378
        },
        {
            "docid": "166404_71",
            "document": "First law of thermodynamics . The first law of thermodynamics is so general that its predictions cannot all be directly tested. In many properly conducted experiments it has been precisely supported, and never violated. Indeed, within its scope of applicability, the law is so reliably established, that, nowadays, rather than experiment being considered as testing the accuracy of the law, it is more practical and realistic to think of the law as testing the accuracy of experiment. An experimental result that seems to violate the law may be assumed to be inaccurate or wrongly conceived, for example due to failure to account for an important physical factor. Thus, some may regard it as a principle more abstract than a law.",
            "score": 53.36071753501892
        },
        {
            "docid": "369978_39",
            "document": "Bird vocalization . Leonardo tested these models directly by recording spike rates in single LMAN neurons of adult zebra finches during singing in conditions with normal and perturbed auditory feedback. His results did not support the BOS-tuned error correction model, as the firing rates of LMAN neurons were unaffected by changes in auditory feedback and therefore, the error signal generated by LMAN appeared unrelated to auditory feedback. Moreover, the results from this study supported the predictions of the efference copy model, in which LMAN neurons are activated during singing by the efference copy of the motor signal (and its predictions of expected auditory feedback), allowing the neurons to be more precisely time-locked to changes in auditory feedback.",
            "score": 75.54801392555237
        },
        {
            "docid": "1434685_12",
            "document": "Prognostics . Prognostic performance evaluation is of key importance for a successful PHM system deployment. The early lack of standardized methods for performance evaluation and benchmark data-sets resulted in reliance on conventional performance metrics borrowed from statistics. Those metrics were primarily accuracy and precision based where performance is evaluated against actual End of Life (EoL) typically known a priori in an offline setting. More recently, efforts towards maturing prognostics technology has put a significant focus on standardizing prognostic methods, including those of performance assessment. A key aspect, missing from the conventional metrics, is the capability to track performance with time. This is important because prognostics is a dynamic process where predictions get updated with an appropriate frequency as more observation data become available from an operational system. Similarly, the performance of prediction changes with time that must be tracked and quantified. Another aspect that makes this process different in a PHM context is the time value of a RUL prediction. As a system approaches failure, the time window to take a corrective action gets shorter and consequently the accuracy of predictions becomes more critical for decision making. Finally, randomness and noise in the process, measurements, and prediction models are unavoidable and hence prognostics inevitably involves uncertainty in its estimates. A robust prognostics performance evaluation must incorporate the effects of this uncertainty.",
            "score": 92.77157187461853
        }
    ],
    "r": [
        {
            "docid": "53953041_3",
            "document": "Predictive coding . Theoretical ancestors to predictive coding date back as early as 1860 with Helmholz\u2019s concept of unconscious inference (Clark, 2013). Unconscious inference refers to the idea that the human brain fills in visual information to make sense of a scene. For example, if something is relatively smaller than another object in the visual field, the brain uses that information as a likely cue of depth, such that the perceiver ultimately (and involuntarily) experiences depth. The understanding of perception as the interaction between sensory stimuli (bottom-up) and conceptual knowledge (top-down) continued to be established by Jerome Bruner (psychologist) who, starting in the 1940s, studied the ways in which needs, motivations and expectations influence perception, research that came to be known as 'New Look' psychology. In 1981, McClelland and Rumelhart in their seminal paper examined the interaction between processing features (lines and contours) which form letters, which in turn form words. While the features suggest the presence of a word, they found that when letters were situated in the context of a word, people were able to identify them faster than when they were situated in a non-word without semantic context. McClelland and Rumelhart\u2019s parallel processing model describes perception as the meeting of top-down (conceptual) and bottom-up (sensory) elements.",
            "score": 159.80142211914062
        },
        {
            "docid": "25140_29",
            "document": "Perception . Philosopher Andy Clark explains that perception, although it occurs quickly, is not simply a bottom-up process (where minute details are put together to form larger wholes). Instead, our brains use what he calls 'predictive coding'. It starts with very broad constraints and expectations for the state of the world, and as expectations are met, it makes more detailed predictions (errors lead to new predictions, or learning processes). Clark says this research has various implications; not only can there be no completely \"unbiased, unfiltered\" perception, but this means that there is a great deal of feedback between perception and expectation (perceptual experiences often shape our beliefs, but those perceptions were based on existing beliefs). Indeed, predictive coding provides an account where this type of feedback assists in stabilizing our inference-making process about the physical world, such as with perceptual constancy examples.",
            "score": 157.30203247070312
        },
        {
            "docid": "54842715_43",
            "document": "Interoception . The EPIC model proposes a method of understanding the brain\u2019s response to stimuli contrary to the classic \"stimulus-response\" model. The classical view of information processing is that when a peripheral stimulus provided information to the central nervous system, it was processed in the brain, and a response was elicited. The EPIC model deviates from this and proposes that the brain is involved in a process of active inference, that is, assiduously making predictions about situations based on previous experiences. These predictions, when coupled with incoming sensory signals, allow the brain to compute a prediction error. Interoceptive prediction errors signal the occurrence of discrepancies within the body, which the brain attempts to minimize. This can be done by 1) modifying the predictions through brain-related pathways, 2) altering the body position/location in order to better align incoming sensory signals with the prediction, or 3) altering the brain\u2019s method of receiving incoming stimuli. Interoceptive prediction error signals are a key component of many theories of interoceptive dysfunction in physical and mental health.",
            "score": 155.39312744140625
        },
        {
            "docid": "53953041_5",
            "document": "Predictive coding . Most of the research literature in the field has been about sensory perception, particularly vision, which is more easily conceptualized. However, the predictive coding framework could also be applied to different neural systems. Taking the sensory system as an example, the brain solves the seemingly intractable problem of modelling distal causes of sensory input through a version of Bayesian inference. It does this by modelling predictions of lower-level sensory inputs via backward connections from relatively higher levels in a cortical hierarchy (Clark, 2013).  Constrained by the statistical regularities of the outside world (and certain evolutionarily prepared predictions), the brain encodes top-down generative models at various temporal and spatial scales in order to predict and effectively suppress sensory inputs rising up from lower levels. A comparison between predictions (priors) and sensory input (likelihood) yields a difference measure (e.g. prediction error, free energy, or surprise) which, if it is sufficiently large beyond the levels of expected statistical noise, will cause the generative model to update so that it better predicts sensory input in the future.",
            "score": 154.04891967773438
        },
        {
            "docid": "53953041_17",
            "document": "Predictive coding . In 2013, Anil Seth proposed that our subjective feeling states, otherwise known as emotions, are generated by predictive models that is built actively of causal interoceptive appraisals. In relation to how we attribute internal states of others to causes, Sasha Ondobaka, James Kilner, and Karl Friston (2015) proposed that the free energy principle requires the brain to produce a continuous series of predictions with the goal of reducing the amount of prediction error that manifests as \u201cfree energy\u201d. These errors are then used to model anticipatory information about what the state of the outside world will be and attributions of causes of that world state, including understanding of causes of others\u2019 behavior. This is especially necessary because, to create these attributions, our multimodal sensory systems need interoceptive predictions to organize themselves. Therefore, Ondobaka posits that predictive coding is key to understanding other people\u2019s internal states.",
            "score": 153.3629608154297
        },
        {
            "docid": "53953041_15",
            "document": "Predictive coding . The empirical evidence for predictive coding is most robust for perceptual processing. As early as 1999, Rao and Ballard proposed a hierarchical visual processing model in which higher-order visual cortical area sends down predictions and the feedforward connections carry the residual errors between the predictions and the actual lower-level activities (Rao and Ballard, 1999). According to this model, each level in the hierarchical model network (except the lowest level, which represents the image) attempts to predict the responses at the next lower level via feedback connections, and the error signal is used to correct the estimate of the input signal at each level concurrently (Rao and Ballard, 1999). Emberson et al. established the top-down modulation in infants using a cross-modal audiovisual omission paradigm, determining that even infant brains have expectation about future sensory input that is carried downstream from visual cortices and are capable of expectation-based feedback (Emberson et al., 2015). Functional near-infrared spectroscopy (fNIRS) data showed that infant occipital cortex responded to unexpected visual omission (with no visual information input) but not to expected visual omission. These results establish that in a hierarchically organized perception system, higher-order neurons send down predictions to lower-order neurons, which in turn sends back up the prediction error signal.",
            "score": 149.3544921875
        },
        {
            "docid": "433584_4",
            "document": "McGurk effect . Vision is the primary sense for humans, but speech perception is multimodal, which means that it involves information from more than one sensory modality, in particular, audition and vision. The McGurk effect arises during phonetic processing because the integration of audio and visual information happens early in speech perception. The McGurk effect is very robust; that is, knowledge about it seems to have little effect on one's perception of it. This is different from certain optical illusions, which break down once one 'sees through' them. Some people, including those that have been researching the phenomenon for more than twenty years, experience the effect even when they are aware that it is taking place. With the exception of people who can identify most of what is being said from speech-reading alone, most people are quite limited in their ability to identify speech from visual-only signals. A more extensive phenomenon is the ability of visual speech to increase the intelligibility of heard speech in a noisy environment. Visible speech can also alter the perception of perfectly audible speech sounds when the visual speech stimuli are mismatched with the auditory speech. Normally, speech perception is thought to be an auditory process; however, our use of information is immediate, automatic, and, to a large degree, unconscious and therefore, despite what is widely accepted as true, speech is not only something we hear. Speech is perceived by all of the senses working together (seeing, touching, and listening to a face move). The brain is often unaware of the separate sensory contributions of what it perceives. Therefore, when it comes to recognizing speech the brain cannot differentiate whether it is seeing or hearing the incoming information.",
            "score": 148.82015991210938
        },
        {
            "docid": "5664_64",
            "document": "Consciousness . In neuroscience, a great deal of effort has gone into investigating how the perceived world of conscious awareness is constructed inside the brain. The process is generally thought to involve two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals arising from sensory organs are transmitted to the brain and then processed in a series of stages, which extract multiple types of information from the raw input. In the visual system, for example, sensory signals from the eyes are transmitted to the thalamus and then to the primary visual cortex; inside the cerebral cortex they are sent to areas that extract features such as three-dimensional structure, shape, color, and motion. Memory comes into play in at least two ways. First, it allows sensory information to be evaluated in the context of previous experience. Second, and even more importantly, working memory allows information to be integrated over time so that it can generate a stable representation of the world\u2014Gerald Edelman expressed this point vividly by titling one of his books about consciousness \"The Remembered Present\". In computational neuroscience, Bayesian approaches to brain function have been used to understand both the evaluation of sensory information in light of previous experience, and the integration of information over time. Bayesian models of the brain are probabilistic inference models, in which the brain takes advantage of prior knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian models have successfully predicted many perceptual phenomena in vision and the nonvisual senses.",
            "score": 147.66067504882812
        },
        {
            "docid": "14339999_6",
            "document": "Virtual pitch . Terhardt rejected the idea of periodicity pitch, because it was not consistent with empirical data on pitch perception, e.g. measurements of the gradual shift of the virtual pitch of a complex tone with a missing fundamental when the partials were gradually shifted. Terhardt instead broke pitch perception into two steps: auditory frequency analysis in the inner ear, and harmonic pitch pattern recognition in the brain. The inner ear effectively performs a running frequency analysis of incoming sounds - otherwise we would not be able to hear out spectral pitches within a complex tone. Physiologically, each spectral pitch depends on both temporal and spectral aspects (i.e. periodicity of the waveform and position of excitation on the basilar membrane), but in Terhardt's approach the spectral pitch itself is a purely experiential parameter, not a physical parameter: it is the outcome of a psychoacoustical experiment in which the conscious listener plays an active role. Psychoacoustic measurements and models can predict which partials are \"perceptually relevant\" in a given complex tone; they are perceptually relevant if you can hear a difference in the whole sound if the frequency or amplitude of a partial is changed). The ear has evolved to separate spectral frequencies, because due to reflection and superposition in everyday environments spectral frequencies are more reliably carriers of environmental information than spectral amplitudies, which in turn are more reliable carriers of environmentally relevant information than phase relationships between partials (when perceived monoaurally). On this basis, Terhardt proposed that spectral pitches - which are what the listener experiences when hearing out partials (as opposed to the physical partials themselves) - are the only information available to the brain for the purpose of extracting virtual pitches. The \"pitch extraction\" process then involves the recognition of incomplete harmonic patterns and happens in neural networks.",
            "score": 147.1389923095703
        },
        {
            "docid": "21107290_10",
            "document": "Bayesian approaches to brain function . During the 1990s some researchers such as Geoffrey Hinton and Karl Friston began examining the concept of free energy as a calculably tractable measure of the discrepancy between actual features of the world and representations of those features captured by neural network models. A synthesis has been attempted recently by Karl Friston, in which the Bayesian brain emerges from a general principle of free energy minimisation. In this framework, both action and perception are seen as a consequence of suppressing free-energy, leading to perceptual and active inference and a more embodied (enactive) view of the Bayesian brain. Using variational Bayesian methods, it can be shown how internal models of the world are updated by sensory information to minimize free energy or the discrepancy between sensory input and predictions of that input. This can be cast (in neurobiologically plausible terms) as predictive coding or, more generally, Bayesian filtering.",
            "score": 145.19979858398438
        },
        {
            "docid": "684801_4",
            "document": "Andy Clark . In contrast to traditional models of cognition, which often posit the one-way flow of sensory information from the periphery towards more remote areas of the brain, Clark has suggested a two-way \"cascade of cortical processing\" underlying perception, action, and learning. The concept of predictive processing lies at the heart of this view, wherein top-down predictions attempt to correctly guess or \"explain away\" bottom-up sensory information in an iterative, hierarchical manner. Discrepancies between the expected signal and actual signal, in essence the \"prediction error,\" travel upward to help refine the accuracy of future predictions. Interactions between forward flow of error (conveyed by \"error units\") and backward flow of prediction are dynamic, with attention playing a key role in weighting the relative influence of either at each level of the cascade (dopamine is mentioned as \"one possible mechanism for encoding precision\" with regard to error units). Action (or action-oriented predictive processing) also plays an important role in Clark's account as another means by which the brain can reduce prediction error by directly influencing the environment. To this, he adds that \"personal, affective, and hedonic\" factors would be implicated along with the minimization of prediction error, creating a more nuanced model for the relationship between action and perception.",
            "score": 142.59616088867188
        },
        {
            "docid": "7330954_12",
            "document": "Pattern recognition (psychology) . Top-down processing refers to the use of background information in pattern recognition. It always begins with a person\u2019s previous knowledge, and makes predictions due to this already acquired knowledge. Psychologist Richard Gregory estimated that about 90% of the information is lost between the time it takes to go from the eye to the brain, which is why the brain must guess what the person sees based on past experiences. In other words, we construct our perception of reality, and these perceptions are hypotheses or propositions based on past experiences and stored information. The formation of incorrect propositions will lead to errors of perception such as visual illusions. Given a paragraph written with difficult handwriting, it is easier to understand what the writer wants to convey if one reads the whole paragraph rather than reading the words in separate terms. The brain may be able to perceive and understand the gist of the paragraph due to the context supplied by the surrounding words.",
            "score": 141.56214904785156
        },
        {
            "docid": "53953041_7",
            "document": "Predictive coding . Expectations about the precision (or inverse variance) of incoming sensory input are crucial for effectively minimizing prediction error in that the expected precision of a given prediction error can inform confidence in that error, which influences the extent to which the error is weighted in updating predictions (Feldman & Friston, 2010). Given that the world we live in is loaded with statistical noise, precision expectations must be represented as part of the brain\u2019s generative models, and they should be able to flexibly adapt to changing contexts. For instance, the expected precision of visual prediction errors likely varies between dawn and dusk, such that greater conditional confidence is assigned to errors in broad daylight than errors in prediction at nightfall (Hohwy, 2012). It has recently been proposed that such weighting of prediction errors in proportion to their estimated precision is, in essence, attention (Friston, 2009), and that the process of devoting attention may be neurobiologically accomplished by ascending reticular activating systems (ARAS) optimizing the \u201cgain\u201d of prediction error units.",
            "score": 140.70773315429688
        },
        {
            "docid": "2999259_3",
            "document": "Choice-supportive bias . What is remembered about a decision can be as important as the decision itself, especially in determining how much regret or satisfaction one experiences. Research indicates that the process of making and remembering choices yields memories that tend to be distorted in predictable ways. In cognitive science, one predictable way that memories of choice options are distorted is that positive aspects tend to be remembered as part of the chosen option, whether or not they originally were part of that option, and negative aspects tend to be remembered as part of rejected options. Once an action has been taken, the ways in which we evaluate the effectiveness of what we did may be biased. It is believed this may influence our future decision-making. These biases may be stored as memories, which are attributions that we make about our mental experiences based on their subjective qualities, our prior knowledge and beliefs, our motives and goals, and the social context. True and false memories arise by the same mechanism because when the brain processes and stores information, it cannot tell the difference from where they came from.",
            "score": 136.41490173339844
        },
        {
            "docid": "2534964_14",
            "document": "Sensory processing . Perhaps one of the most studied sensory integrations is the relationship between vision and audition. These two senses perceive the same objects in the world in different ways, and by combining the two, they help us understand this information better. Vision dominates our perception of the world around us. This is because visual spatial information is one of the most reliable sensory modalities. Visual stimuli are recorded directly onto the retina, and there are few, if any, external distortions that provide incorrect information to the brain about the true location of an object. Other spatial information is not as reliable as visual spatial information. For example, consider auditory spatial input. The location of an object can sometimes be determined solely on its sound, but the sensory input can easily be modified or altered, thus giving a less reliable spatial representation of the object. Auditory information therefore is not spatially represented unlike visual stimuli. But once one has the spatial mapping from the visual information, multisensory integration helps bring the information from both the visual and auditory stimuli together to make a more robust mapping.",
            "score": 135.0167694091797
        },
        {
            "docid": "53953041_9",
            "document": "Predictive coding . Evaluating the empirical evidence that suggests a neurologically plausible basis for predictive coding is a broad and varied task. For one thing, and according to the model, predictive coding occurs at every iterative step in the perceptual and cognitive processes; accordingly, manifestations of predictive coding in the brain include genetics, specific cytoarchitecture of cells, systemic networks of neurons, and whole brain analyses. Due to this range of specificity, different methods of investigating the neural mechanisms of predictive coding have been applied, where available; more generally, however, and at least as it relates to humans, there are significant methodological limitations to investigating the potential evidence and much of the work is based on computational modeling of microcircuits in the brain. Notwithstanding, there has been substantial [theoretical] work that has been applied to understanding predictive coding mechanisms in the brain. This section will focus on specific evidence as it relates to the predictive coding phenomenon, rather than analogues, such as homeostasis (which are, nonetheless, integral to our overall understanding of Bayesian inference but already supported heavily; see Clark, 2012 for a review).",
            "score": 134.71316528320312
        },
        {
            "docid": "10008586_4",
            "document": "Sensory integration therapy . Ayres' sensory integration is a theory that describes (1) how the neurological process of processing and integrating sensory information from the body and the environment contribute to emotional regulation, learning, behavior, and participation in daily life, (2) empirically derived disorders of sensory integration and (3) an intervention approach. \"Sensory integration theory is used to explain why individuals behave in particular ways, plan intervention to ameliorate particular difficulties, and predict how behavior will change as a result of intervention.\" Sensory integration theory originated from the work of A. Jean Ayres, an occupational therapist and psychologist. Ayres wrote, \"Sensory Integration is the organization of sensations for use. Our senses give us information about the physical conditions of our body and the environment around us...The brain must organize all of our sensations if a person is to move and learn and behave in a productive manner\".",
            "score": 133.7137451171875
        },
        {
            "docid": "21647661_3",
            "document": "Self model . The PSM is an entity that \u201cactually exists, not only as a distinct theoretical entity but something that will be empirically discovered in the future- for instance, as a specific stage of the global neural dynamics in the human brain\u201d. Involved in the PSM are three phenomenal properties that must occur in order to explain the concept of the self. The first is mineness, \u201ca higher order property of particular forms of phenomenal content,\u201d or the idea of ownership. The second is perspectivalness, which is \u201ca global, structural property of phenomenal space as a whole\u201d. More simply, it is what is commonly referred to as the ecological self, the immovable center of perception. The third phenomenal property is selfhood, which is \u201cthe phenomenal target property\u201d or the idea of the self over time. It is the property of phenomenal selfhood that plays the most important role in creating the fictional self and the first person perspective. Metzinger defines the first person perspective as the \u201cexistence of single coherent and temporally stable model of reality which is representationally centered around or on a single coherent and temporally stable phenomenal subject\u201d. The first-person perspective can be non-conceptual and is autonomously active due to the constant reception of perceptual information by the brain. The brain, specifically the brainstem and hypothalamus, processes this information into representational content, namely linguistic reflections. The PSM then uses this representational content to attribute phenomenal states to our perceived objects and ourselves. We are thus what Metzinger calls na\u00efve realists, who believe we are perceiving reality directly when in actuality we are only perceiving representations of reality. The data structures and transport mechanisms of the data are \u201ctransparent\u201d so that we can introspect on our representations of perceptions, but cannot introspect on the data or mechanisms themselves. These systemic representational experiences are then connected by subjective experience to generate the phenomenal property of selfhood. Subjective experience is the result of the Phenomenal Model of Intentionality Relationship (PMIR). The PMIR is a \u201cconscious mental model, and its content is an ongoing, episodic subject-object relation\u201d. The model is a result of the combination of our unique set of sensory receptors that acquire input, our unique set of experiences that shape connections within the brain, and our unique positions in space that give our perception perspectivalness.",
            "score": 133.3521270751953
        },
        {
            "docid": "35988494_3",
            "document": "Selective auditory attention . The cocktail party problem was first brought up in 1953 by Colin Cherry. This common problem is how our minds solves the issue of knowing what in the auditory scene is important and combining those in a coherent whole, such as the problem of how we can perceive our friend talking in the midst of a crowded cocktail party. He suggested that the auditory system can filter sounds being heard. Physical characteristics of the auditory information such as speaker's voice or location can improve a person's ability to focus on certain stimuli even if there is other auditory stimuli present. Cherry also did work with shadowing which involves different information being played into both ears and only one ear's information can be processed and remembered (Eysneck, 2012, p.\u00a084). Another psychologist, Albert Bregman, came up with the auditory scene analysis model. The model has three main characteristics: segmentation, integration, and segregation. Segmentation involves the division of auditory messages into segments of importance. The process of combining parts of an auditory message to form a whole is associated with integration. Segregation is the separation of important auditory messages and the unwanted information in the brain. It is important to note that Bregman also makes a link back to the idea of perception. He states that it is essential for one to make a useful representation of the world from sensory inputs around us. Without perception, an individual will not recognize or have the knowledge of what is going on around them. While Begman's seminal work is critical to understanding selective auditory attention, his studies did not focus on the way in which an auditory message is selected, if and when it was correctly segregated from other sounds in a mixture, which is a critical stage of selective auditory attention. Inspired in part by Bregman's work, a number of researchers then set out to link directly work on auditory scene analysis to the processes governing attention, including Maria Chait, Mounya Elhilali, Shihab Shamma, and Barbara Shinn-Cunningham.",
            "score": 132.3126983642578
        },
        {
            "docid": "5366050_62",
            "document": "Speech perception . The fuzzy logical theory of speech perception developed by Dominic Massaro proposes that people remember speech sounds in a probabilistic, or graded, way. It suggests that people remember descriptions of the perceptual units of language, called prototypes. Within each prototype various features may combine. However, features are not just binary (true or false), there is a fuzzy value corresponding to how likely it is that a sound belongs to a particular speech category. Thus, when perceiving a speech signal our decision about what we actually hear is based on the relative goodness of the match between the stimulus information and values of particular prototypes. The final decision is based on multiple features or sources of information, even visual information (this explains the McGurk effect). Computer models of the fuzzy logical theory have been used to demonstrate that the theory's predictions of how speech sounds are categorized correspond to the behavior of human listeners.",
            "score": 132.07632446289062
        },
        {
            "docid": "53953041_2",
            "document": "Predictive coding . Predictive coding models suggest that the brain is constantly generating and updating hypotheses that predict sensory input at varying levels of abstraction. This framework is in contrast to the view that the brain integrates exteroceptive information through a predominantly feedforward process, with feedback connections playing a more minor role in cortical processing.",
            "score": 129.6427764892578
        },
        {
            "docid": "6733469_3",
            "document": "Max Planck Institute for Biological Cybernetics . The institute is studying signal and information processing in the brain. We know that our brain is constantly processing a vast amount of sensory and intrinsic information by which our behavior is coordinated accordingly. How the brain actually achieves these tasks is less well understood, for example, how it perceives, recognizes, and learns new objects. The scientists at the Max Planck Institute for Biological Cybernetics aim to determine which signals and processes are responsible for creating a coherent percept of our environment and for eliciting the appropriate behavior. Scientists of three departments and seven research groups are working towards answering fundamental questions about processing in the brain, using different approaches and methods.",
            "score": 128.86663818359375
        },
        {
            "docid": "15456565_7",
            "document": "Anna Jean Ayres . \u201cSensory integration theory is used to explain why individuals behave in particular ways, plan intervention to ameliorate particular difficulties, and predict how behavior will change as a result of intervention\u201d (p.\u00a05). Dr Ayres defined sensory integration as \"the organization of sensations for use. Our senses give us information about the physical conditions of our body and the environment around us... The brain must organize all of our sensations if a person is to move and learn and behave in a productive manner\" (p.\u00a05).",
            "score": 128.7748260498047
        },
        {
            "docid": "2534964_12",
            "document": "Sensory processing . It may seem redundant that we are being provided with multiple sensory inputs about the same object, but that is not necessarily the case. This so-called \"redundant\" information is in fact verification that what we are experiencing is in fact happening. Perceptions of the world are based on models that we build of the world. Sensory information informs these models, but this information can also confuse the models. Sensory illusions occur when these models do not match up. For example, where our visual system may fool us in one case, our auditory system can bring us back to a ground reality. This prevents sensory misrepresentations, because through the combination of multiple sensory modalities, the model that we create is much more robust and gives a better assessment of the situation. Thinking about it logically, it is far easier to fool one sense than it is to simultaneously fool two or more senses.",
            "score": 127.71607971191406
        },
        {
            "docid": "739262_10",
            "document": "Neural correlate . Neurophysiological studies in animals provided some insights on the neural correlates of conscious behavior. Vernon Mountcastle, in the early 1960s, set up to study this set of problems, which he termed \"the Mind/Brain problem\", by studying the neural basis of perception in the somatic sensory system. His labs at Johns Hopkins were among the first, along with Edward V.Evarts at NIH, to record neural activity from behaving monkeys. Struck with the elegance of SS Stevens approach of magnitude estimation, Mountcastle's group discovered three different modalities of somatic sensation shared one cognitive attribute: in all cases the firing rate of peripheral neurons was linearly related to the strength of the percept elicited. More recently, Ken H. Britten, William T. Newsome, and C. Daniel Salzman have shown that in area MT of monkeys, neurons respond with variability that suggests they are the basis of decision making about direction of motion. They first showed that neuronal rates are predictive of decisions using signal detection theory, and then that stimulation of these neurons could predictably bias the decision. Such studies were followed by Ranulfo Romo in the somatic sensory system, to confirm, using a different percept and brain area, that a small number of neurons in one brain area underlie perceptual decisions.",
            "score": 127.71070098876953
        },
        {
            "docid": "228051_6",
            "document": "Intrapersonal communication . Jones and Fernyhough cite other evidence for this hypothesis that inner speech is essentially like any other action. They mention that schizophrenics suffering auditory verbal hallucinations (AVH) need only open their mouths in order to disrupt the voices in their heads. To try and explain more about how inner speech works, but also what goes wrong with AVH patients, Jones and Fernyhough adapt what is known as the \"forward model\" of motor control, which uses the idea of \"efferent copies\". In a forward model of motor control, the mind generates movement unconsciously. While information is sent to the necessary body parts, the mind basically faxes a copy of that same information to other areas of the brain. This \"efferent\" copy could then be used to make predictions about upcoming movements. If the actual sensations match predictions, we experience the feeling of agency. If there is a mismatch between the body and its predicted position, perhaps due to obstructions or other cognitive disruption, no feeling of agency occurs. Jones and Fernyhough believe that the forward model might explain AVH and inner speech. Perhaps, if inner speech is a normal action, then the malfunction in schizophrenic patients is not the fact that actions (i.e. voices) are occurring at all. Instead, it may be that they are experiencing normal, inner speech, but the \"generation of the predictive efferent copy\" is malfunctioning. Without an efferent copy, motor commands are judged as alien (i.e. one does not feel like they caused the action). This could also explain why an open mouth stops the experience of alien voices: When the patient opens their mouth, the inner speech motor movements are not planned in the first place.",
            "score": 126.71678161621094
        },
        {
            "docid": "122329_31",
            "document": "Out-of-body experience . British psychologist Susan Blackmore and others suggest that an OBE begins when a person loses contact with sensory input from the body while remaining conscious. The person retains the illusion of having a body, but that perception is no longer derived from the senses. The perceived world may resemble the world he or she generally inhabits while awake, but this perception does not come from the senses either. The vivid body and world is made by our brain's ability to create fully convincing realms, even in the absence of sensory information. This process is witnessed by each of us every night in our dreams, though OBEs are claimed to be far more vivid than even a lucid dream.",
            "score": 126.3648910522461
        },
        {
            "docid": "37691878_18",
            "document": "Phonemic restoration effect . Because languages are distinctly structured, the brain has some sense of what word is to come next in a proper sentence. When listeners were listening to sentences with proper structure with missing phonemes, they performed much better than with a nonsensical sentence without a proper structure. This comes from the predictive nature of the pre-frontal cortex in determining what word should be coming next in order for the sentence to make sense. Top-down processing relies on the surrounding information in a sentence to fill in the missing information. If the sentence does not make sense to the observer then there will be little at the top of the process for the observer to go off of. If a puzzle piece of a familiar picture was missing, it would be very simple for the brain to know what that puzzle piece would look like. If the picture of something that makes no sense to the human brain and has never been seen before, the brain will have much more difficulty understanding what is missing.",
            "score": 124.22834014892578
        },
        {
            "docid": "2843988_32",
            "document": "Motor control . Direct perception in the cognitive sense is related to the philosophical notion of na\u00efve or direct realism in that it is predicated on the assumption that what we perceive is what is actually in the world. James J. Gibson is credited with recasting direct perception as ecological perception. While the problem of indirect perception proposes that physical information about object in our environment is not available due to the ambiguity of sensory information, proponents of direct perception (like Gibson) suggest that the relevant information encoded in sensory signals is not the physical properties of objects, but rather the action opportunities the environment affords. These affordances are directly perceivable without ambiguity, and thus preclude the need for internal models or representations of the world. Affordances exist only as a byproduct of the interactions between an agent and its environment, and thus perception is an \"ecological\" endeavor, depending on the whole agent/environment system rather than on the agent in isolation.",
            "score": 124.14032745361328
        },
        {
            "docid": "7652097_8",
            "document": "Perceptual paradox . One branch of research into perception attempts to explain what we perceive by applying formulae to sensory inputs and expecting outputs similar to that which we perceive. For example: what we measure with our eyes should be predicted by applying formulae to what we measure with instruments that imitate our eye.",
            "score": 123.91861724853516
        },
        {
            "docid": "3555532_5",
            "document": "Kappa effect . According to the constant velocity hypothesis proposed by Jones and Huang (1982), the brain incorporates a prior expectation of speed when judging spatiotemporal intervals. Specifically, the brain expects temporal intervals that would produce constant velocity (i.e., uniform motion) movement. Thus, the kappa effect occurs when we apply our knowledge of motion to stimulus sequences, which sometimes leads us to make mistakes. Evidence for the role of a uniform motion expectation in temporal perception comes from a study in which participants observed eight white dots that successively appeared in one direction in a horizontal alignment along a straight line. When the temporal separation was constant and the spatial separation between the dots varied, they observed the kappa effect, which follows the constant velocity hypothesis. However, when both the temporal and spatial separation between the dots varied, they failed to observe the response pattern that the constant velocity hypothesis predicts. A possible explanation is that it is difficult to perceive a uniform motion from such varying, complicated patterns; thus, the context of observed events may affect our temporal perception.",
            "score": 123.697265625
        },
        {
            "docid": "1903855_7",
            "document": "Sensory substitution . In a regular visual system, the data collected by the retina is converted into an electrical stimulus in the optic nerve and relayed to the brain, which re-creates the image and perceives it. Because it is the brain that is responsible for the final perception, sensory substitution is possible. During sensory substitution an intact sensory modality relays information to the visual perception areas of the brain so that the person can perceive to see. With sensory substitution, information gained from one sensory modality can reach brain structures physiologically related to other sensory modalities. Touch-to-visual sensory substitution transfers information from touch receptors to the visual cortex for interpretation and perception. For example, through fMRI, we can determine which parts of the brain are activated during sensory perception. In blind persons, we can see that while they are only receiving tactile information, their visual cortex is also activated as they perceive to \"see\" objects. We can also have touch to touch sensory substitution where information from touch receptors of one region can be used to perceive touch in another region. For example, in one experiment by Bach-y-Rita, he was able to restore the touch perception in a patient who lost peripheral sensation from leprosy.",
            "score": 123.51354217529297
        }
    ]
}