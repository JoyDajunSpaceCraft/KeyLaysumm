{
    "q": [
        {
            "docid": "1659013_2",
            "document": "Miguel Nicolelis . Miguel \u00c2ngelo Laporta Nicolelis, M.D., Ph.D. (, born March 7, 1961), is a Brazilian scientist and physician, best known for his pioneering work in \"reading monkey thought\".  He and his colleagues at Duke University implanted electrode arrays into a monkey's brain that were able to detect the monkey's motor intent and thus able to control reaching and grasping movements performed by a robotic arm. This was possible by decoding signals of hundreds of neurons recorded in volitional areas of the cerebral cortex while the monkey played with a hand-held joystick to move a shape in a video game. These signals were sent to the robot arm, which then mimicked the monkey's movements and thus controlled the game. After a while the monkey realised that thinking about moving the shape was enough and it no longer needed to move the joystick. So it let go of the joystick and controlled the game purely through thought. A system in which brain signals directly control an artificial actuator is commonly referred to as brain-machine interface or brain-computer interface.",
            "score": 144.65679025650024
        },
        {
            "docid": "26603942_3",
            "document": "Silent speech interface . Silent speech interface systems have been created using ultrasound and optical camera input of tongue and lip movements. Electromagnetic devices are another technique for tracking tongue and lip movements. The detection of speech movements by electromyography of speech articulator muscles and the larynx is another technique. Another source of information is the vocal tract resonance signals that get transmitted through bone conduction called non-audible murmurs.  They have also been created as a brain\u2013computer interface using brain activity in the motor cortex obtained from intracortical microelectrodes.",
            "score": 169.12638902664185
        },
        {
            "docid": "3717_59",
            "document": "Brain . Neurophysiologists study the chemical, pharmacological, and electrical properties of the brain: their primary tools are drugs and recording devices. Thousands of experimentally developed drugs affect the nervous system, some in highly specific ways. Recordings of brain activity can be made using electrodes, either glued to the scalp as in EEG studies, or implanted inside the brains of animals for extracellular recordings, which can detect action potentials generated by individual neurons. Because the brain does not contain pain receptors, it is possible using these techniques to record brain activity from animals that are awake and behaving without causing distress. The same techniques have occasionally been used to study brain activity in human patients suffering from intractable epilepsy, in cases where there was a medical necessity to implant electrodes to localize the brain area responsible for epileptic seizures. Functional imaging techniques such as functional magnetic resonance imaging are also used to study brain activity; these techniques have mainly been used with human subjects, because they require a conscious subject to remain motionless for long periods of time, but they have the great advantage of being noninvasive. Another approach to brain function is to examine the consequences of damage to specific brain areas. Even though it is protected by the skull and meninges, surrounded by cerebrospinal fluid, and isolated from the bloodstream by the blood\u2013brain barrier, the delicate nature of the brain makes it vulnerable to numerous diseases and several types of damage. In humans, the effects of strokes and other types of brain damage have been a key source of information about brain function. Because there is no ability to experimentally control the nature of the damage, however, this information is often difficult to interpret. In animal studies, most commonly involving rats, it is possible to use electrodes or locally injected chemicals to produce precise patterns of damage and then examine the consequences for behavior.",
            "score": 181.44387447834015
        },
        {
            "docid": "623686_42",
            "document": "Brain\u2013computer interface . Tetraplegic Matt Nagle became the first person to control an artificial hand using a BCI in 2005 as part of the first nine-month human trial of Cyberkinetics\u2019s BrainGate chip-implant. Implanted in Nagle\u2019s right precentral gyrus (area of the motor cortex for arm movement), the 96-electrode BrainGate implant allowed Nagle to control a robotic arm by thinking about moving his hand as well as a computer cursor, lights and TV. One year later, professor Jonathan Wolpaw received the prize of the Altran Foundation for Innovation to develop a Brain Computer Interface with electrodes located on the surface of the skull, instead of directly in the brain.",
            "score": 153.74263834953308
        },
        {
            "docid": "1168317_17",
            "document": "Mirror neuron . A study published in April 2010 reports recordings from single neurons with mirror properties in the human brain. Mukamel \"et al.\" (Current Biology, 2010) recorded from the brains of 21 patients who were being treated at Ronald Reagan UCLA Medical Center for intractable epilepsy. The patients had been implanted with intracranial depth electrodes to identify seizure foci for potential surgical treatment. Electrode location was based solely on clinical criteria; the researchers, with the patients' consent, used the same electrodes to \"piggyback\" their research. The researchers found a small number of neurons that fired or showed their greatest activity both when the individual performed a task and when they observed a task. Other neurons had anti-mirror properties, that is, they responded when the participant performed an action but were inhibited when the participant saw that action.",
            "score": 155.08449244499207
        },
        {
            "docid": "4833512_9",
            "document": "Mu wave . Brain-computer interfaces (BCIs) are a developing technology that clinicians hope will one day bring more independence and agency to the severely physically disabled. Those the technology has the potential to help include people with near-total or total paralysis, such as those with tetraplegia (quadriplegia) or advanced amyotrophic lateral sclerosis (ALS); BCIs are intended to help them to communicate or even move objects such as motorized wheelchairs, neuroprostheses, or robotic grasping tools. Few of these technologies are currently in regular use by people with disabilities, but a diverse array are in development at an experimental level. One type of BCI uses event-related desynchronization (ERD) of the mu wave in order to control the computer. This method of monitoring brain activity takes advantage of the fact that when a group of neurons is at rest they tend to fire in synchrony with each other. When a participant is cued to imagine movement (an \"event\"), the resulting desynchronization (the group of neurons that was firing in synchronous waves now firing in complex and individualized patterns) can be reliably detected and analyzed by a computer. Users of such an interface are trained in visualizing movements, typically of the foot, hand, and/or tongue, which are each in different locations on the cortical homunculus and thus distinguishable by an electroencephalograph (EEG) or electrocorticograph (ECoG) recording of electrical activity over the motor cortex. In this method, computers monitor for a typical pattern of mu wave ERD contralateral to the visualized movement combined with event-related synchronization (ERS) in the surrounding tissue. This paired pattern intensifies with training, and the training increasingly takes the form of games, some of which utilize virtual reality. Some researchers have found that the feedback from virtual reality games is particularly effective in giving the user tools to improve control of his or her mu wave patterns. The ERD method can be combined with one or more other methods of monitoring the brain's electrical activity to create hybrid BCIs, which often offer more flexibility than a BCI that uses any single monitoring method.",
            "score": 145.8930881023407
        },
        {
            "docid": "35182952_20",
            "document": "Embodied language processing . Neurophysiological evidence has also been presented to prove an ACE. This research used a behavioural paradigm as well as Event-Related Potential (ERP) to record brain activity, allowing the researchers to explore the neural brain markers of the ACE paradigm in semantic processing and motor responses. ERP was particularly beneficial in helping the researchers to investigate the bi-directional hypothesis of action-sentence comprehension, which proposes that language processing facilitates movement and movement also facilitates language comprehension. In the study participants listened to sentences describing an action that involved an open hand, a closed hand or no manual action. They were then required to press a button to indicate their understanding of the sentence. Each participant was assigned a hand-shape, either closed or open, which was required to activate the button. As well as two groups (closed or open hand-shapes), there were three different categories relating to hand-shape: compatible, incompatible and neutral. Behavioural results from the study showed that participants responded quicker when the hand-shape required to press the response-button was compatible with the hand-shape inferred by the sentence. ERP results provided evidence to support the bi-directional hypothesis, showing that cortical markers of motor processes were affected by sentence meaning, therefore providing evidence for a semantics-to-motor effect. ERP results also demonstrated a motor-to-semantics effect as brain markers of comprehension were modified by motor effects.",
            "score": 139.19946718215942
        },
        {
            "docid": "623686_18",
            "document": "Brain\u2013computer interface . Studies that developed algorithms to reconstruct movements from motor cortex neurons, which control movement, date back to the 1970s. In the 1980s, Apostolos Georgopoulos at Johns Hopkins University found a mathematical relationship between the electrical responses of single motor cortex neurons in rhesus macaque monkeys and the direction in which they moved their arms (based on a cosine function). He also found that dispersed groups of neurons, in different areas of the monkey's brains, collectively controlled motor commands, but was able to record the firings of neurons in only one area at a time, because of the technical limitations imposed by his equipment.",
            "score": 132.45529460906982
        },
        {
            "docid": "156940_17",
            "document": "Electrophysiology . An electrode introduced into the brain of a living animal will detect electrical activity that is generated by the neurons adjacent to the electrode tip. If the electrode is a microelectrode, with a tip size of about 1 micrometre, the electrode will usually detect the activity of at most one neuron. Recording in this way is in general called \"single-unit\" recording. The action potentials recorded are very much like the action potentials that are recorded intracellularly, but the signals are very much smaller (typically about 1 mV). Most recordings of the activity of single neurons in anesthetized and conscious animals are made in this way. Recordings of single neurons in living animals have provided important insights into how the brain processes information. For example, David Hubel and Torsten Wiesel recorded the activity of single neurons in the primary visual cortex of the anesthetized cat, and showed how single neurons in this area respond to very specific features of a visual stimulus. Hubel and Wiesel were awarded the Nobel Prize in Physiology or Medicine in 1981.",
            "score": 108.46769726276398
        },
        {
            "docid": "32018467_7",
            "document": "Christian Keysers . After finishing his master, Christian Keysers decided to concentrate on a subfield of cognitive neuroscience called social neuroscience that uses neuroscience methods to understand how we process the social world. He therefore performed his doctoral studies at the University of St Andrews with David Ian Perrett, one of the founding father of the field, to understand how the brain processes faces and facial expressions. This thesis work led to new insights into how quickly the brain can process the faces of others. During this period, Keysers became fascinated with the question of how the brain can attach meaning to the faces of others. How is it for instance, that we understand that a certain grimace would signal that another person is happy? How do we understand that a certain bodily movement towards a glass indicates that the other person aims to grasp a glass? In 1999, Keysers was exposed to a visit of Vittorio Gallese, who presented his recent discovery of mirror neurons in the Psychology department lecture series. This deeply influenced Keysers who decided to move to the lab of Giacomo Rizzolatti to undertake further studies on how these fascinating neurons could contribute to social perception. In 2000, after finishing his doctorate, Christian Keysers moved to the University of Parma to study mirror neurons. In early work there demonstrated that mirror neurons in the premotor cortex not only respond to the sight of actions, but also when actions can only be deduced or heard, leading to a publication in the journal \"Science\". This work had tremendous impact on the field, as it suggested that the premotor cortex could play a central, modality independent role in perception and may lay the origin for the evolution of speech in humans.  Together this work indicated that brain regions involved in our own actions play a role in how we process the actions of others. Keysers wondered whether a similar principle may underlie how we process the tactile sensations and emotions of others, and became increasingly independent of the research focus on the motor system in Parma. At the time, Keysers had also met his to be wife, Valeria Gazzola, a biologist in the final phases of her studies, and together they decided to explore if the somatosensory system might be involved in perceiving the sensations of others. Via a fruitful collaboration with the French neuroimaging specialist Bruno Wicker, they used functional magnetic resonance imaging, and showed for the first time, that the secondary somatosensory cortex, previously thought only to represent a persons own experiences of touch, is also activated when seeing someone or something else be touched. They also showed that the insula, thought only to respond to the experience of first-hand emotions, was also activated when we see another individual experience similar emotions. Together this indicated a much more general principle than the original mirror neuron theory, in which people process the actions, sensations and emotions of others by vicariously activating owns own actions, sensations and emotions. Jointly, this work laid the foundation of the neuroscientific investigation of empathy.",
            "score": 141.98071551322937
        },
        {
            "docid": "2938828_16",
            "document": "J. A. Scott Kelso . Subsequently, Kelso and his colleagues moved from the hand to the brain, using large arrays of SQUID magnetometers to record the neuromagnetic activity of the brain and Functional Magnetic Resonance Imaging to record BOLD (Blood Oxygen Level Dependent) activation in brain regions. This work showed that mathematical forms observable in the coordinated movement of the hands (such as phase transitions), were also observable in images of brain activity. Or as Kelso puts it, \"the same coordination dynamics governs brain activity and human behavior.\" For example, on the basis of recordings and analysis of human brain activity Viktor Jirsa and Armin Fuchs along with Kelso were able to derive the HKB equations of coordination at the behavioral level from a more realistic anatomical and physiological model of the underlying neural substrate",
            "score": 149.29439389705658
        },
        {
            "docid": "156940_18",
            "document": "Electrophysiology . If the electrode tip is slightly larger, then the electrode might record the activity generated by several neurons. This type of recording is often called \"multi-unit recording\", and is often used in conscious animals to record changes in the activity in a discrete brain area during normal activity. Recordings from one or more such electrodes that are closely spaced can be used to identify the number of cells around it as well as which of the spikes come from which cell. This process is called spike sorting and is suitable in areas where there are identified types of cells with well defined spike characteristics. If the electrode tip is bigger still, in general the activity of individual neurons cannot be distinguished but the electrode will still be able to record a field potential generated by the activity of many cells.",
            "score": 122.86807179450989
        },
        {
            "docid": "623686_97",
            "document": "Brain\u2013computer interface . Each year, about 400,000 people undergo brain mapping during neurosurgery. This procedure is often required for people with tumors or epilepsy that do not respond to medication. During this procedure, electrodes are placed on the brain to precisely identify the locations of structures and functional areas. Patients may be awake during neurosurgery and asked to perform certain tasks, such as moving fingers or repeating words. This is necessary so that surgeons can remove only the desired tissue while sparing other regions, such as critical movement or language regions. Removing too much brain tissue can cause permanent damage, while removing too little tissue can leave the underlying condition untreated and require additional neurosurgery. Thus, there is a strong need to improve both methods and systems to map the brain as effectively as possible.",
            "score": 131.30361104011536
        },
        {
            "docid": "2088_20",
            "document": "Aphasia . There have been many instances showing that there is a form of aphasia among deaf individuals. Sign languages are, after all, forms of language that have been shown to use the same areas of the brain as verbal forms of language. Mirror neurons become activated when an animal is acting in a particular way or watching another individual act in the same manner. These mirror neurons are important in giving an individual the ability to mimic movements of hands. Broca's area of speech production has been shown to contain several of these mirror neurons resulting in significant similarities of brain activity between sign language and vocal speech communication. Facial communication is a significant portion of how animals interact with each other. Humans use facial movements to create, what other humans perceive, to be faces of emotions. While combining these facial movements with speech, a more full form of language is created which enables the species to interact with a much more complex and detailed form of communication. Sign language also uses these facial movements and emotions along with the primary hand movement way of communicating. These facial movement forms of communication come from the same areas of the brain. When dealing with damages to certain areas of the brain, vocal forms of communication are in jeopardy of severe forms of aphasia. Since these same areas of the brain are being used for sign language, these same, at least very similar, forms of aphasia can show in the Deaf community. Individuals can show a form of Wernicke's aphasia with sign language and they show deficits in their abilities in being able to produce any form of expressions. Broca's aphasia shows up in some people, as well. These individuals find tremendous difficulty in being able to actually sign the linguistic concepts they are trying to express.",
            "score": 176.75743532180786
        },
        {
            "docid": "37568453_5",
            "document": "Restorative neurology . Restorative neurology is a new way and a combination of neural components that are able to determine how long a natural functional recovery can take place and to what extent clinical interventions can help such recovery. Although detecting any anatomy of the injured nervous system can be considered really difficult, this approach has made it possible to be able to track changes or improvements occurring in the neural injury. Restorative neurology\u2019s main goal is to take advantage of the new anatomy and physiology approach for enhanced neurological recovery. A study has been done on a 37-year-old male who had unilateral spastic cerebral palsy (USCP). USCP, being the common subtype results with movement impairments on one side of the body. There are a few therapies for this type of rehabilitation. The study participant was diagnosed with USCP at 18 months due to a car accident. Along with robotic therapy, they also used tDCS. They applied them over the motor map of the affected hand. For each therapy session, the participant received 20 min of anodal tDCS. The excitatory sponge was placed over the location of motor map of the damaged hand. The anodal sponge was then place on the contralateral forehead. Both of these sponges were moistened with saline and held in place with a headband. By the end of the study it was confirmed that combined tDCS and robotic upper limb therapy safely improves upper limb function. - This study was adopted from their work with stroke rehab, that being said it is not known if the duration and dose of therapy is actually ideal for people with USCP. For this study in particular, it is stated that the participant confirmed that he reached the max accuracy with the robots by the midpoint of the study. However, it is not known if the effects of therapy would have been persistent had the training been shorter. That being said more work and research has yet to be done to identify \u201cstop signals\u201d, which indicate that participant has reached their improvement goal.  There is another study in which  Another study in which eight adults with chronic incomplete cervical spinal cord injury (iCSCI) participated. Being diagnosed with iCSCI meant minimal finger motor function. tDCS current was transferred by two saline soaked surface sponge electrodes. In order to stimulate the primary motor cortex, the anode electrode was place over C3 and C4. The cathode electrode was then placed over the contralateral supraorbital area. Results proved that the combination therapy protocol of 20 minutes of 2mA anodal tDCS over M1 with 60 minutes of high intensity training along with robotic exoskeleton is known to be safe in treatment of impaired arm and hand functions due to chronic incomplete spinal cord injury. This study\u2019s report proved a promise in improving arm and hand function due to the therapy.",
            "score": 109.13847875595093
        },
        {
            "docid": "3779468_2",
            "document": "Electrocorticography . Electrocorticography (ECoG), or intracranial electroencephalography (iEEG), is a type of electrophysiological monitoring that uses electrodes placed directly on the exposed surface of the brain to record electrical activity from the cerebral cortex. In contrast, conventional electroencephalography (EEG) electrodes monitor this activity from outside the skull. ECoG may be performed either in the operating room during surgery (intraoperative ECoG) or outside of surgery (extraoperative ECoG). Because a craniotomy (a surgical incision into the skull) is required to implant the electrode grid, ECoG is an invasive procedure.",
            "score": 90.36968803405762
        },
        {
            "docid": "21402632_2",
            "document": "Electroencephalography . Electroencephalography (EEG) is an electrophysiological monitoring method to record electrical activity of the brain. It is typically noninvasive, with the electrodes placed along the scalp, although invasive electrodes are sometimes used such as in electrocorticography. EEG measures voltage fluctuations resulting from ionic current within the neurons of the brain. In clinical contexts, EEG refers to the recording of the brain's spontaneous electrical activity over a period of time, as recorded from multiple electrodes placed on the scalp. Diagnostic applications generally focus either on event-related potentials or on the spectral content of EEG. The former investigates potential fluctuations time locked to an event like stimulus onset or button press. The latter analyses the type of neural oscillations (popularly called \"brain waves\") that can be observed in EEG signals in the frequency domain.",
            "score": 110.71111869812012
        },
        {
            "docid": "620396_42",
            "document": "Origin of language . In humans, functional MRI studies have reported finding areas homologous to the monkey mirror neuron system in the inferior frontal cortex, close to Broca's area, one of the language regions of the brain. This has led to suggestions that human language evolved from a gesture performance/understanding system implemented in mirror neurons. Mirror neurons have been said to have the potential to provide a mechanism for action-understanding, imitation-learning, and the simulation of other people's behavior. This hypothesis is supported by some cytoarchitectonic homologies between monkey premotor area F5 and human Broca's area. Rates of vocabulary expansion link to the ability of children to vocally mirror non-words and so to acquire the new word pronunciations. Such speech repetition occurs automatically, quickly and separately in the brain to speech perception. Moreover, such vocal imitation can occur without comprehension such as in speech shadowing and echolalia. Further evidence for this link comes from a recent study in which the brain activity of two participants was measured using fMRI while they were gesturing words to each other using hand gestures with a game of charades\u2014a modality that some have suggested might represent the evolutionary precursor of human language. Analysis of the data using Granger Causality revealed that the mirror-neuron system of the observer indeed reflects the pattern of activity of in the motor system of the sender, supporting the idea that the motor concept associated with the words is indeed transmitted from one brain to another using the mirror system.",
            "score": 164.84081375598907
        },
        {
            "docid": "29806228_17",
            "document": "Neurotrophic electrode . Electrocorticography (ECoG) records the cumulative activity of hundreds to thousands of neurons with a sheet of electrodes placed directly on the surface of the brain. In addition to requiring surgery and having low resolution, the ECoG device is wired, meaning the scalp cannot be completely closed, increasing the risk of infection. However, researchers investigating ECoG claim that the grid \"possesses characteristics suitable for long term implantation\".",
            "score": 79.91550970077515
        },
        {
            "docid": "3779468_6",
            "document": "Electrocorticography . The ECoG recording is performed from electrodes placed on the exposed cortex. In order to access the cortex, a surgeon must first perform a craniotomy, removing a part of the skull to expose the brain surface. This procedure may be performed either under general anesthesia or under local anesthesia if patient interaction is required for functional cortical mapping. Electrodes are then surgically implanted on the surface of the cortex, with placement guided by the results of preoperative EEG and magnetic resonance imaging (MRI). Electrodes may either be placed outside the dura mater (epidural) or under the dura mater (subdural). ECoG electrode arrays typically consist of sixteen sterile, disposable stainless steel, carbon tip, platinum, Platinum-iridium alloy or gold ball electrodes, each mounted on a ball and socket joint for ease in positioning. These electrodes are attached to an overlying frame in a \u201ccrown\u201d or \u201chalo\u201d configuration. Subdural strip and grid electrodes are also widely used in various dimensions, having anywhere from 4 to 256 electrode contacts. The grids are transparent, flexible, and numbered at each electrode contact. Standard spacing between grid electrodes is 1\u00a0cm; individual electrodes are typically 5\u00a0mm in diameter. The electrodes sit lightly on the cortical surface, and are designed with enough flexibility to ensure that normal movements of the brain do not cause injury. A key advantage of strip and grid electrode arrays is that they may be slid underneath the dura mater into cortical regions not exposed by the craniotomy. Strip electrodes and crown arrays may be used in any combination desired. Depth electrodes may also be used to record activity from deeper structures such as the hippocampus.",
            "score": 107.24504613876343
        },
        {
            "docid": "40901980_2",
            "document": "Developmental verbal dyspraxia . Developmental verbal dyspraxia (DVD), also known as childhood apraxia of speech (CAS) and developmental apraxia of speech (DAS), is when children have problems saying sounds, syllables, and words. This is not because of muscle weakness or paralysis. The brain has problems planning to move the body parts (e.g., lips, jaw, tongue) needed for speech. The child knows what they want to say, but their brain has difficulty coordinating the muscle movements necessary to say those words. The exact cause of this disorder is unknown. Some observations suggest a genetic cause of DVD, as many with the disorder have a family history of communication disorders. There is no cure for DVD, but with appropriate, intensive intervention, people with this motor speech disorder can improve significantly.",
            "score": 150.49754238128662
        },
        {
            "docid": "27179535_7",
            "document": "Leah Krubitzer . The parietal cortex is another area of interest for Krubitzer. The parietal cortex allows us to coordinate movements between our eyes and our hands. This ability allows for smooth reaching movements, as well as, grasping. Past research has been done on Old and New World monkeys, as well as humans, to see how the parietal cortex functions in hand use. Imaging used on humans shows that there are similar cortical patterns shared across human and non-human primates, but the extent to which these pathways are used depends on the somatosensory organization and connectivity in the parietal cortex. Krubitzer and her team took this information and investigated a little deeper. Because humans have an opposable thumb, our ability to grip objects and reach for objects is much greater than monkeys. For this reason, the connectivity in the human parietal cortex is much more complex than that of a non-human primate. In Krubitzer's lab, her team investigated different areas of the parietal cortex in order to better pin point which part controls which motor movement. Krubitzer found that when one area of the cortex responsible for a certain motor movement is compromised, the rest of the cortex will reorganize itself to make up for the loss. This finding shows how the parietal cortex can rewire itself in order to maintain functional motor capabilities. Currently in the lab, Krubitzer and colleagues are testing a microchip that may be placed in the posterior parietal cortex of the brain to deactivate certain areas at a time. Using this technique, they are able to see how deactivation of a certain portion of the cortex impacts hand grasping and reaching in monkeys. This technique is performed while the monkeys are performing different manual tasks in order to see the action of the cortex live.",
            "score": 99.98166418075562
        },
        {
            "docid": "20395179_7",
            "document": "Vittorio Gallese . Observing the world is more complex than the mere activation of the visual brain. Vision is multimodal: it encompasses the activation of motor, somatosensory and emotion-related brain networks. Any intentional relation entertained with the external world has an intrinsic pragmatic nature, hence it always bears a motor content. The same motor circuits that control our motor behavior also map the space around us, the objects at hand in that very same space, thus defining and shaping in motor terms their representational content. The space around us is defined by the motor potentialities of our body. Motor neurons also respond to visual, tactile and auditory stimuli. Indeed, premotor neurons controlling the movements of the upper arm also respond to tactile stimuli applied to it, to visual stimuli moved within the arm's peripersonal space, or to auditory stimuli also coming from the same peri-personal space. The same applies to artifacts, like three-dimensional objects. The manipulable objects we look at are classified by the motor brain as potential targets of the interactions we might entertain with them. Premotor and parietal 'canonical neurons' control the grasping and manipulation of objects and also respond to their mere observation. The functional architecture of embodied simulation seems to constitute a basic characteristic of our brain, making possible our rich and diversified experiences of space, objects and other individuals, being at the basis of our capacity to empathize with them.\"",
            "score": 134.2878487110138
        },
        {
            "docid": "6989597_3",
            "document": "Premovement neuronal activity . Research of pre-movement neuronal activity generally involves studying two different kinds of movement, movement in natural settings versus movement triggered by a sensory stimulus. These two types of movements are referred to with different nomenclature throughout different studies and literature on the topic of premovement neuronal activity. Voluntary movements are also known as self-timed, self-initiated, self-paced, and non-triggered movements. This type of movement is what generally occurs in natural settings, carried out independently of a sensory cue or external signal which would trigger or cause the movement to be performed  . In contrast, movements that are carried out as a result of a sensory cue or stimulus, or reflex-reactions to external conditions or changes are called reactive movements, but also known as cued movements, stimulated movements, and externally triggered movements depending on the choice of a particular study. In one such study by Lee and Assad (2003), rhesus monkeys were trained to execute arm movement in response to a visual cue versus the same arm movement performed without any correlation to this external (visual) cue. This is one example of reactive movements in contrast to self-initiated movements . Subsequent studies of rates of neuronal firing in the respective types of movements are recorded in different areas of the brain in order to develop a more thorough understanding of premovement neuronal activity.",
            "score": 127.7072981595993
        },
        {
            "docid": "2567511_18",
            "document": "Neural engineering . Neural interfaces are a major element used for studying neural systems and enhancing or replacing neuronal function with engineered devices. Engineers are challenged with developing electrodes that can selectively record from associated electronic circuits to collect information about the nervous system activity and to stimulate specified regions of neural tissue to restore function or sensation of that tissue (Cullen et al. 2011). The materials used for these devices must match the mechanical properties of neural tissue in which they are placed and the damage must be assessed. Neural interfacing involves temporary regeneration of biomaterial scaffolds or chronic electrodes and must manage the body's response to foreign materials. Microelectrode arrays are recent advances that can be used to study neural networks (Cullen & Pfister 2011). Optical neural interfaces involve optical recordings and optogenetics stimulation that makes brain cells light sensitive. Fiber optics can be implanted in the brain to stimulate and record this photon activity instead of electrodes. Two-photon excitation microscopy can study living neuronal networks and the communicatory events among neurons.",
            "score": 146.81804990768433
        },
        {
            "docid": "490620_34",
            "document": "Human brain . Gross movement \u2013 such as locomotion and the movement of arms and legs \u2013 is generated in the motor cortex, divided into three parts: the primary motor cortex, found in the prefrontal gyrus and has sections dedicated to the movement of different body parts. These movements are supported and regulated by two other areas, lying anterior to the primary motor cortex: the premotor area and the supplementary motor area. The hands and mouth have a much larger area dedicated to them than other body parts, allowing finer movement; this has been visualised in a motor cortical homunculus. Impulses generated from the motor cortex travel along the corticospinal tract along the front of the medulla and cross over (decussate) at the medullary pyramids. These then travel down the spinal cord, with most connecting to interneurons, in turn connecting to lower motor neurons within the grey matter that then transmit the impulse to move to muscles themselves. The cerebellum and basal ganglia, play a role in fine, complex and coordinated muscle movements. Connections between the cortex and the basal ganglia control muscle tone, posture and movement initiation, and are referred to as the extrapyramidal system.",
            "score": 107.65907037258148
        },
        {
            "docid": "49706731_4",
            "document": "Chronic electrode implant . Chronic brain-computer interfaces come in two varieties, stimulating and recording. Applications for stimulating interfaces include sensory prosthetics (cochlear implants, for example, are the most successful variety of sensory prosthetics) and deep brain stimulation therapies, while recording interfaces can be used for research applications and to record the activity of speech or motor centers directly from the brain. In principle these systems are susceptible to the same tissue response that causes failure in implanted electrodes, but stimulating interfaces can overcome this problem by increasing signal strength. Recording electrodes, however, must rely on whatever signals are present where they are implanted, and cannot easily be made more sensitive.",
            "score": 150.41076469421387
        },
        {
            "docid": "2183007_6",
            "document": "Startle response . There are many various reflexes that can occur simultaneously during a startle response. The fastest reflex recorded in humans happens within the masseter muscle or jaw muscle. The reflex was measured by electromyography which records the electrical activity during movement of the muscles. This also showed the latency response or the delay between the stimulus and the response recorded was found to be about 14 milliseconds. The blink of the eye which is the reflex of the orbicularis oculi muscle was found to have a latency of about 20 to 40 milliseconds. Out of larger body parts, the head is quickest in a movement latency in a range from 60 to 120 milliseconds. The neck then moves almost simultaneously with a latency of 75 to 121 milliseconds. Next, the shoulder jerks at 100 to 121 milliseconds along with the arms at 125 to 195 milliseconds. Lastly the legs responds with a latency of 145 to 395 milliseconds. This type of cascading response correlates to how the synapses travel from the brain and down the spinal cord to activate each motor neuron.",
            "score": 113.24056327342987
        },
        {
            "docid": "2878895_6",
            "document": "Edward Evarts . The work of Evarts gave rise to a new field in neuroscience. His followers use single electrodes and electrode arrays temporarily inserted or implanted in the brain to record brain signals during different types of behavioral and cognitive activity and thereby gain knowledge about how the brain works. The knowledge accumulated in this research recently resulted in creation of brain-computer interfaces\u2014electronic devices that sample neuronal activity in the brain, decode its meaning and use decoded information to operate external devices, such as robots.",
            "score": 127.51644802093506
        },
        {
            "docid": "4833512_4",
            "document": "Mu wave . The mirror neuron system consists of a class of neurons that was first studied in the 1990s in macaque monkeys. Studies have found sets of neurons that fire when these monkeys perform simple tasks and also when the monkeys view others performing the same simple tasks. This suggests they play a role in mapping others' movements into the brain without actually physically performing the movements. These sets of neurons are called mirror neurons and together make up the mirror neuron system. Mu waves are suppressed when these neurons fire, a phenomenon which allows researchers to study mirror neuron activity in humans. There is evidence that mirror neurons exist in humans as well as in non-human animals. The right fusiform gyrus, left inferior parietal lobule, right anterior parietal cortex, and left inferior frontal gyrus are of particular interest. Some researchers believe that mu wave suppression can be a consequence of mirror neuron activity throughout the brain, and represents a higher-level integrative processing of mirror neuron activity. Tests in both monkeys (using invasive measuring techniques) and humans (using EEG and fMRI) have found that these mirror neurons not only fire during basic motor tasks, but also have components that deal with intention. There is evidence of an important role for mirror neurons in humans, and mu waves may represent a high level coordination of those mirror neurons.",
            "score": 121.69155585765839
        },
        {
            "docid": "623686_61",
            "document": "Brain\u2013computer interface . Non-invasive BCIs have also been applied to enable brain-control of prosthetic upper and lower extremity devices in people with paralysis. For example, Gert Pfurtscheller of Graz University of Technology and colleagues demonstrated a BCI-controlled functional electrical stimulation system to restore upper extremity movements in a person with tetraplegia due to spinal cord injury. Between 2012 and 2013, researchers at the University of California, Irvine demonstrated for the first time that it is possible to use BCI technology to restore brain-controlled walking after spinal cord injury. In their spinal cord injury research study, a person with paraplegia was able to operate a BCI-robotic gait orthosis to regain basic brain-controlled ambulation.  In 2009 Alex Blainey, an independent researcher based in the UK, successfully used the Emotiv EPOC to control a 5 axis robot arm. He then went on to make several demonstration mind controlled wheelchairs and home automation that could be operated by people with limited or no motor control such as those with paraplegia and cerebral palsy.",
            "score": 146.13257610797882
        },
        {
            "docid": "3717_45",
            "document": "Brain . Motor systems are areas of the brain that are involved in initiating body movements, that is, in activating muscles. Except for the muscles that control the eye, which are driven by nuclei in the midbrain, all the voluntary muscles in the body are directly innervated by motor neurons in the spinal cord and hindbrain. Spinal motor neurons are controlled both by neural circuits intrinsic to the spinal cord, and by inputs that descend from the brain. The intrinsic spinal circuits implement many reflex responses, and contain pattern generators for rhythmic movements such as walking or swimming. The descending connections from the brain allow for more sophisticated control.",
            "score": 120.02097237110138
        }
    ],
    "r": [
        {
            "docid": "3717_59",
            "document": "Brain . Neurophysiologists study the chemical, pharmacological, and electrical properties of the brain: their primary tools are drugs and recording devices. Thousands of experimentally developed drugs affect the nervous system, some in highly specific ways. Recordings of brain activity can be made using electrodes, either glued to the scalp as in EEG studies, or implanted inside the brains of animals for extracellular recordings, which can detect action potentials generated by individual neurons. Because the brain does not contain pain receptors, it is possible using these techniques to record brain activity from animals that are awake and behaving without causing distress. The same techniques have occasionally been used to study brain activity in human patients suffering from intractable epilepsy, in cases where there was a medical necessity to implant electrodes to localize the brain area responsible for epileptic seizures. Functional imaging techniques such as functional magnetic resonance imaging are also used to study brain activity; these techniques have mainly been used with human subjects, because they require a conscious subject to remain motionless for long periods of time, but they have the great advantage of being noninvasive. Another approach to brain function is to examine the consequences of damage to specific brain areas. Even though it is protected by the skull and meninges, surrounded by cerebrospinal fluid, and isolated from the bloodstream by the blood\u2013brain barrier, the delicate nature of the brain makes it vulnerable to numerous diseases and several types of damage. In humans, the effects of strokes and other types of brain damage have been a key source of information about brain function. Because there is no ability to experimentally control the nature of the damage, however, this information is often difficult to interpret. In animal studies, most commonly involving rats, it is possible to use electrodes or locally injected chemicals to produce precise patterns of damage and then examine the consequences for behavior.",
            "score": 181.44387817382812
        },
        {
            "docid": "36058569_6",
            "document": "Frank H. Guenther . In addition to computational modeling and experimental research investigating the neural bases of speech, Guenther directs the Boston University Neural Prosthesis Laboratory, which focuses on the development of technologies that can decode the brain signals of profoundly paralyzed individuals, particularly those suffering from locked-in syndrome, in order to control external devices such as speech synthesizers, mobile robots, and computers. Guenther\u2019s team received widespread press coverage in 2009, when they developed a brain-computer interface for real-time speech synthesis that allowed locked-in patient Erik Ramsey to produce vowel sounds in collaboration with Dr. Philip Kennedy (inventor of the neurotrophic electrode used in the study) and Dr. Jonathan Brumberg. He has also made headlines for his research into non-invasive brain-computer interfaces for communication. In 2011, Guenther founded the \"Unlock Project\", a non-profit project aimed at providing free brain-computer interface technology to patients suffering from locked-in syndrome.",
            "score": 177.0098876953125
        },
        {
            "docid": "2088_20",
            "document": "Aphasia . There have been many instances showing that there is a form of aphasia among deaf individuals. Sign languages are, after all, forms of language that have been shown to use the same areas of the brain as verbal forms of language. Mirror neurons become activated when an animal is acting in a particular way or watching another individual act in the same manner. These mirror neurons are important in giving an individual the ability to mimic movements of hands. Broca's area of speech production has been shown to contain several of these mirror neurons resulting in significant similarities of brain activity between sign language and vocal speech communication. Facial communication is a significant portion of how animals interact with each other. Humans use facial movements to create, what other humans perceive, to be faces of emotions. While combining these facial movements with speech, a more full form of language is created which enables the species to interact with a much more complex and detailed form of communication. Sign language also uses these facial movements and emotions along with the primary hand movement way of communicating. These facial movement forms of communication come from the same areas of the brain. When dealing with damages to certain areas of the brain, vocal forms of communication are in jeopardy of severe forms of aphasia. Since these same areas of the brain are being used for sign language, these same, at least very similar, forms of aphasia can show in the Deaf community. Individuals can show a form of Wernicke's aphasia with sign language and they show deficits in their abilities in being able to produce any form of expressions. Broca's aphasia shows up in some people, as well. These individuals find tremendous difficulty in being able to actually sign the linguistic concepts they are trying to express.",
            "score": 176.75743103027344
        },
        {
            "docid": "26603942_3",
            "document": "Silent speech interface . Silent speech interface systems have been created using ultrasound and optical camera input of tongue and lip movements. Electromagnetic devices are another technique for tracking tongue and lip movements. The detection of speech movements by electromyography of speech articulator muscles and the larynx is another technique. Another source of information is the vocal tract resonance signals that get transmitted through bone conduction called non-audible murmurs.  They have also been created as a brain\u2013computer interface using brain activity in the motor cortex obtained from intracortical microelectrodes.",
            "score": 169.1263885498047
        },
        {
            "docid": "36058569_5",
            "document": "Frank H. Guenther . Frank Guenther\u2019s research is aimed at uncovering the neural computations underlying the processing of speech by the human brain. He is the originator of the Directions Into Velocities of Articulators (DIVA) model, which is currently the leading model of the neural computations underlying speech production. This model mathematically characterizes the computations performed by each brain region involved in speech production as well as the function of the interconnections between these regions. The model has been supported by a wide range of experimental tests of model predictions, including electromagnetic articulometry studies investigating speech movements, auditory perturbation studies involving modification of a speaker\u2019s feedback of his/her own speech in real time, and functional magnetic resonance imaging studies of brain activity during speech, though some parts of the model remain to be experimentally verified. The DIVA model has been used to investigate the neural underpinnings of a number of communication disorders, including stuttering apraxia of speech, and hearing-impaired speech.",
            "score": 167.552734375
        },
        {
            "docid": "179092_24",
            "document": "Neurolinguistics . Transcranial magnetic stimulation (TMS), a new noninvasive technique for studying brain activity, uses powerful magnetic fields that are applied to the brain from outside the head. It is a method of exciting or interrupting brain activity in a specific and controlled location, and thus is able to imitate aphasic symptoms while giving the researcher more control over exactly which parts of the brain will be examined. As such, it is a less invasive alternative to direct cortical stimulation, which can be used for similar types of research but requires that the subject's scalp be removed, and is thus only used on individuals who are already undergoing a major brain operation (such as individuals undergoing surgery for epilepsy). The logic behind TMS and direct cortical stimulation is similar to the logic behind aphasiology: if a particular language function is impaired when a specific region of the brain is knocked out, then that region must be somehow implicated in that language function. Few neurolinguistic studies to date have used TMS; direct cortical stimulation and cortical recording (recording brain activity using electrodes placed directly on the brain) have been used with macaque monkeys to make predictions about the behavior of human brains.",
            "score": 165.36520385742188
        },
        {
            "docid": "620396_42",
            "document": "Origin of language . In humans, functional MRI studies have reported finding areas homologous to the monkey mirror neuron system in the inferior frontal cortex, close to Broca's area, one of the language regions of the brain. This has led to suggestions that human language evolved from a gesture performance/understanding system implemented in mirror neurons. Mirror neurons have been said to have the potential to provide a mechanism for action-understanding, imitation-learning, and the simulation of other people's behavior. This hypothesis is supported by some cytoarchitectonic homologies between monkey premotor area F5 and human Broca's area. Rates of vocabulary expansion link to the ability of children to vocally mirror non-words and so to acquire the new word pronunciations. Such speech repetition occurs automatically, quickly and separately in the brain to speech perception. Moreover, such vocal imitation can occur without comprehension such as in speech shadowing and echolalia. Further evidence for this link comes from a recent study in which the brain activity of two participants was measured using fMRI while they were gesturing words to each other using hand gestures with a game of charades\u2014a modality that some have suggested might represent the evolutionary precursor of human language. Analysis of the data using Granger Causality revealed that the mirror-neuron system of the observer indeed reflects the pattern of activity of in the motor system of the sender, supporting the idea that the motor concept associated with the words is indeed transmitted from one brain to another using the mirror system.",
            "score": 164.8408203125
        },
        {
            "docid": "971305_19",
            "document": "Haemodynamic response . If fMRI can be used to detect the regular flow of blood in a healthy brain, it can also be used to detect the problems with a brain that has undergone degenerative diseases. Functional MRI, using haemodynamic response, can help assess the effects of stroke and other degenerative diseases such as Alzheimer\u2019s disease on brain function. Another way fMRI could be used is in the planning of surgery of the brain. Surgeons can use fMRI to detect blood flow of the most active areas of the brain and the areas involved in critical functions like thought, speech, movement, etc. In this way, brain procedures are less dangerous because there is a brain mapping that shows which areas are vital to a person\u2019s life. Haemodynamic response is vital to fMRI and clinical use because through the study of blood flow we are able to examine the anatomy of the brain and effectively plan out procedures of the brain and link together the causes of degenerative brain disease.",
            "score": 164.71812438964844
        },
        {
            "docid": "10042066_2",
            "document": "Developmental linguistics . Developmental linguistics is the study of the development of linguistic ability in an individual, particularly the acquisition of language in childhood. It involves research into the different stages in language acquisition, language retention, and language loss in both first and second languages, in addition to the area of bilingualism. Before infants can speak, the neural circuits in their brains are constantly being influenced by exposure to language. The neurobiology of language contains a \"critical period\" in which children are most sensitive to language. The different aspects of language have varying \"critical periods\". Studies show that the critical period for phonetics is toward the end of the first year. At 18 months, a toddler's vocabulary vastly expands. The critical period for syntactic learning is 18-36 months. Infants of different mother languages can be differentiated at the age of 10 months. At 20 weeks they begin vocal imitation. Beginning when babies are about 12 months, they take on computational learning and social learning. Social interactions for infants and toddlers is important because it helps associate \"perception and action\". In-person social interaction rather than audio or video better facilitates learning in babies because they learn from how other people respond to them, especially their mothers. Babies have to learn to mimic certain syllables, which takes practice in manipulating tongue and lip movement. Sensory-motor learning in speech is linked to exposure to speech, which is very sensitive to language. Infants exposed to Spanish exhibit a different vocalization than infants exposed to English. One study took infants that were learning English and made them listen to Spanish in 12 sessions. The result showed consequent alterations in their vocalization, which demonstrated Spanish prosody.  One study used MEG to record activation in the brains of newborns, 6 months olds and 12 months olds while presenting them with syllables, harmonics and non-speech sounds. For the 6 month and 12 month old, the auditory and motor areas responded to speech. The newborn showed auditory activation but not motor activation. Another study presented 3 month olds with sentences and recorded their brain activity via fMRI motor speech areas did activate. These studies suggest that the link between perception and action begins to develop at 3 months. When babies are young, they are actually the most sensitive to distinguishing all phonetic units. During an infant\u2019s 1st year of life, they have to differentiate between about 40 phonetic units. When they are older they have usually been exposed to their native language so much that they lose this ability and can only distinguish phonetic units in their native language. Even at 12 months babies exhibit a deficit in differentiated non-native sounds. However, their ability to distinguish sounds in their native language continues to improve and become more fine-tuned. For example, Japanese learning infants learn that there is no differentiation between /r/ and /l/. However, in English, \"rake\" and \"lake\" are two different words. Japanese babies eventually lose their ability to distinguish between /r/ and /l/. Similarly, a Spanish learning infant cannot form words until they learn the difference between works like \"bano\" and \"pano\", because the /p/ sound is different than the /b/ sound. English learning babies do not learn to differentiate between the two.",
            "score": 164.64669799804688
        },
        {
            "docid": "18614_35",
            "document": "Language acquisition . Prosody is the property of speech that conveys an emotional state of the utterance, as well as intended form of speech (whether it be a question, statement or command). Some researchers in the field of developmental neuroscience would argue that fetal auditory learning mechanisms are solely due to discrimination in prosodic elements. Although this would hold merit in an evolutionary psychology perspective (i.e. recognition of mother's voice/familiar group language from emotionally valent stimuli), some theorists argue that there is more than prosodic recognition in elements of fetal learning. Newer evidence shows that fetuses not only react to the native language differently from nonnative, but furthermore that fetuses react differently and can accurately discriminate between native and nonnative vowels (Moon, Lagercrantz, & Kuhl, 2013). Furthermore, a new study in 2016 showed that newborn infants encode the edges of multisyllabic sequences better than the internal components of the sequence (Ferry et al., 2016). Together, these results suggest that newborn infants have learned important properties of syntactic processing in utero, that can be seen in infant knowledge of native language vowels and the sequencing of heard multisyllabic phrases. This ability to sequence specific vowels gives newborn infants some of the fundamental mechanisms needed in order to learn the complex organization of a language.  From a neuroscientific perspective, there are neural correlates have been found that demonstrate human fetal learning of speech-like auditory stimulus that most other studies have been analyzing (Partanen et al., 2013). In a study conducted by Partanen et al. (2013), researchers presented fetuses with certain word variants and saw that these fetuses exhibited higher brain activity to the certain word variants compared to controls. In this same study, there was \"a significant correlation existed between the amount of prenatal exposure and brain activity, with greater activity being associated with a higher amount of prenatal speech exposure,\" pointing to the important learning mechanisms present before birth that is fine-tuned to features in speech (Partanen et al., 2013).",
            "score": 163.51878356933594
        },
        {
            "docid": "1035470_44",
            "document": "Stroke recovery . Unlike many effects of stroke, where the clinician is able to judge the particular area of the brain that a stroke has injured by certain signs or symptoms, the causation of apraxia is less clear. A common theory is that the part of the brain that contains information for previously learned skilled motor activities has been either lost or cannot be accessed. The condition is usually due to an insult to the dominant hemisphere of the brain. More often this is located in the frontal lobe of the left hemisphere of the brain. Treatment of acquired apraxia due to stroke usually consists of physical, occupational, and speech therapy. The Copenhagen Stroke Study, which is a large important study published in 2001, showed that out of 618 stroke patients, manual apraxia was found in 7% and oral apraxia was found in 6%. Both manual and oral apraxia were related to increasing severity of stroke. Oral apraxia was related with an increase in age at the time of the stroke. There was no difference in incidence among gender. It was also found that the finding of apraxia has no negative influence on ability to function after rehabilitation is completed. The National Institute of Neurological Disorders and Stroke (NINDS) is currently sponsoring a clinical trial to gain an understanding of how the brain operates while carrying out and controlling voluntary motor movements in normal subjects. The objective is to determine what goes wrong with these processes in the course of acquired apraxia due to stroke or brain injury.",
            "score": 162.87771606445312
        },
        {
            "docid": "3581220_6",
            "document": "Single-unit recording . Single-unit recordings have provided tools to explore the brain and apply this knowledge to current technologies. Cognitive scientists have used single-unit recordings in the brains of animals and humans to study behaviors and functions. Electrodes can also be inserted into the brain of epileptic patients to determine the position of epileptic foci. More recently, single-unit recordings have been used in brain machine interfaces (BMI). BMIs record brain signals and decode an intended response, which then controls the movement of an external device (such as a computer cursor or prosthetic limb).",
            "score": 162.7945556640625
        },
        {
            "docid": "40621603_5",
            "document": "Linguistic intelligence . Speech production is process by which a thought in the brain is converted into an understandable auditory form. This is a multistage mechanism that involves many different areas of the brain. The first stage is planning, where the brain constructs words and sentences that turn the thought into an understandable form. This occurs primarily in the inferior frontal cortex, specifically in an area known as Broca's area. Next, the brain must plan how to physically create the sounds necessary for speech by linking the planned speech with known sounds, or phonemes. While the location of these associations is not known, it is known that the supplementary motor area plays a key role in this step. Finally, the brain must signal for the words to actually be spoken. This is carried out by the premotor cortex and the motor cortex. In most cases, speech production is controlled by the left hemisphere. In a series of studies, Wilder Penfield, among others, probed the brains of both right-handed (generally left-hemisphere dominant) and left-handed (generally right-hemisphere dominant) patients. They discovered that, regardless of handedness, the left hemisphere was almost always the speech controlling side. However, it has been discovered that in cases of neural stress (hemorrhage, stroke, etc.) the right hemisphere has the ability to take control of speech functions.",
            "score": 161.99008178710938
        },
        {
            "docid": "1124947_3",
            "document": "BrainGate . In its current form, BrainGate consists of a sensor implanted in the brain and an external decoder device, which connects to some kind of prosthetic or other external object. The sensor is in the form of a Multielectrode array, formerly known as the Utah Array, which consists of 100 hair-thin electrodes that sense the electromagnetic signature of neurons firing in specific areas of the brain, for example, the area that controls arm movement. The sensor translates that activity into electrically charged signals, which are then sent to an external device and decoded in software. The decoder connects to and can use the brain signals to control an external device, such as a robotic arm, a computer cursor, or even a wheelchair. In essence, BrainGate allows a person to manipulate objects in the world using only the mind. In addition to real-time analysis of neuron patterns to relay movement, the BrainGate array is also capable of recording electrical data for later analysis. A potential use of this feature would be for a neurologist to study seizure patterns in a patient with epilepsy. BrainGate was originally developed by researchers in the Department of Neuroscience at Brown University in conjunction with bio-tech company Cyberkinetics, Inc. Cyberkinetics later spun off the device manufacturing to Blackrock Microsystems, who now manufactures the sensors and the data acquisition hardware. The BrainGate Company purchased the intellectual property and related technology from Cyberkinetics and continues to own the intellectual property related to BrainGate.",
            "score": 161.66046142578125
        },
        {
            "docid": "179092_3",
            "document": "Neurolinguistics . Neurolinguistics is historically rooted in the development in the 19th century of aphasiology, the study of linguistic deficits (aphasias) occurring as the result of brain damage. Aphasiology attempts to correlate structure to function by analyzing the effect of brain injuries on language processing. One of the first people to draw a connection between a particular brain area and language processing was Paul Broca, a French surgeon who conducted autopsies on numerous individuals who had speaking deficiencies, and found that most of them had brain damage (or \"lesions\") on the left frontal lobe, in an area now known as Broca's area. Phrenologists had made the claim in the early 19th century that different brain regions carried out different functions and that language was mostly controlled by the frontal regions of the brain, but Broca's research was possibly the first to offer empirical evidence for such a relationship, and has been described as \"epoch-making\" and \"pivotal\" to the fields of neurolinguistics and cognitive science. Later, Carl Wernicke, after whom Wernicke's area is named, proposed that different areas of the brain were specialized for different linguistic tasks, with Broca's area handling the motor production of speech, and Wernicke's area handling auditory speech comprehension. The work of Broca and Wernicke established the field of aphasiology and the idea that language can be studied through examining physical characteristics of the brain. Early work in aphasiology also benefited from the early twentieth-century work of Korbinian Brodmann, who \"mapped\" the surface of the brain, dividing it up into numbered areas based on each area's cytoarchitecture (cell structure) and function; these areas, known as Brodmann areas, are still widely used in neuroscience today.",
            "score": 161.2428436279297
        },
        {
            "docid": "4958509_7",
            "document": "Attentional shift . Some of the first research into the neurology behind attention shifts came from examining brain damaged patients. First, Posner \"et al.\", studied persons affected by progressive supranuclear palsy, a condition wherein it is difficult to exert eye movements voluntarily, particularly vertical movements. Patients were found to have damage present in the mid-brain area and associated cortical areas. Although patients were not able to move their eyes, they were still able to shift attention covertly. However, there was a slowing of the process of shifting attention in these patients, suggesting that the mid-brain and cortical areas must be associated with covert attention shifts. Additionally, previous research has shown support for covert attention shifts being associated with activity in the parietal lobe. On the other hand, research seems to indicate differences in brain areas activated for overt attention shifts, as compared to covert shifts. Previous evidence has shown that the superior colliculus is associated with eye movements, or overt attention shifts. Additionally, the medial cerebellum has shown activation only during eye movements.",
            "score": 161.05746459960938
        },
        {
            "docid": "403676_28",
            "document": "Gesture . Gestures are processed in the same areas of the brain as speech and sign language such as the left inferior frontal gyrus (Broca's area) and the posterior middle temporal gyrus, posterior superior temporal sulcus and superior temporal gyrus (Wernicke's area). It has been suggested that these parts of the brain originally supported the pairing of gesture and meaning and then were adapted in human evolution \"for the comparable pairing of sound and meaning as voluntary control over the vocal apparatus was established and spoken language evolved\". As a result, it underlies both symbolic gesture and spoken language in the present human brain. Their common neurological basis also supports the idea that symbolic gesture and spoken language are two parts of a single fundamental semiotic system that underlies human discourse. The linkage of hand and body gestures in conjunction with speech is further revealed by the nature of gesture use in blind individuals during conversation. This phenomenon uncovers a function of gesture that goes beyond portraying communicative content of language and extends David McNeill's view of the gesture-speech system. This suggests that gesture and speech work tightly together, and a disruption of one (speech or gesture) will cause a problem in the other. Studies have found strong evidence that speech and gesture are innately linked in the brain and work in an efficiently wired and choreographed system. McNeill's view of this linkage in the brain is just one of three currently up for debate; the others declaring gesture to be a \"support system\" of spoken language or a physical mechanism for lexical retrieval.",
            "score": 160.96348571777344
        },
        {
            "docid": "490258_12",
            "document": "Split-brain . Roger Sperry continued this line of research up until his death in 1994. Michael Gazzaniga still is researching the split-brain. Their findings have been rarely critiqued and disputed, however a popular belief that some people are more \"right-brained\" or \"left-brained\" has developed. In the mid 1980s Jarre Levy, a psychobiologist at the University of Chicago, had set out and been in the forefront of scientists who wanted to dispel the notion we have two functioning brains. She believes that because each hemisphere has separate functions that they must integrate their abilities instead of separating them. Levy also claims that no human activity uses only one side of the brain. In 1998 a French study by Hommet and Billiard was published that questioned Sperry and Gazzaniga's study that severing the corpus callosum actually divides the hemispheres of the brain. They found that children born without a corpus callosum demonstrated that information was being transmitted between hemispheres, they concluded that subcortical connections must be present in these children with this rare brain malformation. They are unclear about whether these connections are present in split-brain patients though. Another study by Parsons, Gabrieli, Phelps, and Gazzaniga in 1998 demonstrated that split-brain patients may commonly perceive the world differently from the rest of us. Their study suggested that communication between brain hemispheres is necessary for imaging or simulating in your mind the movements of others. Morin's research on inner speech in 2001 suggested that an alternative for interpretation of commissurotomy according to which split-brain patients exhibit two uneven streams of self-awareness: a \"complete\" one in the left hemisphere and a \"primitive\" one in the right hemisphere.",
            "score": 160.66990661621094
        },
        {
            "docid": "5366050_42",
            "document": "Speech perception . Research into the relationship between music and cognition is an emerging field related to the study of speech perception. Originally it was theorized that the neural signals for music were processed in a specialized \"module\" in the right hemisphere of the brain. Conversely, the neural signals for language were to be processed by a similar \"module\" in the left hemisphere. However, utilizing technologies such as fMRI machines, research has shown that two regions of the brain traditionally considered exclusively to process speech, Broca's and Wernicke's areas, also become active during musical activities such as listening to a sequence of musical chords. Other studies, such as one performed by Marques et al. in 2006 showed that 8-year-olds who were given six months of musical training showed an increase in both their pitch detection performance and their electrophysiological measures when made to listen to an unknown foreign language.",
            "score": 160.06539916992188
        },
        {
            "docid": "987320_19",
            "document": "Neurotechnology . Magnetic resonance imaging is a vital tool in neurological research in showing activation in the brain as well as providing a comprehensive image of the brain being studied. While MRIs are used clinically for showing brain size, it still has relevance in the study of brains because it can be used to determine extent of injuries or deformation. These can have a significant effect on personality, sense perception, memory, higher order thinking, movement, and spatial understanding. However, current research tends to focus more so on fMRI or real-time functional MRI (rtfMRI). These two methods allow the scientist or the participant, respectively, to view activation in the brain. This is incredibly vital in understanding how a person thinks and how their brain reacts to a person's environment, as well as understanding how the brain works under various stressors or dysfunctions. Real-time functional MRI is a revolutionary tool available to neurologists and neuroscientists because patients can see how their brain reacts to stressors and can perceive visual feedback. CT scans are very similar to MRI in their academic use because they can be used to image the brain upon injury, but they are more limited in perceptual feedback. CTs are generally used in clinical studies far more than in academic studies, and are found far more often in a hospital than a research facility. PET scans are also finding more relevance in academia because they can be used to observe metabolic uptake of neurons, giving researchers a wider perspective about neural activity in the brain for a given condition. Combinations of these methods can provide researchers with knowledge of both physiological and metabolic behaviors of loci in the brain and can be used to explain activation and deactivation of parts of the brain under specific conditions.",
            "score": 159.19215393066406
        },
        {
            "docid": "605564_8",
            "document": "Clinical neuropsychology . The relationship between human behavior and the brain is the focus of clinical neuropsychology as defined by Meir in 1974. There are two subdivisions of clinical neuropsychology which draw much focus; organic and environmental natures. Ralph M. Reitan, Arthur L. Benton, and A. R. Luria are all past neuropsychologists whom believed and studied the organic nature of clinical neuropsychology. On the other side, environmental nature of clinical neuropsychology did not appear until more recently and is characterized by treatments such as behavior therapy. The relationship between physical brain abnormalities and the presentation of psychopathology is not completely understood, but this is one of the questions which clinical neuropsychologists hope to answer in time. In 1861 the debate over human potentiality versus localization began. The two sides argued over how human behavior presented in the brain. Paul Broca postulated that cognitive problems could be caused by physical damage to specific parts of the brain based on a case study of his in which he found a lesion on the brain of a deceased patient who had presented the symptom of being unable to speak, that portion of the brain is now known as Broca's Area. In 1874 Carl Wernicke also made a similar observation in a case study involving a patient with a brain lesion whom was unable to comprehend speech, the part of the brain with the lesion is now deemed Wernicke's Area. Both Broca and Wernicke believed and studied the theory of localization. On the other hand, equal potentiality theorists believed that brain function was not based on a single piece of the brain but rather on the brain as a whole. Marie J. P Flourens conducted animal studies in which he found that the amount of brain tissue damaged directly affected the amount that behavior ability was altered or damaged. Kurt Goldstein observed the same idea as Flourens except in veterans who had fought in World War I. In the end, despite all of the disagreement, neither theory completely explains the human brains complexity. Thomas Hughlings Jackson created a theory which was thought to be a possible solution. Jackson believed that both potentiality and localization were in part correct and that behavior was made by multiple parts of the brain working collectively to cause behaviors, and Luria (1966-1973) furthered Jackson's theory.",
            "score": 158.83326721191406
        },
        {
            "docid": "292906_160",
            "document": "Biofeedback . Christopher deCharms (of Omneuron in San Francisco) in conjunction with Stanford University School of Medicine has developed a real-time fMRI for the purpose of training the brain to activate its own endogenous opiates. deCharms believes this will revolutionize the treatment of chronic pain. The patient can control his own pain by visually looking at his rtfMRI, watching his own reactions in real time, and then blocking the pathways causing pain. deCharms mentions that clinical trials with rtfMRI is measuring a 44 to 64 percent decrease in chronic pain. With 8 participants in the study, deCharms et al.(2005) demonstrated that subjects can control the pain of heat stimulus, by visually observing in real time their brain activity. The subjects were instructed to use techniques such as changing the focus of their attention to the pain, and changing the emotional value of the pain. Then while viewing their own fMRI in real time the subjects could observe the effect of their thoughts on the part of the brain called the rostral anterior cingulate cortex (rACC). When the subject 'controlled the pain' the virtual flame on the fMRI got dimmer. Results from this study indicate two things: 1. That subjects can learn to voluntarily control brain activity in a specific region of the brain, and 2. There is a significant increase in the ability of healthy subjects to control their pain with repeated training. This study was then repeated with 8 patients with chronic intractable pain. The results showed that these patients were successful in reducing their pain rating by 64% (using the McGill Pain Questionnaire). The authors state that this is not yet a 'treatment', but still under serious investigation.",
            "score": 158.3761749267578
        },
        {
            "docid": "1168317_17",
            "document": "Mirror neuron . A study published in April 2010 reports recordings from single neurons with mirror properties in the human brain. Mukamel \"et al.\" (Current Biology, 2010) recorded from the brains of 21 patients who were being treated at Ronald Reagan UCLA Medical Center for intractable epilepsy. The patients had been implanted with intracranial depth electrodes to identify seizure foci for potential surgical treatment. Electrode location was based solely on clinical criteria; the researchers, with the patients' consent, used the same electrodes to \"piggyback\" their research. The researchers found a small number of neurons that fired or showed their greatest activity both when the individual performed a task and when they observed a task. Other neurons had anti-mirror properties, that is, they responded when the participant performed an action but were inhibited when the participant saw that action.",
            "score": 155.08450317382812
        },
        {
            "docid": "1095131_20",
            "document": "Kinesthetic learning . The cerebral cortex is the brain tissue covering the top and sides of the brain in most vertebrates. It is involved in storing and processing of sensory inputs and motor outputs. In the human brain, the cerebral cortex is actually a sheet of neural tissue about 1/8th inch thick. The sheet is folded so that it can fit inside the skull. The neural circuits in this area of the brain expand with practice of an activity, just like the synaptic plasticity grows with practice. Clarification of some of the mechanisms of learning by neuro science has been advanced, in part, by the advent of non-invasive imaging technologies, such as positron emission tomography (PET) and functional magnetic resonance imaging (FMRI). These technologies have allowed researchers to observe human learning processes directly. Through these types of technologies, we are now able to see and study what happens in the process of learning. In different tests performed the brain being imaged showed a greater blood flow and activation to that area of the brain being stimulated through different activities such as finger tapping in a specific sequence. It has been revealed that the process at the beginning of learning a new skill happens quickly, and later on slows down to almost a plateau. This process can also be referred to as The Law of Learning. The slower learning showed in the FMRI that in the cerebral cortex this was when the long term learning was occurring, suggesting that the structural changes in the cortex reflect the enhancement of skill memories during later stages of training. When a person studies a skill for a longer duration of time, but in a shorter amount of time they will learn quickly, but also only retain the information into their short-term memory. Just like studying for an exam; if a student tries to learn everything the night before, it will not stick in the long run. If a person studies a skill for a shorter duration of time, but more frequently and long-term, their brain will retain this information much longer as it is stored in the long-term memory. Functional and structural studies of the brain have revealed a vast interconnectivity between diverse regions of the cerebral cortex. For example, large numbers of axons interconnect the posterior sensory areas serving vision, audition, and touch with anterior motor regions. Constant communication between sensation and movement makes sense, because to execute smooth movement through the environment, movement must be continuously integrated with knowledge about one's surroundings obtained via sensory perception. The cerebral cortex plays a role in allowing humans to do this.",
            "score": 154.91990661621094
        },
        {
            "docid": "102958_11",
            "document": "Roger Wolcott Sperry . Working with his graduate student Michael Gazzaniga, Sperry invited several of the \"split-brain\" patients to volunteer to take part in his study to determine if the surgery affected their functioning. These tests were designed to test the patients' language, vision, and motor skills. When a person views something in the left visual field (that is on the left side of their body), the information travels to the right hemisphere of the brain and vice versa. In the first series of tests, Sperry would present a word to either the left or right visual field for a short period of time. If the word was shown to the right visual field, meaning the left hemisphere would process it, then the patient could report seeing the word. If the word was shown to the left visual field, meaning the right hemisphere would process it, then the patient could not report seeing the word. This led Sperry to believe that only the left side of the brain could articulate speech. However, in a follow-up experiment, Sperry discovered that the right hemisphere does have some language abilities. In this experiment, he had the patients place their left hands in a tray full of objects located under a partition so the patient would not be able to see the objects. Then a word was shown to the patient's left visual field, which was processed by the right side of the brain. This word described one of the objects in the tray, so the patient's left hand picked up the object corresponding to the word. When participants were asked about the word and the object in their hand, they claimed they had not seen the word and had no idea why they were holding the object. The right side of the brain had recognized the word and told the left hand to pick it up, but because the right side of the brain cannot speak and the left side of the brain had not seen the word, the patient could not articulate what they had seen.",
            "score": 154.8308868408203
        },
        {
            "docid": "490620_75",
            "document": "Human brain . A stroke is a decrease in blood supply to an area of the brain causing cell death and brain injury. This can lead to a wide range of symptoms, including the \"FAST\" symptoms of facial droop, arm weakness, and speech difficulties (including with speaking and finding words or forming sentences). Symptoms relate to the function of the affected area of the brain and can point to the likely site and cause of the stroke. Difficulties with movement, speech, or sight usually relate to the cerebrum, whereas imbalance, double vision, vertigo and symptoms affecting more than one side of the body usually relate to the brainstem or cerebellum.",
            "score": 154.71572875976562
        },
        {
            "docid": "49596807_7",
            "document": "Ludwig Boltzmann Institute for Functional Brain Topography . The study group Walla showed, that deep (i.e. semantic) encoding of a word is associated with more brain activity than a shallow (letter by letter) encoding. Gender-specifically, in women both hemispheres were equally involved, while men were left-lateralized. Smell and memory are closely related, which was studied for words and faces. With Alzheimer patients, in whom dementia had just started (mild cognitive impairment (MCI)) the MEG proved to be predictive in showing whether a certain MCI patient would develop into an Alzheimer patient. This design was also employed for therapy follow-up studies. In the complex of themes \u201cSmell, emotion, memory, words, faces\u201c an influence of the odorous substance PEA (N-Palmitoyl-ethanolamine) upon the encoding and recognition of faces was found, if these were to be classified into \u2019appealing\u2019 and \u2019unappealing.\u2019 Stuttering was investigated as well: 8 stutterers and 8 controls were faced with certain tasks and examined in the MEG. While stuttering in task 1 (silent reading) was not yet noticeable, it was strongly present in task 2 (immediate loud uttering of a word shown): Only the normal controls showed clear neuronal activity prior to the start of speaking. This brain activity is the Readiness Field (RF) or Bereitschaftsfield (BF) and in particular its left-lateralized component BF2 prior to the fluent speech production. With the stutterers' non-fluent speech production, the Bereitschaftsfield was missing or was greatly reduced.",
            "score": 154.25369262695312
        },
        {
            "docid": "2860457_12",
            "document": "Neural ensemble . After the techniques of multielectrode recordings were introduced, the task of real-time decoding of information from large neuronal ensembles became feasible. If, as Georgopoulos showed, just a few primary motor neurons could accurately predict hand motion in two planes, reconstruction of the movement of an entire limb should be possible with enough simultaneous recordings. In parallel, with the introduction of an enormous Neuroscience boost from DARPA, several lab groups used millions of dollars to make brain-machine interfaces. Of these groups, two were successful in experiments showing that animals could control external interfaces with models based on their neural activity, and that once control was shifted from the hand to the brain-model, animals could learn to control it better. These two groups are led by John Donoghue and Miguel Nicolelis, and both are involved in towards human trials with their methods.",
            "score": 154.1214599609375
        },
        {
            "docid": "33932515_22",
            "document": "Social cue . Benjamin Straube, Antonia Green, Andreas Jansen, Anjan Chatterjee, and Tilo Kircher found that social cues influence the neural processing of speech-gesture utterances. Past studies have focused on mentalizing as being a part of perception of social cues and it is believed that this process relies on the neural system, which consists of: When people focus on things in a social context, the medial prefrontal cortex and precuneus areas of the brain are activated, however when people focus on a non-social context there is no activation of these areas. Straube et al. hypothesized that the areas of the brain involved in mental processes were mainly responsible for social cue processing. It is believed that when iconic gestures are involved, the left temporal and occipital regions would be activated and when emblematic gestures were involved the temporal poles would be activated. When it came to abstract speech and gestures, the left frontal gyrus would be activated according to Straube et al. After conducting an experiment on how body position, speech and gestures affected activation in different areas of the brain Straube et al. came to the following conclusions:",
            "score": 154.05625915527344
        },
        {
            "docid": "623686_42",
            "document": "Brain\u2013computer interface . Tetraplegic Matt Nagle became the first person to control an artificial hand using a BCI in 2005 as part of the first nine-month human trial of Cyberkinetics\u2019s BrainGate chip-implant. Implanted in Nagle\u2019s right precentral gyrus (area of the motor cortex for arm movement), the 96-electrode BrainGate implant allowed Nagle to control a robotic arm by thinking about moving his hand as well as a computer cursor, lights and TV. One year later, professor Jonathan Wolpaw received the prize of the Altran Foundation for Innovation to develop a Brain Computer Interface with electrodes located on the surface of the skull, instead of directly in the brain.",
            "score": 153.7426300048828
        },
        {
            "docid": "20011748_7",
            "document": "Apraxia of speech . Apraxia of speech can be diagnosed by a speech language pathologist (SLP) through specific exams that measure oral mechanisms of speech. The oral mechanisms exam involves tasks such as pursing lips, blowing, licking lips, elevating the tongue, and also involves an examination of the mouth. A complete exam also involves observation of the patient eating and talking. SLPs do not agree on a specific set of characteristics that make up the apraxia of speech diagnosis, so any of the characteristics from the section above could be used to form a diagnosis. Patients may be asked to perform other daily tasks such as reading, writing, and conversing with others. In situations involving brain damage, an MRI brain scan also helps identify damaged areas of the brain.",
            "score": 153.68960571289062
        },
        {
            "docid": "776322_18",
            "document": "Non-rapid eye movement sleep . A study was done involving an experimental and a control group to have them learn to navigate a 3D maze. The blood flow in the parahippocampal gyrus increased in conjunction with the individual's performance through the 3D maze. Participants were then trained in the maze for 4 hours and later, during the various sleep cycles of nonREM sleep, REM sleep and wakefulness, they were scanned twelve times using a PET scan during the night. The PET scan demonstrated a higher blood flow in the hippocampus during SWS/non-REM sleep due to the training from the previous day while the control group exhibited no increased blood flow and they had not received the training the prior day. The brain activity during sleep, according to this study, would show the events of the previous day do make a difference. One theory suggests a model of Hippocampal-neocortical dialogue. \"Two stages of hippocampal activity have been proposed, the first being the recording of the memory during waking and the second involving the playback of the memory during nonREM sleep. This process of reactivation of memory firing sequences is believed to gradually reinforce initially weak connections between neocortical sites allowing the original information to be activated in the cortex independently of the hippocampus, and thus ensuring refreshed encoding capacity of the hippocampus.\" Maquet concluded that the areas of the brain involved with information processing and memory have increased brain activity during the slow wave sleep period. Events experienced in the previous day have more efficient and clearer memory recall the next day thus indicating that the memory regions of the brain are activated during SWS/non-REM sleep instead of being dormant as previously thought.",
            "score": 153.12806701660156
        }
    ]
}