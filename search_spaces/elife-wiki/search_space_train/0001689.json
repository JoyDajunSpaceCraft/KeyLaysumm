{
    "q": [
        {
            "docid": "31209304_13",
            "document": "Righting reflex . These automatic postural adjustments can be explained in terms of two reflexes similar to the righting reflex: the vestibulo-ocular reflex (VOR) and the vestibulocollic reflex (VCR). The VOR involves movement of the eyes while the head turns to remain fixated on a stationary image, and the VCR involves control of neck muscles for correction of the head's orientation. During the VOR, the semicircular canals send information to the brain and correct eye movements in the direction opposite head movement by sending excitatory signals to motor neurons on the side opposite to the head rotation. Neurons in the otoliths control not only these signals for control of eye movements, but also signals for head movement correction through the neck muscles. The righting reflex utilizes the VOR and VCR as it brings the body back into position. Visual information under the control of these reflexes creates greater stability for more accurate postural correction.",
            "score": 171.91404628753662
        },
        {
            "docid": "487910_5",
            "document": "Vestibulo\u2013ocular reflex . The VOR has both rotational and translational aspects. When the head rotates about any axis (horizontal, vertical, or torsional) distant visual images are stabilized by rotating the eyes about the same axis, but in the opposite direction. When the head translates, for example during walking, the visual fixation point is maintained by rotating gaze direction in the opposite direction, by an amount that depends on distance.",
            "score": 141.5545003414154
        },
        {
            "docid": "17468688_3",
            "document": "Nystagmus . In a normal condition, while the head rotates about any axis, distant visual images are sustained by rotating eyes in the opposite direction on the respective axis. The semicircular canals in the vestibule sense angular acceleration. These send signals to the nuclei for eye movement in the brain. From here, a signal is relayed to the extraocular muscles to allow one\u2019s gaze to fixate on one object as the head moves. Nystagmus also occurs when the semicircular canals are being stimulated (e.g. by means of the caloric test, or by disease) while the head is not in motion. The direction of ocular movement is related to the semicircular canal that is being stimulated.",
            "score": 173.6881456375122
        },
        {
            "docid": "1894873_16",
            "document": "Eye movement . The visual system in the brain is too slow to process that information if the images are slipping across the retina at more than a few degrees per second. Thus, to be able to see while we are moving, the brain must compensate for the motion of the head by turning the eyes. Another specialisation of visual system in many vertebrate animals is the development of a small area of the retina with a very high visual acuity. This area is called the fovea, and covers about 2 degrees of visual angle in people. To get a clear view of the world, the brain must turn the eyes so that the image of the object of regard falls on the fovea. Eye movement is thus very important for visual perception, and any failure can lead to serious visual disabilities. To see a quick demonstration of this fact, try the following experiment: hold your hand up, about one foot (30\u00a0cm) in front of your nose. Keep your head still, and shake your hand from side to side, slowly at first, and then faster and faster. At first you will be able to see your fingers quite clearly. But as the frequency of shaking passes about 1 Hz, the fingers will become a blur. Now, keep your hand still, and shake your head (up and down or left and right). No matter how fast you shake your head, the image of your fingers remains clear. This demonstrates that the brain can move the eyes opposite to head motion much better than it can follow, or pursue, a hand movement. When your pursuit system fails to keep up with the moving hand, images slip on the retina and you see a blurred hand.",
            "score": 181.83163249492645
        },
        {
            "docid": "33193162_14",
            "document": "Vision in fishes . There is a need for some mechanism that stabilises images during rapid head movements. This is achieved by the vestibulo-ocular reflex, which is a reflex eye movement that stabilises images on the retina by producing eye movements in the direction opposite to head movements, thus preserving the image on the centre of the visual field. For example, when the head moves to the right, the eyes move to the left, and vice versa. In many animals, including human beings, the inner ear functions as the biological analogue of an accelerometer in camera image stabilization systems, to stabilize the image by moving the eyes. When a rotation of the head is detected, an inhibitory signal is sent to the extraocular muscles on one side and an excitatory signal to the muscles on the other side. The result is a compensatory movement of the eyes. Typical human eye movements lag head movements by less than 10 ms.",
            "score": 179.72661674022675
        },
        {
            "docid": "26977166_12",
            "document": "Mantis . Mantises have stereo vision. They locate their prey by sight; their compound eyes contain up to 10,000 ommatidia. A small area at the front called the fovea has greater visual acuity than the rest of the eye, and can produce the high resolution necessary to examine potential prey. The peripheral ommatidia are concerned with perceiving motion; when a moving object is noticed, the head is rapidly rotated to bring the object into the visual field of the fovea. Further motions of the prey are then tracked by movements of the mantis's head so as to keep the image centered on the fovea. The eyes are widely spaced and laterally situated, affording a wide binocular field of vision and precise stereoscopic vision at close range. The dark spot on each eye that moves as it rotates its head is a pseudopupil. This occurs because the ommatidia that are viewed \"head-on\" absorb the incident light, while those to the side reflect it.",
            "score": 159.04540634155273
        },
        {
            "docid": "13731830_18",
            "document": "Listing's law . Since Listing's law and its variants determine the orientation of the eye(s) for any particular gaze direction, it therefore determines the spatial pattern of visual stimulation on the retina(s). For example, since Listing's law defines torsion as zero about a head-fixed axis, this results in 'false torsional' tilts about the line of sight when the eye is at tertiary (oblique) positions, which the brain must compensate for when interpreting the visual image. Torsion is not good for binocular vision because it complicates the already difficult problem of matching images from the two eyes for stereopsis (depth vision). The binocular version of Listing's law is thought to be a best compromise to simplify this problem, although it does not completely rid the visual system of the need to know current eye orientation.",
            "score": 127.26831185817719
        },
        {
            "docid": "889831_8",
            "document": "Labyrinthitis . The vestibular system is a set of sensory inputs consisting of three semicircular canals, sensing changes in rotational motion, and the otoliths, sensing changes in linear motion. The brain combines visual cues with sensory input from the vestibular system to determine adjustments required to retain balance. The vestibular system also relays information on head movement to the eye muscle, forming the vestibulo\u2013ocular reflex to retain continuous visual focus during motion. Not known",
            "score": 148.19487500190735
        },
        {
            "docid": "28354637_6",
            "document": "Richard A. Andersen . Early work centered on the discovery and elucidation of cortical gain fields, a general rule of multiplicative computation used by many areas of the cortex. Andersen and Zipser of UCSD developed one of the first neural network models of cortical function, which generated a mathematical basis for testing hypotheses based on laboratory findings. His research established that the posterior parietal cortex (PPC) is involved in forming movement intentions\u2014the early and abstract plans for movement. Previously this part of the brain was thought only to function for spatial awareness and attention. His laboratory discovered the lateral intraparietal area (LIP) in the PPC and established its role in eye movements. He also discovered the parietal reach region, an area involved in forming early reach plans. His lab has also made a number of discoveries related to visual motion perception. He established that the middle temporal area processes the perception of form from motion. He found that the perception of the direction of heading, important for navigation, is computed in the brain using both visual stimuli and eye movement signals. His lab has also determined how eye position and limb position signals are combined for eye-hand coordination.",
            "score": 162.66965508460999
        },
        {
            "docid": "1070221_16",
            "document": "Human eye . The visual system in the human brain is too slow to process information if images are slipping across the retina at more than a few degrees per second. Thus, to be able to see while moving, the brain must compensate for the motion of the head by turning the eyes. Frontal-eyed animals have a small area of the retina with very high visual acuity, the fovea centralis. It covers about 2 degrees of visual angle in people. To get a clear view of the world, the brain must turn the eyes so that the image of the object of regard falls on the fovea. Any failure to make eye movements correctly can lead to serious visual degradation.",
            "score": 155.260479927063
        },
        {
            "docid": "1070221_26",
            "document": "Human eye . The Optokinetic reflex (or optokinetic nystagmus) stabilizes the image on the retina through visual feedback. It is induced when the entire visual scene drifts across the retina, eliciting eye rotation in the same direction and at a velocity that minimizes the motion of the image on the retina. When the gaze direction deviates too far from the forward heading, a compensatory saccade is induced to reset the gaze to the centre of the visual field.",
            "score": 127.96997237205505
        },
        {
            "docid": "24965027_8",
            "document": "Cognitive neuroscience of visual object recognition . This model, proposed by Marr and Nishihara (1978), states that object recognition is achieved by matching 3-D model representations obtained from the visual object with 3-D model representations stored in memory as veridical shape precepts. Through the use of computer programs and algorithms, Yi Yungfeng (2009) was able to demonstrate the ability for the human brain to mentally construct 3D images using only the 2D images that appear on the retina. Their model also demonstrates a high degree of shape constancy conserved between 2D images, which allow the 3D image to be recognized. The 3-D model representations obtained from the object are formed by first identifying the concavities of the object, which separate the stimulus into individual parts. Recent research suggests that an area of the brain, known as the caudal intraparietal area (CIP), is responsible for storing the slant and tilt of a plan surface that allow for concavity recognition. Rosenburg et al. implanted monkeys with a scleral search coil for monitoring eye position while simultaneously recording single neuron activation from neurons within the CIP. During the experiment, monkeys sat 30\u00a0cm away from an LCD screen that displayed the visual stimuli. Binocular disparity cues were displayed on the screen by rendering stimuli as green-red anaglyphs and the slant-tilt curves ranged from 0 to 330. A single trial consisted of a fixation point and then the presentation of a stimulus for 1 second. Neuron activations were then recorded using the surgically inserted microelectrodes. These single neuron activations for specific concavities of objects lead to the discovery that each axis of an individual part of an object containing concavity are found in memory stores. Identifying the principal axis of the object assists in the normalization process via mental rotation that is required because only the canonical description of the object is stored in memory. Recognition is acquired when the observed object viewpoint is mentally rotated to match the stored canonical description.[11] An extension of Marr and Nishihara's model, the recognition-by-components theory, proposed by Biederman (1987), proposes that the visual information gained from an object is divided into simple geometric components, such as blocks and cylinders, also known as \"geons\" (geometric ions), and are then matched with the most similar object representation that is stored in memory to provide the object's identification (see Figure 1).",
            "score": 149.54729056358337
        },
        {
            "docid": "31454062_3",
            "document": "Laser blended vision . Primarily the treatment is for a condition called presbyopia. Laser Blended Vision can be achieved through laser eye surgery, usually performed as LASIK, although surface laser eye surgery PRK or LASEK can be used to produce the effect. Laser Blended Vision works by increasing the depth of field of each eye through subtle changes in the optics of the corneal spherical aberration. The increase in depth of field allows for the eyes to be corrected in such a way that the dominant eye is set for distance and intermediate vision while the non-dominant eye sees best in the intermediate to near range. Because of the similarity in the visual performance of each eye in the intermediate range the brain is able to fuse the images between the eyes rendering a binocular visual environment. This is in contradiction to traditional monovision where the image disparity between the eyes is too high for image fusion by the brain and instead the brain needs to apply suppression of the blurred eye in order to perceive a clear visual field. In Laser Blended Vision, the eyes are effectively working together to allow good vision at near, intermediate and far, without the use of glasses. The effects of Laser Blended Vision tend to last between 5 and 10 years but can be further adjusted by enhancement procedures.",
            "score": 136.5254819393158
        },
        {
            "docid": "492052_12",
            "document": "Presbyopia . In the visual system, images captured by the eye are translated into electric signals that are transmitted to the brain where they are interpreted. As such, in order to overcome presbyopia, two main components of the visual system can be addressed: the optical system of the eye and the visual processing of the brain.",
            "score": 122.32897138595581
        },
        {
            "docid": "3380919_3",
            "document": "David Heeger . In the fields of perceptual psychology, systems neuroscience, cognitive neuroscience, and computational neuroscience, Heeger has developed computational theories of neuronal processing in the visual system, and he has performed psychophysics (perceptual psychology) and neuroimaging (functional magnetic resonance imaging, fMRI) experiments on human vision. His contributions to computational neuroscience include theories for how the brain can sense optic flow and egomotion, and a theory of neural processing called the normalization model. His empirical research has contributed to our understanding of the topographic organization of visual cortex (retinotopy), visual awareness, visual pattern detection/discrimination, visual motion perception, stereopsis (depth perception), attention, working memory, the control of eye and hand movements, neural processing of complex audio-visual and emotional experiences (movies, music, narrative), abnormal visual processing in dyslexia, and neurophysiological characteristics of autism.",
            "score": 119.20952677726746
        },
        {
            "docid": "22483_92",
            "document": "Optics . Optical illusions (also called visual illusions) are characterized by visually perceived images that differ from objective reality. The information gathered by the eye is processed in the brain to give a percept that differs from the object being imaged. Optical illusions can be the result of a variety of phenomena including physical effects that create images that are different from the objects that make them, the physiological effects on the eyes and brain of excessive stimulation (e.g. brightness, tilt, colour, movement), and cognitive illusions where the eye and brain make unconscious inferences.",
            "score": 123.50656938552856
        },
        {
            "docid": "1057414_50",
            "document": "Traumatic brain injury . As of 2010, the use of predictive visual tracking measurement to identify mild traumatic brain injury was being studied. In visual tracking tests, a head-mounted display unit with eye-tracking capability shows an object moving in a regular pattern. People without brain injury are able to track the moving object with smooth pursuit eye movements and correct trajectory. The test requires both attention and working memory which are difficult functions for people with mild traumatic brain injury. The question being studied, is whether results for people with brain injury will show visual-tracking gaze errors relative to the moving target.",
            "score": 139.2112717628479
        },
        {
            "docid": "39200136_13",
            "document": "Hans Wallach . Wallach\u2019s research showed that when the human head moves (either by tilting or by rotating around a vertical axis), it creates a dynamic pattern of binaural cues that can, when paired with information about the direction and extent of the head movement, enable a listener to determine the elevation of a sound source. It is not necessary that the listener actively make the head movements; a subsequent paper demonstrated that sounds could be correctly located in the median plane when the observer is passively rotated or when a false sense of bodily rotation is induced by means of visual cues.",
            "score": 146.89371418952942
        },
        {
            "docid": "157898_2",
            "document": "Eye . Eyes are organs of the visual system. They provide organisms with vision, the ability to receive and process visual detail, as well as enabling several photo response functions that are independent of vision. Eyes detect light and convert it into electro-chemical impulses in neurons. In higher organisms, the eye is a complex optical system which collects light from the surrounding environment, regulates its intensity through a diaphragm, focuses it through an adjustable assembly of lenses to form an image, converts this image into a set of electrical signals, and transmits these signals to the brain through complex neural pathways that connect the eye via the optic nerve to the visual cortex and other areas of the brain. Eyes with resolving power have come in ten fundamentally different forms, and 96% of animal species possess a complex optical system. Image-resolving eyes are present in molluscs, chordates and arthropods.",
            "score": 142.73673403263092
        },
        {
            "docid": "297924_23",
            "document": "Mantis shrimp . Research also shows their visual experience of colours is not very different from humans'. The eyes are actually a mechanism that operates at the level of individual cones and makes the brain more efficient. This system allows visual information to be preprocessed by the eyes instead of the brain, which would otherwise have to be larger to deal with the stream of raw data and thus require more time and energy. While the eyes themselves are complex and not yet fully understood, the principle of the system appears to be simple. It is similar in function to the human eye but works in the opposite manner. In the human brain, the inferior temporal cortex has a huge amount of colour-specific neurons which process visual impulses from the eyes to create colourful experiences. The mantis shrimp instead uses the different types of photoreceptors in its eyes to perform the same function as the human brain neurons, resulting in a hardwired and more efficient system for an animal that requires rapid colour identification. Humans have fewer types of photoreceptors, but more colour-tuned neurons, while mantis shrimps appears to have fewer colour neurons and more classes of photoreceptors.",
            "score": 123.14966809749603
        },
        {
            "docid": "24990312_3",
            "document": "Optics and vision . The visual system in humans allows individuals to assimilate information from the environment. The act of seeing starts when the lens of the eye focuses an image of its surroundings onto a light-sensitive membrane in the back of the eye, called the retina. The retina converts patterns of light into neuronal signals. The lens of the eye focuses light on the photoreceptive cells of the retina, which detect the photons of light and respond by producing neural impulses. These signals are processed in a hierarchical fashion by different parts of the brain, from the retina to the lateral geniculate nucleus, to the primary and secondary visual cortex of the brain. Signals from the retina can also travel directly from the retina to the Superior colliculus.",
            "score": 150.7062864303589
        },
        {
            "docid": "1070221_22",
            "document": "Human eye . The vestibulo-ocular reflex is a reflex eye movement that stabilizes images on the retina during head movement by producing an eye movement in the direction opposite to head movement in response to neural input from the vestibular system of the inner ear, thus maintaining the image in the center of the visual field. For example, when the head moves to the right, the eyes move to the left. This applies for head movements up and down, left and right, and tilt to the right and left, all of which give input to the ocular muscles to maintain visual stability.",
            "score": 146.3622419834137
        },
        {
            "docid": "599917_9",
            "document": "Mental image . The biological foundation of the mind's eye is not fully understood. Studies using fMRI have shown that the lateral geniculate nucleus and the V1 area of the visual cortex are activated during mental imagery tasks. Ratey writes: The visual pathway is not a one-way street. Higher areas of the brain can also send visual input back to neurons in lower areas of the visual cortex. [...] As humans, we have the ability to see with the mind's eye \u2013 to have a perceptual experience in the absence of visual input. For example, PET scans have shown that when subjects, seated in a room, imagine they are at their front door starting to walk either to the left or right, activation begins in the visual association cortex, the parietal cortex, and the prefrontal cortex - all higher cognitive processing centers of the brain.",
            "score": 142.78563404083252
        },
        {
            "docid": "40452830_2",
            "document": "Ophthalmotrope . An ophthalmotrope (from the Greek roots \u1f40\u03c6\u03b8\u03b1\u03bb\u03bc\u03bf\u1fe6, \"ophthalmos\", i.e. eye and -\u03c4\u03c1\u03bf\u03c0\u03ae, -\"trop\u0113\", i.e. turning) is an apparatus for demonstrating the movements of the eye and the action of the different muscles which produce them, consisting essentially of a model eyeball to which are attached strings and pulleys to duplicate the line force of the muscles. Movements of the eye are kinematically complex and can be described as a combination of rotations about changing rotation centers. But even when ocular mechanics are simplified to pure rotations about a head-fixed rotation center, their noncommutative property makes them difficult to visualize. Ruete, Listing, Donders, Helmholtz, von Graefe, Volkmann and many others have provided the broad outline of an answer to the question how the eye rotates during eye movements.",
            "score": 162.88131546974182
        },
        {
            "docid": "32976137_10",
            "document": "Binocular summation . Both motor fusion and sensory fusion mechanisms are used to combine the two images into a single perceived image. Motor fusion describes the vergence eye movements that rotate the eyes about the vertical axis. Sensory fusion is the psychological process of the visual system that creates a single image perceived by the brain.",
            "score": 114.49104166030884
        },
        {
            "docid": "7596782_4",
            "document": "Optokinetic response . If an optokinetic drum is available, rotate the drum in front of the patient. Ask the patient to look at the drum as you rotate it slowly. If an optokinetic drum is not available, move a strip of paper with alternating 2-inch black and white strips across the patient's visual field. Pass it in front of the patient's eye at reading distance while instructing the patient to look at it as it rapidly moves by. With normal vision, a nystagmus develops in both adults and infants. The nystagmus consists of initial slow phases in the direction of the stimulus (smooth pursuits), followed by fast, corrective phases (saccade). Presence of nystagmus indicates an intact visual pathway. Another effective method is to hold a mirror in front of the patient and slowly rotate the mirror to either side of the patient. The patient with an intact visual pathway will maintain eye contact with herself or himself. This compelling optokinetic stimulus forces reflex slow eye movements. OKN can be used as a crude assessment of the visual system, particularly in infants. When factitious blindness or malingering is suspected, check for optokinetic nystagmus to determine whether there is an intact visual pathway.",
            "score": 141.08131527900696
        },
        {
            "docid": "5212945_3",
            "document": "Visual neuroscience . A recent study using Event-Related Potentials (ERPs) linked an increased neural activity in the occipito-temporal region of the brain to the visual categorization of facial expressions. Results focus on a negative peak in the ERP that occurs 170 milliseconds after the stimulus onset. This action potential, called the N170, was measured using electrodes in the occipito-temporal region, an area already known to be changed by face stimuli. Studying by using the EEG, and ERP methods allow for an extremely high temporal resolution of 4 milliseconds, which makes these kinds of experiments extremely well suited for accurately estimating and comparing the time it takes the brain to perform a certain function. Scientists used classification image techniques, to determine what parts of complex visual stimuli (such as a face) will be relied on when patients are asked to assign them to a category, or emotion. They computed the important features when the stimulus face exhibited one of five different emotions. Stimulus faces exhibiting fear had the distinguishing feature of widening eyes, and stimuli exhibiting happiness exhibited a change in the mouth to make a smile. Regardless of the expression of the stimuli's face, the region near the eyes affected the EEG before the regions near the mouth. This revealed a sequential, and predetermined order to the perception and processing of faces, with the eye being the first, and the mouth, and nose being processed after. This process of downward integration only occurred when the inferior facial features were crucial to the categorization of the stimuli. This is best explained by comparing what happens when participants were shown a face exhibiting fear, versus happiness. The N170 peaked slightly earlier for the fear stimuli at about 175 milliseconds, meaning that it took a participants less time to recognize the facial expression. This is expected because only the eyes need to be processed to recognize the emotion. However, when processing a happy expression, where the mouth is crucial to categorization, downward integration must take place, and thus the N170 peak occurred later at around 185 milliseconds. Eventually visual neuroscience aims to completely explain how the visual system processes all changes in faces as well as objects. This will give a complete view to how the world is constantly visually perceived, and may provide insight into a link between perception and consciousness.",
            "score": 132.03739368915558
        },
        {
            "docid": "1543423_32",
            "document": "Eye tracking . Some results are available on human eye movements under natural conditions where head movements are allowed as well. The relative position of eye and head, even with constant gaze direction, influences neuronal activity in higher visual areas.",
            "score": 98.7624077796936
        },
        {
            "docid": "22396342_7",
            "document": "H1 neuron . Flies are agile flyers and strongly depend on vision during flight. For visual course control, flies optic flow field is analyzed by a set of \u223c60 motion-sensitive neurons, each present in the third visual neuropil of the left and right eyes. A subset of these neurons is thought to be involved in using the optic flow to estimate the parameters of self-motion, such as yaw, roll, and sideward translation. Other neurons are thought to be involved in analyzing the content of the visual scene itself, for example, to separate figure from ground using motion parallax. The H1 neuron is responsible for detecting horizontal motion across the entire visual field of the fly, allowing the fly to generate and guide stabilizing motor corrections mid-flight with respect to yaw.",
            "score": 72.57070803642273
        },
        {
            "docid": "11555180_20",
            "document": "Sopite syndrome . An optokinetic drum may be used to study visually induced sopite effects. The optokinetic drum is a rotating instrument in which test subjects are seated facing the wall of the drum. The interior surface of the drum is normally striped; thus, as the drum rotates, the subject\u2019s eyes are subject to a moving visual field while the subject remains stationary. The speed of the drum and the duration of the test may be varied. Control groups are placed in a drum without stripes or rotation. After exposure to the rotating drum, subjects are surveyed to determine their susceptibility to motion sickness. A study in which the optokinetic drum was used to test the symptoms of the sopite syndrome showed increased mood changes in response to the visual cues, though these effects were compounded by other environmental factors such as boredom and lack of activity.",
            "score": 125.15956735610962
        },
        {
            "docid": "1021754_32",
            "document": "Sound localization . When the head is stationary, the binaural cues for lateral sound localization (interaural time difference and interaural level difference) do not give information about the location of a sound in the median plane. Identical ITDs and ILDs can be produced by sounds at eye level or at any elevation, as long as the lateral direction is constant. However, if the head is rotated, the ITD and ILD change dynamically, and those changes are different for sounds at different elevations. For example, if an eye-level sound source is straight ahead and the head turns to the left, the sound becomes louder (and arrives sooner) at the right ear than at the left. But if the sound source is directly overhead, there will be no change in the ITD and ILD as the head turns. Intermediate elevations will produce intermediate degrees of change, and if the presentation of binaural cues to the two ears during head movement is reversed, the sound will be heard behind the listener. Hans Wallach artificially altered a sound\u2019s binaural cues during movements of the head. Although the sound was objectively placed at eye level, the dynamic changes to ITD and ILD as the head rotated were those that would be produced if the sound source had been elevated. In this situation, the sound was heard at the synthesized elevation. The fact that the sound sources objectively remained at eye level prevented monaural cues from specifying the elevation, showing that it was the dynamic change in the binaural cues during head movement that allowed the sound to be correctly localized in the vertical dimension. The head movements need not be actively produced; accurate vertical localization occurred in a similar setup when the head rotation was produced passively, by seating the blindfolded subject in a rotating chair. As long as the dynamic changes in binaural cues accompanied a perceived head rotation, the synthesized elevation was perceived.",
            "score": 176.94927668571472
        },
        {
            "docid": "62729_24",
            "document": "Sense of balance . Abducens solely innervates the lateral rectus muscle of the eye, moving the eye with trochlear. Trochlear solely innervates the superior oblique muscle of the eye. Together, trochlear and abducens contract and relax to simultaneously direct the pupil towards an angle and depress the globe on the opposite side of the eye (e.g. looking down directs the pupil down and depresses (towards the brain) the top of the globe). The pupil is not only directed but often rotated by these muscles. (See visual system)",
            "score": 140.22636151313782
        }
    ],
    "r": [
        {
            "docid": "679192_10",
            "document": "Superior oblique muscle . The great importance of intorsion and extorsion produced by the two oblique muscles can only be understood when it is considered with regards to the other muscle actions present. The two obliques prevent the eye from rotating about its long axis (retina to pupil) when the superior and inferior rectus muscles contract. This is because the orbit does not face directly forwards- the centre-line of the orbit is a little over 20 degrees out from the mid-line. But because the eyes do face forwards, when acting alone, as well as making the eye look up, superior rectus causes it to rotate slightly about the long axis, so the top of the eye moves medially (intorsion). Similarly, in addition to making the eye look down, inferior rectus would cause the eye to rotate about the long axis so the top of the eye moves slightly laterally (extorsion), if acting alone. Clearly this is undesirable as our vision would rotate when we looked up and down. For this reason, these two rectus muscles work in conjunction with the two obliques. When acting alone, superior oblique causes intorsion, inferior oblique, extorsion. Hence, when inferior rectus contracts so we look down, superior oblique also contracts to prevent extorsion of the eye, and when superior rectus contracts so we look up, inferior oblique contracts to prevent intorsion, thus the undesired rotatory actions of the inferior and superior recti about the long axis of the eye are cancelled out. This keeps our vision horizontally level, irrespective of eye position in the orbit.",
            "score": 188.3071746826172
        },
        {
            "docid": "487910_9",
            "document": "Vestibulo\u2013ocular reflex . In addition to these direct pathways, which drive the velocity of eye rotation, there is an indirect pathway that builds up the position signal needed to prevent the eye from rolling back to center when the head stops moving. This pathway is particularly important when the head is moving slowly, because here position signals dominate over velocity signals. David A. Robinson discovered that the eye muscles require this dual velocity-position drive, and also proposed that it must arise in the brain by mathematically integrating the velocity signal and then sending the resulting position signal to the motoneurons. Robinson was correct: the 'neural integrator' for horizontal eye position was found in the nucleus prepositus hypoglossi in the medulla, and the neural integrator for vertical and torsional eye positions was found in the interstitial nucleus of Cajal in the midbrain. The same neural integrators also generate eye position for other conjugate eye movements such as saccades and smooth pursuit.",
            "score": 186.2151336669922
        },
        {
            "docid": "1894873_16",
            "document": "Eye movement . The visual system in the brain is too slow to process that information if the images are slipping across the retina at more than a few degrees per second. Thus, to be able to see while we are moving, the brain must compensate for the motion of the head by turning the eyes. Another specialisation of visual system in many vertebrate animals is the development of a small area of the retina with a very high visual acuity. This area is called the fovea, and covers about 2 degrees of visual angle in people. To get a clear view of the world, the brain must turn the eyes so that the image of the object of regard falls on the fovea. Eye movement is thus very important for visual perception, and any failure can lead to serious visual disabilities. To see a quick demonstration of this fact, try the following experiment: hold your hand up, about one foot (30\u00a0cm) in front of your nose. Keep your head still, and shake your hand from side to side, slowly at first, and then faster and faster. At first you will be able to see your fingers quite clearly. But as the frequency of shaking passes about 1 Hz, the fingers will become a blur. Now, keep your hand still, and shake your head (up and down or left and right). No matter how fast you shake your head, the image of your fingers remains clear. This demonstrates that the brain can move the eyes opposite to head motion much better than it can follow, or pursue, a hand movement. When your pursuit system fails to keep up with the moving hand, images slip on the retina and you see a blurred hand.",
            "score": 181.83163452148438
        },
        {
            "docid": "33193162_14",
            "document": "Vision in fishes . There is a need for some mechanism that stabilises images during rapid head movements. This is achieved by the vestibulo-ocular reflex, which is a reflex eye movement that stabilises images on the retina by producing eye movements in the direction opposite to head movements, thus preserving the image on the centre of the visual field. For example, when the head moves to the right, the eyes move to the left, and vice versa. In many animals, including human beings, the inner ear functions as the biological analogue of an accelerometer in camera image stabilization systems, to stabilize the image by moving the eyes. When a rotation of the head is detected, an inhibitory signal is sent to the extraocular muscles on one side and an excitatory signal to the muscles on the other side. The result is a compensatory movement of the eyes. Typical human eye movements lag head movements by less than 10 ms.",
            "score": 179.7266082763672
        },
        {
            "docid": "1021754_32",
            "document": "Sound localization . When the head is stationary, the binaural cues for lateral sound localization (interaural time difference and interaural level difference) do not give information about the location of a sound in the median plane. Identical ITDs and ILDs can be produced by sounds at eye level or at any elevation, as long as the lateral direction is constant. However, if the head is rotated, the ITD and ILD change dynamically, and those changes are different for sounds at different elevations. For example, if an eye-level sound source is straight ahead and the head turns to the left, the sound becomes louder (and arrives sooner) at the right ear than at the left. But if the sound source is directly overhead, there will be no change in the ITD and ILD as the head turns. Intermediate elevations will produce intermediate degrees of change, and if the presentation of binaural cues to the two ears during head movement is reversed, the sound will be heard behind the listener. Hans Wallach artificially altered a sound\u2019s binaural cues during movements of the head. Although the sound was objectively placed at eye level, the dynamic changes to ITD and ILD as the head rotated were those that would be produced if the sound source had been elevated. In this situation, the sound was heard at the synthesized elevation. The fact that the sound sources objectively remained at eye level prevented monaural cues from specifying the elevation, showing that it was the dynamic change in the binaural cues during head movement that allowed the sound to be correctly localized in the vertical dimension. The head movements need not be actively produced; accurate vertical localization occurred in a similar setup when the head rotation was produced passively, by seating the blindfolded subject in a rotating chair. As long as the dynamic changes in binaural cues accompanied a perceived head rotation, the synthesized elevation was perceived.",
            "score": 176.94927978515625
        },
        {
            "docid": "17468688_3",
            "document": "Nystagmus . In a normal condition, while the head rotates about any axis, distant visual images are sustained by rotating eyes in the opposite direction on the respective axis. The semicircular canals in the vestibule sense angular acceleration. These send signals to the nuclei for eye movement in the brain. From here, a signal is relayed to the extraocular muscles to allow one\u2019s gaze to fixate on one object as the head moves. Nystagmus also occurs when the semicircular canals are being stimulated (e.g. by means of the caloric test, or by disease) while the head is not in motion. The direction of ocular movement is related to the semicircular canal that is being stimulated.",
            "score": 173.68814086914062
        },
        {
            "docid": "31209304_13",
            "document": "Righting reflex . These automatic postural adjustments can be explained in terms of two reflexes similar to the righting reflex: the vestibulo-ocular reflex (VOR) and the vestibulocollic reflex (VCR). The VOR involves movement of the eyes while the head turns to remain fixated on a stationary image, and the VCR involves control of neck muscles for correction of the head's orientation. During the VOR, the semicircular canals send information to the brain and correct eye movements in the direction opposite head movement by sending excitatory signals to motor neurons on the side opposite to the head rotation. Neurons in the otoliths control not only these signals for control of eye movements, but also signals for head movement correction through the neck muscles. The righting reflex utilizes the VOR and VCR as it brings the body back into position. Visual information under the control of these reflexes creates greater stability for more accurate postural correction.",
            "score": 171.91404724121094
        },
        {
            "docid": "15669613_11",
            "document": "Spinning Dancer . One way of changing the direction perceived is to use averted vision and mentally look for an arm going behind instead of in front, then carefully move the eyes back. Some may perceive a change in direction more easily by narrowing visual focus to a specific region of the image, such as the spinning foot or the shadow below the dancer and gradually looking upwards. One can also try to tilt one's head to perceive a change in direction. Another way is to watch the base shadow foot, and perceive it as the toes always pointing away from you and it can help with direction change. You can also close your eyes and try and envision the dancer going in a direction then reopen them and the dancer should change directions. Still another way is to wait for the dancer's legs to cross in the projection and then try to perceive a change in the direction in what follows. You could also try using your peripheral vision to distract the dominant part of the brain, slowly look away from the ballerina and you may begin to see it spin in the other direction. Perhaps the easiest method is to blink rapidly (slightly varying the rate if necessary) until consecutive images are going in the 'new' direction. Then open your eyes and the new rotational direction is maintained. It is even possible to see the illusion in a way that the dancer is not spinning at all, but simply rotating back and forth 180 degrees.",
            "score": 167.47506713867188
        },
        {
            "docid": "40452830_2",
            "document": "Ophthalmotrope . An ophthalmotrope (from the Greek roots \u1f40\u03c6\u03b8\u03b1\u03bb\u03bc\u03bf\u1fe6, \"ophthalmos\", i.e. eye and -\u03c4\u03c1\u03bf\u03c0\u03ae, -\"trop\u0113\", i.e. turning) is an apparatus for demonstrating the movements of the eye and the action of the different muscles which produce them, consisting essentially of a model eyeball to which are attached strings and pulleys to duplicate the line force of the muscles. Movements of the eye are kinematically complex and can be described as a combination of rotations about changing rotation centers. But even when ocular mechanics are simplified to pure rotations about a head-fixed rotation center, their noncommutative property makes them difficult to visualize. Ruete, Listing, Donders, Helmholtz, von Graefe, Volkmann and many others have provided the broad outline of an answer to the question how the eye rotates during eye movements.",
            "score": 162.88131713867188
        },
        {
            "docid": "28354637_6",
            "document": "Richard A. Andersen . Early work centered on the discovery and elucidation of cortical gain fields, a general rule of multiplicative computation used by many areas of the cortex. Andersen and Zipser of UCSD developed one of the first neural network models of cortical function, which generated a mathematical basis for testing hypotheses based on laboratory findings. His research established that the posterior parietal cortex (PPC) is involved in forming movement intentions\u2014the early and abstract plans for movement. Previously this part of the brain was thought only to function for spatial awareness and attention. His laboratory discovered the lateral intraparietal area (LIP) in the PPC and established its role in eye movements. He also discovered the parietal reach region, an area involved in forming early reach plans. His lab has also made a number of discoveries related to visual motion perception. He established that the middle temporal area processes the perception of form from motion. He found that the perception of the direction of heading, important for navigation, is computed in the brain using both visual stimuli and eye movement signals. His lab has also determined how eye position and limb position signals are combined for eye-hand coordination.",
            "score": 162.66966247558594
        },
        {
            "docid": "26977166_12",
            "document": "Mantis . Mantises have stereo vision. They locate their prey by sight; their compound eyes contain up to 10,000 ommatidia. A small area at the front called the fovea has greater visual acuity than the rest of the eye, and can produce the high resolution necessary to examine potential prey. The peripheral ommatidia are concerned with perceiving motion; when a moving object is noticed, the head is rapidly rotated to bring the object into the visual field of the fovea. Further motions of the prey are then tracked by movements of the mantis's head so as to keep the image centered on the fovea. The eyes are widely spaced and laterally situated, affording a wide binocular field of vision and precise stereoscopic vision at close range. The dark spot on each eye that moves as it rotates its head is a pseudopupil. This occurs because the ommatidia that are viewed \"head-on\" absorb the incident light, while those to the side reflect it.",
            "score": 159.04539489746094
        },
        {
            "docid": "495153_3",
            "document": "Afterimage . Negative afterimages are caused when the eye's photoreceptors, primarily known as rods and cones, adapt to overstimulation and lose sensitivity. Newer evidence suggests there is cortical contribution as well. Normally, the overstimulating image is moved to a fresh area of the retina with small eye movements known as microsaccades. However, if the image is large or the eye remains too steady, these small movements are not enough to keep the image constantly moving to fresh parts of the retina. The photoreceptors that are constantly exposed to the same stimulus will eventually exhaust their supply of photopigment, resulting in a decrease in signal to the brain. This phenomenon can be seen when moving from a bright environment to a dim one, like walking indoors on a bright snowy day. These effects are accompanied by neural adaptations in the occipital lobe of the brain that function similar to color balance adjustments in photography. These adaptations attempt to keep vision consistent in dynamic lighting. Viewing a uniform background while these adaptations are still occurring will allow an individual to see the after image because localized areas of vision are still being processed by the brain using adaptations that are no longer needed.",
            "score": 158.85130310058594
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 158.51620483398438
        },
        {
            "docid": "3151702_5",
            "document": "Smooth pursuit . The neural circuitry underlying smooth pursuit is an object of debate. The first step towards the initiation of pursuit is to see a moving target. Signals from the retina ascend through the lateral geniculate nucleus and activate neurons in primary visual cortex. Primary visual cortex sends the information about the target to the middle temporal visual cortex, which responds very selectively to directions of movement. The processing of motion in this area is necessary for smooth pursuit responses. This sensory area provides the motion signal, which may or may not be smoothly pursued. A region of cortex in the frontal lobe, known as the frontal pursuit area, responds to particular vectors of pursuit, and can be electrically stimulated to induce pursuit movements. Recent evidence suggests that the superior colliculus also responds during smooth pursuit eye movement. These two areas are likely involved in providing the \"go\"-signal to initiate pursuit, as well as selecting which target to track. The \"go\"-signal from the cortex and the superior colliculus is relayed to several pontine nuclei, including the dorsolateral pontine nuclei and the nucleus reticularis tegmenti pontis. The neurons of the pons are tuned to eye velocity and are directionally selective, and can be stimulated to change the velocity of pursuit. The pontine nuclei project to the cerebellum, specifically the vermis and the paraflocculus. These neurons code for the target velocity and are responsible for the particular velocity profile of pursuit. The cerebellum, especially the vestibulo-cerebellum, is also involved in the online correction of velocity during pursuit. The cerebellum then projects to optic motoneurons, which control the eye muscles and cause the eye to move.",
            "score": 157.91444396972656
        },
        {
            "docid": "14573357_12",
            "document": "Efference copy . In 1950, Erich von Holst and Horst Mittelstaedt investigated how species are able to distinguish between exafference and reafference given a seemingly identical percept of the two. To explore this question, they rotated the head of a fly 180 degrees, effectively reversing the right and left edges of the retina and reversing the subject's subsequent reafferent signals. In this state, self-initiated movements of the fly would result in a perception that the world was also moving, rather than standing still as they would in a normal fly. After rotation of the eyes, the animal showed a reinforcement of the optokinetic response in the same direction as the moving visual input. Von Holst and Mittelstaedt interpreted their findings as evidence that corollary discharge (i.e. neural inhibition with active movement) could not have accounted for this observed change as this would have been expected to inhibit the optokinetic reaction. They concluded that an \"Efferenzkopie\" of the motor command was responsible for this reaction due to the persistence of the reafferent signal and given the consequent discrepancy between expected and actual sensory signals which reinforced the response rather than preventing it.",
            "score": 157.2452392578125
        },
        {
            "docid": "2905826_3",
            "document": "Path integration . Charles Darwin first postulated an inertially-based navigation system in animals in 1873. Studies beginning in the middle of the 20th century confirmed that animals could return directly to a starting point, such as a nest, in the absence of vision and having taken a circuitous outwards journey. This shows that they can use cues to track distance and direction in order to estimate their position, and hence how to get home. This process was named \"path integration\" to capture the concept of continuous integration of movement cues over the journey. Manipulation of inertial cues confirmed that at least one of these movement (or \"idiothetic\") cues is information from the vestibular organs, which detect movement in the three dimensions. Other cues probably include proprioception (information from muscles and joints about limb position), motor efference (information from the motor system telling the rest of the brain what movements were commanded and executed), and optic flow (information from the visual system signaling how fast the visual world is moving past the eyes). Together, these sources of information can tell the animal which direction it is moving, at what speed, and for how long. In addition, sensitivity to the earth's magnetic field for underground animals (e.g., mole rat) can give path integration.",
            "score": 155.91629028320312
        },
        {
            "docid": "1070221_16",
            "document": "Human eye . The visual system in the human brain is too slow to process information if images are slipping across the retina at more than a few degrees per second. Thus, to be able to see while moving, the brain must compensate for the motion of the head by turning the eyes. Frontal-eyed animals have a small area of the retina with very high visual acuity, the fovea centralis. It covers about 2 degrees of visual angle in people. To get a clear view of the world, the brain must turn the eyes so that the image of the object of regard falls on the fovea. Any failure to make eye movements correctly can lead to serious visual degradation.",
            "score": 155.26048278808594
        },
        {
            "docid": "613052_12",
            "document": "Direct and indirect realism . Direct realists can potentially deny the existence of any such thing as a mental image but this is difficult to maintain, since we seem able to visually imagine all sorts of things with ease. Even if perception does not involve images other mental processes like imagination certainly seem to. One view, similar to Reid's, is that we do have images of various sorts in our minds when we perceive, dream, hallucinate and imagine but when we actually perceive things, our sensations cannot be considered objects of perception or attention. The only objects of perception are external objects. Even if perception is accompanied by images, or sensations, it is wrong to say we perceive sensations. Direct realism defines perception as perception of external objects where an \"external object\" is allowed to be a photon in the eye but not an impulse in a nerve leading from the eye. Recent work in neuroscience suggests a shared ontology for perception, imagination and dreaming, with similar areas of brain being used for all of these.",
            "score": 155.1769561767578
        },
        {
            "docid": "2438760_7",
            "document": "Change blindness . With the rise of the ability to present complex, real-world images on a computer screen, Dr. George McConkie, in the early 1990s, as part of the new initiatives of the new Beckman Institute for Advanced Science and Technology, began a renewed attempt to investigate why the world looked stable and continuous despite the shifting retinal input signal that accompanied each saccade. This research began when John Grimes and Dr. George McConkie (1996) began to use actual photographs to study visual stability. This development in change blindness research was able to show the effects of change blindness in more realistic settings. Additionally, further research stated that rather large changes will not be detected when they occur during saccadic movements of the eye. In the first experiment of this kind, in 1995, Blackmore \"et al.\" forced saccades by moving the image and making a change in the scene at the same time. Observers' ability to detect the changes fell to chance. The effect was stronger using this method than when using brief grey flashes between images, although subsequent research has mostly used grey flashes or masking stimuli. Another finding based on similar studies stated that a change was easily picked up on by participants when the eye was fixated on the point of change. Therefore, the eye must be directly fixated on the area of change for it to be noticed. This was called the saccade target theory of transsaccadic memory of visual stability. However, other research in the mid-1990s has indicated that individuals still have difficulty detecting change even when they are directly fixated on a particular scene. A study by Rensink, O'Regan, & Clarke demonstrated that change blindness can have an effect even if the eye was fixated on a scene. In this study, a picture was presented followed by a blank screen or \u201cmasking\u201d stimulus, which was followed by the initial picture with a change. The masking stimulus almost acts like a saccadic movement of the eye which makes it significantly more difficult for individuals to detect the change. This was a critical contribution to change blindness research because it demonstrated that a change can remain unnoticed with the smallest disruptions.",
            "score": 154.51095581054688
        },
        {
            "docid": "1841851_20",
            "document": "Stereopsis . In the 1960s, Bela Julesz invented random-dot stereograms. Unlike previous stereograms, in which each half image showed recognizable objects, each half image of the first random-dot stereograms showed a square matrix of about 10,000 small dots, with each dot having a 50% probability of being black or white. No recognizable objects could be seen in either half image. The two half images of a random-dot stereogram were essentially identical, except that one had a square area of dots shifted horizontally by one or two dot diameters, giving horizontal disparity. The gap left by the shifting was filled in with new random dots, hiding the shifted square. Nevertheless, when the two half images were viewed one to each eye, the square area was almost immediately visible by being closer or farther than the background. Julesz whimsically called the square a Cyclopean image after the mythical Cyclops who had only one eye. This was because it was as though we have a cyclopean eye inside our brains that can see cyclopean stimuli hidden to each of our actual eyes. Random-dot stereograms highlighted a problem for stereopsis, the correspondence problem. This is that any dot in one half image can realistically be paired with many same-coloured dots in the other half image. Our visual systems clearly solve the correspondence problem, in that we see the intended depth instead of a fog of false matches. Research began to understand how.",
            "score": 153.97303771972656
        },
        {
            "docid": "5209682_9",
            "document": "Infant visual development . To perceive depth, infants as well as adults rely on several signals such as distances and kinetics. For instance, the fact that objects closer to the observer fill more space in our visual field than farther objects provides some cues into depth perception for infants. Evidence has shown that newborns' eyes do not work in the same fashion as older children or adults \u2013 mainly due to poor coordination of the eyes. Newborn\u2019s eyes move in the same direction only about half of the time. The strength of eye muscle control is positively correlated to achieve depth perception. Human eyes are formed in such a way that each eye reflects a stimulus at a slightly different angle thereby producing two images that are processed in the brain. These images provide the essential visual information regarding 3D features of the external world. Therefore, an infant\u2019s ability to control his eye movement and converge on one object is critical for developing depth perception.",
            "score": 152.0661163330078
        },
        {
            "docid": "177127_21",
            "document": "Balance disorder . Movement of fluid in the semicircular canals signals the brain about the direction and speed of rotation of the head \u2013 for example, whether we are nodding our head up and down or looking from right to left. Each semicircular canal has a bulbed end, or enlarged portion, that contains hair cells. Rotation of the head causes a flow of fluid, which in turn causes displacement of the top portion of the hair cells that are embedded in the jelly-like cupula. Two other organs that are part of the vestibular system are the utricle and saccule. These are called the otolithic organs and are responsible for detecting linear acceleration, or movement in a straight line. The hair cells of the otolithic organs are blanketed with a jelly-like layer studded with tiny calcium stones called otoconia. When the head is tilted or the body position is changed with respect to gravity, the displacement of the stones causes the hair cells to bend.",
            "score": 150.71310424804688
        },
        {
            "docid": "24990312_3",
            "document": "Optics and vision . The visual system in humans allows individuals to assimilate information from the environment. The act of seeing starts when the lens of the eye focuses an image of its surroundings onto a light-sensitive membrane in the back of the eye, called the retina. The retina converts patterns of light into neuronal signals. The lens of the eye focuses light on the photoreceptive cells of the retina, which detect the photons of light and respond by producing neural impulses. These signals are processed in a hierarchical fashion by different parts of the brain, from the retina to the lateral geniculate nucleus, to the primary and secondary visual cortex of the brain. Signals from the retina can also travel directly from the retina to the Superior colliculus.",
            "score": 150.70628356933594
        },
        {
            "docid": "24965027_8",
            "document": "Cognitive neuroscience of visual object recognition . This model, proposed by Marr and Nishihara (1978), states that object recognition is achieved by matching 3-D model representations obtained from the visual object with 3-D model representations stored in memory as veridical shape precepts. Through the use of computer programs and algorithms, Yi Yungfeng (2009) was able to demonstrate the ability for the human brain to mentally construct 3D images using only the 2D images that appear on the retina. Their model also demonstrates a high degree of shape constancy conserved between 2D images, which allow the 3D image to be recognized. The 3-D model representations obtained from the object are formed by first identifying the concavities of the object, which separate the stimulus into individual parts. Recent research suggests that an area of the brain, known as the caudal intraparietal area (CIP), is responsible for storing the slant and tilt of a plan surface that allow for concavity recognition. Rosenburg et al. implanted monkeys with a scleral search coil for monitoring eye position while simultaneously recording single neuron activation from neurons within the CIP. During the experiment, monkeys sat 30\u00a0cm away from an LCD screen that displayed the visual stimuli. Binocular disparity cues were displayed on the screen by rendering stimuli as green-red anaglyphs and the slant-tilt curves ranged from 0 to 330. A single trial consisted of a fixation point and then the presentation of a stimulus for 1 second. Neuron activations were then recorded using the surgically inserted microelectrodes. These single neuron activations for specific concavities of objects lead to the discovery that each axis of an individual part of an object containing concavity are found in memory stores. Identifying the principal axis of the object assists in the normalization process via mental rotation that is required because only the canonical description of the object is stored in memory. Recognition is acquired when the observed object viewpoint is mentally rotated to match the stored canonical description.[11] An extension of Marr and Nishihara's model, the recognition-by-components theory, proposed by Biederman (1987), proposes that the visual information gained from an object is divided into simple geometric components, such as blocks and cylinders, also known as \"geons\" (geometric ions), and are then matched with the most similar object representation that is stored in memory to provide the object's identification (see Figure 1).",
            "score": 149.5472869873047
        },
        {
            "docid": "62729_2",
            "document": "Sense of balance . The sense of balance or equilibrioception is one of the physiological senses related to balance. It helps prevent humans and animals from falling over when standing or moving. Balance is the result of a number of body systems working together: the eyes (visual system), ears (vestibular system) and the body's sense of where it is in space (proprioception) ideally need to be intact. The vestibular system, the region of the inner ear where three semicircular canals converge, works with the visual system to keep objects in focus when the head is moving. This is called the vestibulo-ocular reflex (VOR). The balance system works with the visual and skeletal systems (the muscles and joints and their sensors) to maintain orientation or balance. Visual signals sent to the brain about the body's position in relation to its surroundings are processed by the brain and compared to information from the vestibular, visual and skeletal systems.",
            "score": 148.4326629638672
        },
        {
            "docid": "25788044_5",
            "document": "Globe effect . An alternative approach for explaining the globe effect comes from the technical journalist and optics specialist Walter E. Sch\u00f6n. He states that the observed effect is in fact not that of a rolling globe but that of a vertically rotating cylinder. The globe shape of the illusion seen by most observers is only because the field of view through the optical device is circular. This illusion of a rotating cylinder during panning is caused by the horizontal movement of the image being (due to the angular magnification of the device) faster and more uniform (with less parallax) compared to the naked eye and also not corresponding to the felt rotational speed of the observer's head. When the brain tries to integrate these conflicting signals, it creates the perception that the image is moving slower at the left and right edges than in the middle, giving the illusion of a rotating cylinder.",
            "score": 148.2949981689453
        },
        {
            "docid": "889831_8",
            "document": "Labyrinthitis . The vestibular system is a set of sensory inputs consisting of three semicircular canals, sensing changes in rotational motion, and the otoliths, sensing changes in linear motion. The brain combines visual cues with sensory input from the vestibular system to determine adjustments required to retain balance. The vestibular system also relays information on head movement to the eye muscle, forming the vestibulo\u2013ocular reflex to retain continuous visual focus during motion. Not known",
            "score": 148.1948699951172
        },
        {
            "docid": "1947410_18",
            "document": "Critical period . In mammals, neurons in the brain that process vision actually develop after birth based on signals from the eyes. A landmark experiment by David H. Hubel and Torsten Wiesel (1963) showed that cats that had one eye sewn shut from birth to three months of age (monocular deprivation) only fully developed vision in the open eye. They showed that columns in the primary visual cortex receiving inputs from the other eye took over the areas that would normally receive input from the deprived eye. In general electrophysiological analyses of axons and neurons in the lateral geniculate nucleus showed that the visual receptive field properties was comparable to adult cats. However, the layers of cortex that were deprived had less activity and fewer responses were isolated. The kittens had abnormally small ocular dominance columns (part of the brain that processes sight) connected to the closed eye, and abnormally large, wide columns connected to the open eye. Because the critical period time had elapsed, it would be impossible for the kittens to alter and develop vision in the closed eye. This did not happen to adult cats even when one eye was sewn shut for a year because they had fully developed their vision during their critical period. Later experiments in monkeys found similar results.",
            "score": 147.7899169921875
        },
        {
            "docid": "768413_25",
            "document": "Ear . Dynamic balance is provided through the three semicircular canals. These three canals are orthogonal (at right angles) to each other. At the end of each canal is a slight enlargement, known as the ampulla, which contains numerous cells with filaments in a central area called the cupula. The fluid in these canals rotates according to the momentum of the head. When a person changes acceleration, the inertia of the fluid changes. This affects the pressure on the cupula, and results in the opening of ion channels. This causes depolarisation, which is passed as a signal to the brain along the vestibulocochlear nerve. Dynamic balance also helps maintain eye tracking when moving, via the vestibulo\u2013ocular reflex.",
            "score": 147.28173828125
        },
        {
            "docid": "2534964_16",
            "document": "Sensory processing . Hand eye coordination is one example of sensory integration. In this case, we require a tight integration of what we visually perceive about an object, and what we tactilely perceive about that same object. If these two senses were not combined within the brain, then one would have less ability to manipulate an object. Hand-eye coordination is the tactile sensation in the context of the visual system. The visual system is very static, in that it doesn't move around much, but the hands and other parts used in tactile sensory collection can freely move around. This movement of the hands must be included in the mapping of both the tactile and visual sensations, otherwise one would not be able to comprehend where they were moving their hands, and what they were touching and looking at. An example of this happening is looking at an infant. The infant picks up objects and puts them in his mouth, or touches them to his feet or face. All of these actions are culminating to the formation of spatial maps in the brain and the realization that \"Hey, that thing that's moving this object is actually a part of me.\" Seeing the same thing that they are feeling is a major step in the mapping that is required for infants to begin to realize that they can move their arms and interact with an object. This is the earliest and most explicit way of experiencing sensory integration.",
            "score": 147.2653045654297
        },
        {
            "docid": "1023992_2",
            "document": "Autokinetic effect . The autokinetic effect (also referred to as autokinesis) is a phenomenon of visual perception in which a stationary, small point of light in an otherwise dark or featureless environment appears to move. It was first recorded by a Russian officer keeping watch, who observed illusory movement of a star near the horizon . It is presumed to occur because motion perception is always relative to some reference point, and in darkness or in a featureless environment there is no reference point, so the position of the single point is undefined. The direction of the movements does not appear to be correlated with involuntary eye movements, but may be determined by errors between eye position and that specified by efference copy of the movement signals sent to the extraocular muscles. Several researchers, including Richard Gregory, have shown that autokinesis occurs when no eye movements are recorded. Gregory has suggested that, with lack of peripheral information, eye movements which correct movements due to muscle fatigue are wrongly interpreted in the brain as movement of the perceived light.",
            "score": 147.08193969726562
        },
        {
            "docid": "31148473_12",
            "document": "Transsaccadic memory . This is an area within the visual cortex that has been found to play an important role in the target selection of saccades. In other words, this area is important for determining which objects our eyes shift to when they move. Studies have shown that there is a large amount of activation within the visual area V4 before the saccade even takes place. This occurs in the form of shrinking receptive fields. The receptive fields of these brain cells tend to shift towards the object that the eye is about to move towards, generally more so if the object is close to the original fixation point. This dynamic change in receptive fields is thought to enhance the perception and recognition of objects in a visual scene. Because the receptive fields become smaller around the targeted objects, attention within the visual scene is very focused on these objects. Increased attention to target objects within a visual scene help direct eye movements from one object to another. Understanding of the visual scene becomes more efficient because these attention shifts guide the eyes towards relevant objects as opposed to objects that may not be as important.",
            "score": 146.97543334960938
        }
    ]
}