{
    "q": [
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 174.19844770431519
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 119.19778823852539
        },
        {
            "docid": "33431597_16",
            "document": "Attentional control . According to fMRI studies of the brain and behavioral observations, visual attention can be moved independently of moving eye position. Studies have had participants fixate their eyes on a central point and measured brain activity as stimuli were presented outside the visual fixation point. fMRI findings show changes in brain activity correlated with the shift in spatial attention to the various stimuli. Behavioral studies have also shown that when a person knows where a stimulus is likely to appear, their attention can shift to it more rapidly and process it better.",
            "score": 81.26587867736816
        },
        {
            "docid": "17258308_3",
            "document": "Two-alternative forced choice . There are various manipulations in the design of the task, engineered to test specific behavioral dynamics of choice. In one well known experiment of attention that examines the attentional shift, the Posner Cueing Task uses a 2AFC design to present two stimuli representing two given locations. In this design there is an arrow that cues which stimulus (location) to attend to. The person then has to make a response between the two stimuli (locations) when prompted. In animals, the 2AFC task has been used to test reinforcement probability learning, for example such as choices in pigeons after reinforcement of trials. A 2AFC task has also been designed to test decision making and the interaction of reward and probability learning in monkeys. Monkeys were trained to look at a center stimulus and were then presented with two salient stimuli side by side. A response can then be made in the form of a saccade to the left or to the right stimulus. A juice reward is then administered after each response. The amount of juice reward is then varied to modulate choice.",
            "score": 40.907891511917114
        },
        {
            "docid": "31329046_8",
            "document": "Pre-attentive processing . Visual pre-attentive processing uses a distinct memory mechanism. When a stimulus is presented consecutively, the stimulus is perceived at a faster rate than if different stimuli are presented consecutively. The theory behind this is called the dimension-weighting account (DWA) where each time a specific stimulus (i.e. color) is presented it contributes to the weight of the stimuli. More presentations increase the weight of the stimuli, and therefore, subsequently decrease the reaction time to the stimulus. The dimensional-weighting system, which calculates pre-attentive processing for our visual system, codes the stimulus and thus directs attention to the stimulus with the most weight.",
            "score": 59.05457925796509
        },
        {
            "docid": "27313901_5",
            "document": "Visual N1 . After the amplitude of the N1 was found to vary according to levels of attention, researchers became interested in how identical stimuli were perceived when they were attended versus unattended. An experimental paradigm, sometimes referred to as the Filtering Paradigm, was developed to assess how attention influences perception of stimuli. In the Filtering Paradigm, participants are instructed to focus their attention on either the right or left visual field of a computer screen. The visual field is typically counterbalanced within subjects across trials or experimental blocks. Thus, for the first set of trials, participants may pay attention to the right visual field, but subsequently they may pay attention to the left visual field. Within each trial and across visual fields, participants are presented with the same stimuli, for example flashes of lights varying in duration. Participants are told that when a particular stimulus, such as a short duration flash of light, referred to as a target, appears in the visual field they are attending, they should respond with a button press. The number of targets within each visual field is less than that number of non-targets, and participants are also told to ignore the other visual field and to not respond to the targets presented in that visual field. When targets in the attended visual field are compared to targets in the unattended visual field, the unattended targets are found to elicit a smaller N1 than the attended targets, suggesting that attention acts as a sensory gain mechanism that enhances perception of attended (vs. unattended) stimuli.",
            "score": 75.91493558883667
        },
        {
            "docid": "2613534_22",
            "document": "Visual extinction . Visual extinction has also been used to demonstrate brain bias towards gestalt processing. When presented with a figure containing illusory contours, patients were able to correctly report the presence of stimuli in both contralesional and ipsilesional hemispheres, due to their unconscious processing of the whole field to produce the illusion. This experiment implied that the attention center prioritizes the visualization of surfaces over other stimuli \u2013 therefore, although under race model the ipsilesional stimuli should extinguish the contralesional, the creation of the gestalt takes priority over detection of both. Further, a study using Gabor signals (alternating blurred and noisy black and white bars, commonly used by opticians in diagnostic tests) investigated how the orientation of these signals affected their extinction rate. Bilateral stimuli were least extinguished when both stimuli were oriented horizontally, although both stimuli being oriented vertically also showed a reduction in extinguishing rate when compared to one stimulus vertical and one horizontal \u2013 in what could be assumed by the brain to represent two different surfaces.",
            "score": 55.52365446090698
        },
        {
            "docid": "4958509_4",
            "document": "Attentional shift . In attention research, one prominent theory attempting to explain how visual attention is shifted is the moving-spotlight theory. The primary idea being that attention is like a movable spotlight that is directed towards intended targets, focusing on each target in a serial manner. When information is illuminated by the spotlight, hence attended, processing proceeds in a more efficient manner, directing attention to a particular point and inhibiting input from any stimuli outside of the spotlight. However, when a shift of spatial attention occurs, the spotlight is, in effect, turned off while attention shifts to the next attended location. Attention, however, has also been proposed to adhere to a gradient theory in which attentional resources are given to a region in space rather than a spotlight, so that attentional resources are most concentrated at the center of attentional focus and then decrease the further a stimuli is from the center. Attention in this theory reflects both current and previous attentional allocation, so that attention can build up and decay across more than one attentional fixation over time. This means that time to detect a target may be dependent upon where attention was directed before the target was presented and attention needed to be shifted.",
            "score": 79.84406924247742
        },
        {
            "docid": "35299914_2",
            "document": "Repetitive visual stimulus . Repetitive Visual Stimulus (RVS) is a visual stimulus that has a distinctive property (e.g., frequency or phase). The stimuli are simultaneously presented to the user when focusing his/her attention on the corresponding stimulus. For example, when the user focuses his/her attention on an RVS, an SSVEP is elicited which manifests as oscilliatory components in the user's EEG, especially in the signals from the primary visual cortex, matching the frequency or harmonics of that RVS. Repetitive visual stimuli (RVS) are said to evoke a lesser response in brain cells, specifically superior collicular cells, than moving stimuli. Habituation is very rapid in normal healthy patients in reference to repetitive visual stimuli. Development changes around the first year of life are attributed for attentional control and these are said to be fully functional around the ages of two and four years old. This is the age that toddlers seem to now prefer moving and changing stimuli, much like healthy adults. In infants, there is evidence that supports the hypothesis that infants prefer repetitive visual stimuli or patterns, in comparison to moving or changing targets.",
            "score": 59.488290786743164
        },
        {
            "docid": "41121858_10",
            "document": "Binocular neurons . The stereo model is an energy model that integrates both the position-shift model and the phase-difference model. The position-shift model suggests that the receptive fields of left and right simple cells are identical in shape but are shifted horizontally relative to each other. This model was proposed by Bishop and Pettigrew in 1986. According to the phase-difference model the excitatory and inhibitory sub-regions of the left and right receptive fields of simple cells are shifted in phase such that their boundaries overlap. This model was developed by Ohzawa in 1990. The stereo model uses Fourier phase dependence of simple cell responses, and it suggests that the use of the response of only simple cells is not enough to accurately depict the physiological observations found in cat, monkey, and human visual pathways. In order to make the model more representative of physiological observations, the stereo model combines the responses of both simple and complex cells into a single signal. How this combination is done depends on the incoming stimulus. As one example, the model uses independent Fourier phases for some types of stimuli, and finds the preferred disparity of the complex cells equal to the left-right receptive field shift. For other stimuli, the complex cell becomes less phase sensitive than the simple cells alone, and when the complex cells larger receptive field is included in the model, the phase sensitivity is returns to results similar to normal physiological observations. In order to include the larger receptive fields of complex cells, the model averages several pairs of simple cells nearby and overlaps their receptive fields to construct the complex cell model. This allows the complex cell to be phase independent for all stimuli presented while still maintaining an equal receptive field shift to the simple cells it is composed of in the model.",
            "score": 89.46033465862274
        },
        {
            "docid": "37940820_23",
            "document": "Emotion perception . Researchers employ several methods designed to examine biases toward emotional stimuli to determine the salience of particular emotional stimuli, population differences in emotion perception, and also attentional biases toward or away from emotional stimuli. Tasks commonly utilized include the modified Stroop task, the dot probe task, visual search tasks, and spatial cuing tasks.  The Stroop task, or modified Stroop task, displays different types of words (e.g., threatening and neutral) in varying colors. The participant is then asked to identify the color of the word while ignoring the actual semantic content. Increased response time to indicate the color of threat words relative to neutral words suggests an attentional bias toward such threat. The Stroop task, however, has some interpretational difficulties in addition to the lack of allowance for the measurement of spatial attention allocation. To address some of the limitations of the Stroop task, the dot probe task displays two words or pictures on a computer screen (either one at the top or left and the other on the bottom or right, respectively) and after a brief stimuli presentation, often less than 1000ms, a probe appears in the location of one of the two stimuli and participants are asked to press a button indicating the location of the probe. Different response times between target (e.g., threat) and neutral stimuli infer attentional biases to the target information with shorter response times for when the probe is in the place of the target stimuli indicating an attention bias for that type of information. In another task that examines spatial attentional allocation, the visual search task asks participants to detect a target stimulus embedded in a matrix of distractors (e.g., an angry face among several neutral or other emotional faces or vice versa). Faster detection times to find emotional stimuli among neutral stimuli or slower detection times to find neutral stimuli among emotional distractors infer an attentional bias for such stimuli. The spatial cuing task asks participants to focus on a point located between two rectangles at which point a cue is presented, either in the form of one of the rectangles lighting up or some emotional stimuli appearing within one of the rectangles and this cue either directs attention toward or away from the actual location of the target stimuli. Participants then press a button indicating the location of the target stimuli with faster response times indicating an attention bias toward such stimuli.",
            "score": 64.72493696212769
        },
        {
            "docid": "4236583_10",
            "document": "Visual search . Visual orienting does not necessarily require overt movement, though. It has been shown that people can covertly (without eye movement) shift attention to peripheral stimuli. In the 1970s, it was found that the firing rate of cells in the parietal lobe of monkeys increased in response to stimuli in the receptive field when they attended to peripheral stimuli, even when no eye movements were allowed. These findings indicate that attention plays a critical role in understanding visual search.",
            "score": 68.290842294693
        },
        {
            "docid": "49990541_21",
            "document": "Visual selective attention in dementia . Visual selective attention is typically impaired in this disease. In a study by Peters et al., individuals with AD or DLB completed a Rapid Serial Visual Presentation (RSVP) task. This RSVP paradigm involves the presentation of visual stimuli at the same location in rapid sequence. Each stimulus was presented rapidly, and the target stimulus was a different colour (shown in red) than the distractors (black). The stimulus set consisted of 24 English letters as targets (excluding I and O), and the digits 2\u20139 served as distractors. Results suggested that there were definite differences in terms of ability to inhibit distractor information in the attentional dynamics between AD and DLB patients and healthy controls, however, selective attention deficits are shown to be more severe in DLB patients than AD patients. Both DLB and AD patients showed a decrease in accuracy in the test. Patients with DLB were more severely impaired in visual selective attention compared to both AD patients and healthy controls.",
            "score": 58.38461399078369
        },
        {
            "docid": "27169449_16",
            "document": "Auditory spatial attention . The first experiment used an endogenous or top down orthogonal cuing paradigm to investigate the cortical regions involved in audiospatial attention vs. visuospatial attention. The orthogonal cuing paradigm refers to the information provided by the cue stimuli; participants were asked to make a spatial up/down elevation judgement to stimuli that can appear either centrally, or laterally to the left / right side. While cues provided information to the lateralization of the target to be presented, they contained no information as to the correct elevation judgement. Such a procedure was used to dissociate the functional effects of spatial attention from those of motor-response priming. The same task was used for visual and auditory targets, in alternating blocks. Crucially, the primary focus of analysis was on \u201ccatch trials,\u201d in which cued targets are not presented. This allowed for investigation of functional activation related to attending to a specific location, free of contamination from target-stimulus related activity. In the auditory domain, comparing activation following peripheral right and left cues to central cues revealed significant activation in the posterior parietal cortex (PPC,) frontal eye fields (FEF), and supplementary motor area (SMA.) These areas overlap those that were significantly active during the visuospatial attention condition; a comparison of the activation during the auditory and visual spatial attention conditions found no significant difference between the two.",
            "score": 95.70832061767578
        },
        {
            "docid": "4236583_22",
            "document": "Visual search . Moreover, research into monkeys and single cell recording found that the superior colliculus is involved in the selection of the target during visual search as well as the initiation of movements. Conversely, it also suggested that activation in the superior colliculus results from disengaging attention, ensuring that the next stimulus can be internally represented. The ability to directly attend to a particular stimuli during visual search experiments has been linked to the pulvinar nucleus (located in the midbrain) while inhibiting attention to unattended stimuli. Conversely, Bender and Butter (1987) found that during testing on monkeys, no involvement of the pulvinar nucleus was identified during visual search tasks.",
            "score": 64.98115396499634
        },
        {
            "docid": "27313901_2",
            "document": "Visual N1 . The visual N1 is a visual evoked potential, a type of event-related electrical potential (ERP), that is produced in the brain and recorded on the scalp. The N1 is so named to reflect the polarity and typical timing of the component. The \"N\" indicates that the polarity of the component is negative with respect to an average mastoid reference. The \"1\" originally indicated that it was the first negative-going component, but it now better indexes the typical peak of this component, which is around 150 to 200 milliseconds post-stimulus. The N1 deflection may be detected at most recording sites, including the occipital, parietal, central, and frontal electrode sites. Although, the visual N1 is widely distributed over the entire scalp, it peaks earlier over frontal than posterior regions of the scalp, suggestive of distinct neural and/or cognitive correlates. The N1 is elicited by visual stimuli, and is part of the visual evoked potential \u2013 a series of voltage deflections observed in response to visual onsets, offsets, and changes. Both the right and left hemispheres generate an N1, but the laterality of the N1 depends on whether a stimulus is presented centrally, laterally, or bilaterally. When a stimulus is presented centrally, the N1 is bilateral. When presented laterally, the N1 is larger, earlier, and contralateral to the visual field of the stimulus. When two visual stimuli are presented, one in each visual field, the N1 is bilateral. In the latter case, the N1's asymmetrical skewedness is modulated by attention. Additionally, its amplitude is influenced by selective attention, and thus it has been used to study a variety of attentional processes.",
            "score": 58.596309185028076
        },
        {
            "docid": "425938_17",
            "document": "Animal cognition . Attention is a limited resource and is not an all-or-nothing response: the more attention devoted to one aspect of the environment, the less is available for others. A number of experiments have studied this in animals. In one experiment, a tone and a light are presented simultaneously to pigeons. The pigeons gain a reward only by choosing the correct combination of the two stimuli (e.g. a high frequency tone together with a yellow light). The birds perform well at this task, presumably by dividing attention between the two stimuli. When only one of the stimuli varies and the other is presented at its rewarded value, discrimination improves on the variable stimulus but discrimination on the alternative stimulus worsens. These outcomes are consistent with the notion that attention is a limited resource that can be more or less focused among incoming stimuli.",
            "score": 46.98516798019409
        },
        {
            "docid": "35988954_3",
            "document": "Sensory enhancement theory of object-based attention . Single-cell recordings experiments were the first experiments to support the presence of sensory enhancement. V1 neurons in monkeys were measured for neural responses by Roelfsema, Lamme & Spekreijse (1998), while the monkeys performed a curve-tracing task. The neurons were found to be more active when their receptor fields were on the target-curve as opposed to when their receptor fields fell on the distractor-curve. Furthermore, enhancement was present in the neurons whose receptor fields were on segments of the target-curve relative to segments of the distractor-curve. This effect occurred regardless of whether the curves were spatially separate or overlapping. The presence of neural enhancement when the neurons receptor fields fell on the target-curve could suggest that attention is spreading to the boundaries of the object and then stopping. More recently, Roelfesema and Houtkamp (2011) found that there was a time difference in the onset of enhancement in these V1 neurons. The enhancement of the neuron took longer to appear as the spatial distance between the fixation of attention and receptor field increased. This finding is supported by the performance of mental curve tracing tasks in humans. The results of these single cell recording studies therefore suggest that attention when deployed within an object enhances the representations of the object as a whole and this process of enhancement is gradual so it takes time to complete.",
            "score": 170.04234838485718
        },
        {
            "docid": "18345264_14",
            "document": "Neural correlates of consciousness . Logothetis and colleagues recorded a variety of visual cortical areas in awake macaque monkeys performing a binocular rivalry task. Macaque monkeys can be trained to report whether they see the left or the right image. The distribution of the switching times and the way in which changing the contrast in one eye affects these leaves little doubt that monkeys and humans experience the same basic phenomenon. In the primary visual cortex (V1) only a small fraction of cells weakly modulated their response as a function of the percept of the monkey while most cells responded to one or the other retinal stimulus with little regard to what the animal perceived at the time. But in a high-level cortical area such as the inferior temporal cortex along the ventral stream almost all neurons responded only to the perceptually dominant stimulus, so that a \"face\" cell only fired when the animal indicated that it saw the face and not the pattern presented to the other eye. This implies that NCC involve neurons active in the inferior temporal cortex: it is likely that specific reciprocal actions of neurons in the inferior temporal and parts of the prefrontal cortex are necessary.",
            "score": 107.69748592376709
        },
        {
            "docid": "27313901_14",
            "document": "Visual N1 . The large corpus of studies focused on factors that modulate the amplitude of the visual N1 have provided a wealth of evidence suggesting that, while the visual N1 is a sensory component evoked by any visual stimulus, it also reflects a benefit of correctly allocating attentional resources and that it is a manifestation of an important sensory gating mechanism of attention. When attention is focused on areas of the visual field in which relevant information is presented (vs. evenly distributed across the visual field or focused on an area in which relevant information is not presented), the amplitude of the N1 is largest and indicates a benefit of correctly allocating attentional resources. Additionally, the amplitude of the N1 is believed to represent a sensory gain control mechanism because focusing attention on one area of the visual field serves to increase the amplitude of the N1 to relevant perceptual information presented in that field (vs. the other visual field), and thus facilitates further perceptual processing of stimuli. This finding supports the Early Selection Model of Attention, which contends that attention acts (i.e., filters information) on a stimulus set early in the information processing stream.",
            "score": 83.69062113761902
        },
        {
            "docid": "24978422_3",
            "document": "Visual adaptation . The aftereffects of exposure to a visual stimulus or pattern causes loss of sensitivity to that pattern and induces stimulus bias. An example of this phenomenon is the \"lilac chaser\", introduced by Jeremy Hinton. The stimulus here are lilac circles, that once removed, leave green circles that then become the most prominent stimulus. The fading of the lilac circles is due to a loss of sensitivity to that stimulus and the adaptation to the new stimulus. To experience the \"lilac chaser\" effect, the subject needs to fixate their eyes on the cross in the middle of the image, and after a while the effect will settle in. Visual coding, a process involved in visual adaptation, is the means by which the brain adapts to certain stimuli, resulting in a biased perception of those stimuli. This phenomenon is referred to as visual plasticity; the brain's ability to change and adapt according to certain, repeated stimuli, altering the way information is perceived and processed. The rate and strength of visual adaptation depends heavily on the number of stimuli presented simultaneously, as well as the amount of time for which the stimulus is present. Visual adaptation was found to be weaker when there were more stimuli present. Moreover, studies have found that stimuli can rival each other, which explains why higher numbers of simultaneous stimuli lead to lower stimulus adaptation. Studies have also found that visual adaptation can have a reversing effect; if the stimulus is absent long enough, the aftereffects of visual adaptation will subside. Studies have also shown that visual adaptation occurs in the early stages of processing.",
            "score": 44.42265176773071
        },
        {
            "docid": "42980268_15",
            "document": "Visual spatial attention . It is debated in research on visual spatial attention whether it is possible to split attention across different areas in the visual field. The \u2018spotlight\u2019 and \u2018zoom-lens\u2019 accounts postulate that attention uses a single unitary focus. Therefore, spatial attention can only be allocated to adjacent areas in the visual field and consequently cannot be split. This was supported by an experiment that altered the spatial cueing paradigm by using two cues, a primary and a secondary cue. It was found that the secondary cue was only effective in focusing attention when its location was adjacent to the primary cue. In addition, it has been demonstrated that observers are unable to ignore stimuli presented in areas situated between two cued locations. These findings have proposed that attention cannot be split across two non-contiguous regions. However, other studies have demonstrated that spatial attention can be split across two locations. For example, observers were able to attend simultaneously to two different targets located in opposite hemifields. Research has even suggested that humans are able to focus attention across two to four locations in the visual field. Another perspective is that spatial attention can be split only under certain conditions. This perspective suggests that the splitting of spatial attention is flexible. Research demonstrated that whether spatial attention is unitary or divided depends on the goals of the task. Therefore, if dividing attention is beneficial to the observer then a divided focus of attention will be utilised.",
            "score": 78.29419016838074
        },
        {
            "docid": "68753_22",
            "document": "Attention . \"Covert orienting\" is the act to mentally shifting one's focus without moving one's eyes. Simply, it is changes in attention that are not attributable to overt eye movements. Covert orienting has the potential to affect the output of perceptual processes by governing attention to particular items or locations (for example, the activity of a V4 neuron whose receptive field lies on an attended stimuli will be enhanced by covert attention) but does not influence the information that is processed by the senses. Researchers often use \"filtering\" tasks to study the role of covert attention of selecting information. These tasks often require participants to observe a number of stimuli, but attend to only one. The current view is that visual covert attention is a mechanism for quickly scanning the field of view for interesting locations. This shift in covert attention is linked to eye movement circuitry that sets up a slower saccade to that location.",
            "score": 150.0073697566986
        },
        {
            "docid": "27309832_10",
            "document": "P200 . The visual P2 has been studied in the context of visual priming paradigms, oddball paradigms (where the amplitude is enhanced to targets), and studies of repetition in language. One of the more well-studied paradigms with regards to the visual P2 has classically been the visual search paradigm, which tests perception, attention, memory, and response selection. In this paradigm, participants are instructed to focus their attention at a central point on a screen. It is then that participants are given a cue indicating the identity of a target stimulus. Following a delay, participants are then presented with a set of items. Instructed to identify the location of the target stimulus, participants respond by button-pressing or some other method. Trials are classified as either \"efficient\" or \"inefficient\" based upon the relationship between the target stimuli and non-target stimuli, known as \"distracters\". In the case of efficient search arrays, the target object or stimuli does not share any features in common with the distracters in the array. Likewise, in an inefficient array, the targets share one or more features with the \"distracters\".",
            "score": 55.700191259384155
        },
        {
            "docid": "739262_12",
            "document": "Neural correlate . Using such design, Nikos Logothetis and colleagues discovered perception-reflecting neurons in the temporal lobe. They created an experimental situation in which conflicting images were presented to different eyes (\"i.e.\", binocular rivalry). Under such conditions, human subjects report bistable percepts: they perceive alternatively one or the other image. Logothetis and colleagues trained the monkeys to report with their arm movements which image they perceived. Interestingly, temporal lobe neurons in Logothetis experiments often reflected what the monkeys' perceived. Neurons with such properties were less frequently observed in the primary visual cortex that corresponds to relatively early stages of visual processing. Another set of experiments using binocular rivalry in humans showed that certain layers of the cortex can be excluded as candidates of the neural correlate of consciousness. Logothetis and colleagues switched the images between eyes during the percept of one of the images. Surprisingly the percept stayed stable. This means that the conscious percept stayed stable and at the same time the primary input to layer 4, which is the input layer, in the visual cortex changed. Therefore layer 4 can not be a part of the neural correlate of consciousness. Mikhail Lebedev and their colleagues observed a similar phenomenon in monkey prefrontal cortex. In their experiments monkeys reported the perceived direction of visual stimulus movement (which could be an illusion) by making eye movements. Some prefrontal cortex neurons represented actual and some represented perceived displacements of the stimulus. Observation of perception related neurons in prefrontal cortex is consistent with the theory of Christof Koch and Francis Crick who postulated that neural correlate of consciousness resides in prefrontal cortex. Proponents of distributed neuronal processing may likely dispute the view that consciousness has a precise localization in the brain.",
            "score": 96.08057308197021
        },
        {
            "docid": "35970915_13",
            "document": "Colavita visual dominance effect . The Colavita effect has been shown to be affected by factors that contribute to the intermodal binding of auditory and visual stimuli during perception. These factors of interest are spatial and temporal coincidence between the auditory and visual stimuli, which modulate the Colavita effect through temporal separation and temporal order . For example, results from an experiment, conducted by Koppen and Spence (2007b), showed a larger Colavita effect when auditory and visual stimuli were presented closer together in time. When the stimuli were presented further apart in time, the Colavita effect was reduced. Their results also showed that the Colavita effect was largest when the visual stimulus was presented before the auditory stimulus during the bimodal trials. Conversely, the Colavita effect was reversed or reduced when the auditory stimulus preceded the visual stimulus . In addition, Koppen and Spence conducted an experiment in which participants showed a significantly larger Colavita effect when the auditory and visual stimuli were presented from the same spatial location, rather than from different locations. Based on these results, Koppen and his colleagues proposed that the \u2018unity effect\u2019 can adequately explain the role of spatial and temporal coincidence between stimuli in modulating the Colavita effect. According to the Unity effect, intersensory bias is greater when the participants unconsciously bind the two sensory events and believe that a single unimodal object is being perceived, rather than two separate events.",
            "score": 39.44768762588501
        },
        {
            "docid": "37759941_2",
            "document": "Crossmodal attention . Crossmodal attention refers to the distribution of attention to different senses. Attention is the cognitive process of selectively emphasizing and ignoring sensory stimuli. According to the crossmodal attention perspective, attention often occurs simultaneously through multiple sensory modalities. These modalities process information from the different sensory fields, such as: visual, auditory, spatial, and tacitile. While each of these is designed to process a specific type of sensory information, there is considerable overlap between them which has led researchers to question whether attention is modality-specific or the result of shared \"cross-modal\" resources. \"Cross-modal attention\" is considered to be the overlap between modalities that can both enhance and limit attentional processing. The most common example given of crossmodal attention is the Cocktail Party Effect, which is when a person is able to focus and attend to one important stimulus instead of other less important stimuli. This phenomenon allows deeper levels of processing to occur for one stimuli while others are then ignored.",
            "score": 72.36085295677185
        },
        {
            "docid": "2229041_5",
            "document": "N400 (neuroscience) . A typical experiment designed to study the N400 will usually involve the visual presentation of words, either in sentence or list contexts. In a typical visual N400 experiment, for example, subjects will be seated in front of a computer monitor while words are presented one-by-one at a central screen location. Stimuli must be presented centrally because eye movements will generate large amounts of electrical noise that will mask the relatively small N400 component. Subjects will often be given a behavioral task (e.g., making a word/nonword decision, answering a comprehension question, responding to a memory probe), either after each stimulus or at longer intervals, to ensure that subjects are paying attention. Note, however, that overt responses by the subject are not required to elicit the N400\u2014passively viewing stimuli will still evoke this response.",
            "score": 44.52301216125488
        },
        {
            "docid": "2210835_6",
            "document": "Attentional blink . According to the LC-NE hypothesis, when a salient, or meaningful stimulus is presented, neurons in the locus coeruleus release norepinephrine, a neurotransmitter that benefits the detection of the stimulus. The effect of this release lasts for 100 ms after the salient stimulus is presented and benefits the second target when presented immediately after the first one, accounting for lag 1 sparing. Eventually the neurons in the locus coeruleus enter a refractory period, due to the auto-inhibitory effect of norepinephrine. According to the hypothesis, targets presented during this refractory period cannot trigger a release of norepinephrine, resulting in the attentional blink. The episodic distinctiveness hypothesis of the ST2 model suggests that the attentional blink reflects a limitation of the visual system attempting to allocate unique episodic contexts to the ephemeral target stimuli presented in RSVP.",
            "score": 93.33383965492249
        },
        {
            "docid": "27169449_13",
            "document": "Auditory spatial attention . Further evidence as to the modality specificity of the 'what' and 'where' pathways has been provided in a recent study by Diaconescu et al., who suggest that while 'what' processes have discrete pathways for vision and audition, the 'where' pathway may be supra-modal, shared by both modalities. Participants were asked in randomly alternating trials to respond to either the feature or spatial elements of stimuli, which varied between the auditory and visual domain in set blocks. Between two experiments, the modality of the cue was also varied; the first experiment contained auditory cues as to which element (feature or spatial) of the stimuli to respond to, while the second experiment utilized visual cues. During the period between cue and target, when participants were presumably attending to the cued feature to be presented, both auditory and vision spatial attention conditions elicited greater positivity in source space from a centro-medial location at 600-1200 ms following cue onset, which the authors of the study propose may be the result of a supra-modal pathway for spatial information. Conversely, source space activity for feature attention were not consistent between modalities, with auditory feature attention associated with greater positivity at the right auditory radial dipole around 300-600 ms, and spatial feature attention associated with greater negativity at the left-visual central-inferior dipole at 700-1050ms, suggested as evidence for separate feature or 'what' pathways for vision and audition.",
            "score": 65.26009714603424
        },
        {
            "docid": "31148473_12",
            "document": "Transsaccadic memory . This is an area within the visual cortex that has been found to play an important role in the target selection of saccades. In other words, this area is important for determining which objects our eyes shift to when they move. Studies have shown that there is a large amount of activation within the visual area V4 before the saccade even takes place. This occurs in the form of shrinking receptive fields. The receptive fields of these brain cells tend to shift towards the object that the eye is about to move towards, generally more so if the object is close to the original fixation point. This dynamic change in receptive fields is thought to enhance the perception and recognition of objects in a visual scene. Because the receptive fields become smaller around the targeted objects, attention within the visual scene is very focused on these objects. Increased attention to target objects within a visual scene help direct eye movements from one object to another. Understanding of the visual scene becomes more efficient because these attention shifts guide the eyes towards relevant objects as opposed to objects that may not be as important.",
            "score": 140.58456444740295
        },
        {
            "docid": "2138419_5",
            "document": "Rapid serial visual presentation . Sperling and colleagues examined the RSVP paradigm to investigate the dynamics of shifts of spatial attention (e.g., Reeves & Sperling, 1986; Sperling & Weichselgartner, 1995). Spatial attention is defined as the ability to center on specific stimuli in a visual environment (Johnson & Proctor, 2004). Sperling used an attention shift procedure in which two RSVP series were presented altogether. There was a central point where one was to the left and the other was to the right of the focus point. One series contained letters and the other series contained numbers. The object of the task was for participants to focus on the letter stream and to report items from the number series following a certain letter. Results showed that participants frequently reported numbers that were heard around 400 milliseconds after the cue. They concluded that the findings were parallel with the time participants were required to shift attention from the series that had the letters to the series that had the numbers.",
            "score": 55.56814527511597
        }
    ],
    "r": [
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 174.19845581054688
        },
        {
            "docid": "35988954_3",
            "document": "Sensory enhancement theory of object-based attention . Single-cell recordings experiments were the first experiments to support the presence of sensory enhancement. V1 neurons in monkeys were measured for neural responses by Roelfsema, Lamme & Spekreijse (1998), while the monkeys performed a curve-tracing task. The neurons were found to be more active when their receptor fields were on the target-curve as opposed to when their receptor fields fell on the distractor-curve. Furthermore, enhancement was present in the neurons whose receptor fields were on segments of the target-curve relative to segments of the distractor-curve. This effect occurred regardless of whether the curves were spatially separate or overlapping. The presence of neural enhancement when the neurons receptor fields fell on the target-curve could suggest that attention is spreading to the boundaries of the object and then stopping. More recently, Roelfesema and Houtkamp (2011) found that there was a time difference in the onset of enhancement in these V1 neurons. The enhancement of the neuron took longer to appear as the spatial distance between the fixation of attention and receptor field increased. This finding is supported by the performance of mental curve tracing tasks in humans. The results of these single cell recording studies therefore suggest that attention when deployed within an object enhances the representations of the object as a whole and this process of enhancement is gradual so it takes time to complete.",
            "score": 170.0423583984375
        },
        {
            "docid": "25671719_6",
            "document": "Michael Graziano . Each multisensory neuron responded to a touch within a specific \"tactile receptive field\" on the body surface. Each neuron also responded to a visual stimulus near or approaching the tactile receptive field. The \"visual receptive field\" was therefore a region of nearby space affixed to the relevant body part. Some neurons responded to sound sources near the tactile receptive field. Some neurons also responded mnemonically, becoming active when a part of the body moved through space and approached the remembered location of an object in the dark. The activity of these multisensory neurons therefore signaled the presence of an object near or touching a part of the body, regardless of whether the object was felt, seen, heard, or remembered.",
            "score": 162.36929321289062
        },
        {
            "docid": "41848173_2",
            "document": "Surround suppression . Surround suppression is a descriptive term referring to observations that the relative firing rate of a neuron may under certain conditions decrease when a particular stimulus is enlarged. It is has been observed in electrophysiology studies of the brain and has been noted in many sensory neurons, most notably in the early visual system. Surround suppression is defined as a reduction in the activity of a neuron in response to a stimulus outside its classical receptive field. (The classical receptive field refers to a concept of neural behavior that was understood to be invalid virtally from the start. As Spillman et al (2015)) note, quoting Kuffler (1953), \"not only the areas from which responses can actually be set up by retinal illumination may be included in a definition of the receptive field but also all areas which show a functional connection, by an inhibitory or excitatory effect on a ganglion cell.\" The necessary functional connections with other neurons influenced by stimulation outside a particular area and by dynamic processes in general, and the absence of a theoretical description of a system state to be treated as a baseline, deprive the term \"classical receptive field\" of functional meaning. The descriptor \"surround suppression\" suffers from a similar problem, as the activities of neurons in the \"surround\" of the \"classical receptive field are similarly determined by connectivities and processes involving neurons beyond it.) This nonlinear effect is one of many that reveals the complexity of biological sensory systems, and the connections of properties of neurons that may cause this effect (or its opposite) are still being studied. The characteristics, mechanisms, and perceptual consequences of this phenomenon are of interest to many communities, including neurobiology, computational neuroscience, psychology, and computer vision.",
            "score": 156.55111694335938
        },
        {
            "docid": "2860430_34",
            "document": "Neural oscillation . Neural synchronization can be modulated by task constraints, such as attention, and is thought to play a role in feature binding, neuronal communication, and motor coordination. Neuronal oscillations became a hot topic in neuroscience in the 1990s when the studies of the visual system of the brain by Gray, Singer and others appeared to support the neural binding hypothesis. According to this idea, synchronous oscillations in neuronal ensembles bind neurons representing different features of an object. For example, when a person looks at a tree, visual cortex neurons representing the tree trunk and those representing the branches of the same tree would oscillate in synchrony to form a single representation of the tree. This phenomenon is best seen in local field potentials which reflect the synchronous activity of local groups of neurons, but has also been shown in EEG and MEG recordings providing increasing evidence for a close relation between synchronous oscillatory activity and a variety of cognitive functions such as perceptual grouping.",
            "score": 155.753173828125
        },
        {
            "docid": "9170159_9",
            "document": "Binocular disparity . Brain cells (neurons) in a part of the brain responsible for processing visual information coming from the retinae (primary visual cortex) can detect the existence of disparity in their input from the eyes. Specifically, these neurons will be active, if an object with \"their\" special disparity lies within the part of the visual field to which they have access (receptive field).",
            "score": 154.07891845703125
        },
        {
            "docid": "1492605_11",
            "document": "Pretectal area . Pretectal nuclei, in particular the NOT, are involved in coordinating eye movements during smooth pursuit. These movements allow the eye to closely follow a moving object and to catch up to an object after an unexpected change in direction or velocity. Direction-sensitive retinal slip neurons within the NOT provide ipsiversive horizontal retinal error information to the cortex through the inferior olive. During the day, this information is sensed and relayed by neurons with large receptive fields, whereas parafoveal neurons with small receptive fields do so in the dark. It is through this pathway that the NOT is able to provide retinal error information to guide eye movements. In addition to its role in maintaining smooth pursuit, the pretectum is activated during the optokinetic nystagmus in which the eye returns to a central, forward-facing position after an object it was following passes out of the field of vision.",
            "score": 153.6101837158203
        },
        {
            "docid": "1025417_18",
            "document": "Electromagnetic theories of consciousness . Locating consciousness in the brain's EM field, rather than the neurons, has the advantage of neatly accounting for how information located in millions of neurons scattered through the brain can be unified into a single conscious experience (sometimes called the binding or combination problem): the information is unified in the EM field . In this way EM field consciousness can be considered to be \"joined-up information\". This theory accounts for several otherwise puzzling facts, such as the finding that attention and awareness tend to be correlated with the synchronous firing of multiple neurons rather than the firing of individual neurons. When neurons fire together, their EM fields generate stronger EM field disturbances; so synchronous neuron firing will tend to have a larger impact on the brain's EM field (and thereby consciousness) than the firing of individual neurons. However their generation by synchronous firing is not the only important characteristic of conscious electromagnetic fields\u2014in Pockett's original theory, spatial pattern is the defining feature of a conscious (as opposed to a non-conscious) field.",
            "score": 152.02928161621094
        },
        {
            "docid": "68753_22",
            "document": "Attention . \"Covert orienting\" is the act to mentally shifting one's focus without moving one's eyes. Simply, it is changes in attention that are not attributable to overt eye movements. Covert orienting has the potential to affect the output of perceptual processes by governing attention to particular items or locations (for example, the activity of a V4 neuron whose receptive field lies on an attended stimuli will be enhanced by covert attention) but does not influence the information that is processed by the senses. Researchers often use \"filtering\" tasks to study the role of covert attention of selecting information. These tasks often require participants to observe a number of stimuli, but attend to only one. The current view is that visual covert attention is a mechanism for quickly scanning the field of view for interesting locations. This shift in covert attention is linked to eye movement circuitry that sets up a slower saccade to that location.",
            "score": 150.0073699951172
        },
        {
            "docid": "13001588_43",
            "document": "Animal consciousness . Most experiments show that one neural correlate of attention is enhanced firing. If a neuron has a certain response to a stimulus when the animal is not attending to the stimulus, then when the animal does attend to the stimulus, the neuron's response will be enhanced even if the physical characteristics of the stimulus remain the same. In many cases attention produces changes in the EEG. Many animals, including humans, produce gamma waves (40\u201360\u00a0Hz) when focusing attention on a particular object or activity.",
            "score": 149.36053466796875
        },
        {
            "docid": "19628311_9",
            "document": "Earl K. Miller . Miller has innovated techniques for recording from many neurons simultaneously in multiple brain areas. This is a departure from the classic single-neuron recording approach. It allows detailed and direct comparison of neuron properties between brain areas that are not confounded by extraneous factors and examination of the temporal dynamics of activity between neurons. Miller's lab has used this approach to make a number of discoveries of how different brain areas collaborate to produce thought and action. This includes recent discoveries that oscillating \"brain waves\" may control the timing of shifts of attention and that different items simultaneously held in short-term memory line up on different phases of each brain wave. The latter may explain why we can only think about a few things at the same time.",
            "score": 148.38824462890625
        },
        {
            "docid": "1168317_27",
            "document": "Mirror neuron . Many studies link mirror neurons to understanding goals and intentions. Fogassi et al. (2005) recorded the activity of 41 mirror neurons in the inferior parietal lobe (IPL) of two rhesus macaques. The IPL has long been recognized as an association cortex that integrates sensory information. The monkeys watched an experimenter either grasp an apple and bring it to his mouth or grasp an object and place it in a cup. Only the type of action, and not the kinematic force with which models manipulated objects, determined neuron activity. It was also significant that neurons fired before the monkey observed the human model starting the second motor act (bringing the object to the mouth or placing it in a cup). Therefore, IPL neurons \"code the same act (grasping) in a different way according to the final goal of the action in which the act is embedded\". They may furnish a neural basis for predicting another individual's subsequent actions and inferring intention.",
            "score": 147.86358642578125
        },
        {
            "docid": "13279771_9",
            "document": "Modeling (psychology) . The mirror neuron system, located in the frontal lobe of the brain, is a network of neurons that become active when an animal either performs a behavior or observes that behavior being performed by another. For example, the same mirror neurons will become active when a monkey grasps an object as when it watches another monkey do so. While the significance of mirror neurons is still up for debate in the scientific community, there are many who believe them to be the primary biological component in imitative learning.",
            "score": 147.4371337890625
        },
        {
            "docid": "39199253_5",
            "document": "Percolation (cognitive psychology) . Percolation has been developed outside of the cognitive sciences; however, its application in the field has proven it to be a useful tool for understanding neural processes. Researchers have focused their attention not only studying how neural activity is diffused across networks but also how percolation and its aspect of phase transition can affect decision making and thought processes. Percolation theory has enabled researchers to better understand many psychological conditions, such as epilepsy, disorganized schizophrenia and divergent thinking. These conditions are often indicative of percolating clusters and their involvement in propagating the excess firing of neurons. Seizures occur when neurons in the brain fire simultaneously, and often these seizures can occur in one part of the brain and transfer to other parts. Researchers are able to facilitate a better understanding of these conditions because \"the neurons involved in a seizure are analogous to the sites in a percolating cluster\". Disorganized schizophrenia is more complex as the activity is indicative activity in a percolating cluster; however, some researchers have suggested that the percolation of information occurs not in a small cluster but on a global functional scale. Attention as well as percolation also plays a key role in disorganized and divergent thinking; however, it is more likely that directed percolation, that is a directionally controlled percolation, is more useful to study divergent thinking and creativity.",
            "score": 146.6990509033203
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 145.6676483154297
        },
        {
            "docid": "4305783_14",
            "document": "Premotor cortex . Mirror neurons were first discovered in area F5 in the monkey brain by Rizzolatti and colleagues. These neurons are active when the monkey grasps an object. Yet the same neurons become active when the monkey watches an experimenter grasp an object in the same way. The neurons are therefore both sensory and motor. Mirror neurons are proposed to be a basis for understanding the actions of others by internally imitating the actions using one\u2019s own motor control circuits.",
            "score": 145.17518615722656
        },
        {
            "docid": "1188574_17",
            "document": "Motor cortex . Mirror neurons were first discovered in area F5 in the monkey brain by Rizzolatti and colleagues. These neurons are active when the monkey grasps an object. Yet the same neurons become active when the monkey watches an experimenter grasp an object in the same way. The neurons are therefore both sensory and motor. Mirror neurons are proposed to be a basis for understanding the actions of others by internally imitating the actions using one\u2019s own motor control circuits.",
            "score": 145.17518615722656
        },
        {
            "docid": "941909_26",
            "document": "Receptive field . The term receptive field is also used in the context of artificial neural networks, most often in relation to convolutional neural networks (CNNs). When used in this sense, the term adopts a meaning reminiscent of receptive fields in actual biological nervous systems. CNNs have a distinct architecture, designed to mimic the way in which real animal brains are understood to function; instead of having every neuron in each layer connect to all neurons in the next layer (Multilayer perceptron), the neurons are arranged in a 3-dimensional structure in such a way as to take into account the spatial relationships between different neurons with respect to the original data. Since CNNs are used primarily in the field of computer vision, the data that the neurons represent is typically an image; each input neuron represents one pixel from the original image. The first layer of neurons is composed of all the input neurons; neurons in the next layer will receive connections from some of the input neurons (pixels), but not all, as would be the case in a MLP and in other traditional neural networks. Hence, instead of having each neuron receive connections from all neurons in the previous layer, CNNs use a receptive field-like layout in which each neuron receives connections only from a subset of neurons in the previous (lower) layer. The receptive field of a neuron in one of the lower layers encompasses only a small area of the image, while the receptive field of a neuron in subsequent (higher) layers involves a combination of receptive fields from several (but not all) neurons in the layer before (i. e. a neuron in a higher layer \"looks\" at a larger portion of the image than does a neuron in a lower layer). In this way, each successive layer is capable of learning increasingly abstract features of the original image. The use of receptive fields in this fashion is thought to give CNNs an advantage in recognizing visual patterns when compared to other types of neural networks.",
            "score": 144.70159912109375
        },
        {
            "docid": "14782003_12",
            "document": "Body schema . A working body schema must be able to interactively track the movements and positions of body parts in space. Neurons in the premotor cortex may contribute to this function. A class of neuron in the premotor cortex is multisensory. Each of these multisensory neurons responds to tactile stimuli and also to visual stimuli. The neuron has a tactile receptive field (responsive region on the body surface) typically on the face, arms, or hands. The same neuron also responds to visual stimuli in the space near the tactile receptive field. For example, if a neuron's tactile receptive field covers the arm, the same neuron will respond to visual stimuli in the space near the arm. As shown by Graziano and colleagues, the visual receptive field will update with arm movement, translating through space as the arm moves. Similar body-part-centered neuronal receptive fields relate to the face. These neurons apparently monitor the location of body parts and the location of nearby objects with respect to body parts. Similar neuronal properties may also be important for the ability to incorporate external objects into the body schema, such as in tool use.",
            "score": 144.3502655029297
        },
        {
            "docid": "43666413_11",
            "document": "Cerebral polyopia . Another possible pathophysiological mechanism for this disorder is the reorganization of receptive fields of neurons close to the damaged area of visual cortex. This theory is supported by findings that parafoveal retinal lesions deprive a region of striate cortex of visual input, and as a result, the receptive fields of neurons near the boundary of the deprived cortical region enlarge and expand into nearby regions of the visual field. Thus, polyopia results from altered coding of contour information by neurons near the lesioned area. This mechanism offers that after a focal lesion of neurons in striate cortex, or following a retinal lesion depriving these neurons of visual input, the receptive fields of nearby healthy neurons converge to code information about contours of objects normally coded by the damaged neurons while still coding the same information about retinal location prior to the injury. This mechanism may explain why polyopia extending into a patient\u2019s scotoma occurs following damage to primary visual cortex.",
            "score": 144.28355407714844
        },
        {
            "docid": "41121858_9",
            "document": "Binocular neurons . An energy model, a kind of stimulus-response model, of binocular neurons allows for investigation behind the computational function these disparity tuned cells play in the creation of depth perception. Energy models of binocular neurons involve the combination of monocular receptive fields that are either shifted in position or phase. These shifts in either position or phase allow for the simulated binocular neurons to be sensitive to disparity. The relative contributions of phase and position shifts in simple and complex cells combine together in order to create depth perception of an object in 3-dimensional space. Binocular simple cells are modeled as linear neurons. Due to the linear nature of these neurons, positive and negative values are encoded by two neurons where one neuron encodes the positive part and the other the negative part. This results in the neurons being complements of each other where the excitatory region of one binocular simple cell overlaps with the inhibitory region of another. Each neuron's response is limited such that only one may have a non-zero response for any time. This kind of limitation is called halfwave-rectifing. Binocular complex cells are modeled as energy neurons since they do not have discrete on and off regions in their receptive fields. Energy neurons sum the squared responses of two pairs of linear neurons which must be 90 degrees out of phase. Alternatively, they can also be the sum the squared responses of four halfwave-rectified linear neurons.",
            "score": 142.36544799804688
        },
        {
            "docid": "33431597_15",
            "document": "Attentional control . Our brains have distinct attention systems that have been shaped throughout time by evolution. Visual attention operates mainly on three different representations: location , feature, and object-based. The spatial separation between two objects has an effect on attention. People can selectively pay attention to one of two objects in the same general location. Research has also been done on attention to non-object based things like motion. When directing attention to a feature like motion, neuronal activity increases in areas specific for the feature. When visually searching for a non-spatial feature or a perceptual feature, selectively enhancing the sensitivity to that specific feature plays a role in directing attention. When people are told to look for motion, then motion will capture their attention, but attention is not captured by motion if they are told to look for color.",
            "score": 141.99789428710938
        },
        {
            "docid": "5004685_21",
            "document": "Transcranial direct-current stimulation . While the tDCS method is gaining interest, the most commonly used method of brain stimulation is transcranial magnetic stimulation (TMS). This technique of brain stimulation utilizes an electric coil held above the region of interest on the scalp that uses rapidly changing magnetic fields to induce small electrical currents in the brain. There are two types of TMS: repetitive TMS and single pulse TMS. Both are used in research therapy but effects lasting longer than the stimulation period are only observed in repetitive TMS. Similar to tDCS, an increase or decrease in neuronal activity can be achieved using this technique, but the method of how this is induced is very different. Transcranial direct current stimulation has the two different directions of current that cause the different effects. Increased neuronal activity is induced in repetitive TMS by using a higher frequency and decreased neuronal activity is induced by using a lower frequency.",
            "score": 141.97726440429688
        },
        {
            "docid": "21445461_20",
            "document": "Nonsynaptic plasticity . Central nervous system (CNS) neurons integrate signals from many neurons. In the short term, it is important to have changes in activity of the neuron because this is how information is conveyed in the nervous system. However, for long-term sustainability, drift towards excitability or inexcitability will disturb the circuit's ability to convey information. Long-term potentiation (LTP) induces a higher firing rate in post synaptic neurons. Without a homeostatic mechanism, this would result in downstream saturation and all information would be lost. If a neuron could achieve any firing rate, saturation would not be an issue, but firing rates are bounded at zero and a maximal rate of firing. The entire dynamic range (0-maximum) of a neuron's firing rates should be used to encode information. Ideally, the intrinsic properties of a neuron should be arranged to make the most of the dynamic range, acting as a homeostatic mechanism. In vitro studies have found that when the spontaneous activity of neuronal cultures is inhibited, the neurons become hyper excitable and that when an increase in activity is induced for long periods, the firing rates of the culture drop.",
            "score": 141.57179260253906
        },
        {
            "docid": "33246145_2",
            "document": "Neural decoding . Neural decoding is a neuroscience field concerned with the hypothetical reconstruction of sensory and other stimuli from information that has already been encoded and represented in the brain by networks of neurons. Reconstruction refers to the ability of the researcher to predict what sensory stimuli the subject is receiving based purely on neuron action potentials. Therefore, the main goal of neural decoding is to characterize how the electrical activity of neurons elicit activity and responses in the brain.",
            "score": 141.52976989746094
        },
        {
            "docid": "22870810_5",
            "document": "Su-Chun Zhang . In January 2005, Zhang's group differentiated human blastocyst stem cells into neural stem cells, then further into the starts of motor neurons, and eventually into spinal motor neuron cells (which play important role in delivering information from the brain to the spinal cord in the human body). The artificially generated motor neurons exhibited profiles the same as those normal natural ones, including functions like electrophysiological activity which is the signature of neurons. Zhang described this study as \"... you need to teach the blastocyst stem cells to change step by step, where each step has different conditions and a strict window of time\". This research would have high significance for those human diseases or injuries related to spinal cord or motor neurons. Zhang's next step focused on the communicational ability of these newly generated neurons when they are transplanted into a living vertebrate.",
            "score": 141.4990234375
        },
        {
            "docid": "35988954_4",
            "document": "Sensory enhancement theory of object-based attention . Attention to an object or surface has been directly linked by Wannig, Rodr\u03afguez and Freiwald (2007) to increased neural activation of representations in the early sensory areas. They found support for the enhancement of targets when motion sensitive neurons in the middle temporal (MT) areas of monkey brains were activated during a cued transparent random-dot surface task. As there was more activation in the MT region when there was a motion related to the attended surface or object as opposed to the unattended surface or object, even though the two surfaces were overlapping.",
            "score": 141.13572692871094
        },
        {
            "docid": "156940_17",
            "document": "Electrophysiology . An electrode introduced into the brain of a living animal will detect electrical activity that is generated by the neurons adjacent to the electrode tip. If the electrode is a microelectrode, with a tip size of about 1 micrometre, the electrode will usually detect the activity of at most one neuron. Recording in this way is in general called \"single-unit\" recording. The action potentials recorded are very much like the action potentials that are recorded intracellularly, but the signals are very much smaller (typically about 1 mV). Most recordings of the activity of single neurons in anesthetized and conscious animals are made in this way. Recordings of single neurons in living animals have provided important insights into how the brain processes information. For example, David Hubel and Torsten Wiesel recorded the activity of single neurons in the primary visual cortex of the anesthetized cat, and showed how single neurons in this area respond to very specific features of a visual stimulus. Hubel and Wiesel were awarded the Nobel Prize in Physiology or Medicine in 1981.",
            "score": 140.87234497070312
        },
        {
            "docid": "31148473_12",
            "document": "Transsaccadic memory . This is an area within the visual cortex that has been found to play an important role in the target selection of saccades. In other words, this area is important for determining which objects our eyes shift to when they move. Studies have shown that there is a large amount of activation within the visual area V4 before the saccade even takes place. This occurs in the form of shrinking receptive fields. The receptive fields of these brain cells tend to shift towards the object that the eye is about to move towards, generally more so if the object is close to the original fixation point. This dynamic change in receptive fields is thought to enhance the perception and recognition of objects in a visual scene. Because the receptive fields become smaller around the targeted objects, attention within the visual scene is very focused on these objects. Increased attention to target objects within a visual scene help direct eye movements from one object to another. Understanding of the visual scene becomes more efficient because these attention shifts guide the eyes towards relevant objects as opposed to objects that may not be as important.",
            "score": 140.58456420898438
        },
        {
            "docid": "2860430_13",
            "document": "Neural oscillation . A group of neurons can also generate oscillatory activity. Through synaptic interactions the firing patterns of different neurons may become synchronized and the rhythmic changes in electric potential caused by their action potentials will add up (constructive interference). That is, synchronized firing patterns result in synchronized input into other cortical areas, which gives rise to large-amplitude oscillations of the local field potential. These large-scale oscillations can also be measured outside the scalp using electroencephalography (EEG) and magnetoencephalography (MEG). The electric potentials generated by single neurons are far too small to be picked up outside the scalp, and EEG or MEG activity always reflects the summation of the synchronous activity of thousands or millions of neurons that have similar spatial orientation. Neurons in a neural ensemble rarely all fire at exactly the same moment, i.e. fully synchronized. Instead, the probability of firing is rhythmically modulated such that neurons are more likely to fire at the same time, which gives rise to oscillations in their mean activity (see figure at top of page). As such, the frequency of large-scale oscillations does not need to match the firing pattern of individual neurons. Isolated cortical neurons fire regularly under certain conditions, but in the intact brain cortical cells are bombarded by highly fluctuating synaptic inputs and typically fire seemingly at random. However, if the probability of a large group of neurons is rhythmically modulated at a common frequency, they will generate oscillations in the mean field (see also figure at top of page). Neural ensembles can generate oscillatory activity endogenously through local interactions between excitatory and inhibitory neurons. In particular, inhibitory interneurons play an important role in producing neural ensemble synchrony by generating a narrow window for effective excitation and rhythmically modulating the firing rate of excitatory neurons.",
            "score": 140.51068115234375
        },
        {
            "docid": "2872287_23",
            "document": "Neural binding . Much of the experimental evidence for neural binding has traditionally revolved around sensory awareness. Sensory awareness is accomplished by integrating things together by cognitively perceiving them and then segmenting them so that, in total, there is an image created. Since there can be an infinite number of possibilities in the perception of an object, this has been a unique area of study. The way the brain then collectively pieces certain things together via networking is important not only in the global way of perceiving but also in segmentation. Much of sensory awareness has to do with the taking of a single piece of an object's makeup and then binding its total characteristics so that the brain perceives the object in its final form. Much of the research for the understanding of segmentation and how the brain perceives an object has been done by studying cats. A major finding of this research has to do with the understanding of gamma waves oscillating at 40\u00a0Hz. The information was extracted from a study using the cat visual cortex. It was shown that the cortical neurons responded differently to spatially different objects. These firings of neurons ranged from 40\u201360\u00a0Hz in measure and when observed showed that they fired synchronously when observing different parts of the object. Such coherent responses point to the fact that the brain is doing a kind of coding where it is piecing certain neurons together in the works of making the form of an object. Since the brain is putting these segmented pieces together unsupervised, a significant consonance is found with many philosophers (like Sigmund Freud) who theorize an underlying subconscious that helps to form every aspect of our conscious thought processes.",
            "score": 140.14027404785156
        },
        {
            "docid": "2860430_26",
            "document": "Neural oscillation . Both single neurons and groups of neurons can generate oscillatory activity spontaneously. In addition, they may show oscillatory responses to perceptual input or motor output. Some types of neurons will fire rhythmically in the absence of any synaptic input. Likewise, brain-wide activity reveals oscillatory activity while subjects do not engage in any activity, so-called resting-state activity. These ongoing rhythms can change in different ways in response to perceptual input or motor output. Oscillatory activity may respond by increases or decreases in frequency and amplitude or show a temporary interruption, which is referred to as phase resetting. In addition, external activity may not interact with ongoing activity at all, resulting in an additive response.",
            "score": 139.4382781982422
        }
    ]
}