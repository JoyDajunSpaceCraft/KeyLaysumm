{
    "q": [
        {
            "docid": "5198024_14",
            "document": "Efficient coding hypothesis . In one study by Doi et al. in 2012, the researchers created a predicted response model of the retinal ganglion cells that would be based on the statistics of the natural images used, while considering noise and biological constraints. They then compared the actual information transmission as observed in real retinal ganglion cells to this optimal model to determine the efficiency. They found that the information transmission in the retinal ganglion cells had an overall efficiency of about 80% and concluded that \"the functional connectivity between cones and retinal ganglion cells exhibits unique spatial structure...consistent with coding efficiency. A study by van Hateren and Ruderman in 1998 used ICA to analyze video-sequences and compared how a computer analyzed the independent components of the image to data for visual processing obtained from a cat in DeAngelis et al. 1993. The researchers described the independent components obtained from a video sequence as the \"basic building blocks of a signal\", with the independent component filter (ICF) measuring \"how strongly each building block is present\". They hypothesized that if simple cells are organized to pick out the \"underlying structure\" of images over time then cells should act like the independent component filters. They found that the ICFs determined by the computer were similar to the \"receptive fields\" that were observed in actual neurons.",
            "score": 143.7729490995407
        },
        {
            "docid": "23843184_6",
            "document": "Intravital microscopy . Fluorescence labeling of different cell lineages with differently coloured proteins allows visualizing cellular dynamics in a context of their microenvironment. If the image resolution is high enough (50 \u2013 100 \u03bcm) it can be possible to use several images to generate 3D models of cellular interactions, including protrusions that cells make while extending toward each other. 3D models from time-lapse image sequences allow assessing speed and directionality of cellular movements. Vascular structures can also be reconstructed in 3D space and changes of their permeability can be monitored throughout a period of time as fluorescent signal intensity of dyes changes when vascular permeability does. High resolution intravital microscopy can be used to visualize spontaneous and transient events. <br> It might be useful to pair up multiphoton and confocal microscopy as this allows getting more information from every imaging session. This includes visualization of more different cell types and structures to obtain more informative images and using a single animal to obtain images of all the different cell types and structures that are of interest for a given experiment. This latter is an example of The Three Rs principle implementation.",
            "score": 124.1492782831192
        },
        {
            "docid": "41121858_10",
            "document": "Binocular neurons . The stereo model is an energy model that integrates both the position-shift model and the phase-difference model. The position-shift model suggests that the receptive fields of left and right simple cells are identical in shape but are shifted horizontally relative to each other. This model was proposed by Bishop and Pettigrew in 1986. According to the phase-difference model the excitatory and inhibitory sub-regions of the left and right receptive fields of simple cells are shifted in phase such that their boundaries overlap. This model was developed by Ohzawa in 1990. The stereo model uses Fourier phase dependence of simple cell responses, and it suggests that the use of the response of only simple cells is not enough to accurately depict the physiological observations found in cat, monkey, and human visual pathways. In order to make the model more representative of physiological observations, the stereo model combines the responses of both simple and complex cells into a single signal. How this combination is done depends on the incoming stimulus. As one example, the model uses independent Fourier phases for some types of stimuli, and finds the preferred disparity of the complex cells equal to the left-right receptive field shift. For other stimuli, the complex cell becomes less phase sensitive than the simple cells alone, and when the complex cells larger receptive field is included in the model, the phase sensitivity is returns to results similar to normal physiological observations. In order to include the larger receptive fields of complex cells, the model averages several pairs of simple cells nearby and overlaps their receptive fields to construct the complex cell model. This allows the complex cell to be phase independent for all stimuli presented while still maintaining an equal receptive field shift to the simple cells it is composed of in the model.",
            "score": 86.04577207565308
        },
        {
            "docid": "401150_3",
            "document": "Photoreceptor cell . There are currently three known types of photoreceptor cells in mammalian eyes: rods, cones, and photosensitive retinal ganglion cells. The two classic photoreceptor cells are rods and cones, each contributing information used by the visual system to form a representation of the visual world, sight. The rods are narrower than the cones and distributed differently across the retina, but the chemical process in each that supports phototransduction is similar. A third class of mammalian photoreceptor cell was discovered during the 1990s: the photosensitive ganglion cells. These cells do not contribute to sight directly, but are thought to support circadian rhythms and pupillary reflex.",
            "score": 144.99786257743835
        },
        {
            "docid": "941909_23",
            "document": "Receptive field . Idealized models of visual receptive fields similar to those found in the retina, lateral geniculate nucleus (LGN) and the primary visual cortex of higher mammals can be derived in an axiomatic way from structural requirements on the first stages of visual processing that reflect symmetry properties of the surrounding world. Specifically, functional models for linear receptive fields can be derived in a principled manner to constitute a combination of Gaussian derivatives over the spatial domain and either non-causal Gaussian derivatives or truly time-causal temporal scale-space kernels over the temporal domain. Such receptive fields can be shown to enable computation of invariant visual representations under natural image transformations. By these results, the different shapes of receptive field profiles found in biological vision, which are tuned to different sizes and orientations in the image domain as well as to different image velocities in space-time, can be seen as well adapted to structure of the physical world and be explained from the requirement that the visual system should be invariant to the natural types of image transformations that occur in its environment.",
            "score": 115.86973190307617
        },
        {
            "docid": "6320685_6",
            "document": "Simple cell . However, it has been claimed that the Gabor model does not conform to the anatomical structure of the visual system as it short-cuts the LGN and uses the 2D image as it is projected on the retina. Azzopardi and Petkov have proposed a computational model of a simple cell, which combines the responses of model LGN cells with center-surround receptive fields (RFs). They call it Combination of RFs (CORF) model. Besides orientation selectivity, it exhibits cross orientation suppression, contrast invariant orientation tuning and response saturation. These properties are observed in real simple cells but are not possessed by the Gabor model. Using simulated reverse correlation they also demonstrate that the RF map of the CORF model can be divided into elongated excitatory and inhibitory regions typical of simple cells.",
            "score": 103.55301213264465
        },
        {
            "docid": "801776_2",
            "document": "Retinal ganglion cell . A retinal ganglion cell (RGC) is a type of neuron located near the inner surface (the ganglion cell layer) of the retina of the eye. It receives visual information from photoreceptors via two intermediate neuron types: bipolar cells and retina amacrine cells. Retina amacrine cells, particularly narrow field cells, are important for creating functional subunits within the ganglion cell layer and making it so that ganglion cells can observe a small dot moving a small distance. Retinal ganglion cells collectively transmit image-forming and non-image forming visual information from the retina in the form of action potential to several regions in the thalamus, hypothalamus, and mesencephalon, or midbrain.",
            "score": 215.25161385536194
        },
        {
            "docid": "305136_25",
            "document": "Visual system . The information about the image via the eye is transmitted to the brain along the optic nerve. Different populations of ganglion cells in the retina send information to the brain through the optic nerve. About 90% of the axons in the optic nerve go to the lateral geniculate nucleus in the thalamus. These axons originate from the M, P, and K ganglion cells in the retina, see above. This parallel processing is important for reconstructing the visual world; each type of information will go through a different route to perception. Another population sends information to the superior colliculus in the midbrain, which assists in controlling eye movements (saccades) as well as other motor responses.",
            "score": 216.40772223472595
        },
        {
            "docid": "48334_34",
            "document": "Retina . In the retinal ganglion cells there are two types of response, depending on the receptive field of the cell. The receptive fields of retinal ganglion cells comprise a central, approximately circular area, where light has one effect on the firing of the cell, and an annular surround, where light has the opposite effect. In ON cells, an increment in light intensity in the centre of the receptive field causes the firing rate to increase. In OFF cells, it makes it decrease. In a linear model, this response profile is well described by a difference of Gaussians and is the basis for edge detection algorithms. Beyond this simple difference, ganglion cells are also differentiated by chromatic sensitivity and the type of spatial summation. Cells showing linear spatial summation are termed X cells (also called parvocellular, P, or midget ganglion cells), and those showing non-linear summation are Y cells (also called magnocellular, M, or parasol retinal ganglion cells), although the correspondence between X and Y cells (in the cat retina) and P and M cells (in the primate retina) is not as simple as it once seemed.",
            "score": 137.02222895622253
        },
        {
            "docid": "410879_3",
            "document": "GIS file formats . A raster data type is, in essence, any type of digital image represented by reducible and enlargeable grids. Anyone who is familiar with digital photography will recognize the Raster graphics pixel as the smallest individual grid unit building block of an image, usually not readily identified as an artifact shape until an image is produced on a very large scale. A combination of the pixels making up an image color formation scheme will compose details of an image, as is distinct from the commonly used points, lines, and polygon area location symbols of scalable vector graphics as the basis of the vector model of area attribute rendering. While a digital image is concerned with its output blending together its grid based details as an identifiable representation of reality, in a photograph or art image transferred into a computer, the raster data type will reflect a digitized abstraction of reality dealt with by grid populating tones or objects, quantities, cojoined or open boundaries, and map relief schemas. Aerial photos are one commonly used form of raster data, with one primary purpose in mind: to display a detailed image on a map area, or for the purposes of rendering its identifiable objects by digitization. Additional raster data sets used by a GIS will contain information regarding elevation, a digital elevation model, or reflectance of a particular wavelength of light, Landsat, or other electromagnetic spectrum indicators. Raster data type consists of rows and columns of cells, with each cell storing a single value. Raster data can be images raster images with each pixel (or cell) containing a color value. Additional values recorded for each cell may be a discrete value, such as land use, a continuous value, such as temperature, or a null value if no data is available. While a raster cell stores a single value, it can be extended by using raster bands to represent RGB (red, green, blue) colors, colormaps (a mapping between a thematic code and RGB value), or an extended attribute table with one row for each unique cell value. The resolution of the raster data set is its cell width in ground units.",
            "score": 81.83559918403625
        },
        {
            "docid": "14530184_14",
            "document": "Vision in toads . First, the retina is connected to the optic tectum by at least three types of ganglion cells, each with an excitatory receptive field and a surrounding inhibitory receptive field, but they differ in the diameter of their central excitatory receptive fields. Diameters in Class II (R2) ganglion cells are approximately four degrees visual angle. Those in Class III (R3) cells are about eight degrees and Class IV (R4) ganglion cells range from twelve to fifteen degrees. As stimuli move across the toad's visual field, information is sent to the optic tectum in the toad's midbrain. The optic tectum exists as an ordered localization system, in the form of a topographical map. Each point on the map corresponds to a particular region of the toad's retina and thus its entire visual field. Likewise, when a spot on the tectum was electrically stimulated, the toad would turn toward a corresponding part of its visual field, providing further evidence of the direct spatial connections.",
            "score": 156.31255555152893
        },
        {
            "docid": "3242434_9",
            "document": "Retinal implant . Since the nerve fiber layer has similar stimulation threshold to that of the retinal ganglion cells, axons passing under the epiretinal electrodes are stimulated, creating arcuate percepts, and thereby distorting the retinotopic map. So far, none of the epiretinal implants had light-sensitive pixels, and hence they rely on external camera for capturing the visual information. Therefore, unlike natural vision, eye movements do not shift the transmitted image on the retina, which creates a perception of the moving object when person with such an implant changes the direction of gaze. Therefore, patients with such implants are asked to not move their eyes, but rather scan the visual field with their head. Additionally, encoding visual information at the ganglion cell layer requires very sophisticated image processing techniques in order to account for various types of the retinal ganglion cells encoding different features of the image.",
            "score": 172.67115890979767
        },
        {
            "docid": "26846987_11",
            "document": "Parasol cell . While neurons are typically studied by the extracellular use of metal electrodes, retinal ganglion cells are specifically studied in vitro. This method allows parasol cells' complicated and intertwined structure to be analyzed intracellularly. In 1941, Polyak was the first scientist to use Golgi staining to identify retinal ganglion cells. Here, dendritic morphology was closely analyzed and revealed large dendritic trees. Later in 1986, Kaplan and Shapley were then the first researchers to link parasol cells with the visual system. Recordings of S potentials at the axon terminals of RGCs in the LGN suggest that there is high contrast sensitivity in the cells terminating in the magnocellular layer of primates; opposed by low contrast sensitivity in cells found in the parvocellular layer. Both old and new world primates have been used as model systems for human vision and have subsequently been beneficial in researching parasol cells. Many retrograde labeling experiments using macaques, for example, have linked parasol and midget retinal ganglion cells with the magnocellular and parvocellular pathways respectively. In addition, similar studies have led to theories underlying color opponency. Research by Dacey (1996) supports this idea where in vitro primate retinal cells were treated with dye fillings. Parasol cells of the magnocellular pathway were found to be achromatic. In other studies, new world monkeys, such as marmosets, have aided in the current understanding of spatial and temporal frequency of the magnocellular layer in the LGN. Using the Nissl staining method, the magnocellular layer, in addition to the parvocellular layer, have darker and more dense cell bodies than the koniocellular layers, for example.",
            "score": 145.8841471672058
        },
        {
            "docid": "41121858_9",
            "document": "Binocular neurons . An energy model, a kind of stimulus-response model, of binocular neurons allows for investigation behind the computational function these disparity tuned cells play in the creation of depth perception. Energy models of binocular neurons involve the combination of monocular receptive fields that are either shifted in position or phase. These shifts in either position or phase allow for the simulated binocular neurons to be sensitive to disparity. The relative contributions of phase and position shifts in simple and complex cells combine together in order to create depth perception of an object in 3-dimensional space. Binocular simple cells are modeled as linear neurons. Due to the linear nature of these neurons, positive and negative values are encoded by two neurons where one neuron encodes the positive part and the other the negative part. This results in the neurons being complements of each other where the excitatory region of one binocular simple cell overlaps with the inhibitory region of another. Each neuron's response is limited such that only one may have a non-zero response for any time. This kind of limitation is called halfwave-rectifing. Binocular complex cells are modeled as energy neurons since they do not have discrete on and off regions in their receptive fields. Energy neurons sum the squared responses of two pairs of linear neurons which must be 90 degrees out of phase. Alternatively, they can also be the sum the squared responses of four halfwave-rectified linear neurons.",
            "score": 55.76969587802887
        },
        {
            "docid": "40466325_2",
            "document": "Cerebral organoid . A cerebral organoid describes artificially grown, in vitro, miniature organs resembling the brain.  Cerebral organoids are created by culturing human pluripotent stem cells in a three-dimensional rotational bioreactor and develop over a course of months. The human brain is an extremely complex system of heterogeneous tissues and consists of an extremely diverse array of neurons. This complexity  has made studying the brain and understanding how it works a difficult task in neuroscience, especially  when it comes to neurodegenerative diseases. The purpose of creating an in vitro neurological model is to  study these diseases in a more simple and variable space; free of in vivo limitations, especially when  working with humans. The varying physiology between human and other mammalian models limits the  scope of study in neurological disorders. Cerebral organoids are synthesized tissues that contain several types of nerve cells and have anatomical features that resemble mammalian brains. Cerebral organoids are most similar to layers of neurons called the cortex and choroid plexus. In some cases, structures similar to the retina, meninges and hippocampus can form. Stem cells have the potential to grow into many different types of tissues and their fate is dependent on many factors. Below is an image showing some of the chemical factors that can lead stem cells to differentiate into various neural tissues. Similar techniques are used on stem cells used to grow cerebral organoids.",
            "score": 150.63212668895721
        },
        {
            "docid": "49787567_4",
            "document": "Frank Werblin . In 1969, Werblin and Dowling published their seminal studies of the electrophysiological response properties of all the major neuron types in the vertebrate retina. The micropipette used to record from each cell contained a dye so that each physiologically identified cell could also be morphologically characterized within the layers of the retina. In 1978, he published the first isolated retinal slice preparation for a quicker and easier means to access all of the neurons in the various layers of the retina, while leaving the cells largely intact with their supporting matrix and synaptic connections and electrical junctions. However, because the retinal slice was isolated from the supportive retinal pigment epithelium (PE) that enables the light responses of photoreceptors, light evoked responses were not reported until the retinal slices were constructed with PE still attached. In this manner, whole cell patch recording of amacrine neurons in the salamander retina allowed light evoked excitatory post-synaptic currents (EPSCs) to be measured for the first time, as well as their light elicited spiking potentials, and voltage-gated currents. The new slice technique allowed, for the first time, a neuron to be characterized by its natural stimulus (light), and then to be fully characterized by its morphological, histological, electrophysiological (EPSCs, voltage gated currents, and graded and spike potentials), and chemical identity. The new light-responsive slice methodology also allowed interplexiform cells to be identified and characterized for the first time, as well as sustained and transient amacrine neurons. Precise localization of synaptic inputs to the cell, and localization of functional receptors in the cell was achieved. The slice technique would become a standard for retinal research and be developed for other animals with much smaller neurons, including the Zebrafish and rat. Werblin would then use these data to construct elegant models of visual information processing in the different layers of the retina.",
            "score": 187.26114356517792
        },
        {
            "docid": "54190649_17",
            "document": "Electrical capacitance volume tomography . Reconstruction methods address the inverse problem of ECVT imaging, i.e. to determine the volumetric permittivity distribution form the mutual capacitance measurements. Traditionally, the inverse problem is handled through the linearization of the (nonlinear) relationship between the capacitance and the material permittivity equation using the Born approximation. Typically, this approximation is only valid for small permittivity contrasts. For other cases, the nonlinear nature of the electric field distribution poses a challenge for both 2D and 3D image reconstruction, making the reconstruction methods an active research area for better image quality. Reconstruction methods for ECVT/ECT can be categorized as iterative and non-iterative (single step) methods. The examples of non-iterative methods are linear back projection (LBP), and direct method based on singular value decomposition and Tikhonov regularization. These algorithms are computationally inexpensive; however, their tradeoff is less accurate images without quantitative information. Iterative methods can be roughly classified into projection-based and optimization-based methods. Some of the linear projection iterative algorithms used for ECVT include Newton-Raphson, Landweber iteration and steepest descent algebraic reconstruction and simultaneous reconstruction techniques, and model-based iteration. Similar to single step methods, these algorithms also use linearized sensitivity matrix for the projections to obtain the permittivity distribution inside the domain. Projection-based iterative methods typically provide better images than non-iterative algorithms yet require more computational resources. The second type of iterative reconstruction methods are optimization-based reconstruction algorithms such as neural network optimization. These methods need more computational resources than the previously mentioned methods along with added complexity for the implementation. Optimization reconstruction methods employ multiple objective functions and use iterative process to minimize them. The resultant images contain less artifacts from the nonlinear nature and tend to be more reliable for quantitative applications.",
            "score": 85.04966509342194
        },
        {
            "docid": "25522368_8",
            "document": "Feature detection (nervous system) . In the late 1950s, Jerome Lettvin and his colleagues began to expand the feature detection hypothesis and clarify the relationship between single neurons and sensory perception. In their paper \"What the Frog's Eye Tells the Frog's Brain\", Lettvin et al. (1959) looked beyond the mechanisms for signal-noise discrimination in the frog's retina and were able to identify four classes of ganglion cells in the frog retina: \"sustained contrast detectors\", \"net convexity detectors\" (or \"bug detectors\"), \"moving edge detectors\", and \"net dimming detectors.\"  In the same year, David Hubel and Torsten Wiesel began investigating properties of neurons in the visual cortex of cats, processing in the mammalian visual system. In their first paper in 1959, Hubel and Wiesel took recording from single cells in the striate cortex of lightly anesthetized cats. The retinas of the cats were stimulated either individually or simultaneously with spots of light of various sizes and shapes. From the analysis of these recordings, Hubel and Wiesel identified orientation-selective cells in the cat's visual cortex and generated a map of the receptive field of cortical cells. At the time, circular spots of light were used as stimuli in studies of the visual cortex. However, Hubel and Wiesel noticed that rectangular bars of light were more effective stimuli (i.e. more natural stimuli) than circular spots of light, as long as the orientation was adjusted to the correct angle appropriate for each ganglion cell. These so-called simple cells were later called bar detectors or edge detectors. While comparing the receptive fields of neurons in the cat striate cortex with the concentric \"on\" and \"off\" receptive fields identified in cat ganglion cells by Kuffler et al., Hubel and Wiesel noticed that, although \"on\" and \"off\" regions were present in the striate cortex, they were not arranged in concentric circles. From their discovery of these uniquely orienting receptive fields, Hubel and Wiesel concluded that orientation-selective cells exist within the cat's visual cortex.",
            "score": 172.00304293632507
        },
        {
            "docid": "8297063_10",
            "document": "Spatial view cells . Current Research shows that the maximum firing rate of spatial view cells is obtained when the test agent is allowed to explore the environment freely. Tests in which the monkey was not allowed to have active locomotion provided very few results of spatial view cells being detected in the hippocampus. Majority of the experiments conducted for spatial view cells involved the use of macaque monkeys as test subjects. These types of cells are identified by monitoring the hippocampus of the monkeys while the brains are stimulated by presenting various images and objects in the monkey's vision. Various researchers use different methodologies in sync with the experiment being conducted in order to identify these spatial view cells. For example, in a delayed spatial response task, the monkey is shown a stimulus on one side of a screen and then the stimulus is taken away. After a short while, the stimulus is again presented to the monkey in the same location and the firing of the cell in the hippocampus that is specifically associated with the location at which the monkey is looking and is independent of the location of the monkey helps identify the spatial view cell. The monkeys in this of experiment are encouraged by rewarding them with fruit juice when they correctly identify the same object in the same location twice in a row and if they get it incorrect, the monkeys receive a saline taste.",
            "score": 105.66081976890564
        },
        {
            "docid": "22155527_23",
            "document": "Bioimage informatics . Cell image segmentation as an important procedure is often used to study gene expression and colocalization relationship etc. of individual cells. In such cases of single-cell analysis it is often needed to uniquely determine the identities of cells while segmenting the cells. Such a recognition task is often non-trivial computationally. For model organisms such as C. elegans that have well-defined cell lineages, it is possible to explicitly recognize the cell identities via image analysis, by combining both image segmentation and pattern recognition methods. Simultaneous segmentation and recognition of cells has also been proposed as a more accurate solution for this problem when an \"atlas\" or other prior information of cells is available. Since gene expression at single cell resolution can be obtained using these types of imaging based approaches, it is possible to combine these methods with other single cell gene expression quantification methods such as RNAseq.",
            "score": 68.5849449634552
        },
        {
            "docid": "51517174_6",
            "document": "Axiomatic theory of receptive fields . Theoretical arguments have been presented of preferring this generalized Gaussian model of receptive fields over a Gabor model of receptive fields, because of the better theoretical properties of the generalized Gaussian model under natural image transformations. Specifically, these generalized Gaussian receptive fields can be shown to enable computation of \"invariant visual representations under natural image transformations\". By these results, the different shapes of receptive field profiles found in biological vision, which are tuned to different sizes and orientations in the image domain as well as to different image velocities in space-time, can be seen as well adapted to structure of the physical world and be explained from the requirement that the visual system should have the possibility of being invariant to the natural types of image transformations that occur in its environment.",
            "score": 85.07188498973846
        },
        {
            "docid": "35522851_5",
            "document": "Retinal waves . As the idea of retinal waves became established, neurobiologist Carla Shatz used calcium imaging and microelectrode recording to visualize the movement of action potentials in a wave-like formation. For more information on calcium imaging and microelectrode recording, see section below. The calcium imaging showed ganglion cells initiating the formation of retinal waves, along with adjacent amacrine cells, which take part in the movement of the electrical activity. Microelectrode recordings were also thought to show LGN neurons being driven by the wave-like formation of electrical activity across neighboring retinal ganglion cells. From these results, it was suggested that the waves of electrical activity were responsible for driving the pattern of spatiotemporal activity and also playing a role in the formation of the visual system during prenatal development.",
            "score": 128.75897705554962
        },
        {
            "docid": "8285473_2",
            "document": "Cell fate determination . Within the field of developmental biology one goal is to understand how a particular cell (or embryo) develops into the final cell type (or organism), essentially how a cell's fate is determined. Within an embryo, 4 processes play out at the cellular and tissue level to essentially create the final organism. These processes are cell proliferation, cell specialization, cell interaction and cell movement. Each cell in the embryo receives and gives cues to its neighboring cells and retains a cell memory of its own cell proliferation history. Almost all animals undergo a similar sequence of events during embryogenesis and have, at least at this developmental stage, the three germ layers and undergo gastrulation. While embryogenesis has been studied for more than a century, it was only recently (the past 15 years or so) that scientists discovered that a basic set of the same proteins and mRNAs are involved in all of embryogenesis. This is one of the reasons that model systems such as the fly (\"Drosophila melanogaster\"), the mouse (Muridae), and the leech (\"Helobdella\"), can all be used to study embryogenesis and developmental biology relevant to other animals, including humans. The fate map of the nematode (\"Caenorhabditis)\" can be analyzed down to the cellular level. This is due no cell mixing during development. What continues to be discovered and investigated is how the basic set of proteins (and mRNAs) are expressed differentially between cells types, temporally and spatially; and whether this is responsible for the vast diversity of organisms produced. This leads to one of the key questions of developmental biology of how is cell fate determined.",
            "score": 82.85090672969818
        },
        {
            "docid": "22391885_6",
            "document": "Neural processing for individual categories of objects . It may be that the use of distinct brain regions for processing different object categories results from different processing requirements necessary for each class. Indeed, Malach et al. (2002) detail findings that buildings and faces require processing at different resolutions in order to be recognised - face recognition requires the analysis of fine detail, while buildings can be recognised using larger scale feature integration. As a result, faces are associated with central visual field processing while buildings are processed more peripherally. Malach et al. (2002) report that points on the retina sharing foveal centricity are mapped onto parallel cortical bands and it therefore follows that object classes that are processed differently by retinal cells should be represented distinctly within the brain. Consistently, faces and buildings were found to be processed independently of each other and in discrete cortical regions suggesting that processing is facilitated by assigning object categories to distinct cortical regions according to the level and type of processing that they require.",
            "score": 146.50224018096924
        },
        {
            "docid": "41121858_3",
            "document": "Binocular neurons . In the 19th century Charles Wheatstone determined that retinal disparity was a large contributor to depth perception. Using a stereoscope, he showed that horizontal disparity is used by the brain to calculate the relative depths of different objects in 3-dimensional space in reference to a fixed point. This process is called stereopsis. Two main classes of cells in visual cortex were identified by David H. Hubel and Torsten Wiesel in 1962 through their investigation of the cat's primary visual cortex. These classes were called simple and complex cells, which differ in how their receptive fields respond to light and dark stimuli. B\u00e9la Julesz in 1971 used random dot stereograms to find that monocular depth cues, such as shading, are not required for stereoscopic vision. Disparity selective cells were first recorded in the striate cortex (V1) of the cat by Peter Orlebar Bishop and John Douglas Pettigrew in the late 1960s, however this discovery was unexpected and was not published until 1986. These disparity selective cells, also known as binocular neurons, were again found in the awake behaving macaque monkey in 1985. Additionally, population responses of binocular neurons have been found in human ventral and dorsal pathways using fMRI.",
            "score": 124.55104064941406
        },
        {
            "docid": "10913_21",
            "document": "Fractal . Modeled fractals may be sounds, digital images, electrochemical patterns, circadian rhythms, etc. Fractal patterns have been reconstructed in physical 3-dimensional space and virtually, often called \"in silico\" modeling. Models of fractals are generally created using fractal-generating software that implements techniques such as those outlined above. As one illustration, trees, ferns, cells of the nervous system, blood and lung vasculature, and other branching patterns in nature can be modeled on a computer by using recursive algorithms and L-systems techniques. The recursive nature of some patterns is obvious in certain examples\u2014a branch from a tree or a frond from a fern is a miniature replica of the whole: not identical, but similar in nature. Similarly, random fractals have been used to describe/create many highly irregular real-world objects. A limitation of modeling fractals is that resemblance of a fractal model to a natural phenomenon does not prove that the phenomenon being modeled is formed by a process similar to the modeling algorithms.",
            "score": 64.05717182159424
        },
        {
            "docid": "237704_36",
            "document": "Saccharomyces cerevisiae . Ruderfer et al. (2006) analyzed the ancestry of natural \"S. cerevisiae\" strains and concluded that outcrossing occurs only about once every 50,000 cell divisions. Thus, it appears that in nature, mating is likely most often between closely related yeast cells. Mating occurs when haploid cells of opposite mating type MATa and MAT\u03b1 come into contact. Ruderfer et al. pointed out that such contacts are frequent between closely related yeast cells for two reasons. The first is that cells of opposite mating type are present together in the same ascus, the sac that contains the cells directly produced by a single meiosis, and these cells can mate with each other. The second reason is that haploid cells of one mating type, upon cell division, often produce cells of the opposite mating type with which they can mate. The relative rarity in nature of meiotic events that result from outcrossing is inconsistent with the idea that production of genetic variation is the main selective force maintaining meiosis in this organism. However, this finding is consistent with the alternative idea that the main selective force maintaining meiosis is enhanced recombinational repair of DNA damage, since this benefit is realized during each meiosis, whether or not out-crossing occurs.",
            "score": 64.98885893821716
        },
        {
            "docid": "3343370_25",
            "document": "Mating of yeast . Ruderfer et al. analyzed the ancestry of natural \"S. cerevisiae\" strains and concluded that matings involving out-crossing occur only about once every 50,000 cell divisions. Thus it appears that, in nature, mating is most often between closely related yeast cells. Mating occurs when haploid cells of opposite mating type \"MATa and \"MAT\u03b1 come into contact. Ruderfer et al. pointed out that such contacts are frequent between closely related yeast cells for two reasons. The first is that cells of opposite mating type are present together in the same ascus, the sac that contains the cells directly produced by a single meiosis, and these cells can mate with each other. The second reason is that haploid cells of one mating type, upon cell division, often produce cells of the opposite mating type with which they can mate (see section \u201cMating type switching\u201d, above). The relative rarity in nature of meiotic events that result from out-crossing appears to be inconsistent with the idea that production of genetic variation is the primary selective force maintaining mating capability in this organism. However this finding is consistent with the alternative idea that the primary selective force maintaining mating capability is enhanced recombinational repair of DNA damage during meiosis, since this benefit is realized during each meiosis subsequent to a mating, whether or not out-crossing occurs.",
            "score": 64.83253276348114
        },
        {
            "docid": "5198024_16",
            "document": "Efficient coding hypothesis . In a report in \"Science\" from 2000, William E. Vinje and Jack Gallant outlined a series of experiments used to test elements of the efficient coding hypothesis, including a theory that the non-classical receptive field (nCRF) decorrelates projections from the primary visual cortex. To test this, they took recordings from the V1 neurons in awake macaques during \"free viewing of natural images and conditions\" that simulated natural vision conditions. The researchers hypothesized that the V1 uses sparse code, which is minimally redundant and \"metabolically more efficient\". They also hypothesized that interactions between the classical receptive field (CRF) and the nCRF produced this pattern of sparse coding during the viewing of these natural scenes. In order to test this, they created eye-scan paths and also extracted patches that ranged in size from 1-4 times the diameter of the CRF. They found that the sparseness of the coding increased with the size of the patch. Larger patches encompassed more of the nCRF\u2014indicating that the interactions between these two regions created sparse code. Additionally as stimulus size increased, so did the sparseness. This suggests that the V1 uses sparse code when natural images span the entire visual field. The CRF was defined as the circular area surrounding the locations where stimuli evoked action potentials. They also tested to see if the stimulation of the nCRF increased the independence of the responses from the V1 neurons by randomly selecting pairs of neurons. They found that indeed, the neurons were more greatly decoupled upon stimulation of the nCRF. In conclusion, the experiments of Vinje and Gallant showed that the V1 uses sparse code by employing both the CRF and nCRF when viewing natural images, with the nCRF showing a definitive decorrelating effect on neurons which may increase their efficiency by increasing the amount of independent information they carry. They propose that the cells may represent the individual components of a given natural scene, which may contribute to pattern recognition",
            "score": 98.46868693828583
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 157.0470175743103
        },
        {
            "docid": "1887433_5",
            "document": "Visual phototransduction . The photoreceptor cells involved in vision are the rods and cones. These cells contain a chromophore (11-cis retinal, the aldehyde of Vitamin A1 and light-absorbing portion) bound to cell membrane protein, opsin. Rods deal with low light level and do not mediate color vision. Cones, on the other hand, can code the color of an image through comparison of the outputs of the three different types of cones. Each cone type responds best to certain wavelengths, or colors, of light because each type has a slightly different opsin. The three types of cones are L-cones, M-cones and S-cones that respond optimally to long wavelengths (reddish color), medium wavelengths (greenish color), and short wavelengths (bluish color) respectively. Humans have a trichromatic visual system consisting of three unique systems, rods, mid and long-wavelength sensitive (red and green) cones and short wavelength sensitive (blue) cones.",
            "score": 120.85853910446167
        },
        {
            "docid": "941909_11",
            "document": "Receptive field . The receptive field is often identified as the region of the retina where the action of light alters the firing of the neuron. In retinal ganglion cells (see below), this area of the retina would encompass all the photoreceptors, all the rods and cones from one eye that are connected to this particular ganglion cell via bipolar cells, horizontal cells, and amacrine cells. In binocular neurons in the visual cortex, it is necessary to specify the corresponding area in both retinas (one in each eye). Although these can be mapped separately in each retina by shutting one or the other eye, the full influence on the neuron's firing is revealed only when both eyes are open.",
            "score": 146.89684438705444
        }
    ],
    "r": [
        {
            "docid": "24990312_3",
            "document": "Optics and vision . The visual system in humans allows individuals to assimilate information from the environment. The act of seeing starts when the lens of the eye focuses an image of its surroundings onto a light-sensitive membrane in the back of the eye, called the retina. The retina converts patterns of light into neuronal signals. The lens of the eye focuses light on the photoreceptive cells of the retina, which detect the photons of light and respond by producing neural impulses. These signals are processed in a hierarchical fashion by different parts of the brain, from the retina to the lateral geniculate nucleus, to the primary and secondary visual cortex of the brain. Signals from the retina can also travel directly from the retina to the Superior colliculus.",
            "score": 228.11434936523438
        },
        {
            "docid": "305136_25",
            "document": "Visual system . The information about the image via the eye is transmitted to the brain along the optic nerve. Different populations of ganglion cells in the retina send information to the brain through the optic nerve. About 90% of the axons in the optic nerve go to the lateral geniculate nucleus in the thalamus. These axons originate from the M, P, and K ganglion cells in the retina, see above. This parallel processing is important for reconstructing the visual world; each type of information will go through a different route to perception. Another population sends information to the superior colliculus in the midbrain, which assists in controlling eye movements (saccades) as well as other motor responses.",
            "score": 216.40773010253906
        },
        {
            "docid": "401150_15",
            "document": "Photoreceptor cell . The process of phototransduction occurs in the retina. The retina has many layers of various cell types. The best-known photoreceptor cells (\"rods\" and \"cones\") form the outermost layer. They are the photoreceptors responsible for sight. The middle layer contains bipolar cells, which collect neural signals from the rods and the cones and then transmit them to the innermost layer of the retina, where the neurons called retinal ganglion cells (RGCs), a small percentage of which are themselves photosensitive, organize the signals and send them to the brain.",
            "score": 215.6614227294922
        },
        {
            "docid": "801776_2",
            "document": "Retinal ganglion cell . A retinal ganglion cell (RGC) is a type of neuron located near the inner surface (the ganglion cell layer) of the retina of the eye. It receives visual information from photoreceptors via two intermediate neuron types: bipolar cells and retina amacrine cells. Retina amacrine cells, particularly narrow field cells, are important for creating functional subunits within the ganglion cell layer and making it so that ganglion cells can observe a small dot moving a small distance. Retinal ganglion cells collectively transmit image-forming and non-image forming visual information from the retina in the form of action potential to several regions in the thalamus, hypothalamus, and mesencephalon, or midbrain.",
            "score": 215.25161743164062
        },
        {
            "docid": "490620_37",
            "document": "Human brain . Vision is generated by light that hits the retina of the eye. Photoreceptors in the retina transduce the sensory stimulus of light into an electrical nerve signal that is sent to the visual cortex in the occipital lobe. Vision from the left visual field is received on the right side of each retina (and vice versa) and passes through the optic nerve until some information changes sides, so that all information about one side of the visual field passes through tracts in the opposite side of the brain. The nerves reach the brain at the lateral geniculate nucleus, and travel through the optic radiation to reach the visual cortex.",
            "score": 214.27886962890625
        },
        {
            "docid": "25140_40",
            "document": "Perception . In many ways, vision is the primary human sense. Light is taken in through each eye and focused in a way which sorts it on the retina according to direction of origin. A dense surface of photosensitive cells, including rods, cones, and intrinsically photosensitive retinal ganglion cells captures information about the intensity, color, and position of incoming light. Some processing of texture and movement occurs within the neurons on the retina before the information is sent to the brain. In total, about 15 differing types of information are then forwarded to the brain proper via the optic nerve.",
            "score": 206.75621032714844
        },
        {
            "docid": "21280496_4",
            "document": "Visual perception . The visual system in animals allows individuals to assimilate information from their surroundings. The act of seeing starts when the cornea and then the lens of the eye focuses light from its surroundings onto a light-sensitive membrane in the back of the eye, called the retina. The retina is actually part of the brain that is isolated to serve as a transducer for the conversion of light into neuronal signals. Based on feedback from the visual system, the lens of the eye adjusts its thickness to focus light on the photoreceptive cells of the retina, also known as the rods and cones, which detect the photons of light and respond by producing neural impulses. These signals are processed via complex feedforward and feedback processes by different parts of the brain, from the retina upstream to central ganglia in the brain.",
            "score": 205.8486328125
        },
        {
            "docid": "2961628_5",
            "document": "Special senses . The visual system in animals allows individuals to assimilate information from their surroundings. The act of seeing starts when the cornea and then the lens of the eye focuses light from its surroundings onto a light-sensitive membrane in the back of the eye, called the retina. The retina is actually part of the brain that is isolated to serve as a transducer for the conversion of light into neuronal signals. Based on feedback from the visual system, the lens of the eye adjusts its thickness to focus light on the photoreceptive cells of the retina, also known as the rods and cones, which detect the photons of light and respond by producing neural impulses. These signals are processed via complex feedforward and feedback processes by different parts of the brain, from the retina upstream to central ganglia in the brain.",
            "score": 203.12738037109375
        },
        {
            "docid": "14470771_4",
            "document": "Light effects on circadian rhythm . Light first passes into a mammal's system through the retina, then takes one of two paths: the light either gets collected by rod cells and cone cells before being transmitted to the retinal ganglion cells (RGCs), or it is directly collected by these RGCs. The RGCs use the photopigment melanopsin to absorb the light energy. Specifically, this class of RGCs being discussed is referred to as \"intrinsically photosensitive,\" which just means they are sensitive to light. There are five known types of intrinsically photosensitive retinal ganglion cells (ipRGCs): M1, M2, M3, M4, and M5. These connect to amacrine cells in the inner plexiform layer of the retina. Ultimately, via this retinohypothalamic tract (RHT) the suprachiasmatic nucleus (SCN) of the hypothalamus receives light information from these ipRCGs.",
            "score": 202.83340454101562
        },
        {
            "docid": "646563_12",
            "document": "Briard . This breed is also commonly screened for congenital stationary night blindness (SNB) with a DNA test. SNB is inherited through recessive genes. Progressive retinal atrophy PRA, is a disease that causes nerve cells at the back of the eye to degenerate. The condition usually begins in older pets and can lead to blindness. Progressive retinal degeneration or atrophy (PRD/PRA) represents a group of inherited eye diseases characterized by abnormal development or premature degeneration of the retina. There are two types of photoreceptors in the retina and these are the light-sensitive rods and cones. They are responsible for detecting light and converting it into an electrical signal that travels to the brain. When the photoreceptor cells deteriorate, vision is lost because the animal has no way to generate an image from the light reaching the retina. Puppies are usually blind before one year of age. For the first time ever, animals (Briards) that were born blind gained the ability to see after undergoing gene therapy, according to research from the University of Florida, Cornell University and the University of Pennsylvania. UF researchers had established that the apparently harmless adeno-associated virus can carry healthy copies of a gene into the cells of the retina, which is composed of layers of light-sensitive nerve cells. The healthy gene's mission: to produce a protein critical to translating light waves into nerve impulses that can be interpreted as images by the brain. The study was successful and the puppies could see in the eye that was treated. Officials from the Foundation Fighting Blindness, which supported the study with grant funds, said the success in reversing blindness in dogs is an important advance.",
            "score": 199.74424743652344
        },
        {
            "docid": "305136_18",
            "document": "Visual system . In the retina, the photoreceptors synapse directly onto bipolar cells, which in turn synapse onto ganglion cells of the outermost layer, which will then conduct action potentials to the brain. A significant amount of visual processing arises from the patterns of communication between neurons in the retina. About 130 million photo-receptors absorb light, yet roughly 1.2 million axons of ganglion cells transmit information from the retina to the brain. The processing in the retina includes the formation of center-surround receptive fields of bipolar and ganglion cells in the retina, as well as convergence and divergence from photoreceptor to bipolar cell. In addition, other neurons in the retina, particularly horizontal and amacrine cells, transmit information laterally (from a neuron in one layer to an adjacent neuron in the same layer), resulting in more complex receptive fields that can be either indifferent to color and sensitive to motion or sensitive to color and indifferent to motion.",
            "score": 198.89622497558594
        },
        {
            "docid": "305136_16",
            "document": "Visual system . The retina consists of a large number of photoreceptor cells which contain particular protein molecules called opsins. In humans, two types of opsins are involved in conscious vision: rod opsins and cone opsins. (A third type, melanopsin in some of the retinal ganglion cells (RGC), part of the body clock mechanism, is probably not involved in conscious vision, as these RGC do not project to the lateral geniculate nucleus but to the pretectal olivary nucleus.) An opsin absorbs a photon (a particle of light) and transmits a signal to the cell through a signal transduction pathway, resulting in hyper-polarization of the photoreceptor.",
            "score": 198.3540496826172
        },
        {
            "docid": "48334_4",
            "document": "Retina . Light striking the retina initiates a cascade of chemical and electrical events that ultimately trigger nerve impulses that are sent to various visual centres of the brain through the fibres of the optic nerve. Neural signals from the rods and cones undergo processing by other neurons, whose output takes the form of action potentials in retinal ganglion cells whose axons form the optic nerve. Several important features of visual perception can be traced to the retinal encoding and processing of light.",
            "score": 193.982666015625
        },
        {
            "docid": "33246145_4",
            "document": "Neural decoding . When looking at a picture, people's brains are constantly making decisions about what object they are looking at, where they need to move their eyes next, and what they find to be the most salient aspects of the input stimulus. As these images hit the back of the retina, these stimuli are converted from varying wavelengths to a series of neural spikes called action potentials. These pattern of action potentials are different for different objects and different colors; we therefore say that the neurons are encoding objects and colors by varying their spike rates or temporal pattern. Now, if someone were to probe the brain by placing electrodes in the primary visual cortex, they may find what appears to be random electrical activity. These neurons are actually firing in response to the lower level features of visual input, possibly the edges of a picture frame. This highlights the crux of the neural decoding hypothesis: that it is possible to reconstruct a stimulus from the response of the ensemble of neurons that represent it. In other words, it is possible to look at spike train data and say that the person or animal being recorded is looking at a red ball.",
            "score": 192.3160400390625
        },
        {
            "docid": "23416874_9",
            "document": "Sense . Sight or vision (adjectival form: visual/optical) is the capability of the eye(s) to focus and detect images of visible light on photoreceptors in the retina of each eye that generates electrical nerve impulses for varying colors, hues, and brightness. There are two types of photoreceptors: rods and cones. Rods are very sensitive to light, but do not distinguish colors. Cones distinguish colors, but are less sensitive to dim light. There is some disagreement as to whether this constitutes one, two or three senses. Neuroanatomists generally regard it as two senses, given that different receptors are responsible for the perception of color and brightness. Some argue that stereopsis, the perception of depth using both eyes, also constitutes a sense, but it is generally regarded as a cognitive (that is, post-sensory) function of the visual cortex of the brain where patterns and objects in images are recognized and interpreted based on previously learned information. This is called visual memory.",
            "score": 190.713134765625
        },
        {
            "docid": "305136_29",
            "document": "Visual system . The lateral geniculate nucleus (LGN) is a sensory relay nucleus in the thalamus of the brain. The LGN consists of six layers in humans and other primates starting from catarhinians, including cercopithecidae and apes. Layers 1, 4, and 6 correspond to information from the contralateral (crossed) fibers of the nasal retina (temporal visual field); layers 2, 3, and 5 correspond to information from the ipsilateral (uncrossed) fibers of the temporal retina (nasal visual field). Layer one (1) contains M cells which correspond to the M (magnocellular) cells of the optic nerve of the opposite eye and are concerned with depth or motion. Layers four and six (4 & 6) of the LGN also connect to the opposite eye, but to the P cells (color and edges) of the optic nerve. By contrast, layers two, three and five (2, 3, & 5) of the LGN connect to the M cells and P (parvocellular) cells of the optic nerve for the same side of the brain as its respective LGN. Spread out, the six layers of the LGN are the area of a credit card and about three times its thickness. The LGN is rolled up into two ellipsoids about the size and shape of two small birds' eggs. In between the six layers are smaller cells that receive information from the K cells (color) in the retina. The neurons of the LGN then relay the visual image to the primary visual cortex (V1) which is located at the back of the brain (posterior end) in the occipital lobe in and close to the calcarine sulcus. The LGN is not just a simple relay station but it is also a center for processing; it receives reciprocal input from the cortical and subcortical layers and reciprocal innervation from the visual cortex.",
            "score": 190.6297149658203
        },
        {
            "docid": "32197396_4",
            "document": "Form perception . In addition to photoreceptors, the eye requires a properly functioning lens, retina, and an undamaged optic nerve to recognize form. Light travels through the lens, hits the retina, activates the appropriate photoreceptors, depending on available light, which convert the light into an electrical signal that travels along the optic nerve to the lateral geniculate nucleus of the thalamus and then to the primary visual cortex. In the cortex, the adult brain processes information such as lines, orientation, and color. These inputs are integrated in the occipito-temporal cortex where a representation of the object as a whole is created. Visual information continues to be processed in the posterior parietal cortex, also known as the dorsal stream, where the representation of an object\u2019s shape is formed using motion-based cues. It is believed that simultaneously information is processed in the anterior temporal cortex, also known as the ventral stream, where object recognition, identification and naming occur. In the process of recognizing an object, both the dorsal and ventral streams are active, but the ventral stream is more important in discriminating between and recognizing objects. The dorsal stream contributes to object recognition only when two objects have similar shapes and the images are degraded. Observed latency in activation of different parts of the brain supports the idea of hierarchal processing of visual stimuli, with object representations progressing from simple to complex.",
            "score": 190.29669189453125
        },
        {
            "docid": "49787567_4",
            "document": "Frank Werblin . In 1969, Werblin and Dowling published their seminal studies of the electrophysiological response properties of all the major neuron types in the vertebrate retina. The micropipette used to record from each cell contained a dye so that each physiologically identified cell could also be morphologically characterized within the layers of the retina. In 1978, he published the first isolated retinal slice preparation for a quicker and easier means to access all of the neurons in the various layers of the retina, while leaving the cells largely intact with their supporting matrix and synaptic connections and electrical junctions. However, because the retinal slice was isolated from the supportive retinal pigment epithelium (PE) that enables the light responses of photoreceptors, light evoked responses were not reported until the retinal slices were constructed with PE still attached. In this manner, whole cell patch recording of amacrine neurons in the salamander retina allowed light evoked excitatory post-synaptic currents (EPSCs) to be measured for the first time, as well as their light elicited spiking potentials, and voltage-gated currents. The new slice technique allowed, for the first time, a neuron to be characterized by its natural stimulus (light), and then to be fully characterized by its morphological, histological, electrophysiological (EPSCs, voltage gated currents, and graded and spike potentials), and chemical identity. The new light-responsive slice methodology also allowed interplexiform cells to be identified and characterized for the first time, as well as sustained and transient amacrine neurons. Precise localization of synaptic inputs to the cell, and localization of functional receptors in the cell was achieved. The slice technique would become a standard for retinal research and be developed for other animals with much smaller neurons, including the Zebrafish and rat. Werblin would then use these data to construct elegant models of visual information processing in the different layers of the retina.",
            "score": 187.2611541748047
        },
        {
            "docid": "157898_57",
            "document": "Eye . Cones are responsible for colour vision. They require brighter light to function than rods require. In humans, there are three types of cones, maximally sensitive to long-wavelength, medium-wavelength, and short-wavelength light (often referred to as red, green, and blue, respectively, though the sensitivity peaks are not actually at these colours). The colour seen is the combined effect of stimuli to, and responses from, these three types of cone cells. Cones are mostly concentrated in and near the fovea. Only a few are present at the sides of the retina. Objects are seen most sharply in focus when their images fall on the fovea, as when one looks at an object directly. Cone cells and rods are connected through intermediate cells in the retina to nerve fibres of the optic nerve. When rods and cones are stimulated by light, they connect through adjoining cells within the retina to send an electrical signal to the optic nerve fibres. The optic nerves send off impulses through these fibres to the brain.",
            "score": 186.30709838867188
        },
        {
            "docid": "18416476_20",
            "document": "Bird vision . The four spectrally distinct cone pigments are derived from the protein opsin, linked to a small molecule called retinal, which is closely related to vitamin A. When the pigment absorbs light the retinal changes shape and alters the membrane potential of the cone cell affecting neurons in the ganglia layer of the retina. Each neuron in the ganglion layer may process information from a number of photoreceptor cells, and may in turn trigger a nerve impulse to relay information along the optic nerve for further processing in specialised visual centres in the brain. The more intense a light, the more photons are absorbed by the visual pigments; the greater the excitation of each cone, and the brighter the light appears.",
            "score": 184.4457244873047
        },
        {
            "docid": "27108706_3",
            "document": "Gene therapy for color blindness . The retina of the human eye contains photoreceptive cells called cones that allow color vision. A normal trichromat individual possesses three different types of cones to distinguish different colors within the visible spectrum from 380\u00a0nm to 740\u00a0nm. The three types of cones are designated L, M, and S cones, and each type is sensitive to a certain range of wavelength of light depending on what photopigment it contains. More specifically, the L cone absorbs around 560\u00a0nm, the M cone absorbs near 530\u00a0nm, and the S cone absorbs near 420\u00a0nm. Contrary to popular belief, the peak absorption frequency for L, M, and S cones do not exactly correspond to red, green, and blue wavelength. Rather, the peak frequency for the L cone is orange, yellowish green in M cones, and blue-violet in S cones. These cones transduce the absorbed light into electrical information to be relayed to neurons in the retina such as retinal bipolar cells and retinal ganglion cells, before reaching the brain.",
            "score": 184.36578369140625
        },
        {
            "docid": "1894873_3",
            "document": "Eye movement . The eyes are the visual organs of the human body, and move using a system of six muscles. The retina, a specialised type of tissue containing photoreceptors, senses light. These specialised cells convert light into electrochemical signals. These signals travel along the optic nerve fibers to the brain, where they are interpreted as vision in the visual cortex.",
            "score": 181.62142944335938
        },
        {
            "docid": "29150377_11",
            "document": "Empirical theory of perception . Color vision is dependent on activation of three cone cell types in the human retina, each of which is primarily responsive to a different spectrum of light frequencies. While these retinal mechanisms enable subsequent color processing, their properties alone cannot account for the full range of color perception phenomena. In part this is due to the fact that illuminance (the amount of light shining on an object), reflectance (the amount of light an object is predisposed to reflect), and transmittance (the extent to which the light medium distorts the light as it travels) are conflated in the retinal image. This is problematic because, if color vision is to be useful, it must somehow guide behavior in line with these properties. Even so, the visual system only has access to retinal input, which does not distinguish the relative contributions of each of these factors to the final light spectra that stimulate the retina.",
            "score": 176.080078125
        },
        {
            "docid": "157898_5",
            "document": "Eye . The first proto-eyes evolved among animals about the time of the Cambrian explosion. The last common ancestor of animals possessed the biochemical toolkit necessary for vision, and more advanced eyes have evolved in 96% of animal species in six of the ~35 main phyla. In most vertebrates and some molluscs, the eye works by allowing light to enter and project onto a light-sensitive panel of cells, known as the retina, at the rear of the eye. The cone cells (for colour) and the rod cells (for low-light contrasts) in the retina detect and convert light into neural signals for vision. The visual signals are then transmitted to the brain via the optic nerve. Such eyes are typically roughly spherical, filled with a transparent gel-like substance called the vitreous humour, with a focusing lens and often an iris; the relaxing or tightening of the muscles around the iris change the size of the pupil, thereby regulating the amount of light that enters the eye, and reducing aberrations when there is enough light. The eyes of most cephalopods, fish, amphibians and snakes have fixed lens shapes, and focusing vision is achieved by telescoping the lens\u2014similar to how a camera focuses.",
            "score": 175.6754913330078
        },
        {
            "docid": "16176078_26",
            "document": "Cat health . The retina, a thin layer of tissue in the back of the eye, is the structure affected by this disorder. This structure receives the light gathered and focused from the lens. It essentially take light and converts it into electrical nerve signals that the brain interprets as vision. The retina contains rods and cones which are photo-receptors that help the animal see (rods) and see certain colours (cones).",
            "score": 175.64137268066406
        },
        {
            "docid": "21944_40",
            "document": "Nervous system . Feature detection is the ability to extract biologically relevant information from combinations of sensory signals. In the visual system, for example, sensory receptors in the retina of the eye are only individually capable of detecting \"points of light\" in the outside world. Second-level visual neurons receive input from groups of primary receptors, higher-level neurons receive input from groups of second-level neurons, and so on, forming a hierarchy of processing stages. At each stage, important information is extracted from the signal ensemble and unimportant information is discarded. By the end of the process, input signals representing \"points of light\" have been transformed into a neural representation of objects in the surrounding world and their properties. The most sophisticated sensory processing occurs inside the brain, but complex feature extraction also takes place in the spinal cord and in peripheral sensory organs such as the retina.",
            "score": 175.17745971679688
        },
        {
            "docid": "31329046_6",
            "document": "Pre-attentive processing . Information for pre-attentive processing is detected through the five senses. In the visual system, the receptive fields at the back of the eye (retina) transfer the image via axons to the thalamus, specifically the lateral geniculate nuclei. The image then travels to the primary visual cortex and continues on to be processed by the visual association cortex. At each stage, the image is processed with increasing complexity. Pre-attentive processing starts with the retinal image; this image is magnified as it moves from retina to the cortex of the brain. Shades of light and dark are processed in the lateral geniculate nuclei of the thalamus. Simple and complex cells in the brain process boundary and surface information by deciphering the image's contrast, orientation, and edges. When the image hits the fovea, it is highly magnified, facilitating object recognition. The images in the periphery are less clear but help to create a complete image used for scene perception.",
            "score": 175.03208923339844
        },
        {
            "docid": "55932268_31",
            "document": "Cat cognitive support diets . The retina, a thin layer of tissue in the back of the eye, is the structure affected by this disorder. This structure receives the light gathered and focused from the lens. It essentially take light and converts it into electrical nerve signals that the brain interprets as vision. The retina contains rods and cones which are photo-receptors that help the animal see (rods) and see certain colours (cones).",
            "score": 174.19955444335938
        },
        {
            "docid": "17198736_16",
            "document": "Visual prosthesis . Patients with retinitis pigmentosa will be the first to participate in the studies, followed by age-related macular degeneration. Each prototype consists of a camera, attached to a pair of glasses which sends the signal to the implanted microchip, where it is converted into electrical impulses to stimulate the remaining healthy neurons in the retina. This information is then passed on to the optic nerve and the vision processing centres of the brain.",
            "score": 173.7141571044922
        },
        {
            "docid": "379957_12",
            "document": "Lateral geniculate nucleus . Both the LGN in the right hemisphere and the LGN in the left hemisphere receive input from each eye. However, each LGN only receives information from one half of the visual field. This occurs due to axons of the ganglion cells from the inner halves of the retina (the nasal sides) decussating (crossing to the other side of the brain) through the optic chiasma (\"khiasma\" means \"cross-shaped\"). The axons of the ganglion cells from the outer half of the retina (the temporal sides) remain on the same side of the brain. Therefore, the right hemisphere receives visual information from the left visual field, and the left hemisphere receives visual information from the right visual field.  Within one LGN, the visual information is divided among the various layers as follows:",
            "score": 173.422119140625
        },
        {
            "docid": "48334_14",
            "document": "Retina . In adult humans, the entire retina is approximately 72% of a sphere about 22\u00a0mm in diameter. The entire retina contains about 7 million cones and 75 to 150 million rods. The optic disc, a part of the retina sometimes called \"the blind spot\" because it lacks photoreceptors, is located at the optic papilla, where the optic-nerve fibres leave the eye. It appears as an oval white area of 3\u00a0mm\u00b2. Temporal (in the direction of the temples) to this disc is the macula, at whose centre is the fovea, a pit that is responsible for our sharp central vision but is actually less sensitive to light because of its lack of rods. Human and non-human primates possess one fovea, as opposed to certain bird species, such as hawks, who are bifoviate, and dogs and cats, who possess no fovea but a central band known as the visual streak. Around the fovea extends the central retina for about 6\u00a0mm and then the peripheral retina. The farthest edge of the retina is defined by the ora serrata. The distance from one ora to the other (or macula), the most sensitive area along the horizontal meridian is about 32\u00a0mm.",
            "score": 173.2085723876953
        },
        {
            "docid": "48334_2",
            "document": "Retina . The retina is the innermost, light-sensitive \"coat\", or layer, of shell tissue of the eye of most vertebrates and some molluscs. The optics of the eye create a focused two-dimensional image of the visual world on the retina, which translates that image into electrical neural impulses to the brain to create visual perception, the retina serving much the same function as film or a CCD in a camera.",
            "score": 172.87496948242188
        }
    ]
}