{
    "q": [
        {
            "docid": "42980268_3",
            "document": "Visual spatial attention . Spatial attention allows humans to selectively process visual information through prioritization of an area within the visual field. A region of space within the visual field is selected for attention and the information within this region then receives further processing. Research shows that when spatial attention is evoked, an observer is typically faster and more accurate at detecting a target that appears in an expected location compared to an unexpected location.",
            "score": 142.08509612083435
        },
        {
            "docid": "35982062_9",
            "document": "Biased Competition Theory . A Top-down process is characterized by a high level of direction of sensory processing by more cognition; Top-down processing is based on pre-existing knowledge when interpreting sensory information. Top-down guidance of attention refers to when the properties of an object (i.e. color, shape) are activated and held in working memory to facilitate the visual search for that object. This controls visual search by guiding attention only to objects that could be the target and avoiding attention on irrelevant objects. Top-down processes are not a complete representation of the object but are coarse, which is why objects similar in color, shape or meaning are often attended to in the process of discriminating irrelevant objects. There is evidence that observers have Top-down control over the locations that will benefit from biased competition in spatial selection visual tasks. Evidence supports that observers can make voluntary decision about which locations are selected. or features that capture the attention in a stimulus-driven manner. Neurophysiology studies have showed that the neural mechanisms in Top-down processing are also seen in attention and working memory, suggesting Top-down processes play an important role in those functions as well. Additionally, Top-down processes can modulate Bottom-up processes by suppressing the \u201cpop-out\u201d features of Bottom-up processing from distracting from the visual search. fMRI studies have investigated the Top-down and Bottom-up processes involved in biased competition theory. Results of fMRI suggest that both Bottom-up and Top-down processes work in parallel to bias competition. Multiple studies have shown that stimuli in the visual field suppress each other when presented together, but not when each stimulus is presented alone. Kastner and colleagues also found that directing attention to the specific location of a stimulus reduces the suppressive effect. Increased activity in the visual cortex was also observed; this was the result of Top-down biasing due to the favoring of the attended location.",
            "score": 146.99327504634857
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 191.7401773929596
        },
        {
            "docid": "27313901_12",
            "document": "Visual N1 . Although spatial attention has been shown to be unique in selection for perceptual information that will be further processed, objects have also been shown to be important in filtering information for further processing. For example, in a Filtering Paradigm (see above), rectangles were presented on either side of the visual field. Participants were directed to attend to one side of the visual field and to the top 50% of the object within that visual field. The target was a shaded region of the top right-hand side corner; however, similar targets were presented in the unattended bottom half of the object in the attended visual field and in the top and bottom halves of the object in the unattended visual field. As expected, when comparing targets in the attended visual field to targets in the unattended visual field, it was found that the amplitude of the N1 was greater for attended (vs. unattended) objects. Additionally, although the amplitude of the N1 was greatest for targets in the attended visual field and the attended part of object, the amplitude of the N1 for targets in the unattended portion of the attended object was larger than the amplitude of the N1 for targets at an equivalent distance from the locus of attention but on an unattended object. These results provide evidence that while spatial attention does serve as a selection mechanism for further processing, spatial attention can spread across objects and influences further perceptual processing.",
            "score": 162.5538808107376
        },
        {
            "docid": "49045837_6",
            "document": "Spatial ability . Spatial perception is also very relevant in sports. For example, a study found that cricket players who were faster at picking up information from briefly presented visual displays were significantly better batsmen in an actual game. A 2015 study published in the \"Journal of Vision\" found that soccer players had higher perceptual ability for body kinematics such as processing multitasking crowd scenes which involve pedestrians crossing a street or complex dynamic visual scenes. Another study published in the \"Journal of Human Kinetics\" on fencing athletes found that achievement level was highly correlated with spatial perceptual skills such as visual discrimination, visual-spatial relationships, visual sequential memory, narrow attentional focus and visual information processing. A review published in the journal of \"Neuropsychologia\" found that spatial perception involves attributing meaning to an object or space, so that their sensory processing is actually part of semantic processing of the incoming visual information. The review also found that spatial perception involves the human visual system in the brain and the parietal lobule which is responsible for visuomotor processing and visually goal-directed action. Studies have also found that individuals who played first person shooting games had better spatial perceptual skills like faster and more accurate performance in a peripheral and identification task while simultaneously performing a central search. Researchers suggested that, in addition to enhancing the ability to divide attention, playing action games significantly enhances perceptual skills like top-down guidance of attention to possible target locations.",
            "score": 122.07245516777039
        },
        {
            "docid": "42980268_12",
            "document": "Visual spatial attention . According to the \u2018spotlight\u2019 metaphor, the focus of attention is analogous to the beam of a spotlight. The moveable spotlight is directed at one location and everything within its beam is attended and processed preferentially, while information outside the beam is unattended. This suggests that the focus of visual attention is limited in spatial size and moves to process other areas in the visual field.",
            "score": 147.8738899230957
        },
        {
            "docid": "35982062_3",
            "document": "Biased Competition Theory . Research into the subject of attentional mechanisms in regard to visual perception was undertaken as an attempt to better understand the functional principles and potential constraints surrounding visual perception Visual search tasks are commonly used by experimenters to aid the exploration of visual perception. The classical view of visual attention suggests that there are two basic principles: the pre-attentive stage and the attentive stage. In the pre-attentive stage, an individual has an unlimited capacity for perception which is capable of processing information from the entire visual field concurrently. During the attentive stage, the processing of visual information corresponding to local spatial areas takes place. This classical view of visual attention suggests that there is no competition within the visual field. Within this theory an individual is assumed to be capable of processing all information provided concurrently. Until recently it was still thought that individuals had a pre-attentive stage. This is no longer the case, research has now suggested that the pre-attentive stage is now limited in its capacity.  The attentive stage of being able to process important information has now transformed into what is known as selectivity. The classical view of attention has built the ground work for the recent emergence of two new principles to benefit the understanding of visual attention. The first of these relates to the limited capacity of information processing. This suggests that at any given time, only a small amount of information can actually be retained and used to control behaviour. The principle of selectivity incorporates the notion that a person has the ability to filter out unwanted information. Koch and Ullman proposed that attentive selection could be implemented by competitive \"winner-takes-all\" networks. Robert Desimone and John Duncan expanded on this idea. They proposed that at some point between the visual input of objects and the response to objects in the visual field there is some competition occurring; competition for representation, analysis, and behavior. This suggests that attention to stimuli makes more demands on processing capacity than unattended stimuli. This idea of competition led researchers to develop a new theory of attention, which they termed the \u201cbiased competition theory\". The theory attempts to provide an explanation of the processes leading visual attention and their effects on the brain\u2019s neural systems.",
            "score": 147.85463106632233
        },
        {
            "docid": "33431597_15",
            "document": "Attentional control . Our brains have distinct attention systems that have been shaped throughout time by evolution. Visual attention operates mainly on three different representations: location , feature, and object-based. The spatial separation between two objects has an effect on attention. People can selectively pay attention to one of two objects in the same general location. Research has also been done on attention to non-object based things like motion. When directing attention to a feature like motion, neuronal activity increases in areas specific for the feature. When visually searching for a non-spatial feature or a perceptual feature, selectively enhancing the sensitivity to that specific feature plays a role in directing attention. When people are told to look for motion, then motion will capture their attention, but attention is not captured by motion if they are told to look for color.",
            "score": 177.19869089126587
        },
        {
            "docid": "42980268_4",
            "document": "Visual spatial attention . Spatial attention is distinctive from other forms of visual attention such as object-based attention and feature-based attention. These other forms of visual attention select an entire object or a specific feature of an object regardless of its location, whereas spatial attention selects a specific region of space and the objects and features within that region are processed.",
            "score": 95.90433120727539
        },
        {
            "docid": "37759941_4",
            "document": "Crossmodal attention . As cross-modal attention requires attending to two or more types of sensory information simultaneously, attentional resources are typically divided unequally. It has been suggested by most research that this divided attention can result in more attentional deficits than benefits. This has raised the question as to the effectiveness of multitasking and the potential dangers associated with it. Significant amounts of delay in reaction times are present when various distractions across modalities occur. In real-life situations these slower reaction times can result in dangerous situations. Recent concerns in the media on this topic revolve around the topic of cellphone usage while driving. Studies have found that processing, and therefore attending to, auditory information can impair the simultaneous processing of visual information. This suggests that attending to the auditory information from cellphone usage while driving will impair a driver's visual attention and ability to drive. This would result in the endangering of the driver, passengers of the driver, pedestrians, and other drivers and their passengers. Similar studies have examined how visual attention is affected by auditory stimuli as it relates to hemispatial neglect, responses to cuing, and general spatial processing. The majority of this research suggests that multitasking and dividing attention, while possible, degrade the quality of the directed attention. This also suggests that attention is a limited resource that cannot be infinitely divided between modalities and tasks.",
            "score": 130.30393743515015
        },
        {
            "docid": "27169449_13",
            "document": "Auditory spatial attention . Further evidence as to the modality specificity of the 'what' and 'where' pathways has been provided in a recent study by Diaconescu et al., who suggest that while 'what' processes have discrete pathways for vision and audition, the 'where' pathway may be supra-modal, shared by both modalities. Participants were asked in randomly alternating trials to respond to either the feature or spatial elements of stimuli, which varied between the auditory and visual domain in set blocks. Between two experiments, the modality of the cue was also varied; the first experiment contained auditory cues as to which element (feature or spatial) of the stimuli to respond to, while the second experiment utilized visual cues. During the period between cue and target, when participants were presumably attending to the cued feature to be presented, both auditory and vision spatial attention conditions elicited greater positivity in source space from a centro-medial location at 600-1200 ms following cue onset, which the authors of the study propose may be the result of a supra-modal pathway for spatial information. Conversely, source space activity for feature attention were not consistent between modalities, with auditory feature attention associated with greater positivity at the right auditory radial dipole around 300-600 ms, and spatial feature attention associated with greater negativity at the left-visual central-inferior dipole at 700-1050ms, suggested as evidence for separate feature or 'what' pathways for vision and audition.",
            "score": 119.4611908197403
        },
        {
            "docid": "176997_28",
            "document": "Blindsight . To put it in a more complex way, recent physiological findings suggest that visual processing takes place along several independent, parallel pathways. One system processes information about shape, one about color, and one about movement, location and spatial organization. This information moves through an area of the brain called the lateral geniculate nucleus, located in the thalamus, and on to be processed in the primary visual cortex, area V1 (also known as the striate cortex because of its striped appearance). People with damage to V1 report no conscious vision, no visual imagery, and no visual images in their dreams. However, some of these people still experience the blindsight phenomenon, though this too is controversial, with some studies showing a limited amount of consciousness without V1 or projections relating to it.",
            "score": 123.51132678985596
        },
        {
            "docid": "42980268_15",
            "document": "Visual spatial attention . It is debated in research on visual spatial attention whether it is possible to split attention across different areas in the visual field. The \u2018spotlight\u2019 and \u2018zoom-lens\u2019 accounts postulate that attention uses a single unitary focus. Therefore, spatial attention can only be allocated to adjacent areas in the visual field and consequently cannot be split. This was supported by an experiment that altered the spatial cueing paradigm by using two cues, a primary and a secondary cue. It was found that the secondary cue was only effective in focusing attention when its location was adjacent to the primary cue. In addition, it has been demonstrated that observers are unable to ignore stimuli presented in areas situated between two cued locations. These findings have proposed that attention cannot be split across two non-contiguous regions. However, other studies have demonstrated that spatial attention can be split across two locations. For example, observers were able to attend simultaneously to two different targets located in opposite hemifields. Research has even suggested that humans are able to focus attention across two to four locations in the visual field. Another perspective is that spatial attention can be split only under certain conditions. This perspective suggests that the splitting of spatial attention is flexible. Research demonstrated that whether spatial attention is unitary or divided depends on the goals of the task. Therefore, if dividing attention is beneficial to the observer then a divided focus of attention will be utilised.",
            "score": 163.41219449043274
        },
        {
            "docid": "26945761_8",
            "document": "Cross modal plasticity . Deaf individuals lack auditory input, so the auditory cortex is instead used to assist with visual and language processing. Auditory activations also appear to be attention-dependent in the deaf. However, the process of visual attention in the deaf is not significantly different from that of hearing subjects. Stronger activations of the auditory cortex during visual observation occur when deaf individuals pay attention to a visual cue, and the activations are weaker if the cue is not in the direct line of sight. One study found that deaf participants process peripheral visual stimuli more quickly than hearing subjects. Deafness appears to heighten spatial attention to the peripheral visual field, but not the central one. The brain thus seems to compensate for the auditory loss within its visual system by enhancing peripheral field attention resources; however, central visual resources may suffer.",
            "score": 152.81167125701904
        },
        {
            "docid": "226722_25",
            "document": "Functional magnetic resonance imaging . Researchers have checked the BOLD signal against both signals from implanted electrodes (mostly in monkeys) and signals of field potentials (that is the electric or magnetic field from the brain's activity, measured outside the skull) from EEG and MEG. The local field potential, which includes both post-neuron-synaptic activity and internal neuron processing, better predicts the BOLD signal. So the BOLD contrast reflects mainly the inputs to a neuron and the neuron's integrative processing within its body, and less the output firing of neurons. In humans, electrodes can be implanted only in patients who need surgery as treatment, but evidence suggests a similar relationship at least for the auditory cortex and the primary visual cortex. Activation locations detected by BOLD fMRI in cortical areas (brain surface regions) are known to tally with CBF-based functional maps from PET scans. Some regions just a few millimeters in size, such as the lateral geniculate nucleus (LGN) of the thalamus, which relays visual inputs from the retina to the visual cortex, have been shown to generate the BOLD signal correctly when presented with visual input. Nearby regions such as the pulvinar nucleus were not stimulated for this task, indicating millimeter resolution for the spatial extent of the BOLD response, at least in thalamic nuclei. In the rat brain, single-whisker touch has been shown to elicit BOLD signals from the somatosensory cortex.",
            "score": 140.20053839683533
        },
        {
            "docid": "42980268_29",
            "document": "Visual spatial attention . The thalamic nuclei have been speculated to be involved in directing attention to locations in visual space. Specifically, the pulvinar nucleus appears to be implicated in the subcortical control of spatial attention, and lesions in this area can cause neglect. Evidence suggests that the pulvinar nucleus of the thalamus might be responsible for engaging in spatial attention at a previously cued location. A study by Rafal and Posner found that patients who had acute pulvinar lesions were slower to detect a target which appeared in the contralesional visuospatial field compared to the appearance of a target in the ipsilesional field during a spatial cuing task. This suggests a deficit in the ability to use attention to improve performance in detection and processing of visual targets in the contralesional region.",
            "score": 129.48170948028564
        },
        {
            "docid": "31329046_6",
            "document": "Pre-attentive processing . Information for pre-attentive processing is detected through the five senses. In the visual system, the receptive fields at the back of the eye (retina) transfer the image via axons to the thalamus, specifically the lateral geniculate nuclei. The image then travels to the primary visual cortex and continues on to be processed by the visual association cortex. At each stage, the image is processed with increasing complexity. Pre-attentive processing starts with the retinal image; this image is magnified as it moves from retina to the cortex of the brain. Shades of light and dark are processed in the lateral geniculate nuclei of the thalamus. Simple and complex cells in the brain process boundary and surface information by deciphering the image's contrast, orientation, and edges. When the image hits the fovea, it is highly magnified, facilitating object recognition. The images in the periphery are less clear but help to create a complete image used for scene perception.",
            "score": 167.24000453948975
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 153.73980736732483
        },
        {
            "docid": "43116037_29",
            "document": "Sex differences in intelligence . A number of studies have shown that women tend to rely more on visual information than men in a number of spatial tasks related to perceived orientation. However, 'visual dependence' has been found to be task specific and not a general characteristic of spatial processing that differs between the sexes. Here an alternative hypothesis suggests that heightened visual dependence in females does not generalize to all aspects of spatial processing but is probably attributable to task-specific differences in how male and females brains process multisensory spatial information.",
            "score": 93.17675185203552
        },
        {
            "docid": "27313901_11",
            "document": "Visual N1 . Amplitude differences in the N1 have provided evidence that attention allows for more extensive analysis of visual information, such as color and motion. For example, in a Filtering Paradigm (see description above), participants were instructed to identify targets based on either color or motion. In some cases, participants were told to attend to one side of the visual field, while in other cases participants' attention was not focused on one side of the visual field. It was found that the amplitude of the N1 was greater for targets of the correct color and motion when participants were instructed to attend to one side of the visual field versus when they were not instructed to do so. These findings suggest that attention to a particular location serves to facilitate further processing of visual information and suppress further visual processing in unattended locations.",
            "score": 190.97112321853638
        },
        {
            "docid": "963201_12",
            "document": "Hemispatial neglect . Spatial attention is the process where objects in one location are chosen for processing over objects in another location. This would imply that neglect is more intentional. The patient has an affinity to direct attention to the unaffected side. Neglect is caused by a decrease in stimuli in the contralesional side because of a lack of ipsilesional stimulation of the visual cortex and an increased inhibition of the contralesional side. In this theory neglect is seen as disorder of attention and orientation caused by disruption of the visual cortex. Patients with this disorder will direct attention and movements to the ipsilesional side and neglect stimuli in the contralesional side despite having preserved visual fields. The result of all of this is an increased sensitivity of visual performance in the unaffected side. The patient shows an affinity to the ipsilesional side being unable to disengage attention from that side.",
            "score": 123.78572845458984
        },
        {
            "docid": "24965027_11",
            "document": "Cognitive neuroscience of visual object recognition . The visual processing of objects in the brain can be divided into two processing pathways: the dorsal stream (how/where), which extends from the visual cortex to the parietal lobes, and ventral stream (what), which extends from the visual cortex to the inferotemporal cortex (IT). The existence of these two separate visual processing pathways was first proposed by Ungerleider and Mishkin (1982) who, based on their lesion studies, suggested that the dorsal stream is involved in the processing of visual spatial information, such as object localization (where), and the ventral stream is involved in the processing of visual object identification information (what). Since this initial proposal, it has been alternatively suggested that the dorsal pathway should be known as the 'How' pathway as the visual spatial information processed here provides us with information about how to interact with objects, For the purpose of object recognition, the neural focus is on the ventral stream.",
            "score": 83.5758626461029
        },
        {
            "docid": "305136_32",
            "document": "Visual system . The visual cortex is the largest system in the human brain and is responsible for processing the visual image. It lies at the rear of the brain (highlighted in the image), above the cerebellum. The region that receives information directly from the LGN is called the primary visual cortex, (also called V1 and striate cortex). Visual information then flows through a cortical hierarchy. These areas include V2, V3, V4 and area V5/MT (the exact connectivity depends on the species of the animal). These secondary visual areas (collectively termed the extrastriate visual cortex) process a wide variety of visual primitives. Neurons in V1 and V2 respond selectively to bars of specific orientations, or combinations of bars. These are believed to support edge and corner detection. Similarly, basic information about color and motion is processed here.",
            "score": 128.66963648796082
        },
        {
            "docid": "27380813_16",
            "document": "N2pc . Other work has explored further cognitive processes that could be linked to the N2pc. For instance, the classic visual search paradigm that elicits the N2pc could be broken down further into processes of shifting attention, and spatially based processing of non-target locations. When combining the visual search task with visual cues that drew attention to spatial locations in the display, experimenters found that while the N2pc may not reflect shifts of attention, it may still reflect processing of a location in space that may or may not contain a target.",
            "score": 90.10270309448242
        },
        {
            "docid": "35940059_17",
            "document": "Object-based attention . Object-based attentional effects are attributed to the improved sensory representation of the object that results from attentional spread (an object-guided spatial selection). When attention is directed to a location within an object, other locations within that object also acquire an attentional advantage (via enhanced sensory processing). Two or more features belonging to a single object are identified more quickly and more accurately than are features belonging to different objects. Attention to a single visual feature of an object, such as its speed of motion, results in an automatic transfer of attention to other task-relevant features, such as, colour. Studies measuring neuron response in animals provided evidence supporting the theory that attention spreads within an object.",
            "score": 131.5400025844574
        },
        {
            "docid": "27169449_18",
            "document": "Auditory spatial attention . The anatomical locus of the executive control of endogenous audiospatial attention was investigated using fMRI by Wu \"et al.\". Participants received auditory cues to attend to either their left or right, in anticipation of an auditory stimulus. A third cue, instructing participants to attend to neither left nor right, served as a control, non-spatial condition. Comparing activation in the spatial vs. non-spatial attentional conditions showed increased activation in several areas implicated in the executive control of visual attention, including the prefrontal cortex, FEF, anterior cingulate cortex (ACC), and superior parietal lobe, again supporting the notion of these structures as supra-modal attentional areas. The spatial attention vs. control comparison further revealed increased activity in auditory cortex, increases which were contralateral to the side of audiospatial attention, which may reflect top-down biasing of early sensory areas as has been seen with visual attention.",
            "score": 98.16091632843018
        },
        {
            "docid": "33431597_16",
            "document": "Attentional control . According to fMRI studies of the brain and behavioral observations, visual attention can be moved independently of moving eye position. Studies have had participants fixate their eyes on a central point and measured brain activity as stimuli were presented outside the visual fixation point. fMRI findings show changes in brain activity correlated with the shift in spatial attention to the various stimuli. Behavioral studies have also shown that when a person knows where a stimulus is likely to appear, their attention can shift to it more rapidly and process it better.",
            "score": 131.27550983428955
        },
        {
            "docid": "1616390_25",
            "document": "Simultanagnosia . Saliency of a feature facilitates the ease with which it can be indexed. For example, the greater the difference between a specific feature and surrounding ones, the more easily it can be indexed. The indexed features, or anchor points, can serve as a \"spotlight\" that directs focal attention to certain objects, which can then channel visual information to specialized systems for space and shape analysis. Deficits in the spatial indexing mechanism would result in symptoms of simultanagnosia because interpretation of a complex scene requires rapid shifting of attention to various elements, and impairments in spatial indexing lead to the inability to index multiple visual features rapidly. In addition, perception is slowed, and low-level visual processing is disrupted since the patient would not be able to extract and index salient features.",
            "score": 109.83537554740906
        },
        {
            "docid": "68753_10",
            "document": "Attention . A significant debate emerged in the last decade of the 20th century in which Treisman's 1993 Feature Integration Theory (FIT) was compared to Duncan and Humphrey's 1989 attentional engagement theory (AET). FIT posits that \"objects are retrieved from scenes by means of selective spatial attention that picks out objects' features, forms feature maps, and integrates those features that are found at the same location into forming objects.\" Duncan and Humphrey's AET understanding of attention maintained that \"there is an initial pre-attentive parallel phase of perceptual segmentation and analysis that encompasses all of the visual items present in a scene. At this phase, descriptions of the objects in a visual scene are generated into structural units; the outcome of this parallel phase is a multiple-spatial-scale structured representation. Selective attention intervenes after this stage to select information that will be entered into visual short-term memory.\" The contrast of the two theories placed a new emphasis on the separation of visual attention tasks alone and those mediated by supplementary cognitive processes. As Rastophopoulos summarizes the debate: \"Against Treisman's FIT, which posits spatial attention as a necessary condition for detection of objects, Humphreys argues that visual elements are encoded and bound together in an initial parallel phase without focal attention, and that attention serves to select among the objects that result from this initial grouping.\"",
            "score": 98.20614016056061
        },
        {
            "docid": "68753_22",
            "document": "Attention . \"Covert orienting\" is the act to mentally shifting one's focus without moving one's eyes. Simply, it is changes in attention that are not attributable to overt eye movements. Covert orienting has the potential to affect the output of perceptual processes by governing attention to particular items or locations (for example, the activity of a V4 neuron whose receptive field lies on an attended stimuli will be enhanced by covert attention) but does not influence the information that is processed by the senses. Researchers often use \"filtering\" tasks to study the role of covert attention of selecting information. These tasks often require participants to observe a number of stimuli, but attend to only one. The current view is that visual covert attention is a mechanism for quickly scanning the field of view for interesting locations. This shift in covert attention is linked to eye movement circuitry that sets up a slower saccade to that location.",
            "score": 206.8765721321106
        },
        {
            "docid": "27313901_15",
            "document": "Visual N1 . Additionally, research on the visual N1 suggests that spatial and object attention serve as an early selection mechanism that influences the selection of other perceptual features (e.g., color, motion) for further processing. The amplitude of the N1 is largest for perceptual features in attended (vs. unattended) locations and on attended (vs. unattended) objects, providing evidence that perceptual features are only selected for further perceptual processing if they are in attended locations or on attended objects.",
            "score": 113.08501553535461
        },
        {
            "docid": "1626279_21",
            "document": "Anne Treisman . In the early 1980s, neuroscientists such as Torston Wiesel and David H. Hubel were discovering that different areas of the primate visual cortex were finely tuned to selective features, such as line orientation, luminance, color, movement, etc. These findings prompted the question of how these distinct features are connected into a unified whole, e.g., the binding problem. For example, when you see a red ball roll by, cells sensitive to movement fire in the medial temporal cortex, while cells sensitive to color, shape and location fire in other areas. Despite all this distinct neuronal firing, you don't perceive the ball as separated by shape, movement and color perceptions; you experience an integrated experience with all these components occurring together. The question of how these elements are combined is the essence of the binding problem and continued into the late 1990s. A number of possible mechanisms were envisaged, including grandmother cells responding to specific conjunctions of features that uniquely identify a particular object; local cell assemblies onto which the pathways from different feature maps converge, perhaps with adjustable connections allowing flexible routing of signals; a serial scan of different spatial areas selected by an adjustable attention window, conjoining the features that each contains and excluding features from adjacent areas; detection of temporal contiguity \u2013 parts and properties whose onset, offset or motion coincide probably belong to the same object synchronised firing of cells responding to features of the same object, perhaps assisted by oscillatory neural activity. Treisman used failures of binding to shed light on its underlying mechanisms. Specifically, she found that left-brain-damaged patients have increasing illusory conjunctions and decreased performance in a spatially cued attention task, which suggests a link between attentional binding and the parietal lobes. Treisman also cited corroborating evidence from positron emission tomography and event-related potential studies which were consistent with the spatial attention account of feature integration.",
            "score": 128.7771143913269
        }
    ],
    "r": [
        {
            "docid": "31148473_12",
            "document": "Transsaccadic memory . This is an area within the visual cortex that has been found to play an important role in the target selection of saccades. In other words, this area is important for determining which objects our eyes shift to when they move. Studies have shown that there is a large amount of activation within the visual area V4 before the saccade even takes place. This occurs in the form of shrinking receptive fields. The receptive fields of these brain cells tend to shift towards the object that the eye is about to move towards, generally more so if the object is close to the original fixation point. This dynamic change in receptive fields is thought to enhance the perception and recognition of objects in a visual scene. Because the receptive fields become smaller around the targeted objects, attention within the visual scene is very focused on these objects. Increased attention to target objects within a visual scene help direct eye movements from one object to another. Understanding of the visual scene becomes more efficient because these attention shifts guide the eyes towards relevant objects as opposed to objects that may not be as important.",
            "score": 231.3267822265625
        },
        {
            "docid": "68753_22",
            "document": "Attention . \"Covert orienting\" is the act to mentally shifting one's focus without moving one's eyes. Simply, it is changes in attention that are not attributable to overt eye movements. Covert orienting has the potential to affect the output of perceptual processes by governing attention to particular items or locations (for example, the activity of a V4 neuron whose receptive field lies on an attended stimuli will be enhanced by covert attention) but does not influence the information that is processed by the senses. Researchers often use \"filtering\" tasks to study the role of covert attention of selecting information. These tasks often require participants to observe a number of stimuli, but attend to only one. The current view is that visual covert attention is a mechanism for quickly scanning the field of view for interesting locations. This shift in covert attention is linked to eye movement circuitry that sets up a slower saccade to that location.",
            "score": 206.87657165527344
        },
        {
            "docid": "941909_26",
            "document": "Receptive field . The term receptive field is also used in the context of artificial neural networks, most often in relation to convolutional neural networks (CNNs). When used in this sense, the term adopts a meaning reminiscent of receptive fields in actual biological nervous systems. CNNs have a distinct architecture, designed to mimic the way in which real animal brains are understood to function; instead of having every neuron in each layer connect to all neurons in the next layer (Multilayer perceptron), the neurons are arranged in a 3-dimensional structure in such a way as to take into account the spatial relationships between different neurons with respect to the original data. Since CNNs are used primarily in the field of computer vision, the data that the neurons represent is typically an image; each input neuron represents one pixel from the original image. The first layer of neurons is composed of all the input neurons; neurons in the next layer will receive connections from some of the input neurons (pixels), but not all, as would be the case in a MLP and in other traditional neural networks. Hence, instead of having each neuron receive connections from all neurons in the previous layer, CNNs use a receptive field-like layout in which each neuron receives connections only from a subset of neurons in the previous (lower) layer. The receptive field of a neuron in one of the lower layers encompasses only a small area of the image, while the receptive field of a neuron in subsequent (higher) layers involves a combination of receptive fields from several (but not all) neurons in the layer before (i. e. a neuron in a higher layer \"looks\" at a larger portion of the image than does a neuron in a lower layer). In this way, each successive layer is capable of learning increasingly abstract features of the original image. The use of receptive fields in this fashion is thought to give CNNs an advantage in recognizing visual patterns when compared to other types of neural networks.",
            "score": 196.34536743164062
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 191.74017333984375
        },
        {
            "docid": "27313901_11",
            "document": "Visual N1 . Amplitude differences in the N1 have provided evidence that attention allows for more extensive analysis of visual information, such as color and motion. For example, in a Filtering Paradigm (see description above), participants were instructed to identify targets based on either color or motion. In some cases, participants were told to attend to one side of the visual field, while in other cases participants' attention was not focused on one side of the visual field. It was found that the amplitude of the N1 was greater for targets of the correct color and motion when participants were instructed to attend to one side of the visual field versus when they were not instructed to do so. These findings suggest that attention to a particular location serves to facilitate further processing of visual information and suppress further visual processing in unattended locations.",
            "score": 190.97113037109375
        },
        {
            "docid": "2676126_6",
            "document": "Retinotopy . In many locations within the brain, adjacent neurons have receptive fields that include slightly different, but overlapping portions of the visual field. The position of the center of these receptive fields forms an orderly sampling mosaic that covers a portion of the visual field. Because of this orderly arrangement, which emerges from the spatial specificity of connections between neurons in different parts of the visual system, cells in each structure can be seen as contributing to a map of the visual field (also called a retinotopic map, or a visuotopic map). Retinotopic maps are a particular case of topographic organization. Many brain structures that are responsive to visual input, including much of the visual cortex and visual nuclei of the brain stem (such as the superior colliculus) and thalamus (such as the lateral geniculate nucleus and the pulvinar), are organized into retinotopic maps, also called visual field maps.",
            "score": 190.63026428222656
        },
        {
            "docid": "4231622_7",
            "document": "Inferior temporal gyrus . The information for color and form comes from P-cells that receive their information mainly from cones, so they are sensitive to differences in form and color, as opposed to the M-cells that receive information about motion mainly from rods. The neurons in the inferior temporal cortex, also called the inferior temporal visual association cortex, process this information from the P-cells.  The neurons in the ITC have several unique properties that offer an explanation as to why this area is essential in recognizing patterns. They only respond to visual stimuli and their receptive fields always include the fovea, which is one of the densest areas of the retina and is responsible for acute central vision. These receptive fields tend to be larger than those in the striate cortex and often extend across the midline to unite the two visual half fields for the first time. IT neurons are selective for shape and/or color of stimulus and are usually more responsive to complex shapes as opposed to simple ones. A small percentage of them are selective for specific parts of the face. Faces and likely other complex shapes are seemingly coded by a sequence of activity across a group of cells, and IT cells can display both short or long term memory for visual stimuli based on experience.",
            "score": 189.54034423828125
        },
        {
            "docid": "941909_2",
            "document": "Receptive field . The receptive field of an individual sensory neuron is the particular region of the sensory space (e.g., the body surface, or the visual field) in which a stimulus will modify the firing of that neuron. This region can be a hair in the cochlea or a piece of skin, retina, tongue or other part of an animal's body. Additionally, it can be the space surrounding an animal, such as an area of auditory space that is fixed in a reference system based on the ears but that moves with the animal as it moves (the space inside the ears), or in a fixed location in space that is largely independent of the animal's location (place cells). Receptive fields have been identified for neurons of the auditory system, the somatosensory system, and the visual system.",
            "score": 187.88221740722656
        },
        {
            "docid": "14782003_12",
            "document": "Body schema . A working body schema must be able to interactively track the movements and positions of body parts in space. Neurons in the premotor cortex may contribute to this function. A class of neuron in the premotor cortex is multisensory. Each of these multisensory neurons responds to tactile stimuli and also to visual stimuli. The neuron has a tactile receptive field (responsive region on the body surface) typically on the face, arms, or hands. The same neuron also responds to visual stimuli in the space near the tactile receptive field. For example, if a neuron's tactile receptive field covers the arm, the same neuron will respond to visual stimuli in the space near the arm. As shown by Graziano and colleagues, the visual receptive field will update with arm movement, translating through space as the arm moves. Similar body-part-centered neuronal receptive fields relate to the face. These neurons apparently monitor the location of body parts and the location of nearby objects with respect to body parts. Similar neuronal properties may also be important for the ability to incorporate external objects into the body schema, such as in tool use.",
            "score": 187.71888732910156
        },
        {
            "docid": "41848173_3",
            "document": "Surround suppression . The classical model of early vision presumes that each neuron responds independently to a specific stimulus in a localized area of the visual field. (According to Carandini et al (2005), this computational model, which may be fit to various datasets, \"degrade[s] quickly if we change almost any aspect of the test stimulus.\") The stimulus and corresponding location in the visual field are collectively called the classical receptive field. However, not all effects can be explained by via ad hoc independent filters. Surround suppression is one of an infinite number of possible effects in which neurons do not behave according to the classical model. These effects are collectively called non-classical receptive field effects, and have recently become a substantial research area in vision and other sensory systems.",
            "score": 186.27012634277344
        },
        {
            "docid": "32528_6",
            "document": "Visual cortex . Neurons in the visual cortex fire action potentials when visual stimuli appear within their receptive field. By definition, the receptive field is the region within the entire visual field that elicits an action potential. But, for any given neuron, it may respond best to a subset of stimuli within its receptive field. This property is called \"neuronal tuning\". In the earlier visual areas, neurons have simpler tuning. For example, a neuron in V1 may fire to any vertical stimulus in its receptive field. In the higher visual areas, neurons have complex tuning. For example, in the inferior temporal cortex (IT), a neuron may fire only when a certain face appears in its receptive field.",
            "score": 185.93853759765625
        },
        {
            "docid": "2664501_4",
            "document": "Microsaccade . Experiments in neurophysiology from different laboratories showed that fixational eye movements, particularly microsaccades, strongly modulate the activity of neurons in the visual areas of the macaque brain. In the lateral geniculate nucleus (LGN) and the primary visual cortex (V1), microsaccades can move a stationary stimulus in and out of a neuron's receptive field, thereby producing transient neural responses. Microsaccades might account for much of the response variability of neurons in visual area V1 of the awake monkey.",
            "score": 184.00408935546875
        },
        {
            "docid": "305136_18",
            "document": "Visual system . In the retina, the photoreceptors synapse directly onto bipolar cells, which in turn synapse onto ganglion cells of the outermost layer, which will then conduct action potentials to the brain. A significant amount of visual processing arises from the patterns of communication between neurons in the retina. About 130 million photo-receptors absorb light, yet roughly 1.2 million axons of ganglion cells transmit information from the retina to the brain. The processing in the retina includes the formation of center-surround receptive fields of bipolar and ganglion cells in the retina, as well as convergence and divergence from photoreceptor to bipolar cell. In addition, other neurons in the retina, particularly horizontal and amacrine cells, transmit information laterally (from a neuron in one layer to an adjacent neuron in the same layer), resulting in more complex receptive fields that can be either indifferent to color and sensitive to motion or sensitive to color and indifferent to motion.",
            "score": 182.8319549560547
        },
        {
            "docid": "941909_10",
            "document": "Receptive field . In the visual system, receptive fields are volumes in visual space. They are smallest in the fovea where they can be a few minutes of arc like a dot on this page, to the whole page. For example, the receptive field of a single photoreceptor is a cone-shaped volume comprising all the visual directions in which light will alter the firing of that cell. Its apex is located in the center of the lens and its base essentially at infinity in visual space. Traditionally, visual receptive fields were portrayed in two dimensions (e.g., as circles, squares, or rectangles), but these are simply slices, cut along the screen on which the researcher presented the stimulus, of the volume of space to which a particular cell will respond. In the case of binocular neurons in the visual cortex, receptive fields do not extend to optical infinity. Instead, they are restricted to a certain interval of distance from the animal, or from where the eyes are fixating (see Panum's area).",
            "score": 182.02101135253906
        },
        {
            "docid": "40409788_16",
            "document": "Convolutional neural network . Work by Hubel and Wiesel in the 1950s and 1960s showed that cat and monkey visual cortexes contain neurons that individually respond to small regions of the visual field. Provided the eyes are not moving, the region of visual space within which visual stimuli affect the firing of a single neuron is known as its receptive field. Neighboring cells have similar and overlapping receptive fields. Receptive field size and location varies systematically across the cortex to form a complete map of visual space. The cortex in each hemisphere represents the contralateral visual field.",
            "score": 178.97633361816406
        },
        {
            "docid": "43666413_11",
            "document": "Cerebral polyopia . Another possible pathophysiological mechanism for this disorder is the reorganization of receptive fields of neurons close to the damaged area of visual cortex. This theory is supported by findings that parafoveal retinal lesions deprive a region of striate cortex of visual input, and as a result, the receptive fields of neurons near the boundary of the deprived cortical region enlarge and expand into nearby regions of the visual field. Thus, polyopia results from altered coding of contour information by neurons near the lesioned area. This mechanism offers that after a focal lesion of neurons in striate cortex, or following a retinal lesion depriving these neurons of visual input, the receptive fields of nearby healthy neurons converge to code information about contours of objects normally coded by the damaged neurons while still coding the same information about retinal location prior to the injury. This mechanism may explain why polyopia extending into a patient\u2019s scotoma occurs following damage to primary visual cortex.",
            "score": 178.16810607910156
        },
        {
            "docid": "33431597_15",
            "document": "Attentional control . Our brains have distinct attention systems that have been shaped throughout time by evolution. Visual attention operates mainly on three different representations: location , feature, and object-based. The spatial separation between two objects has an effect on attention. People can selectively pay attention to one of two objects in the same general location. Research has also been done on attention to non-object based things like motion. When directing attention to a feature like motion, neuronal activity increases in areas specific for the feature. When visually searching for a non-spatial feature or a perceptual feature, selectively enhancing the sensitivity to that specific feature plays a role in directing attention. When people are told to look for motion, then motion will capture their attention, but attention is not captured by motion if they are told to look for color.",
            "score": 177.1986846923828
        },
        {
            "docid": "3380919_3",
            "document": "David Heeger . In the fields of perceptual psychology, systems neuroscience, cognitive neuroscience, and computational neuroscience, Heeger has developed computational theories of neuronal processing in the visual system, and he has performed psychophysics (perceptual psychology) and neuroimaging (functional magnetic resonance imaging, fMRI) experiments on human vision. His contributions to computational neuroscience include theories for how the brain can sense optic flow and egomotion, and a theory of neural processing called the normalization model. His empirical research has contributed to our understanding of the topographic organization of visual cortex (retinotopy), visual awareness, visual pattern detection/discrimination, visual motion perception, stereopsis (depth perception), attention, working memory, the control of eye and hand movements, neural processing of complex audio-visual and emotional experiences (movies, music, narrative), abnormal visual processing in dyslexia, and neurophysiological characteristics of autism.",
            "score": 176.0144500732422
        },
        {
            "docid": "25671719_6",
            "document": "Michael Graziano . Each multisensory neuron responded to a touch within a specific \"tactile receptive field\" on the body surface. Each neuron also responded to a visual stimulus near or approaching the tactile receptive field. The \"visual receptive field\" was therefore a region of nearby space affixed to the relevant body part. Some neurons responded to sound sources near the tactile receptive field. Some neurons also responded mnemonically, becoming active when a part of the body moved through space and approached the remembered location of an object in the dark. The activity of these multisensory neurons therefore signaled the presence of an object near or touching a part of the body, regardless of whether the object was felt, seen, heard, or remembered.",
            "score": 175.32681274414062
        },
        {
            "docid": "41848173_2",
            "document": "Surround suppression . Surround suppression is a descriptive term referring to observations that the relative firing rate of a neuron may under certain conditions decrease when a particular stimulus is enlarged. It is has been observed in electrophysiology studies of the brain and has been noted in many sensory neurons, most notably in the early visual system. Surround suppression is defined as a reduction in the activity of a neuron in response to a stimulus outside its classical receptive field. (The classical receptive field refers to a concept of neural behavior that was understood to be invalid virtally from the start. As Spillman et al (2015)) note, quoting Kuffler (1953), \"not only the areas from which responses can actually be set up by retinal illumination may be included in a definition of the receptive field but also all areas which show a functional connection, by an inhibitory or excitatory effect on a ganglion cell.\" The necessary functional connections with other neurons influenced by stimulation outside a particular area and by dynamic processes in general, and the absence of a theoretical description of a system state to be treated as a baseline, deprive the term \"classical receptive field\" of functional meaning. The descriptor \"surround suppression\" suffers from a similar problem, as the activities of neurons in the \"surround\" of the \"classical receptive field are similarly determined by connectivities and processes involving neurons beyond it.) This nonlinear effect is one of many that reveals the complexity of biological sensory systems, and the connections of properties of neurons that may cause this effect (or its opposite) are still being studied. The characteristics, mechanisms, and perceptual consequences of this phenomenon are of interest to many communities, including neurobiology, computational neuroscience, psychology, and computer vision.",
            "score": 174.96954345703125
        },
        {
            "docid": "3132756_7",
            "document": "Troxler's fading . Troxler's fading can occur without any extraordinary stabilization of the retinal image in peripheral vision because the neurons in the visual system beyond the rods and cones have large receptive fields. This means that the small, involuntary eye movements made when fixating on something fail to move the stimulus onto a new cell's receptive field, in effect giving unvarying stimulation. Further experimentation this century by Hsieh and Tse showed that at least some portion of the perceptual fading occurred in the brain, not in the eyes.",
            "score": 174.52548217773438
        },
        {
            "docid": "379957_26",
            "document": "Lateral geniculate nucleus . Like other areas of the thalamus, particularly other \"relay nuclei\", the LGN likely helps the visual system focus its attention on the most important information. That is, if you hear a sound slightly to your left, the auditory system likely \"tells\" the visual system, through the LGN via its surrounding peri-reticular nucleus, to direct visual attention to that part of space. The LGN is also a station that refines certain receptive fields. Experiments using fMRI in humans reported in 2010 that both spatial attention and saccadic eye movements can modulate activity in the LGN.",
            "score": 169.38702392578125
        },
        {
            "docid": "51517174_6",
            "document": "Axiomatic theory of receptive fields . Theoretical arguments have been presented of preferring this generalized Gaussian model of receptive fields over a Gabor model of receptive fields, because of the better theoretical properties of the generalized Gaussian model under natural image transformations. Specifically, these generalized Gaussian receptive fields can be shown to enable computation of \"invariant visual representations under natural image transformations\". By these results, the different shapes of receptive field profiles found in biological vision, which are tuned to different sizes and orientations in the image domain as well as to different image velocities in space-time, can be seen as well adapted to structure of the physical world and be explained from the requirement that the visual system should have the possibility of being invariant to the natural types of image transformations that occur in its environment.",
            "score": 169.32041931152344
        },
        {
            "docid": "25522368_9",
            "document": "Feature detection (nervous system) . In their second major paper, Hubel and Wiesel extended their technique to more complex regions in the visual cortex in an effort to understand the difference between cortical receptive fields and lateral geniculate fields. They observed that the cat striate cortex contained more cells than the lateral geniculate, and they reasoned that the cortex needs a large number of neurons to digest the large amount of information it receives. Through experimentation, they found that each neuron in the cortex is responsible for a small region of the visual field and also has its own orientation specificity. From the results of these single cell readings in the striate cortex and lateral geniculate, Hubel and Wiesel postulated that simple cortical receptive fields gain complexity and an intricate spatial arrangement through the patterned convergence of multiple \"on\" or \"off\" projections from lateral geniculate cells onto single cortical cells.",
            "score": 168.83810424804688
        },
        {
            "docid": "941909_23",
            "document": "Receptive field . Idealized models of visual receptive fields similar to those found in the retina, lateral geniculate nucleus (LGN) and the primary visual cortex of higher mammals can be derived in an axiomatic way from structural requirements on the first stages of visual processing that reflect symmetry properties of the surrounding world. Specifically, functional models for linear receptive fields can be derived in a principled manner to constitute a combination of Gaussian derivatives over the spatial domain and either non-causal Gaussian derivatives or truly time-causal temporal scale-space kernels over the temporal domain. Such receptive fields can be shown to enable computation of invariant visual representations under natural image transformations. By these results, the different shapes of receptive field profiles found in biological vision, which are tuned to different sizes and orientations in the image domain as well as to different image velocities in space-time, can be seen as well adapted to structure of the physical world and be explained from the requirement that the visual system should be invariant to the natural types of image transformations that occur in its environment.",
            "score": 168.02011108398438
        },
        {
            "docid": "9170159_9",
            "document": "Binocular disparity . Brain cells (neurons) in a part of the brain responsible for processing visual information coming from the retinae (primary visual cortex) can detect the existence of disparity in their input from the eyes. Specifically, these neurons will be active, if an object with \"their\" special disparity lies within the part of the visual field to which they have access (receptive field).",
            "score": 167.9618682861328
        },
        {
            "docid": "4455796_9",
            "document": "Lateral inhibition . Sensory information collected by the peripheral nervous system is transmitted to specific areas of the primary somatosensory area in the parietal cortex according to its origin on any given part of the body. For each neuron in the primary somatosensory area, there is a corresponding region of the skin that is stimulated or inhibited by that neuron. The regions that correspond to a location on the somatosensory cortex are mapped by a homonculus. This corresponding region of the skin is referred to as the neuron's receptive field. The most sensitive regions of the body have the greatest representation in any given cortical area, but they also have the smallest receptive fields. The lips, tongue, and fingers are examples of this phenomenon. Each receptive field is composed of two regions: a central excitatory region and a peripheral inhibitory region. One entire receptive field can overlap with other receptive fields, making it difficult to differentiate between stimulation locations, but lateral inhibition helps to reduce that overlap. When an area of the skin is touched, the central excitatory region activates and the peripheral region is inhibited, creating a contrast in sensation and allowing sensory precision. The person can then pinpoint exactly which part of the skin is being touched. In the face of inhibition, only the neurons that are most stimulated and least inhibited will fire, so the firing pattern tends to concentrate at stimulus peaks. This ability becomes less precise as stimulation moves from areas with small receptive fields to larger receptive fields, e.g. moving from the fingertips to the forearm to the upper arm.",
            "score": 167.2964324951172
        },
        {
            "docid": "31329046_6",
            "document": "Pre-attentive processing . Information for pre-attentive processing is detected through the five senses. In the visual system, the receptive fields at the back of the eye (retina) transfer the image via axons to the thalamus, specifically the lateral geniculate nuclei. The image then travels to the primary visual cortex and continues on to be processed by the visual association cortex. At each stage, the image is processed with increasing complexity. Pre-attentive processing starts with the retinal image; this image is magnified as it moves from retina to the cortex of the brain. Shades of light and dark are processed in the lateral geniculate nuclei of the thalamus. Simple and complex cells in the brain process boundary and surface information by deciphering the image's contrast, orientation, and edges. When the image hits the fovea, it is highly magnified, facilitating object recognition. The images in the periphery are less clear but help to create a complete image used for scene perception.",
            "score": 167.24000549316406
        },
        {
            "docid": "25522368_8",
            "document": "Feature detection (nervous system) . In the late 1950s, Jerome Lettvin and his colleagues began to expand the feature detection hypothesis and clarify the relationship between single neurons and sensory perception. In their paper \"What the Frog's Eye Tells the Frog's Brain\", Lettvin et al. (1959) looked beyond the mechanisms for signal-noise discrimination in the frog's retina and were able to identify four classes of ganglion cells in the frog retina: \"sustained contrast detectors\", \"net convexity detectors\" (or \"bug detectors\"), \"moving edge detectors\", and \"net dimming detectors.\"  In the same year, David Hubel and Torsten Wiesel began investigating properties of neurons in the visual cortex of cats, processing in the mammalian visual system. In their first paper in 1959, Hubel and Wiesel took recording from single cells in the striate cortex of lightly anesthetized cats. The retinas of the cats were stimulated either individually or simultaneously with spots of light of various sizes and shapes. From the analysis of these recordings, Hubel and Wiesel identified orientation-selective cells in the cat's visual cortex and generated a map of the receptive field of cortical cells. At the time, circular spots of light were used as stimuli in studies of the visual cortex. However, Hubel and Wiesel noticed that rectangular bars of light were more effective stimuli (i.e. more natural stimuli) than circular spots of light, as long as the orientation was adjusted to the correct angle appropriate for each ganglion cell. These so-called simple cells were later called bar detectors or edge detectors. While comparing the receptive fields of neurons in the cat striate cortex with the concentric \"on\" and \"off\" receptive fields identified in cat ganglion cells by Kuffler et al., Hubel and Wiesel noticed that, although \"on\" and \"off\" regions were present in the striate cortex, they were not arranged in concentric circles. From their discovery of these uniquely orienting receptive fields, Hubel and Wiesel concluded that orientation-selective cells exist within the cat's visual cortex.",
            "score": 166.9558563232422
        },
        {
            "docid": "20395179_7",
            "document": "Vittorio Gallese . Observing the world is more complex than the mere activation of the visual brain. Vision is multimodal: it encompasses the activation of motor, somatosensory and emotion-related brain networks. Any intentional relation entertained with the external world has an intrinsic pragmatic nature, hence it always bears a motor content. The same motor circuits that control our motor behavior also map the space around us, the objects at hand in that very same space, thus defining and shaping in motor terms their representational content. The space around us is defined by the motor potentialities of our body. Motor neurons also respond to visual, tactile and auditory stimuli. Indeed, premotor neurons controlling the movements of the upper arm also respond to tactile stimuli applied to it, to visual stimuli moved within the arm's peripersonal space, or to auditory stimuli also coming from the same peri-personal space. The same applies to artifacts, like three-dimensional objects. The manipulable objects we look at are classified by the motor brain as potential targets of the interactions we might entertain with them. Premotor and parietal 'canonical neurons' control the grasping and manipulation of objects and also respond to their mere observation. The functional architecture of embodied simulation seems to constitute a basic characteristic of our brain, making possible our rich and diversified experiences of space, objects and other individuals, being at the basis of our capacity to empathize with them.\"",
            "score": 166.8434295654297
        },
        {
            "docid": "4236583_10",
            "document": "Visual search . Visual orienting does not necessarily require overt movement, though. It has been shown that people can covertly (without eye movement) shift attention to peripheral stimuli. In the 1970s, it was found that the firing rate of cells in the parietal lobe of monkeys increased in response to stimuli in the receptive field when they attended to peripheral stimuli, even when no eye movements were allowed. These findings indicate that attention plays a critical role in understanding visual search.",
            "score": 166.12725830078125
        },
        {
            "docid": "27313901_5",
            "document": "Visual N1 . After the amplitude of the N1 was found to vary according to levels of attention, researchers became interested in how identical stimuli were perceived when they were attended versus unattended. An experimental paradigm, sometimes referred to as the Filtering Paradigm, was developed to assess how attention influences perception of stimuli. In the Filtering Paradigm, participants are instructed to focus their attention on either the right or left visual field of a computer screen. The visual field is typically counterbalanced within subjects across trials or experimental blocks. Thus, for the first set of trials, participants may pay attention to the right visual field, but subsequently they may pay attention to the left visual field. Within each trial and across visual fields, participants are presented with the same stimuli, for example flashes of lights varying in duration. Participants are told that when a particular stimulus, such as a short duration flash of light, referred to as a target, appears in the visual field they are attending, they should respond with a button press. The number of targets within each visual field is less than that number of non-targets, and participants are also told to ignore the other visual field and to not respond to the targets presented in that visual field. When targets in the attended visual field are compared to targets in the unattended visual field, the unattended targets are found to elicit a smaller N1 than the attended targets, suggesting that attention acts as a sensory gain mechanism that enhances perception of attended (vs. unattended) stimuli.",
            "score": 164.24444580078125
        }
    ]
}