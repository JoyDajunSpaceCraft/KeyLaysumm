{
    "q": [
        {
            "docid": "48845497_7",
            "document": "Number sense in animals . The experimental setup for the study of numerical cognition in animals was further enriched by the work of Francis and Platt and Johnson. In their experiments, the researchers deprived rats of food and then taught them to press a lever a specific number of times to obtain food. The rats learned to press the lever approximately the number of times specified by the researchers. Additionally, the researchers showed that rats' behavior was dependent on the number of required presses, and not for example on the time of pressing, as they varied the experiment to include faster and slower behavior on the rat's part by controlling how hungry the animal was.",
            "score": 129.14282083511353
        },
        {
            "docid": "14083964_27",
            "document": "Animal psychopathology . Certain laboratory rat strains that have been created by controlled breeding for many generations show a higher tendency towards compulsive behaviors than other strains. Lewis rats show more compulsive lever pressing behavior than Sprague Dawley or Wistar rats and are less responsive to the anti-compulsive drug paroxetine. In this study, rats were taught to press a lever to receive food in an operant conditioning task. Once food was no longer provided when they pressed the lever, rats were expected to stop pressing it. Lewis rats pressed the lever more often than the other two types, even though they had presumably learned that they would not receive food, and continued to press it more often even after treatment with the drug. An analysis of the genetic differences between the three rat strains might help to identify genes that might be responsible for the compulsive behavior.",
            "score": 114.38205707073212
        },
        {
            "docid": "84864_8",
            "document": "Edward Thorndike . Thorndike was a pioneer not only in behaviorism and in studying learning, but also in using animals in clinical experiments. Thorndike was able to create a theory of learning based on his research with animals. His doctoral dissertation, \"Animal Intelligence: An Experimental Study of the Associative Processes in Animals\", was the first in psychology where the subjects were nonhumans. Thorndike was interested in whether animals could learn tasks through imitation or observation. To test this, Thorndike created puzzle boxes. The puzzle boxes were approximately 20\u00a0inches long, 15\u00a0inches wide, and 12\u00a0inches tall. Each box had a door that was pulled open by a weight attached to a string that ran over a pulley and was attached to the door. The string attached to the door led to a lever or button inside the box. When the animal pressed the bar or pulled the lever, the string attached to the door would cause the weight to lift and the door to open. Thorndike\u2019s puzzle boxes were arranged so that the animal would be required to perform a certain response (pulling a lever or pushing a button), while he measured the amount of time it took them to escape. Once the animal had performed the desired response they were allowed to escape and were also given a reward, usually food. Thorndike primarily used cats in his puzzle boxes. When the cats were put into the cages they would wander restlessly and meow, but they did not know how to escape. Eventually, the cats would step on the switch on the floor by chance, and the door would open. To see if the cats could learn through observation, he had them observe other animals escaping from the box. He would then compare the times of those who got to observe others escaping with those who did not, and he found that there was no difference in their rate of learning. Thorndike saw the same results with other animals, and he observed that there was no improvement even when he placed the animals\u2019 paws on the correct levers, buttons, or bar. These failures led him to fall back on a trial and error explanation of learning. He found that after accidentally stepping on the switch once, they would press the switch faster in each succeeding trial inside the puzzle box. By observing and recording the animals\u2019 escapes and escape times, Thorndike was able to graph the times it took for the animals in each trial to escape, resulting in a learning curve. The animals had difficulty escaping at first, but eventually \"caught on\" and escaped faster and faster with each successive puzzle box trial, until they eventually leveled off. The quickened rate of escape results in the s-shape of the learning curve. The learning curve also suggested that different species learned in the same way but at different speeds. From his research with puzzle boxes, Thorndike was able to create his own theory of learning. The puzzle box experiments were motivated in part by Thorndike's dislike for statements that animals made use of extraordinary faculties such as insight in their problem solving: \"In the first place, most of the books do not give us a psychology, but rather a eulogy of animals. They have all been about animal intelligence, never about animal stupidity.\"",
            "score": 118.85374581813812
        },
        {
            "docid": "2621864_3",
            "document": "Shaping (psychology) . The trainer starts by reinforcing all behaviors in the first category, here turning toward the lever. When the animal regularly performs that response (turning), the trainer restricts reinforcement to responses in the second category (moving toward), then the third, and so on, progressing to each more accurate approximation as the animal learns the one currently reinforced. Thus, the response gradually approximates the desired behavior until finally the target response (lever pressing) is established. At first the rat is not likely to press the lever; in the end it presses rapidly.",
            "score": 115.28051710128784
        },
        {
            "docid": "569334_4",
            "document": "Association (psychology) . Edward Thorndike did research in this area and developed the law of effect, where associations between a stimulus and response are affected by the consequence of the response. For example, behaviors increase in strength and/or frequency when they have been followed by reward.\u00a0This occurs because of an association between the behavior and a\u00a0mental representation\u00a0of the reward (such as food). Conversely, receiving a negative consequence lowers the frequency of the behavior due to the negative association. An example of this would be a rat in a cage with a bar lever. If pressing the lever results in a food pellet, the rat will learn to press the lever to receive food. If pressing the lever resulted in an electric shock on the floor of the cage, the rat would learn to avoid pressing the lever.",
            "score": 105.51830339431763
        },
        {
            "docid": "448244_11",
            "document": "Caudate nucleus . Meanwhile, behavioral studies provide another layer to the argument: recent studies suggest that the caudate is fundamental to goal direction action, that is, \"the selection of behavior based on the changing values of goals and a knowledge of which actions lead to what outcomes.\" One such study presented rats with levers that triggered the release of a cinnamon flavored solution. After the rats learned to press the lever, the researchers changed the value of the outcome (the rats were taught to dislike the flavor either by being given too much of the flavor, or by making the rats ill after drinking the solution) and the effects were observed. Normal rats pressed the lever less frequently, while rats with lesions in the caudate did not suppress the behavior as effectively. In this way, the study demonstrates the link between the caudate and goal-directed behavior; rats with damaged caudate nuclei had difficulty assessing the changing value of the outcome. In a 2003 human behavioral study, a similar process was repeated, but the decision this time was whether or not to trust another person when money was at stake. While here the choice was far more complex\u2013\u2013the subjects were not simply asked to press a lever, but had to weigh a host of different factors\u2013\u2013at the crux of the study was still behavioral selection based on changing values of outcomes.",
            "score": 111.1690788269043
        },
        {
            "docid": "1095131_20",
            "document": "Kinesthetic learning . The cerebral cortex is the brain tissue covering the top and sides of the brain in most vertebrates. It is involved in storing and processing of sensory inputs and motor outputs. In the human brain, the cerebral cortex is actually a sheet of neural tissue about 1/8th inch thick. The sheet is folded so that it can fit inside the skull. The neural circuits in this area of the brain expand with practice of an activity, just like the synaptic plasticity grows with practice. Clarification of some of the mechanisms of learning by neuro science has been advanced, in part, by the advent of non-invasive imaging technologies, such as positron emission tomography (PET) and functional magnetic resonance imaging (FMRI). These technologies have allowed researchers to observe human learning processes directly. Through these types of technologies, we are now able to see and study what happens in the process of learning. In different tests performed the brain being imaged showed a greater blood flow and activation to that area of the brain being stimulated through different activities such as finger tapping in a specific sequence. It has been revealed that the process at the beginning of learning a new skill happens quickly, and later on slows down to almost a plateau. This process can also be referred to as The Law of Learning. The slower learning showed in the FMRI that in the cerebral cortex this was when the long term learning was occurring, suggesting that the structural changes in the cortex reflect the enhancement of skill memories during later stages of training. When a person studies a skill for a longer duration of time, but in a shorter amount of time they will learn quickly, but also only retain the information into their short-term memory. Just like studying for an exam; if a student tries to learn everything the night before, it will not stick in the long run. If a person studies a skill for a shorter duration of time, but more frequently and long-term, their brain will retain this information much longer as it is stored in the long-term memory. Functional and structural studies of the brain have revealed a vast interconnectivity between diverse regions of the cerebral cortex. For example, large numbers of axons interconnect the posterior sensory areas serving vision, audition, and touch with anterior motor regions. Constant communication between sensation and movement makes sense, because to execute smooth movement through the environment, movement must be continuously integrated with knowledge about one's surroundings obtained via sensory perception. The cerebral cortex plays a role in allowing humans to do this.",
            "score": 94.96668148040771
        },
        {
            "docid": "530708_17",
            "document": "Muscle memory . Skilled motor tasks have been divided into two distinct phases: a fast-learning phase, in which an optimal plan for performance is established, and a slow-learning phase, in which longer-term structural modifications are made on specific motor modules. Even a small amount of training may be enough to induce neural processes that continue to evolve even after the training has stopped, which provides a potential basis for consolidation of the task. In addition, studying mice while they are learning a new complex reaching task, has found that \"motor learning leads to rapid formation of dendritic spines (spinogenesis) in the motor cortex contralateral to the reaching forelimb\". However, motor cortex reorganization itself does not occur at a uniform rate across training periods. It has been suggested that the synaptogenesis and motor map reorganization merely represent the consolidation, and not the acquisition itself, of a specific motor task. Furthermore, the degree of plasticity in various locations (namely motor cortex versus spinal cord) is dependent on the behavioural demands and nature of the task (i.e., skilled reaching versus strength training).",
            "score": 112.6866512298584
        },
        {
            "docid": "487908_17",
            "document": "Motor learning . Impairments associated with developmental coordination disorder (DCD) involve difficulty in learning new motor skills as well as limited postural control and deficits in sensorimotor coordination. It appears that children with DCD are not able to improve performance of complex motor tasks by practice alone. However, there is evidence that task-specific training can improve performance of simpler tasks. Impaired skills learning may be correlated with brain activity, particularly, a reduction of brain activity in regions associated with skilled motor practice.",
            "score": 104.76153635978699
        },
        {
            "docid": "18143331_10",
            "document": "Neurogenetics . In addition to examining how genetic mutations affect the actual structure of the brain, researchers in neurogenetics also examine how these mutations affect cognition and behavior. One method of examining this involves purposely engineering model organisms with mutations of certain genes of interest. These animals are then classically conditioned to perform certain types of tasks, such as pulling a lever in order to gain a reward. The speed of their learning, the retention of the learned behavior, and other factors are then compared to the results of healthy organisms to determine what kind of an effect \u2013 if any \u2013 the mutation has had on these higher processes. The results of this research can help identify genes that may be associated with conditions involving cognitive and learning deficiencies.",
            "score": 95.18203139305115
        },
        {
            "docid": "487908_11",
            "document": "Motor learning . The specificity of learning hypothesis suggests that learning is most effective when practice sessions include environment and movement conditions which closely resemble those required during performance of the task\u00a0\u2014 replicating the target skill level and context for performance. It suggests that the benefit of specificity in practice occurs because motor learning is combined with physical practice during the learned sport or skill. Contrary to previous beliefs, skill learning is accomplished by alternating motor learning and physical performance, making the sources of feedback work together. The learning process, especially for a difficult task, results in the creation of a representation of the task where all relevant information pertaining to task performance is integrated. This representation becomes tightly coupled with increasing experience performing the task. As a result, removing or adding a significant source of information after a practice period where it was present or not, does not cause performance to deteriorate. Interestingly, alternating motor learning and physical practice can ultimately lead to a great, if not better performance as opposed to just physical practice.",
            "score": 93.39409172534943
        },
        {
            "docid": "48845497_14",
            "document": "Number sense in animals . Rats have demonstrated behavior consistent with an approximate number system in experiments where they had to learn to press a lever a specified number of times to obtain food. While they did learn to press the lever the amount specified by the researchers, between 4 and 16, their behavior was approximate, proportional to the number of lever presses expected from them. This means that for the target number of 4, the rats' responses varied from 3 to 7, and for the target number of 16 the responses varied from 12 to 24, showing a much greater interval. This is compatible with the approximate number system and magnitude and distance effects.",
            "score": 126.28076910972595
        },
        {
            "docid": "6226648_18",
            "document": "Brain stimulation reward . The first portion of an ICSS experiment involves training subjects to respond for stimulation using a fixed-ratio 1 (FR-1) reinforcement schedule (1 response = 1 reward). In experiments involving rats, subjects are trained to press a lever for stimulation, and the rate of lever-pressing is typically the dependent variable. In ICSS studies using mice, a response wheel is usually used instead of a lever, as mice do not consistently perform lever-pressing behaviors. Each quarter turn of the response wheel is recorded and rewarded with stimulation. The rewarding stimulus in BSR experiments is typically a train of short-duration pulses separated by interval pulses, which can be manipulated experimentally using the independent variables of stimulation amplitude, frequency, and pulse duration.",
            "score": 183.57063603401184
        },
        {
            "docid": "530708_27",
            "document": "Muscle memory . It has been suggested that consistent practice of a gross motor skill can help a patient with Alzheimer's disease learn and remember that skill. It was thought that the damage to the hippocampus may result in the need for a specific type of learning requirement. A study was created to test this assumption in which the patients were trained to throw a bean bag at a target. It was found that the Alzheimer's patients performed better on the task when learning occurred under constant training as opposed to variable. Also, it was found that gross motor memory in Alzheimer's patients was the same as that of healthy adults when learning occurs under constant practice. This suggests that damage to the hippocampal system does not impair an Alzheimer's patient from retaining new gross motor skills, implying that motor memory for gross motor skills is stored elsewhere in the brain.",
            "score": 113.27367854118347
        },
        {
            "docid": "40568034_15",
            "document": "Neuroenhancement . Stimulating higher cognitive functions of the brain, such as the language function, with tDCS in one study resulted in improved word retrieval. tDCS works by enhancing the connectivity in a given stimulated network, providing neural efficiency in highly specific brain areas critical for task performance. During this time, fMRI images also showed reduced activity in the semantic retrieval processes, suggesting more efficient processing in task-critical areas of the brain. Reduced activity in circumscribed task-related areas has been attributed to consolidation of motor learning and superior memory performance. New research in tDCS is trying to localize the stimulation to affect the desired subset of highly specific task-relevant neurons.",
            "score": 110.53259062767029
        },
        {
            "docid": "21312297_20",
            "document": "Memory consolidation . Rapid eye movement (REM) sleep has been thought of to be an important concept in the overnight learning in humans by establishing information in the hippocampal and cortical regions of the brain. REM sleep elicits an increase in neuronal activity following an enriched or novel waking experience, thus increasing neuronal plasticity and therefore playing an essential role in the consolidation of memories. This has come into question in recent years however and studies on sleep deprivation have shown that animals and humans who are denied REM sleep do not show deficits in task learning. It has been proposed that since the brain is in a non-memory encoding state during sleep, consolidation would be unlikely to occur. Recent studies have examined the relationship between REM sleep and procedural learning consolidation.  In particular studies have been done on sensory and motor related tasks. In one study testing finger-tapping, people were split into two groups and tested post-training with or without intervening sleep; results concluded that sleep post-training increases both speed and accuracy in this particular task, while increasing the activation of both cortical and hippocampal regions; whereas the post-training awake group had no such improvements. It has been theorized that this may be related more-so to a process of synaptic consolidation rather than systems consolidation because of the short-term nature of the process involved. Researchers examining the effect of sleep on motor learning have noted that while consolidation occurs over a period of 4\u20136 hours during sleep, this is also true during waking hours, which may negate any role of sleep in learning. In this sense sleep would serve no special purpose to enhance consolidation of memories because it occurs independently of sleep. Other studies have examined the process of replay which has been described as a reactivation of patterns that were stimulated during a learning phase. Replay has been demonstrated in the hippocampus and this has lent support to the notion that it serves a consolidation purpose. However, replay is not specific to sleep and both rats and primates show signs during restful-awake periods. Also, replay may simply be residual activation in areas that were involved previously in the learning phase and may have no actual effect on consolidation. This reactivation of the memory traces has also been seen in non-REM sleep specifically for hippocampus-dependant memories. Researchers have noted strong reactivation of the hippocampus during sleep immediately after a learning task. This reactivation led to enhanced performance on the learned task. Researchers following this line of work have come to assume that dreams are a by-product of the reactivation of the brain areas and this can explain why dreams may be unrelated to the information being consolidated. The dream experience itself is not what enhances memory performance but rather it is the reactivation of the neural circuits that causes this.",
            "score": 114.0144213438034
        },
        {
            "docid": "232386_5",
            "document": "Motor skill . In the childhood stages of development, gender differences can greatly influence motor skill. In the article \"An Investigation of Age and Gender Differences in Preschool Children's Specific Motor Skills\", girls scored significantly higher than boys on visual motor and graphomotor tasks. However, boys were seen to be more proficient in the balance task. The results from this study suggest that girls attain manual dexterity earlier than boys (Junaid & Fellowes, 2006). Variability of results in the tests can be attributed towards the multiplicity of different assessment tools used (Piek et al. 2012). Furthermore, gender differences in motor skills are seen to be affected by environmental factors. In essence, \"parents and teachers often encourage girls to engage in quite activities requiring fine motor skills, while they promote boys' participation in dynamic movement actions\" (Vlachos, Papadimitriou, & Bonoti, 2014). In the journal article Gender Differences in Motor Skill Proficiency From Childhood to Adolescence by Lisa Barrett, the evidence for motor skill based on gender is apparent. In general, boys are more skillful in object control and object manipulation skills. These tasks include throwing, kicking, and catching skills. These skills were tested and concluded that boys perform better with these tasks. There was no evidence for the difference in locomotor skill between the genders, but both are improved in the intervention of physical activity. Overall, the predominance of development on balance skills (gross motor) in boys and manual skills (fine motor) in girls (Vlachos, Papadimitriou, & Bonoti, 2014). Components of Development: Growth: Increase in the size of the body or its parts as the individual progresses toward maturity, Quantitative structural changes Maturation: Refers to qualitative changes that enable one to progress to higher levels of functioning; It is primarily innate Experience/Learning: Refers to factors within the environment that may alter or modify the appearance of various developmental characteristics through the process of learning Adaptation: Refers to the complex interplay or interaction between forces within the individual (nature) and the environment (nurture)",
            "score": 122.45418798923492
        },
        {
            "docid": "13149599_14",
            "document": "Habit . The following is a description of a classic goal devaluation experiment (from a Scientific American MIND guest blog post called Should Habits or Goals Direct Your Life? It Depends) which demonstrates the difference between goal-directed and habitual behavior: A series of elegant experiments conducted by Anthony Dickinson and colleagues in the early 1980s at the University of Cambridge in England clearly exposes the behavioral differences between goal-directed and habitual processes. Basically, in the training phase, a rat was trained to press a lever in order to receive some food. Then, in a second phase, the rat was placed in a different cage without a lever and was given the food, but it was made ill whenever it ate the food. This caused the rat to \"devalue\" the food, because it associated the food with being ill, without directly associating the action of pressing the lever with being ill. Finally, in the test phase, the rat was placed in the original cage with the lever. (To prevent additional learning, no food was delivered in the test phase.) Rats that had undergone an extensive training phase continued to press the lever in the test phase even though the food was devalued; their behavior was called habitual. Rats that had undergone a moderate training phase did not, and their behavior was called goal-directed. \u2026 [G]oal-directed behavior is explained by the rat using an explicit prediction of the consequence, or outcome, of an action to select that action. If the rat wants the food, it presses the lever, because it predicts that pressing the lever will deliver the food. If the food has been devalued, the rat will not press the lever. Habitual behavior is explained by a strong association between an action and the situation from which the action was executed. The rat presses the lever when it sees the lever, not because of the predicted outcome.",
            "score": 136.54560947418213
        },
        {
            "docid": "487908_18",
            "document": "Motor learning . Motor learning has been applied to stroke recovery and neurorehabilitation, as rehabilitation is generally a process of relearning lost skills through practice and/or training. Although rehabilitation clinicians utilize practice as a major component within an intervention, a gap remains between motor control and motor learning research and rehabilitation practice. Common motor learning paradigms include robot arm paradigms, where individuals are encouraged to resist against a hand held device throughout specific arm movements. Another important concept to motor learning is the amount practice implemented in an intervention. Studies regarding the relationship between the amount of training received and the retention of the memory a set amount of time afterwards have been a popular focus in research. It has been shown that over learning leads to major improvements in long term retention and little effect on performance. Motor learning practice paradigms have compared the differences of different practice schedules, and it has proposed that repetition of the same movements is not enough in order to relearn a skill, as it is unclear whether true brain recovery is elicited through repetition alone. It is suggested that compensation methods develop through pure repetition and to elicit cortical changes (true recovery), individuals should be exposed to more challenging tasks. Research that has implemented motor learning and rehabilitation practice has been used within the stroke population and includes arm ability training, constraint-induced movement therapy, electromyograph-triggered neuromuscular stimulation, interactive robot therapy and virtual reality-based rehabilitation. A recent study ischemic conditioning was delivered via blood pressure cuff inflation and deflation to the arm, to facilitate learning. It showed for the first time in humans and animals, that ischemic conditioning can enhance motor learning and that the enhancement is retained over time. The potential benefits of ischemic conditioning extend far beyond stroke to other neuro-, geriatric, and pediatric rehabilitation populations. These findings were featured on Global Medical Discovery news.",
            "score": 104.83728551864624
        },
        {
            "docid": "10567836_12",
            "document": "Ordinal numerical competence . Experiments have shown that rats are able to be trained to press one lever after hearing two bursts of white noise, then press another lever after four bursts of white noise. The interburst interval is varied between trials so the discrimination is based on number of bursts and not time duration of the sequence. Studies show that rats as well as pigeons learned to make different responses to both short and long durations of signals. During testing, rats exhibited a pattern called \"break-run-break\"; when it came to responding after a stint of little to no response, they would suddenly respond in high frequency, then return to little or no response activity.  Data suggests that rats and pigeons are able to process time and number information at the same time. The Mode Control Model shows that these animals can process number and time information by transmission pulses to accumulators controlled by switches that operate different modes.",
            "score": 132.99442744255066
        },
        {
            "docid": "52588865_9",
            "document": "William T. Greenough . This view of brain structure, neural activity, and learning was completely overturned by Greenough's research. Greenough initially worked with mice and rat models, later studying primates and humans. His studies demonstrated that fundamental physical changes occurred in neurons in the brain in response to stimulating environments. At the most basic cellular level, the brains of rats that lived in stimulating environments developed more synapses than those that did not. He went on to demonstrate that new synapses were formed as a result of activities that involved learning, not just increased activity. Moreover, changes occurred in areas of the brain that were associated with the performance of specific learned tasks. Observed changes in learning, memory, and synapse formation persisted after training. Learning and memory formation were therefore fundamentally related to ongoing synapse formation. The result of Greenough's work has been a new model of brain 'plasticity' in which long-term memories are formed at a structural level in the brain as part of lifelong processes of learning.",
            "score": 105.76296675205231
        },
        {
            "docid": "14942624_23",
            "document": "Vocal learning . There has been intense debate on whether these songs are innate or learned. In 2011, Kikusui \"et al\". cross-fostered two strains of mice with distinct song phenotypes and discovered that strain-specific characteristics of each song persisted in the offspring, indicating that these vocalizations are innate. However, a year later work by Arriaga et al. contradicted these results as their study found a motor cortex region active during singing, which projects directly to brainstem motor neurons and is also important for keeping songs stereotyped and on pitch. Vocal control by forebrain motor areas and direct cortical projections to vocal motor neurons are both features of vocal learning. Furthermore, male mice were shown to depend on auditory feedback to maintain some ultrasonic song features, and sub-strains with differences in their songs were able to match each other\u2019s pitch when cross-housed under competitive social conditions.",
            "score": 108.13564944267273
        },
        {
            "docid": "29109801_4",
            "document": "Methastyridone . \"Merck\u2019s behavioral psychopharmacology screening program finally identified one highly promising new antidepressant. Code named MK-202, the chemical increased lever-pressing work output under a range of conditions, in seemingly more adaptive ways than amphetamine. For instance, in the \u201cstrained fixed-ratio\u201d test, designed to measure \u201can animal\u2019s ability to handle an overly large workload with inadequate motivation,\u201d MK-202 performed better than dextroamphetamine. Here, hungry rats were given a drop of condensed milk only after pressing a lever two hundred times in response to a light signal. However, in the middle of their heavy and under-rewarded task a second light would turn on intermittently, and if they immediately responded by pressing a second lever they would get a milk drop instantly. Thus, this experiment measured both willingness to do \u201ca particularly long and tedious job\u201d as well as \u201calertness\u201d to a second stimulus, according to Merck researchers. The rats on amphetamine performed well on the repetitive task but tended to miss the second stimulus; not so the rats on MK-202. Given the similarity between the rat\u2019s situation and the repetitive work that most people must endure to make a living, a drug that increased lever pressing without producing unresponsiveness would seem a likely antidepressant\u2014provided we accept that inefficiency in unrewarding jobs indicates psychiatric depression.\" \"This implicit identification of impaired work efficiency with depressive illness, inscribed in the use of amphetamine-boosted lever pressing as the benchmark that subsequent antidepressants had to meet, applied to the highest level executive type of work also. (The business world is called a \u201crat race\u201d with reason!) This is evident from another test, designed to measure a rat\u2019s capacity to perform complex tasks. Here, to get a reward, rats had to press a lever rapidly when a white light was on, slowly when a red light was on, and not at all when both lights were on. The rats on amphetamine pressed their levers fast no matter what lights were on, but the rats on MK-202 only pressed fast when high speed was rewarded. In these and a half a dozen other experiments with trained rats subject to diabolically ingenious \u201creinforcement schedules\u201d (that is, particular programs of reward and punishment), MK-202 outperformed amphetamine for boosting work output, maximizing reward, and minimizing punishment, particularly when tasks were both difficult and unrewarding. A more promising antidepressant drug candidate could hardly be imagined, and in January 1960 the behavioral psychopharmacology unit passed it on for human testing as an antidepressant, with its highest recommendation.\"",
            "score": 136.98422491550446
        },
        {
            "docid": "577858_14",
            "document": "Imitation . Paralleling these studies, comparative psychologists provided tools or apparatuses that could be handled in different ways. Heyes and co-workers reported evidence for imitation in rats that pushed a lever in the same direction as their models, though later on they withdrew their claims due to methodological problems in their original setup. By trying to design a testing paradigm that is less arbitrary than pushing a lever to the left or to the right, Custance and co-workers introduced the \"artificial fruit\" paradigm, where a small object could be opened in different ways to retrieve food placed inside\u2014not unlike a hard-shelled fruit. Using this paradigm, scientists reported evidence for imitation in monkeys and apes. There remains a problem with such tool (or apparatus) use studies: what animals might learn in such studies need not be the actual behavior patterns (i.e., the actions) that were observed. Instead they might learn about some effects in the environment (i.e., how the tool moves, or how the apparatus works). This type of observational learning, which focuses on results, not actions, has been dubbed emulation (see Emulation (observational learning)).",
            "score": 78.14924192428589
        },
        {
            "docid": "31595494_5",
            "document": "Motor Skill Consolidation . One of the earliest studies demonstrating that motor skills undergo a consolidation process, in which they are susceptible to interference, came from the lab of Emilio Bizzi at MIT in 1996. In this study, subjects were trained in a reaching task using a robotic manipulator that imparted an unknown (to the subject) force on the hand during the reach, which is a common laboratory test for motor learning. Over a short period of time, subjects learned to compensate for this force to make accurate reaches to a target. Thus, a new motor skill was acquired. Some subjects were then trained in a different reaching task shortly after learning the first, with varying periods between the two tasks. Tests the next day showed that consolidation of the new motor skill was disrupted when the second task was learned immediately after the first - a process known as 'retrograde interference.' There was no disruption if at least four hours elapsed between learning the two tasks, with consolidation occurring gradually over this period.",
            "score": 94.59628546237946
        },
        {
            "docid": "26685741_43",
            "document": "Sleep and memory . The effects of REM sleep deprivation (RSD) on neurotrophic factors, specifically nerve growth factor (NGF) and brain-derived neurotrophic factor (BDNF), were assessed in 2000 by Sie et el. Neurotrophins are proteins found in the brain and periphery that aid in the survival, functioning and generation of neurons; this is an important element in the synaptic plasticity process, the underlying neurochemical foundation in forming memories. Sei et al., inserted electrodes into the skulls of seven pairs of rats to measure Electroencephalogram (EEG), and inserted wire into the neck muscles of the rats to measure Electromyogram (EMG), a technique used to measure the amount of muscle activity. Half the rats experienced a six-hour REM sleep deprivation period, while the other half experienced a six-hour sleep period, containing all sleep cycles. Results showed that in the rats in the REM sleep deprivation group showed decreased level of brain-derived neurotrophic factor in the cerebellum (coordination, motor learning) and brainstem (sensory and motor ascending pathway), conversely the hippocampus (long-term memory, spatial navigation), showed decreases in nerve growth factor levels. BDNF protein has been shown to be necessary for procedural learning (form of non-declarative memory). Since procedural learning has also exhibited consolidation and enhancement under REM sleep, it is proposed that the impairment of procedural learning tasks is due to the lack of BDNF proteins in the cerebellum and brainstem during RSD. In regards to NGF, the basal forebrain (production and distribution of AcH in the brain), more specifically the medial septal area, sends cholinergic (excitatory in hippocampus) and GABAinergic (inhibitory) neurotransmitters through fibres to the hippocampus target cells. These target cells then secrete NGF which plays a key role in the physiological state of the hippocampus and its functions. It has been noted that REM sleep increases the secretion of NGF, therefore it has been proposed that during RSD cholinergic activity decreases leading to a decrease in NGF and impairment in procedural learning. Walker and Stickgold hypothesized that after initial memory acquisition, sleep reorganizes memory representation at a macro-brain systems level. Their experiment consisted of two groups; the night-sleep group was taught a motor sequence block tapping task at night, put to sleep and then retested 12 hours later. The day-wake group was taught the same task in the morning and tested 12 hours later with no intervening sleep. FMRI was used to measure brain activity during retest. Results indicated significantly fewer errors/sequence in the night-sleep group compared to the day wake group. FMRI output for the night-sleep group indicated increased activation in the right primary motor cortex/M1/Prefrontal Gyrus (contra lateral to the hand they were block tapping with), right anterior medial prefrontal lobe, right hippocampus (long-term memory, spatial memory), right ventral striatum (olfactory tubercle, nucleus accumbens), as well as regions of the cerebellum (lobules V1, V11). In the day-wake group, fMRI showed \"decreased\" signal activation bilaterally in the parietal cortices (integrates multiple modalities), in addition to the left insular cortex (regulation of homeostasis), left temporal pole (most anterior of temporal cortex), and the left inferior fronto-polar cortex. Previous investigations have shown that signal increases indicate brain plasticity. The increased signal activity seen in M1 after sleep corresponds to increased activity in this area seen during practice; however, an individual must practice for longer periods than they would have to sleep in order to obtain the same level of M1 signal increases. Therefore, it is suggested that sleep enhances the cortical representation of motor tasks by brain system expansion, as seen by increased signal activity.",
            "score": 105.9649041891098
        },
        {
            "docid": "487908_10",
            "document": "Motor learning . KR seems to have many different roles, some of which can be viewed as temporary or transient (i.e. performance effects). Three of these roles include: 1) motivation, 2) associative function, and 3) guidance. The motivational influence can increase the effort and interest of the performer in the task as well as maintain this interest once KR is removed. Though important to create interest in the task for performance and learning purposes, however the extent to which it affects learning is unknown. The associative function of KR is likely to be involved in the formation of associations between stimulus and response (i.e., Law of Effect). However, this additional effect is not able to account for findings in transfer tasks manipulating the relative frequency of KR; specifically, decreasing relative frequency results in enhanced learning. For an alternate discussion on how KR may calibrate the motor system to the outside world (see schema theory in motor program). The guidance role of KR is likely the most influential to learning as both internal and external sources of feedback play a guiding role in performance of a motor task. As the performer is informed of errors in task performance, the discrepancy can be used to continually improve performance in following trials. However, the \"guidance hypothesis\" postulates that provision of too much external, augmented feedback (e.g., KR) during practice may cause the learner to develop a harmful dependency on this source of feedback. This may lead to superior performance during practice but poor performance at transfer\u00a0\u2013 an indication of poor motor learning. Additionally, it implies that, as the performer improves, the conditions of KR must be adapted according to the performer\u2019s skill and difficulty of the task in order to maximize learning (see challenge point framework).",
            "score": 86.87356090545654
        },
        {
            "docid": "4868_26",
            "document": "B. F. Skinner . An operant conditioning chamber (also known as a \"Skinner Box\") is a laboratory apparatus used in the experimental analysis of animal behavior. It was invented by Skinner while he was a graduate student at Harvard University. As used by Skinner, the box had a lever (for rats), or a disk in one wall (for pigeons). A press on this \"manipulandum\" could deliver food to the animal through an opening in the wall, and responses reinforced in this way increased in frequency. By controlling this reinforcement together with discriminative stimuli such as lights and tones, or punishments such as electric shocks, experimenters have used the operant box to study a wide variety of topics, including schedules of reinforcement, discriminative control, delayed response (\"memory\"), punishment, and so on. By channeling research in these directions, the operant conditioning chamber has had a huge influence on course of research in animal learning and its applications. It enabled great progress on problems that could be studied by measuring the rate, probability, or force of a simple, repeatable response. However, it discouraged the study of behavioral processes not easily conceptualized in such terms\u2014spatial learning, in particular, which is now studied in quite different ways, for example, by the use of the water maze.",
            "score": 76.29636442661285
        },
        {
            "docid": "530708_7",
            "document": "Muscle memory . The neuroanatomy of memory is widespread throughout the brain; however, the pathways important to motor memory are separate from the medial temporal lobe pathways associated with declarative memory. As with declarative memory, motor memory is theorized to have two stages: a short-term memory encoding stage, which is fragile and susceptible to damage, and a long-term memory consolidation stage, which is more stable.  The memory encoding stage is often referred to as motor learning, and requires an increase in brain activity in motor areas as well as an increase in attention. Brain areas active during motor learning include the motor and somatosensory cortices; however, these areas of activation decrease once the motor skill is learned. The prefrontal and frontal cortices are also active during this stage due to the need for increased attention on the task being learned.",
            "score": 86.55456209182739
        },
        {
            "docid": "8582684_22",
            "document": "Reward system . The first clue to the presence of a reward system in the brain came with an accident discovery by James Olds and Peter Milner in 1954. They discovered that rats would perform behaviors such as pressing a bar, to administer a brief burst of electrical stimulation to specific sites in their brains. This phenomenon is called intracranial self-stimulation or brain stimulation reward. Typically, rats will press a lever hundreds or thousands of times per hour to obtain this brain stimulation, stopping only when they are exhausted. While trying to teach rats how to solve problems and run mazes, stimulation of certain regions of the brain where the stimulation was found seemed to give pleasure to the animals. They tried the same thing with humans and the results were similar. The explanation to why animals engage in a behavior that has no value to the survival of either themselves or their species is that the brain stimulation is activating the system underlying reward.",
            "score": 116.58418011665344
        },
        {
            "docid": "380406_10",
            "document": "Comparative psychology . A persistent question with which comparative psychologists have been faced is the relative intelligence of different species of animal. Indeed, some early attempts at a genuinely comparative psychology involved evaluating how well animals of different species could learn different tasks. These attempts floundered; in retrospect it can be seen that they were not sufficiently sophisticated, either in their analysis of the demands of different tasks, or in their choice of species to compare. However, the definition of \"intelligence\" in comparative psychology is deeply affected by anthropomorphism, and focuses on simple tasks, complex problems, reversal learning, learning sets, and delayed alternation are plagued with practical and theoretical problems. In the literature, \"intelligence\" is defined as whatever is closest to human performance and neglects behaviors that humans are usually incapable of (e.g. echolocation). Specifically, comparative researchers encounter problems associated with individual differences, differences in motivation, differences in reinforcement, differences in sensory function, differences in motor capacities, and species-typical preparedness (i.e. some species have evolved to acquire some behaviors quicker than other behaviors).",
            "score": 78.98831677436829
        },
        {
            "docid": "23631964_23",
            "document": "Primary motor cortex . One of the most common misconceptions about the primary motor cortex is that the map of the body is cleanly segregated. Yet it is not a map of individuated muscles or even individuated body parts. The map contains considerable overlap. This overlap increases in more anterior regions of the primary motor cortex. One of the main goals in the history of work on the motor cortex was to determine just how much the different body parts are overlapped or segregated in the motor cortex. Researchers who addressed this issue found that the map of the hand, arm, and shoulder contained extensive overlap. Studies that map the precise functional connectivity from cortical neurons to muscles show that even a single neuron in the primary motor cortex can influence the activity of many muscles related to many joints. In experiments on cats and monkeys, as animals learn complex, coordinated movements, the map in the primary motor cortex becomes more overlapping, evidently learning to integrate the control of many muscles. In monkeys, when electrical stimulation is applied to the motor cortex on a behavioral timescale, it evokes complex, highly integrated movements such as reaching with the hand shaped to grasp, or bringing the hand to the mouth and opening the mouth. This type of evidence suggests that the primary motor cortex, while containing a rough map of the body, may participate in integrating muscles in meaningful ways rather than in segregating the control of individual muscle groups. It has been suggested that a deeper principle of organization may be a map of the statistical correlations in the behavioral repertoire, rather than a map of body parts. To the extent that the movement repertoire breaks down partly into the actions of separate body parts, the map contains a rough and overlapping body arrangement.",
            "score": 104.93554139137268
        }
    ],
    "r": [
        {
            "docid": "6226648_18",
            "document": "Brain stimulation reward . The first portion of an ICSS experiment involves training subjects to respond for stimulation using a fixed-ratio 1 (FR-1) reinforcement schedule (1 response = 1 reward). In experiments involving rats, subjects are trained to press a lever for stimulation, and the rate of lever-pressing is typically the dependent variable. In ICSS studies using mice, a response wheel is usually used instead of a lever, as mice do not consistently perform lever-pressing behaviors. Each quarter turn of the response wheel is recorded and rewarded with stimulation. The rewarding stimulus in BSR experiments is typically a train of short-duration pulses separated by interval pulses, which can be manipulated experimentally using the independent variables of stimulation amplitude, frequency, and pulse duration.",
            "score": 183.5706329345703
        },
        {
            "docid": "14438348_28",
            "document": "Cannabinoid receptor type 1 . CB receptors are expressed throughout motor regions of the mammalian brain, suggesting that CB has a role in motor control. CB activation has been shown to effect specific kinematic variables in rodents, such as the rate of applied force during lever pressing, and the amplitude (but not timing) of whisker movements.",
            "score": 147.21090698242188
        },
        {
            "docid": "6226648_23",
            "document": "Brain stimulation reward . The independent variables of stimulation train and pulse duration can also be varied to determine how each affects ICSS response rates. Longer train durations produce more vigorous responding up to a point, after which rate of responding varies inversely with train length. This is due to lever-pressing for additional stimulation before the previously earned train has finished.",
            "score": 146.22618103027344
        },
        {
            "docid": "29109801_4",
            "document": "Methastyridone . \"Merck\u2019s behavioral psychopharmacology screening program finally identified one highly promising new antidepressant. Code named MK-202, the chemical increased lever-pressing work output under a range of conditions, in seemingly more adaptive ways than amphetamine. For instance, in the \u201cstrained fixed-ratio\u201d test, designed to measure \u201can animal\u2019s ability to handle an overly large workload with inadequate motivation,\u201d MK-202 performed better than dextroamphetamine. Here, hungry rats were given a drop of condensed milk only after pressing a lever two hundred times in response to a light signal. However, in the middle of their heavy and under-rewarded task a second light would turn on intermittently, and if they immediately responded by pressing a second lever they would get a milk drop instantly. Thus, this experiment measured both willingness to do \u201ca particularly long and tedious job\u201d as well as \u201calertness\u201d to a second stimulus, according to Merck researchers. The rats on amphetamine performed well on the repetitive task but tended to miss the second stimulus; not so the rats on MK-202. Given the similarity between the rat\u2019s situation and the repetitive work that most people must endure to make a living, a drug that increased lever pressing without producing unresponsiveness would seem a likely antidepressant\u2014provided we accept that inefficiency in unrewarding jobs indicates psychiatric depression.\" \"This implicit identification of impaired work efficiency with depressive illness, inscribed in the use of amphetamine-boosted lever pressing as the benchmark that subsequent antidepressants had to meet, applied to the highest level executive type of work also. (The business world is called a \u201crat race\u201d with reason!) This is evident from another test, designed to measure a rat\u2019s capacity to perform complex tasks. Here, to get a reward, rats had to press a lever rapidly when a white light was on, slowly when a red light was on, and not at all when both lights were on. The rats on amphetamine pressed their levers fast no matter what lights were on, but the rats on MK-202 only pressed fast when high speed was rewarded. In these and a half a dozen other experiments with trained rats subject to diabolically ingenious \u201creinforcement schedules\u201d (that is, particular programs of reward and punishment), MK-202 outperformed amphetamine for boosting work output, maximizing reward, and minimizing punishment, particularly when tasks were both difficult and unrewarding. A more promising antidepressant drug candidate could hardly be imagined, and in January 1960 the behavioral psychopharmacology unit passed it on for human testing as an antidepressant, with its highest recommendation.\"",
            "score": 136.98422241210938
        },
        {
            "docid": "13149599_14",
            "document": "Habit . The following is a description of a classic goal devaluation experiment (from a Scientific American MIND guest blog post called Should Habits or Goals Direct Your Life? It Depends) which demonstrates the difference between goal-directed and habitual behavior: A series of elegant experiments conducted by Anthony Dickinson and colleagues in the early 1980s at the University of Cambridge in England clearly exposes the behavioral differences between goal-directed and habitual processes. Basically, in the training phase, a rat was trained to press a lever in order to receive some food. Then, in a second phase, the rat was placed in a different cage without a lever and was given the food, but it was made ill whenever it ate the food. This caused the rat to \"devalue\" the food, because it associated the food with being ill, without directly associating the action of pressing the lever with being ill. Finally, in the test phase, the rat was placed in the original cage with the lever. (To prevent additional learning, no food was delivered in the test phase.) Rats that had undergone an extensive training phase continued to press the lever in the test phase even though the food was devalued; their behavior was called habitual. Rats that had undergone a moderate training phase did not, and their behavior was called goal-directed. \u2026 [G]oal-directed behavior is explained by the rat using an explicit prediction of the consequence, or outcome, of an action to select that action. If the rat wants the food, it presses the lever, because it predicts that pressing the lever will deliver the food. If the food has been devalued, the rat will not press the lever. Habitual behavior is explained by a strong association between an action and the situation from which the action was executed. The rat presses the lever when it sees the lever, not because of the predicted outcome.",
            "score": 136.5456085205078
        },
        {
            "docid": "9591787_12",
            "document": "Punishment (psychology) . One variable affecting punishment is contingency, which is defined as the dependency of events. A behavior may be dependent on a stimulus or dependent on a response. The purpose of punishment is to reduce a behavior, and the degree to which punishment is effective in reducing a targeted behavior is dependent on the relationship between the behavior and a punishment. For example, if a rat receives an aversive stimulus, such as a shock each time it presses a lever, then it is clear that contingency occurs between lever pressing and shock. In this case, the punisher (shock) is contingent upon the appearance of the behavior (lever pressing). Punishment is most effective when contingency is present between a behavior and a punisher. A second variable affecting punishment is contiguity, which is the closeness of events in time and/or space. Contiguity is important to reducing behavior because the longer the time interval between an unwanted behavior and a punishing effect, the less effective the punishment will be. One major problem with a time delay between a behavior and a punishment is that other behaviors may present during that time delay. The subject may then associate the punishment given with the unintended behaviors, and thus suppressing those behaviors instead of the targeted behavior. Therefore, immediate punishment is more effective in reducing a targeted behavior than a delayed punishment would be.",
            "score": 133.723876953125
        },
        {
            "docid": "10567836_12",
            "document": "Ordinal numerical competence . Experiments have shown that rats are able to be trained to press one lever after hearing two bursts of white noise, then press another lever after four bursts of white noise. The interburst interval is varied between trials so the discrimination is based on number of bursts and not time duration of the sequence. Studies show that rats as well as pigeons learned to make different responses to both short and long durations of signals. During testing, rats exhibited a pattern called \"break-run-break\"; when it came to responding after a stint of little to no response, they would suddenly respond in high frequency, then return to little or no response activity.  Data suggests that rats and pigeons are able to process time and number information at the same time. The Mode Control Model shows that these animals can process number and time information by transmission pulses to accumulators controlled by switches that operate different modes.",
            "score": 132.9944305419922
        },
        {
            "docid": "4024765_23",
            "document": "Tilling-Stevens . With the electrical generator (a large dynamo) for the motor permanently connected to the petrol engine, the early petrol electric controls available were a sprung return throttle pedal (with a hand operated variable latching throttle to set and adjust the idle speed), a brake pedal, a means of steering (wheel, etc.) and two usually column mounted levers. One centre off lever operated a three position changeover switch to permit running in either direction, and the other lever operated a wiper across a bank of large high current wire wound resistances which affected the motor and dynamo fields, to give the electrical effect of gearing. It was (is, the author of this section has maintained and driven a 1914 TS3 model for over fifteen years as of 2015) very important to set the minimum possible idle speed, or when engaging the direction switch excess load on the system and possible unwanted movement will occur. The resistance \"gear\" lever is then set to max torque, and then the direction lever set to (say) forward. On releasing the handbrake and pressing the throttle pedal a little the vehicle will glide away smoothly. Giving more throttle and gradually altering the resistance lever will then produce higher speed, with none of the jerking and pauses in acceleration of a gearbox. To stop, the throttle pedal is released, the resistance lever is brought back to \"slow speed\", the brake applied and as rest is achieved the forward/reverse lever moved to neutral and handbrake applied. There is however NO engine braking available as from a mechanical drive changed into a lower gear, so the system relies totally on the mechanical wheel brakes, which on early chassis applied to the rear axle only.",
            "score": 130.8983612060547
        },
        {
            "docid": "48845497_7",
            "document": "Number sense in animals . The experimental setup for the study of numerical cognition in animals was further enriched by the work of Francis and Platt and Johnson. In their experiments, the researchers deprived rats of food and then taught them to press a lever a specific number of times to obtain food. The rats learned to press the lever approximately the number of times specified by the researchers. Additionally, the researchers showed that rats' behavior was dependent on the number of required presses, and not for example on the time of pressing, as they varied the experiment to include faster and slower behavior on the rat's part by controlling how hungry the animal was.",
            "score": 129.142822265625
        },
        {
            "docid": "48845497_14",
            "document": "Number sense in animals . Rats have demonstrated behavior consistent with an approximate number system in experiments where they had to learn to press a lever a specified number of times to obtain food. While they did learn to press the lever the amount specified by the researchers, between 4 and 16, their behavior was approximate, proportional to the number of lever presses expected from them. This means that for the target number of 4, the rats' responses varied from 3 to 7, and for the target number of 16 the responses varied from 12 to 24, showing a much greater interval. This is compatible with the approximate number system and magnitude and distance effects.",
            "score": 126.28076934814453
        },
        {
            "docid": "19337310_45",
            "document": "Rodent . Because laboratory mice (house mice) and rats (brown rats) are widely used as scientific models to further our understanding of biology, a great deal has come to be known about their cognitive capacities. Brown rats exhibit cognitive bias, where information processing is biased by whether they are in a positive or negative affective state. For example, laboratory rats trained to respond to a specific tone by pressing a lever to receive a reward, and to press another lever in response to a different tone so as to avoid receiving an electric shock, are more likely to respond to an intermediate tone by choosing the reward lever if they have just been tickled (something they enjoy), indicating \"a link between the directly measured positive affective state and decision making under uncertainty in an animal model.\"",
            "score": 123.95671081542969
        },
        {
            "docid": "34967526_4",
            "document": "Conditioned emotional response . In 1941 B.F. Skinner and William Kaye Estes were the first to use the term \"CER\" and demonstrated the phenomenon with rats. They trained food-deprived rats to lever-press (operant conditioning) for food pellets, maintained on a variable interval (VI) schedule of reinforcement. Periodically, a tone was presented, for a brief amount of time, which co-terminated with electric shock to the metal floor (classical delay conditioning). The rats, upon receipt of the first shock, displayed the expected unconditional responses to the shock (e.g., jumping, squealing, urinating, etc.), however with subsequent presentations of the tone-shock trials, those responses habituated somewhat. The largest change in behavior occurred during the time the tone was presented. That is, lever-pressing during the tone reduced to near zero levels. Given that the tone-shock pairings were likely sufficient to produce classical conditioning, Estes and Skinner hypothesized that the tone elicited fear that interfered or interrupted ongoing operant behavior. In a sense, the now CS (tone) \"paralyzed in fear\" the rat. Note that the suppression of lever-pressing was robust, even though the operant, lever-press - food contingency was not altered at all. This experiment is critical in experimental psychology for it demonstrated that the interaction of classical and operant conditioning contingency could be powerful in altering behavior. This work sparked a number of experiments on this interaction, resulting in important experimental and theoretical contributions on autoshaping, negative automaintenance, and potentiated feeding, to name a few.",
            "score": 122.8802261352539
        },
        {
            "docid": "232386_5",
            "document": "Motor skill . In the childhood stages of development, gender differences can greatly influence motor skill. In the article \"An Investigation of Age and Gender Differences in Preschool Children's Specific Motor Skills\", girls scored significantly higher than boys on visual motor and graphomotor tasks. However, boys were seen to be more proficient in the balance task. The results from this study suggest that girls attain manual dexterity earlier than boys (Junaid & Fellowes, 2006). Variability of results in the tests can be attributed towards the multiplicity of different assessment tools used (Piek et al. 2012). Furthermore, gender differences in motor skills are seen to be affected by environmental factors. In essence, \"parents and teachers often encourage girls to engage in quite activities requiring fine motor skills, while they promote boys' participation in dynamic movement actions\" (Vlachos, Papadimitriou, & Bonoti, 2014). In the journal article Gender Differences in Motor Skill Proficiency From Childhood to Adolescence by Lisa Barrett, the evidence for motor skill based on gender is apparent. In general, boys are more skillful in object control and object manipulation skills. These tasks include throwing, kicking, and catching skills. These skills were tested and concluded that boys perform better with these tasks. There was no evidence for the difference in locomotor skill between the genders, but both are improved in the intervention of physical activity. Overall, the predominance of development on balance skills (gross motor) in boys and manual skills (fine motor) in girls (Vlachos, Papadimitriou, & Bonoti, 2014). Components of Development: Growth: Increase in the size of the body or its parts as the individual progresses toward maturity, Quantitative structural changes Maturation: Refers to qualitative changes that enable one to progress to higher levels of functioning; It is primarily innate Experience/Learning: Refers to factors within the environment that may alter or modify the appearance of various developmental characteristics through the process of learning Adaptation: Refers to the complex interplay or interaction between forces within the individual (nature) and the environment (nurture)",
            "score": 122.45418548583984
        },
        {
            "docid": "404084_27",
            "document": "Hebbian theory . Evidence for that perspective comes from many experiments that show that motor programs can be triggered by novel auditory or visual stimuli after repeated pairing of the stimulus with the execution of the motor program (for a review of the evidence, see Giudice et al., 2009). For instance, people who have never played the piano do not activate brain regions involved in playing the piano when listening to piano music. Five hours of piano lessons, in which the participant is exposed to the sound of the piano each time he presses a key, suffices to later trigger activity in motor regions of the brain upon listening to piano music. Consistent with the fact that spike-timing-dependent plasticity occurs only if the presynaptic neuron's firing predicts the post-synaptic neuron's firing, the link between sensory stimuli and motor programs also only seem to be potentiated if the stimulus is contingent on the motor program.",
            "score": 122.38015747070312
        },
        {
            "docid": "55036262_11",
            "document": "Chris Sherwin . He went on to conduct extensive studies on laboratory cage design, showing that mice kept in ordinary cages chose to drink more of an anxiety-reducing drug than mice housed in larger cages with nesting material, a nest box, and a running wheel, where they could burrow and be with other mice. He trained mice to open a lever to access cages with more space, varying how often the lever had to be pressed, and found that more space was something they were willing to work for. He found that cage colour affected mouse welfare, including body weight; the mice liked white cages most and red least. In another study, he demonstrated that mice need to engage in burrowing behaviour. Laboratory mice spent the same amount of time burrowing whether or not they were supplied with ready-made burrows. Sherwin used burrows constructed by the same mouse in an earlier part of the experiment, thereby addressing the argument that the mouse continued to burrow only because the ready-made burrows were inadequate.",
            "score": 121.98919677734375
        },
        {
            "docid": "425938_55",
            "document": "Animal cognition . Cognitive bias is sometimes illustrated by using answers to the question \"Is the glass half empty or half full?\". Choosing \"half empty\" is supposed to indicate pessimism whereas choosing \"half full\" indicates optimism. To test this in animals, an individual is trained to anticipate that stimulus A, e.g. a 100\u00a0Hz tone, precedes a positive event, e.g. highly desired food is delivered when a lever is pressed by the animal. The same individual is trained to anticipate that stimulus B, e.g. a 900\u00a0Hz tone, precedes a negative event, e.g. bland food is delivered when the animal presses a lever. The animal is then tested by being given an intermediate stimulus C, e.g. a 500\u00a0Hz tone, and observing whether the animal presses the lever associated with the positive or negative reward. This has been suggested to indicate whether the animal is in a positive or negative mood.",
            "score": 121.52400970458984
        },
        {
            "docid": "33820872_19",
            "document": "Degrees of freedom problem . Bernstein suggested that as humans learn a movement, we first reduce our DOFs by stiffening the musculature in order to have tight control, then gradually \"loosen up\" and explore the available DOFs as the task becomes more comfortable, and from there find an optimal solution. In terms of optimal control, it has been postulated that the nervous system can learn to find task-specific variables through an optimal control search strategy. It has been shown that adaptation in a visuomotor reaching task becomes optimally tuned so that the cost of movement trajectories decreases over trials. These results suggest that the nervous system is capable of both nonadaptive and adaptive processes of optimal control. Furthermore, these and other results suggest that rather than being a control variable, consistent movement trajectories and velocity profiles are the natural outcome of an adaptive optimal control process.",
            "score": 119.25850677490234
        },
        {
            "docid": "530708_22",
            "document": "Muscle memory . Certain human behaviours, especially actions like the finger movements in musical performances, are very complex and require many interconnected neural networks where information can be transmitted across multiple brain regions. It has been found that there are often functional differences in the brains of professional musicians, when compared to other individuals. This is thought to reflect the musician's innate ability, which may be fostered by an early exposure to musical training. An example of this is bimanual synchronized finger movements, which play an essential role in piano playing. It is suggested that bimanual coordination can come only from years of bimanual training, where such actions become adaptations of the motor areas. When comparing professional musicians to a control group in complex bimanual movements, professionals are found to use an extensive motor network much less than those non-professionals. This is because professionals rely on a motor system that has increased efficiency, and, therefore, those less trained have a network that is more strongly activated. It is implied that the untrained pianists have to invest more neuronal activity to have the same level of performance that is achieved by professionals. This, yet again, is said to be a consequence of many years of motor training and experience that helps form a fine motor memory skill of musical performance.",
            "score": 118.96310424804688
        },
        {
            "docid": "84864_8",
            "document": "Edward Thorndike . Thorndike was a pioneer not only in behaviorism and in studying learning, but also in using animals in clinical experiments. Thorndike was able to create a theory of learning based on his research with animals. His doctoral dissertation, \"Animal Intelligence: An Experimental Study of the Associative Processes in Animals\", was the first in psychology where the subjects were nonhumans. Thorndike was interested in whether animals could learn tasks through imitation or observation. To test this, Thorndike created puzzle boxes. The puzzle boxes were approximately 20\u00a0inches long, 15\u00a0inches wide, and 12\u00a0inches tall. Each box had a door that was pulled open by a weight attached to a string that ran over a pulley and was attached to the door. The string attached to the door led to a lever or button inside the box. When the animal pressed the bar or pulled the lever, the string attached to the door would cause the weight to lift and the door to open. Thorndike\u2019s puzzle boxes were arranged so that the animal would be required to perform a certain response (pulling a lever or pushing a button), while he measured the amount of time it took them to escape. Once the animal had performed the desired response they were allowed to escape and were also given a reward, usually food. Thorndike primarily used cats in his puzzle boxes. When the cats were put into the cages they would wander restlessly and meow, but they did not know how to escape. Eventually, the cats would step on the switch on the floor by chance, and the door would open. To see if the cats could learn through observation, he had them observe other animals escaping from the box. He would then compare the times of those who got to observe others escaping with those who did not, and he found that there was no difference in their rate of learning. Thorndike saw the same results with other animals, and he observed that there was no improvement even when he placed the animals\u2019 paws on the correct levers, buttons, or bar. These failures led him to fall back on a trial and error explanation of learning. He found that after accidentally stepping on the switch once, they would press the switch faster in each succeeding trial inside the puzzle box. By observing and recording the animals\u2019 escapes and escape times, Thorndike was able to graph the times it took for the animals in each trial to escape, resulting in a learning curve. The animals had difficulty escaping at first, but eventually \"caught on\" and escaped faster and faster with each successive puzzle box trial, until they eventually leveled off. The quickened rate of escape results in the s-shape of the learning curve. The learning curve also suggested that different species learned in the same way but at different speeds. From his research with puzzle boxes, Thorndike was able to create his own theory of learning. The puzzle box experiments were motivated in part by Thorndike's dislike for statements that animals made use of extraordinary faculties such as insight in their problem solving: \"In the first place, most of the books do not give us a psychology, but rather a eulogy of animals. They have all been about animal intelligence, never about animal stupidity.\"",
            "score": 118.85374450683594
        },
        {
            "docid": "330102_12",
            "document": "Social learning theory . Recent research in neuroscience has implicated mirror neurons as a neurophysiology basis for social learning, observational learning, motor cognition and social cognition. Mirror neurons have been heavily linked to social learning in humans. Mirror neurons were first discovered in primates in studies which involved teaching the monkey motor activity tasks. One such study, focused on teaching primates to crack nuts with a hammer. When the primate witnessed another individual cracking nuts with a hammer, the mirror neuron systems became activated as the primate learned to use the hammer to crack nuts. However, when the primate was not presented with a social learning opportunity, the mirror neuron systems did not activate and learning did not occur. Similar studies with humans also show similar evidence to the human mirror neuron system activating when observing another person perform a physical task. The activation of the mirror neuron system is thought to be critical for the understanding of goal directed behaviors and understanding their intention. Although still controversial, this provides a direct neurological link to understanding social cognition.",
            "score": 117.2576675415039
        },
        {
            "docid": "54102859_3",
            "document": "Pavlovian-instrumental transfer . An example of specific PIT, as described by a neuroscience review from 2013 on Pavlovian-instrumental transfer, is as follows: \"in a typical experimental scenario a rat is trained to associate a sound (CS) with the delivery of food. Later, the rat undergoes an instrumental training where it learns to press a lever to get some food (without the sound being present). Finally, the rat is presented again with the opportunity to press the lever, this time both in the presence and absence of the sound. The results show that the rat will press the lever more in the presence of the sound than without, even if the sound has not been previously paired with lever pressing. The Pavlovian sound-food association learned in the first phase has somehow transferred to the instrumental situation, hence the name 'Pavlovian-instrumental transfer.'\"",
            "score": 117.00363159179688
        },
        {
            "docid": "2199417_16",
            "document": "Gamma motor neuron . In addition, serotonin receptor 1d (5-ht 1d) has been concluded to be a novel marker for gamma motor neurons enabling researchers to distinguish between the various types of lower motor neurons. Mice lacking this serotonin receptor 1d, displayed lower monosynaptic reflex (a reflex arc involving only a sensory and motor neuron), which may be caused by a reduced response to sensory stimulation in motor neurons. In addition, knockout mice without this serotonin receptor exhibited more coordination on a balance beam task, suggesting that less activation of motor neurons by Ia afferents during movement could reduce the unnecessary excess of muscle output.",
            "score": 116.81608581542969
        },
        {
            "docid": "8582684_22",
            "document": "Reward system . The first clue to the presence of a reward system in the brain came with an accident discovery by James Olds and Peter Milner in 1954. They discovered that rats would perform behaviors such as pressing a bar, to administer a brief burst of electrical stimulation to specific sites in their brains. This phenomenon is called intracranial self-stimulation or brain stimulation reward. Typically, rats will press a lever hundreds or thousands of times per hour to obtain this brain stimulation, stopping only when they are exhausted. While trying to teach rats how to solve problems and run mazes, stimulation of certain regions of the brain where the stimulation was found seemed to give pleasure to the animals. They tried the same thing with humans and the results were similar. The explanation to why animals engage in a behavior that has no value to the survival of either themselves or their species is that the brain stimulation is activating the system underlying reward.",
            "score": 116.58418273925781
        },
        {
            "docid": "205126_29",
            "document": "Drill . For most drill presses\u2014especially those meant for woodworking or home use\u2014speed change is achieved by manually moving a belt across a stepped pulley arrangement. Some drill presses add a third stepped pulley to increase the number of available speeds. Modern drill presses can, however, use a variable-speed motor in conjunction with the stepped-pulley system. Medium-duty drill presses such as those used in machine shop (tool room) applications are equipped with a continuously variable transmission. This mechanism is based on variable-diameter pulleys driving a wide, heavy-duty belt. This gives a wide speed range as well as the ability to change speed while the machine is running. Heavy-duty drill presses used for metalworking are usually of the gear-head type described below.",
            "score": 116.48887634277344
        },
        {
            "docid": "425938_43",
            "document": "Animal cognition . The details of interval timing have been studied in a number of species. One of the most common methods is the \"peak procedure\". In a typical experiment, a rat in an operant chamber presses a lever for food. A light comes on, a lever-press brings a food pellet at a fixed later time, say 10 seconds, and then the light goes off. Timing is measured during occasional test trials on which no food is presented and the light stays on. On these test trials, the rat presses the lever more and more until about 10 sec and then, when no food comes, gradually stops pressing. The time at which the rat presses most on these test trials is taken to be its estimate of the payoff time.",
            "score": 116.10601806640625
        },
        {
            "docid": "2621864_3",
            "document": "Shaping (psychology) . The trainer starts by reinforcing all behaviors in the first category, here turning toward the lever. When the animal regularly performs that response (turning), the trainer restricts reinforcement to responses in the second category (moving toward), then the third, and so on, progressing to each more accurate approximation as the animal learns the one currently reinforced. Thus, the response gradually approximates the desired behavior until finally the target response (lever pressing) is established. At first the rat is not likely to press the lever; in the end it presses rapidly.",
            "score": 115.280517578125
        },
        {
            "docid": "5160010_18",
            "document": "Emotion in animals . A cognitive bias is a pattern of deviation in judgment, whereby inferences about other animals and situations may be drawn in an illogical fashion. Individuals create their own \"subjective social reality\" from their perception of the input. It refers to the question \"Is the glass half empty or half full?\", used as an indicator of optimism or pessimism. To test this in animals, an individual is trained to anticipate that stimulus A, e.g. a 20\u00a0Hz tone, precedes a positive event, e.g. highly desired food is delivered when a lever is pressed by the animal. The same individual is trained to anticipate that stimulus B, e.g. a 10\u00a0Hz tone, precedes a negative event, e.g. bland food is delivered when the animal presses a lever. The animal is then tested by being played an intermediate stimulus C, e.g. a 15\u00a0Hz tone, and observing whether the animal presses the lever associated with the positive or negative reward, thereby indicating whether the animal is in a positive or negative mood. This might be influenced by, for example, the type of housing the animal is kept in.",
            "score": 114.59296417236328
        },
        {
            "docid": "673153_9",
            "document": "Dopaminergic pathways . The mesocortical pathway is primarily involved in the regulation of executive functions (e.g., attention, working memory, inhibitory control, planning, etc.), so it is particularly relevant to ADHD. The mesolimbic pathway regulates incentive salience, motivation, reinforcement learning, and fear, among other cognitive processes.  The mesolimbic pathway is involved in motivation cognition. Depletion of dopamine in this pathway, or lesions at its site of origin, decrease the extent to which an animal is willing to go to obtain a reward (e.g., the number of lever presses for nicotine or time searching for food). Dopaminergic drugs are also able to increase the extent an animal is willing to go to get a reward, and the firing rate of neurons in the mesolimbic pathway increases during anticipation of reward. Mesolimbic dopamine release was once thought to be the primary mediator of pleasure, but is now believed to have only a minor role in pleasure perception. Two hypothesized states of prefrontal cortex activity driven by D1 and D2 pathway activity have been proposed; one D1 driven state in which there is a barrier allowing for high level of focus, and one D2 driven allowing for task switching with a weak barrier allowing more information in.",
            "score": 114.403076171875
        },
        {
            "docid": "14083964_27",
            "document": "Animal psychopathology . Certain laboratory rat strains that have been created by controlled breeding for many generations show a higher tendency towards compulsive behaviors than other strains. Lewis rats show more compulsive lever pressing behavior than Sprague Dawley or Wistar rats and are less responsive to the anti-compulsive drug paroxetine. In this study, rats were taught to press a lever to receive food in an operant conditioning task. Once food was no longer provided when they pressed the lever, rats were expected to stop pressing it. Lewis rats pressed the lever more often than the other two types, even though they had presumably learned that they would not receive food, and continued to press it more often even after treatment with the drug. An analysis of the genetic differences between the three rat strains might help to identify genes that might be responsible for the compulsive behavior.",
            "score": 114.3820571899414
        },
        {
            "docid": "21312297_20",
            "document": "Memory consolidation . Rapid eye movement (REM) sleep has been thought of to be an important concept in the overnight learning in humans by establishing information in the hippocampal and cortical regions of the brain. REM sleep elicits an increase in neuronal activity following an enriched or novel waking experience, thus increasing neuronal plasticity and therefore playing an essential role in the consolidation of memories. This has come into question in recent years however and studies on sleep deprivation have shown that animals and humans who are denied REM sleep do not show deficits in task learning. It has been proposed that since the brain is in a non-memory encoding state during sleep, consolidation would be unlikely to occur. Recent studies have examined the relationship between REM sleep and procedural learning consolidation.  In particular studies have been done on sensory and motor related tasks. In one study testing finger-tapping, people were split into two groups and tested post-training with or without intervening sleep; results concluded that sleep post-training increases both speed and accuracy in this particular task, while increasing the activation of both cortical and hippocampal regions; whereas the post-training awake group had no such improvements. It has been theorized that this may be related more-so to a process of synaptic consolidation rather than systems consolidation because of the short-term nature of the process involved. Researchers examining the effect of sleep on motor learning have noted that while consolidation occurs over a period of 4\u20136 hours during sleep, this is also true during waking hours, which may negate any role of sleep in learning. In this sense sleep would serve no special purpose to enhance consolidation of memories because it occurs independently of sleep. Other studies have examined the process of replay which has been described as a reactivation of patterns that were stimulated during a learning phase. Replay has been demonstrated in the hippocampus and this has lent support to the notion that it serves a consolidation purpose. However, replay is not specific to sleep and both rats and primates show signs during restful-awake periods. Also, replay may simply be residual activation in areas that were involved previously in the learning phase and may have no actual effect on consolidation. This reactivation of the memory traces has also been seen in non-REM sleep specifically for hippocampus-dependant memories. Researchers have noted strong reactivation of the hippocampus during sleep immediately after a learning task. This reactivation led to enhanced performance on the learned task. Researchers following this line of work have come to assume that dreams are a by-product of the reactivation of the brain areas and this can explain why dreams may be unrelated to the information being consolidated. The dream experience itself is not what enhances memory performance but rather it is the reactivation of the neural circuits that causes this.",
            "score": 114.01441955566406
        },
        {
            "docid": "31180332_15",
            "document": "Academic achievement . While research suggests that there is a positive link between academic performance and participation in extracurricular activities, the practice behind this relationship is not always clear. Moreover, there are many unrelated factors that influence the relationship between academic achievement and participation in extracurricular activities (Mahoney et al., 2005). These variables include: civic engagement, identity development, positive social relationships and behaviors, and mental health (Mahoney et al., 2005). In other research on youth, it was reported that positive social support and development, which can be acquired through organized after school activities is beneficial for achieving academic success (Eccles & Templeton, 2002). In terms of academic performance there are a whole other group of variables to consider. Some of these variables include: demographic and familial influences, individual characteristics, and program resources and content (Mahoney et al., 2005). For example, socio-economic status has been found to plays a role in the number of students participating in extracurricular activities (Covay & Carbonaro, 2010). Furthermore, it is suggested that the peer relationships and support that develop in extracurricular activities often affect how individuals perform in school (Eccles & Templeton, 2002). With all these variables to consider it is important to create a better understanding how academic achievement can be seen in both a negative and positive light.",
            "score": 113.5592269897461
        },
        {
            "docid": "530708_27",
            "document": "Muscle memory . It has been suggested that consistent practice of a gross motor skill can help a patient with Alzheimer's disease learn and remember that skill. It was thought that the damage to the hippocampus may result in the need for a specific type of learning requirement. A study was created to test this assumption in which the patients were trained to throw a bean bag at a target. It was found that the Alzheimer's patients performed better on the task when learning occurred under constant training as opposed to variable. Also, it was found that gross motor memory in Alzheimer's patients was the same as that of healthy adults when learning occurs under constant practice. This suggests that damage to the hippocampal system does not impair an Alzheimer's patient from retaining new gross motor skills, implying that motor memory for gross motor skills is stored elsewhere in the brain.",
            "score": 113.273681640625
        }
    ]
}