{
    "q": [
        {
            "docid": "23386350_4",
            "document": "BioSim . Diabetes Efforts concentrate on the role of mutations that effect the ion channels of the insulin-producing beta-cells, on the genetic basis for the development of neonatal diabetes, on the study of human (as opposed to mice) pancreatic cells, on the mechanisms underlying the development of insulin resistance, and on the possible role of prenatal nutrition for the development of type-2 diabetes. Models are also developed to analyse the balance between fat and glucose metabolism and to describe the rate of absorption of different insulin variants. Cancer In this area the network uses computer models of the cell cycle and of its coupling to the 24 h day-and-night rhythm to improve the treatment of patients with cancer. The use of chronotherapy implies that the administration of anti-cancer drugs is adjusted in accordance with the circadian rhythm of the patient. For certain forms of cancer this has been found to increase the efficiency of the drug by a factor of five. Efforts are also devoted to the development of new anti-cancer drugs. Hypertension and cardiovascular diseases Activities area focus on the development of 3D heart models that can be used to test how a new drug affects the regularity of the heart rhythm. Work is performed to develop detailed models of the mechanisms by which the individual nephron of the kidney regulates the incoming blood flow and how neighboring nephrons interact. Mental disorders and neuronal systems Work includes application of mathematical models to develop less invasive and demand-controlled electrical stimulation techniques for the treatment of Parkinson's disease. Modelling studies are performed to examine the effect of sleep deprivation in the treatment of depression, and bioinformatic approaches are applied to try to identify forms of depression on the basis of the information available from blood samples. Methodological issues The area encompasses description of complex networks of oscillating biological units, studies of the mechanisms of temperature stabilization in biological feedback regulations, application of new methods of data analysis, and development of modeling software and biomedical search machines. The area includes application of new experimental techniques such as interference microscopy and surface enhanced Raman spectroscopy to study cellular processes. Regulatory issues and dialogue with the public Testing in animal and human subjects is a necessary part of the development of new drugs. Such experiments clearly raises a number of complicated ethical issues that the use of simulation models may reduce. This requires that the regulatory authorities can evaluate computer models and accept them as part of the required documentation.  During the last five years the BioSim Network has published nine books and 800 scientific publications. The network has organized or co-organized 30 conferences and workshops, edited four issues of international journals, and trained about 130 PhD students. New National Centres in Systems Biology have been established in relation to the BioSim partners in Manchester, Warwick, and Edinburgh.",
            "score": 97.32229769229889
        },
        {
            "docid": "55172_37",
            "document": "Proteomics . One major development to come from the study of human genes and proteins has been the identification of potential new drugs for the treatment of disease. This relies on genome and proteome information to identify proteins associated with a disease, which computer software can then use as targets for new drugs. For example, if a certain protein is implicated in a disease, its 3D structure provides the information to design drugs to interfere with the action of the protein. A molecule that fits the active site of an enzyme, but cannot be released by the enzyme, inactivates the enzyme. This is the basis of new drug-discovery tools, which aim to find new drugs to inactivate proteins involved in disease. As genetic differences among individuals are found, researchers expect to use these techniques to develop personalized drugs that are more effective for the individual.",
            "score": 95.36757135391235
        },
        {
            "docid": "44450362_11",
            "document": "Network medicine . Network pharmacology is a developing field based in systems pharmacology that looks at the effect of drugs on both the interactome and the diseasome. The drug-target network (DTN) can play an important role in understanding the mechanisms of action of approved and experimental drugs. The network theory view of pharmaceuticals is based on the effect of the drug in the interactome, especially the region that the drug target occupies. Combination therapy for a complex disease (polypharmacology) is suggested in this field since one active pharmaceutical ingredient (API) aimed at one target may not effect the entire disease module. The concept of disease modules can be used to aid in drug discovery, drug design, and the development of biomarkers for disease detection. There can be a variety of ways to identifying drugs using network pharmacology; a simple example of this is the \"guilt by association\" method. This states if two diseases are treated by the same drug, a drug that treats one disease may treat the other. Drug repurposing, drug-drug interactions and drug side-effects have also been studied in this field.",
            "score": 106.91030287742615
        },
        {
            "docid": "41086554_20",
            "document": "Nanoparticles for drug delivery to the brain . In the early 21st century, extensive research is occurring in the field of nanoparticle drug delivery systems to the brain. One of the common diseases being studied in neuroscience today is Alzheimer's disease. Many studies have been done to show how nanoparticles can be used as a platform to deliver therapeutic drugs to these patients suffering from the disease. A few Alzheimer's drugs that have been studied especially are rivastigmine, tacrine, quinoline, piperine, and curcumin. PBCA, chitosan, and PLGA nanoparticles were used as delivery systems for these drugs. Overall, the results from each drug injection with these nanoparticles showed remarkable improvements in the effects of the drug relative to non-nanoparticle delivery systems. This possibly suggests that nanoparticles could provide a promising solution to how these drugs could cross the BBB. One factor that still must be considered and accounted for is nanoparticle accumulation in the body. With long-term and frequent injections that are often required to treat chronic diseases such as Alzheimer's disease, polymeric nanoparticles could potentially build up in the body, causing undesirable effects. This area for concern would have to be further assessed to analyze these possible effects and to improve them.",
            "score": 102.6290955543518
        },
        {
            "docid": "29069615_9",
            "document": "Resistance Database Initiative . The RDI was established in 2002 to pioneer a new approach: to develop computational models using the genotype and a wide range of other clinically relevant data collected from thousands of patients treated with HAART all over the world and to use these models to predict how an individual patient will respond to different combinations of drugs. The RDI\u2019s goal was to make available a free treatment-response prediction tool over the Internet.",
            "score": 105.21923208236694
        },
        {
            "docid": "1004486_3",
            "document": "Pharmacogenomics . Pharmacogenomics aims to develop rational means to optimize drug therapy, with respect to the patients' genotype, to ensure maximum efficacy with minimal adverse effects. Through the utilization of pharmacogenomics, it is hoped that pharmaceutical drug treatments can deviate from what is dubbed as the \"one-dose-fits-all\" approach. Pharmacogenomics also attempts to eliminate the trial-and-error method of prescribing, allowing physicians to take into consideration their patient's genes, the functionality of these genes, and how this may affect the efficacy of the patient's current or future treatments (and where applicable, provide an explanation for the failure of past treatments). Such approaches promise the advent of precision medicine and even personalized medicine, in which drugs and drug combinations are optimized for narrow subsets of patients or even for each individual's unique genetic makeup. Whether used to explain a patient's response or lack thereof to a treatment, or act as a predictive tool, it hopes to achieve better treatment outcomes, greater efficacy, minimization of the occurrence of drug toxicities and adverse drug reactions (ADRs). For patients who have lack of therapeutic response to a treatment, alternative therapies can be prescribed that would best suit their requirements. In order to provide pharmacogenomic recommendations for a given drug, two possible types of input can be used: genotyping or exome or whole genome sequencing. Sequencing provides many more data points, including detection of mutations that prematurely terminate the synthesized protein (early stop codon).",
            "score": 102.18200027942657
        },
        {
            "docid": "1164_72",
            "document": "Artificial intelligence . Artificial intelligence is breaking into the healthcare industry by assisting doctors. According to Bloomberg Technology, Microsoft has developed AI to help doctors find the right treatments for cancer. There is a great amount of research and drugs developed relating to cancer. In detail, there are more than 800 medicines and vaccines to treat cancer. This negatively affects the doctors, because there are too many options to choose from, making it more difficult to choose the right drugs for the patients. Microsoft is working on a project to develop a machine called \"Hanover\". Its goal is to memorize all the papers necessary to cancer and help predict which combinations of drugs will be most effective for each patient. One project that is being worked on at the moment is fighting myeloid leukemia, a fatal cancer where the treatment has not improved in decades. Another study was reported to have found that artificial intelligence was as good as trained doctors in identifying skin cancers. Another study is using artificial intelligence to try and monitor multiple high-risk patients, and this is done by asking each patient numerous questions based on data acquired from live doctor to patient interactions.",
            "score": 91.23164701461792
        },
        {
            "docid": "5009_44",
            "document": "Zebrafish . This study of the zebrafish's retinal characteristics has also extrapolated into medical enquiry. In 2007, researchers at University College London grew a type of zebrafish adult stem cell found in the eyes of fish and mammals that develops into neurons in the retina. These could be injected into the eye to treat diseases that damage retinal neurons\u2014nearly every disease of the eye, including macular degeneration, glaucoma, and diabetes-related blindness. The researchers studied M\u00fcller glial cells in the eyes of humans aged from 18 months to 91 years, and were able to develop them into all types of retinal neurons. They were also able to grow them easily in the lab. The stem cells successfully migrated into diseased rats' retinas, and took on the characteristics of the surrounding neurons. The team stated that they intended to develop the same approach in humans. As demonstrated through ongoing research programmes, the zebrafish model enables researchers not only to identify genes that might underlie human disease, but also to develop novel therapeutic agents in drug discovery programmes. Zebrafish embryos have proven to be a rapid, cost-efficient, and reliable teratology assay model. Drug screens in zebrafish can be used to identify novel classes of compounds with biological effects, or to repurpose existing drugs for novel uses; an example of the latter would be a screen which found that a commonly used statin (rosuvastatin) can suppress the growth of prostate cancer To date, 65 small-molecule screens have been carried out and at least one has led to clinical trials. Within these screens, many technical challenges remain to be resolved, including differing rates of drug absorption resulting in levels of internal exposure that cannot be extrapolated from the water concentration, and high levels of natural variation between individual animals. To understand drug effects, the internal drug exposure is essential, as this drives the pharmacological effect. Translating experimental results from zebrafish to higher vertebrates (like humans) requires concentration-effect relationships, which can be derived from pharmacokinetic and pharmacodynamic analysis. To date, only a pharmacokinetic model for paracetamol has been developed in zebrafish larvae. The potential for pharmacological analyses in this organism is however promising.",
            "score": 102.50883781909943
        },
        {
            "docid": "34939027_5",
            "document": "Pharmacometabolomics . Although the applications of pharmacometabolomics to personalized medicine are largely only being realized now, the study of an individual\u2019s metabolism has been used to treat disease since the Middle Ages. Early physicians employed a primitive form of metabolomic analysis by smelling, tasting and looking at urine to diagnose disease. Obviously the measurement techniques needed to look at specific metabolites were unavailable at that time, but such technologies have evolved dramatically over the last decade to develop precise, high-throughput devices, as well as the accompanying data analysis software to analyze output. Currently, sample purification processes, such as liquid or gas chromatography, are coupled with either mass spectrometry (MS)-based or nuclear magnetic resonance (NMR)-based analytical methods to characterize the metabolite profiles of individual patients. Continually advancing informatics tools allow for the identification, quantification and classification of metabolites to determine which pathways may influence certain pharmaceutical interventions. One of the earliest studies discussing the principle and applications of pharmacometabolomics was conducted in an animal model to look at the metabolism of paracetamol and liver damage. NMR spectroscopy was used to analyze the urinary metabolic profiles of rats pre- and post-treatment with paracetamol. The analysis revealed a certain metabolic profile associated with increased liver damage following paracetamol treatment. At this point, it was eagerly anticipated that such pharmacometabolomics approaches could be applied to personalized human medicine. Since this publication in 2006, the Pharmacometabolomics Research Network led by Duke University researchers and that included partnerships between centers of excellence in metabolomics, pharmacogenomics and informatics (over sixteen academic centers funded by NIGMS) has been able to illustrate for the first time the power of the pharmacometabolomics approach in informing about treatment outcomes in large clinical studies and with use of drugs that include antidepressants, statins, antihypertensives, antiplatelet therapies and antipsychotics. Totally new concepts emerged from these studies on use of pharmacometabolomics as a tool that can bring a paradigm shift in the field of pharmacology. It illustrated how pharmacometabolomics can enable a Quantitative and Systems Pharmacology approach.  Pharmacometabolomics has been applied for the treatment of numerous human diseases, such as schizophrenia, diabetes, neural disease, depression and cancer.",
            "score": 97.52184009552002
        },
        {
            "docid": "149353_13",
            "document": "Computational biology . Computational pharmacology (from a computational biology perspective) is \u201cthe study of the effects of genomic data to find links between specific genotypes and diseases and then screening drug data\u201d. The pharmaceutical industry requires a shift in methods to analyze drug data. Pharmacologists were able to use Microsoft Excel to compare chemical and genomic data related to the effectiveness of drugs. However, the industry has reached what is referred to as the Excel barricade. This arises from the limited number of cells accessible on a spreadsheet. This development led to the need for computational pharmacology. Scientists and researchers develop computational methods to analyze these massive data sets. This allows for an efficient comparison between the notable data points and allows for more accurate drugs to be developed.",
            "score": 117.59505641460419
        },
        {
            "docid": "48893550_3",
            "document": "Polypharmacology . In recent years even with remarkable scientific advancements and significant increase of global R&D spending, drugs are frequently withdrawn from markets. This is primarily due to their side-effects or toxicities. Drug molecules often interact with multiple targets and the unintended drug-target interactions could cause side-effects. Polypharmacology remains to be one of the major challenges in drug development, and it opens novel avenues to rationally design next generation of more effective but less toxic therapeutic agents. Polypharmacology suggests that more effective drugs can be developed by specifically modulating multiple targets. It is generally thought that complex diseases such as cancer and central nervous system diseases may require complex therapeutic approaches. In this respect, a drug that \"hits\" multiple sensitive nodes belonging to a network of interacting targets offers the potential for higher efficacy and may limit drawbacks generally arising from the use of a single-target drug or a combination of multiple drugs. In contrast, chemical biology continues to be a reductionist discipline, still regarding chemical probes as highly selective small molecules that enable the modulation and study of one specific target. Chemical biology cannot continue to overlook the existence of polypharmacology and it urge to become a more holistic discipline that looks at the use of tool compounds from a systems perspective.",
            "score": 79.50677573680878
        },
        {
            "docid": "2652481_17",
            "document": "Personalized medicine . Today in medicine, it is common that physicians often use a trial and error strategy until they find the treatment therapy that is most effective for their patient. With personalised medicine, these treatments can be more specifically tailored to an individual and give insight into how their body will respond to the drug and if that drug will work based on their genome. The personal genotype can allow physicians to have more detailed information that will guide them in their decision in treatment prescriptions, which will be more cost-effective and accurate. As quoted from the article \"Pharmacogenomics: The Promise of Personalised Medicine\", \u201ctherapy with the right drug at the right dose in the right patient\u201d is a description of how personalized medicine will affect the future of treatment. For instance, tamoxifen used to be a drug commonly prescribed to women with ER+ breast cancer, but 65% of women initially taking it developed resistance. After some research by people such as David Flockhart, it was discovered that women with certain mutation in their CYP2D6 gene, a gene that encodes the metabolizing enzyme, were not able to efficiently break down Tamoxifen, making it an ineffective treatment for their cancer. Since then, women are now genotyped for those specific mutations, so that immediately these women can have the most effective treatment therapy.",
            "score": 70.20726656913757
        },
        {
            "docid": "44248347_28",
            "document": "Gene Disease Database . The response of bioinformatics to new experimental techniques brings a new perspective into the analysis of the experimental data, as demonstrated by the advances in the analysis of information from gene disease databases and other technologies. It is expected that this trend will continue with novel approaches to respond to new techniques, such as next-generation sequencing technologies. For instance, the availability of large numbers of individual human genomes will promote the development of computational analyses of rare variants, including the statistical mining of their relations to lifestyles, drug interactions and other factors. Biomedical research will also be driven by our ability to efficiently mine the large body of existing and continuously generated biomedical data. Text-mining techniques, in particular, when combined with other molecular data, can provide information about gene mutations and interactions and will become crucial to stay ahead of the exponential growth of data generated in biomedical research. Another field that is benefiting from the advances in mining and integration of molecular, clinical and drug analysis is pharmacogenomics. \"In silico\" studies of the relationships between human variations and their effect on diseases will be key to the development of personalized medicine. In summary, Gene Disease Databases have already transformed the search for disease genes and has the potential to become a crucial component of other areas of medical research.",
            "score": 120.00759160518646
        },
        {
            "docid": "42556555_4",
            "document": "Champions Oncology . TumorGrafts are also being used as a pre-clinical research tool to improve clinical drug development. Compared to traditional xenograft models, TumorGrafts, have a greater degree of accuracy in predicting clinical effectiveness of oncology drugs and thus can decrease clinical risk for drug developers. Champions has formed partnerships with multiple drug developers, including Teva and Pfizer.",
            "score": 65.28287196159363
        },
        {
            "docid": "5106067_3",
            "document": "TB Alliance . Tuberculosis infects one third of the world\u2019s population, kills approximately 1.5 million people each year, and costs the global economy $16 billion annually. However, research and development for new TB drugs came to a virtual standstill after the 1960s. Today, a four drug combination therapy exists, but it takes six months or more to be effective. This requires a degree of monitoring (See Direct Observational Therapy, Shortcourse) beyond the capacity of the health infrastructure in many countries; adequate TB treatment is available to less than half of the most infectious cases. This can inhibit control of the disease and fuel the rise of drug resistance. TB is also the number one killer of AIDS patients, but it is generally agreed that current TB treatments do not work well with the antiretroviral drugs used to treat HIV.",
            "score": 82.9039568901062
        },
        {
            "docid": "53404706_9",
            "document": "Cost of drug development . Drug discovery is the area of research and development that amounts to the most amount of time and money. The process can involve scientists to determine the germs, viruses, and bacteria that cause a specific disease or illness. The time frame can range from 3\u201320 years and costs can range between several billion to tens of billions of dollars. Research teams attempt to break down disease components to find abnormal events/processes taking place in the body. Only then do scientists work on developing chemical compounds to treat these abnormalities with the aid of computer models.",
            "score": 75.02565503120422
        },
        {
            "docid": "13033422_6",
            "document": "Multiple sclerosis research . Another research strategy is to evaluate the combined effectiveness of two or more drugs. The main rationale for polytherapy in MS is that the involved treatments target different mechanisms of the disease and therefore, their use is not necessarily exclusive. Moreover, synergies, in which a drug potentiates the effect of another are also possible. Nevertheless, there can also appear important drawbacks such as antagonizing mechanisms of action or potentiation of deleterious secondary effects. While there have been several clinical trials of combined therapy none has shown positive enough effects to merit the consideration as a viable treatment for MS.",
            "score": 67.56163740158081
        },
        {
            "docid": "52801156_10",
            "document": "Cadmium-free quantum dot . Quantum dots (QDs) have been a main focal point in the material science industry in the recent years, allowing scientists and engineers to manipulate and test the properties of these nanoscale particles to develop a better understanding of them. A wide variety of QDs are made from toxic heavy metals, like cadmium, which not only prohibits use in biological systems but also can be problematic in a general to a consumer buying a product composed of toxic metals. In order to combat this, researchers have been developing QDs that are not composed of these metals, such as cadmium-free QDs. The medical field has been constantly evolving in an attempt to master the unknown about diseases, such as cancer. Much is unknown about cancer and most treatment routines includes chemotherapy, where toxic chemicals are flushed throughout the body in order to kill the cancer cells. This viscous treatment has been claiming lives for years and researchers have been heavily studying alternatives to this pathway. This is where Cd-free QDs come into play. Michael Sailor and his team including National Science Foundation (NSF)- supported researched at University of California, San Diego (UCSD), have developed the first nanoscale Cd-free QD that is able to glow brightly enough to allow physicians to examine internal organs. This image can last long enough to release cancer drugs before breaking down into harmless by-products. Silicon wafers were used, this way when they were broken down in the body, silicic acid is formed which is already present in the body which is needed for proper bone and tissue growth. These QDs are projected to be able to lower drug toxicity, lower treatment costs, increase the efficiency of the drug being delivered as well as give better patient diagnosis. These nanoscale particles can be localized to tumors and deliver a specific drug to that area as opposed to treating an individual with chemotherapy, with hope that the localization will allow for better and faster recovery. Not only are Cd-free QDs useful in the medical field, but they have also been making an appearance in technologies for everyday consumers through electronics. Due to the small size of the nanoparticles and their dependence on size for the color emitted, many vibrant colors are able to be produced. The sizes of the Cd-free QDs are able to be controlled extremely well and have great energy transfers which allow for the enhanced displays capable on new QD based televisions. Since the technology is relatively new these televisions are rather pricey for average consumers but as the research on these particles continues it is not radical to think that the price will eventually drop. The Cd-free QDs used in televisions also allow companies to label their products as being greener and helps eliminate such hazards from everyday lives.",
            "score": 70.46108639240265
        },
        {
            "docid": "7663818_43",
            "document": "Management of multiple sclerosis . Another research strategy is to evaluate the combined effectiveness of two or more drugs. The main rationale for polytherapy in MS is that the involved treatments target different mechanisms of the disease and therefore their use is not necessarily exclusive. Moreover, synergies, in which a drug potentiates the effect of another are also possible. Nevertheless, there can also appear important drawbacks such as antagonizing mechanisms of action or potentiation of deleterious secondary effects. While there have been several clinical trials of combined therapy none has shown positive enough effects to merit the consideration as a viable treatment for MS.",
            "score": 66.83472108840942
        },
        {
            "docid": "4584230_5",
            "document": "Biomarker (medicine) . It is necessary to distinguish between \"disease-related\" and \"drug-related biomarkers\". Disease-related biomarkers give an indication of the probable effect of treatment on patient (risk indicator or predictive biomarkers), if a disease already exists (diagnostic biomarker), or how such a disease may develop in an individual case regardless of the type of treatment (prognostic biomarker). Predictive biomarkers help to assess the most likely response to a particular treatment type, while prognostic markers shows the progression of disease with or without treatment. In contrast, drug-related biomarkers indicate whether a drug will be effective in a specific patient and how the patient\u2019s body will process it.",
            "score": 78.74745559692383
        },
        {
            "docid": "6090525_74",
            "document": "Neglected tropical diseases . An alternative model to the profit-driven drug development emerged in the years 2000 to provide an answer to the needs of these neglected patients. Product development partnerships (PDPs) aim at implementing and accelerating the research and development (R&D) of safe and effective health tools (diagnostics, vaccines, drugs) to notably combat diseases that are neglected. Drugs for Neglected Diseases \"initiative\" (DNDi) is one of these PDPs that has already developed new treatments for NTDs",
            "score": 70.3647391796112
        },
        {
            "docid": "53829489_23",
            "document": "Giovanna Mallucci . She added: \u201cWe know that trazodone is safe to use in humans, so a clinical trial is now possible to test whether the protective effects of the drug we see on brain cells in mice with neurodegeneration also applies to people in the early stages of Alzheimer\u2019s disease and other dementias. We could know in 2-3 years whether this approach can slow down disease progression, which would be a very exciting first step in treating these disorders. \u201cInterestingly, trazodone has been used to treat the symptoms of patients in later stages of dementia, so we know it is safe for this group. We now need to find out whether giving the drug to patients at an early stage could help arrest or slow down the disease through its effects on this pathway.\u201d It is known that misfolded proteins build up in the brains of those with neurodegenerative diseases and are a major factor in dementias such as Alzheimer\u2019s and Parkinson\u2019s as well as prion disease.",
            "score": 90.55542254447937
        },
        {
            "docid": "1979482_6",
            "document": "Natalizumab . Natalizumab was evaluated in two randomized, double-blind, placebo-controlled trials in people with multiple sclerosis. The studies enrolled individuals with MS who experienced at least one clinical relapse during the prior year and had a Kurtzke EDSS score between 0 and 5. In these trials natalizumab was shown to reduce relapses in individuals with MS by 68% vs. placebo, a margin far greater than had been seen for other approved MS therapies. Natalizumab also slowed the progression of disability in patients with relapsing MS. In combination with interferon beta-1a (IB1A), relapsing and disability progression were reduced more than IB1A alone. Other benefits of natalizumab use by patients with relapsing MS included reduced visual loss, a significant increase in the proportion of disease-free individuals, significantly improved assessments of health-related quality of life in relapsing individuals, reduced cognitive decline of a portion of individuals with MS, reduced hospitalizations and steroid use, and prevention of the formation of new lesions. Approximately 6% of individuals receiving natalizumab have been found to develop persistent antibodies to the drug, which reduces its efficacy and produce reactions during the infusion of the drug, as well as hypersensitivity. Natalizumab is approved in the United States and the European Union. It is indicated as monotherapy (not combined with other drugs) for the treatment of highly active relapsing remitting MS in spite of prior treatments. Natalizumab offers a limited improvement in efficacy compared to other treatments for MS, but due to the lack of information about long-term use, as well as potentially fatal adverse events, reservations have been expressed over the use of the drug outside of comparative research with existing medications.",
            "score": 62.21820831298828
        },
        {
            "docid": "5824073_12",
            "document": "High-content screening . This technology allows a (very) large number of experiments to be performed, allowing explorative screening. Cell-based systems are mainly used in chemical genetics where large, diverse small molecule collections are systematically tested for their effect on cellular model systems. Novel drugs can be found using screens of tens of thousands of molecules, and these have promise for the future of drug development.  Beyond drug discovery, chemical genetics is aimed at functionalizing the genome by identifying small molecules that acts on most of the 21,000 gene products in a cell. High-content technology will be part of this effort which could provide useful tools for learning where and when proteins act by knocking them out chemically. This would be most useful for gene where knock out mice (missing one or several genes) can not be made because the protein is required for development, growth or otherwise lethal when it is not there. Chemical knock out could address how and where these genes work. Further the technology is used in combination with RNAi to identify sets of genes involved in specific mechanisms, for example cell division. Here, libraries of RNAis, covering a whole set of predicted genes inside the target organism's genome can be used to identify relevant subsets, facilitating the annotation of genes for which no clear role has been established beforehand. The large datasets produced by automated cell biology contain spatially resolved, quantitative data which can be used for building for systems level models and simulations of how cells and organisms function. Systems biology models of cell function would permit prediction of why, where and how the cell responds to external changes, growth and disease.",
            "score": 100.8516218662262
        },
        {
            "docid": "41086554_2",
            "document": "Nanoparticles for drug delivery to the brain . Nanoparticles for drug delivery to the brain is a method for transporting drug molecules across the blood\u2013brain barrier (BBB) using nanoparticles. These drugs cross the BBB and deliver pharmaceuticals to the brain for therapeutic treatment of neurological disorders. These disorders include Parkinson's disease, Alzheimer's disease, schizophrenia, depression, and brain tumors. Part of the difficulty in finding cures for these central nervous system (CNS) disorders is that there is yet no truly efficient delivery method for drugs to cross the BBB. Antibiotics, antineoplastic agents, and a variety of CNS-active drugs, especially neuropeptides, are a few examples of molecules that cannot pass the BBB alone. With the aid of nanoparticle delivery systems, however, studies have shown that some drugs can now cross the BBB, and even exhibit lower toxicity and decrease adverse effects throughout the body. Toxicity is an important concept for pharmacology because high toxicity levels in the body could be detrimental to the patient by affecting other organs and disrupting their function. Further, the BBB is not the only physiological barrier for drug delivery to the brain. Other biological factors influence how drugs are transported throughout the body and how they target specific locations for action. Some of these pathophysiological factors include blood flow alterations, edema and increased intracranial pressure, metabolic perturbations, and altered gene expression and protein synthesis. Though there exist many obstacles that make developing a robust delivery system difficult, nanoparticles provide a promising mechanism for drug transport to the CNS.",
            "score": 79.55663752555847
        },
        {
            "docid": "5747184_2",
            "document": "Stem cell genomics . Stem cell genomics analyzes the genomes of stem cells. Currently, this field is rapidly expanding due to the dramatic decrease in the cost of sequencing genomes. The study of stem cell genomics has wide reaching implications in the study of stem cell biology and possible therapeutic usages of stem cells. Application of research in this field could lead to drug discovery and information on diseases by the molecular characterization of the pluripotent stem cell through DNA and transcriptome sequencing and looking at the epigenetic changes of stem cells and subsequent products. One step in that process is single cell phenotypic analysis, and the connection between the phenotype and genotype of specific stem cells. While current genomic screens are done with entire populations of cells, focusing in on a single stem cell will help determine specific signaling activity associated with varying degrees of stem cell differentiation and limit background due to heterogeneous populations. Single cell analysis of induced pluripotent stem cells (iPSCs), or stem cells able to differentiate into many different cell types, is a suggested method for treating such diseases like Alzheimer's disease (AD). This includes for understanding the differences between sporadic AD and familial AD. By first taking a skin sample from the patient and are transformed by transducing cells using retroviruses to encode such stem cell genes as Oct4, Sox2, KLF4 and cMYC. This allows for skin cells to be reprogrammed into patient-specific stem cell lines. Taking genomic sequences of these individual cells would allow for patient-specific treatments and furthering understanding of AD disease models. This technique would be used for similar diseases, like amyotrophic lateral sclerosis (ALS) and spinal muscular atrophy (SMA). These stem cells developed from a singular patient would also be able to be used to produce cells affected in the above-mentioned diseases. As mentioned, it will also lead to patient specific phenotypes of each disease. Further chemical analyses to develop safer drugs can be done through sequence information and cell-culture tests on iPSCs. After development on a specific drug, it can be transferred to other patient diseased cells while also being safety tested.",
            "score": 90.26306056976318
        },
        {
            "docid": "1685778_2",
            "document": "Neuropharmacology . Neuropharmacology is the study of how drugs affect cellular function in the nervous system, and the neural mechanisms through which they influence behavior. There are two main branches of neuropharmacology: behavioral and molecular. Behavioral neuropharmacology focuses on the study of how drugs affect human behavior (neuropsychopharmacology), including the study of how drug dependence and addiction affect the human brain. Molecular neuropharmacology involves the study of neurons and their neurochemical interactions, with the overall goal of developing drugs that have beneficial effects on neurological function. Both of these fields are closely connected, since both are concerned with the interactions of neurotransmitters, neuropeptides, neurohormones, neuromodulators, enzymes, second messengers, co-transporters, ion channels, and receptor proteins in the central and peripheral nervous systems. Studying these interactions, researchers are developing drugs to treat many different neurological disorders, including pain, neurodegenerative diseases such as Parkinson's disease and Alzheimer's disease, psychological disorders, addiction, and many others.",
            "score": 70.69210243225098
        },
        {
            "docid": "2154572_12",
            "document": "Nanobiotechnology . Nanomedicine is a field of medical science whose applications are increasing more and more thanks to nanorobots and biological machines, which constitute a very useful tool to develop this area of knowledge. In the past years, researchers have done many improvements in the different devices and systems required to develop nanorobots. This supposes a new way of treating and dealing with diseases such as cancer; thanks to nanorobots, side effects of chemotherapy have been controlled, reduced and even eliminated, so some years from now, cancer patients will be offered an alternative to treat this disease instead of chemotherapy, which causes secondary effects such as hair loss, fatigue or nausea killing not only cancerous cells but also the healthy ones. At a clinical level, cancer treatment with nanomedicine will consist of the supply of nanorobots to the patient through an injection that will search for cancerous cells while leaving untouched the healthy ones. Patients that will be treated through nanomedicine will not notice the presence of these nanomachines inside them; the only thing that is going to be noticeable is the progressive improvement of their health.",
            "score": 50.91826009750366
        },
        {
            "docid": "34939027_8",
            "document": "Pharmacometabolomics . The second major application of pharmacometabolomics is the analysis of a patient\u2019s metabolic profile following the administration of a specific therapy. This process is often secondary to a pre-treatment metabolic analysis, allowing for the comparison of pre- and post-treatment metabolite concentrations. This allows for the identification of the metabolic processes and pathways that are being altered by the treatment either intentionally as a designated target of the compound, or unintentionally as a side effect. Furthermore, the concentration and variety of metabolites produced from the compound itself can also be identified, providing information on the rate of metabolism and potentially leading to development of a related compound with increased efficacy or decreased side effects. An example of this approach was used to investigate the effect of several antipsychotic drugs on lipid metabolism in patients treated for schizophrenia. It was hypothesized that these antipsychotic drugs may be altering lipid metabolism in treated patients with schizophrenia, contributing to the weight gain and hypertriglyceridemia. The study monitored lipid metabolites in patients both before and after treatment with antipsychotics. The compiled pre- and post-treatment profiles were then be compared to examine the effect of these compounds on lipid metabolism. Interestingly, the researchers found correlations between treatment with antipsychotic drugs and lipid metabolism, in both a lipid-class-specific and drug-specific manner, establishing new foundations around the concept that pharmacometabolomics provides powerful tools for enabling detailed mapping of drug effects. Additional studies by the Pharmacometabolomics Research Network enabled mapping in ways not possible before effects of statins, atenolol and aspirin. Totally new insights were gained about effect of these drugs on metabolism and they highlighted pathways implicated in response and side effects.",
            "score": 80.93617105484009
        },
        {
            "docid": "1889064_6",
            "document": "Pharmacogenetics . Scientists and doctors are using this new technology for a variety of things, one being improving the efficacy of drugs. In psychology, we can predict quite accurately which anti-depressant a patient will best respond to by simply looking into their genetic code. This is a huge step from the previous practice of adjusting and experimenting with different medications to get the best response. Antidepressants also have a large percentage of unresponsive patients and poor prediction rate of ADRs (adverse drug reactions). In depressed patients, 30% are not helped by antidepressants. In psychopharmacological therapy, a patient must be on a drug for 2 weeks before the effects can be fully examined and evaluated. For a patient in that 30%, this could mean months of trying medications to find an antidote to their pain. Any assistance in predicting a patient\u2019s drug reaction to psychopharmacological therapy should be taken advantage of. Pharmacogenetics is a very useful and important tool in predicting which drugs will be effective in various patients. The drug Plavix blocks platelet reception and is the second best selling prescription drug in the world, however, it is known to warrant different responses among patients. GWAS studies have linked the gene CYP2C19 to those who cannot normally metabolize Plavix. Plavix is given to patients after receiving a stent in the coronary artery to prevent clotting.",
            "score": 94.4403886795044
        },
        {
            "docid": "1269496_2",
            "document": "Bicalutamide . Bicalutamide, sold under the brand name Casodex among others, is an antiandrogen medication that is primarily used to treat prostate cancer. It is typically used together with a gonadotropin-releasing hormone (GnRH) analogue or surgical removal of the testicles to treat advanced prostate cancer. Bicalutamide may also be used to treat excessive hair growth in women, as a component of feminizing hormone therapy for transgender women, to treat early puberty in boys, and to prevent overly long-lasting erections in men. It is taken by mouth. Common side effects in men include breast enlargement, breast tenderness, and hot flashes. Other side effects in men include feminization and sexual dysfunction. While the medication appears to produce few side effects in women, its use in women is not recommended by the Food and Drug Administration (FDA). Use during pregnancy may harm the baby. Bicalutamide causes elevated liver enzymes in around 1% of people. Rarely, it has been associated with cases of liver damage, lung toxicity, and sensitivity to light. Although the risk of adverse liver changes is small, monitoring of liver function is recommended during treatment. Bicalutamide is a member of the nonsteroidal antiandrogen (NSAA) group of medications. It works by blocking the androgen receptor (AR), the biological target of the androgen sex hormones testosterone and dihydrotestosterone (DHT). It does not lower androgen levels. The medication can have some estrogen-like effects in men. Bicalutamide is well-absorbed, and its absorption is not affected by food. The elimination half-life of the medication is around one week. It is believed to cross the blood\u2013brain barrier and affect both the body and brain. Bicalutamide was patented in 1982 and approved for medical use in 1995. It is on the World Health Organization's List of Essential Medicines, the most effective and safe medicines needed in a health system. Bicalutamide is available as a generic medication. The wholesale cost in the developing world is about to per month. In the United States it costs about and above per month. The drug is sold in more than 80\u00a0countries, including most developed countries. It is the most widely used antiandrogen in the treatment of prostate cancer, and has been prescribed to millions of men with the disease.",
            "score": 66.24039781093597
        },
        {
            "docid": "1230676_19",
            "document": "Cystic fibrosis transmembrane conductance regulator . CFTR has been a drug target in efforts to find treatments for related conditions. Ivacaftor (trade name Kalydeco, developed as VX-770) is a drug approved by the FDA in 2012 for people with cystic fibrosis who have specific CFTR mutations Ivacaftor was developed by Vertex Pharmaceuticals in conjunction with the Cystic Fibrosis Foundation and is the first drug that treats the underlying cause rather than the symptoms of the disease. Called \"the most important new drug of 2012\", and \"a wonder drug\" it is one of the most expensive drugs, costing over US$300,000 per year, which has led to criticism of Vertex for the high cost.",
            "score": 81.29271054267883
        }
    ],
    "r": [
        {
            "docid": "44248347_28",
            "document": "Gene Disease Database . The response of bioinformatics to new experimental techniques brings a new perspective into the analysis of the experimental data, as demonstrated by the advances in the analysis of information from gene disease databases and other technologies. It is expected that this trend will continue with novel approaches to respond to new techniques, such as next-generation sequencing technologies. For instance, the availability of large numbers of individual human genomes will promote the development of computational analyses of rare variants, including the statistical mining of their relations to lifestyles, drug interactions and other factors. Biomedical research will also be driven by our ability to efficiently mine the large body of existing and continuously generated biomedical data. Text-mining techniques, in particular, when combined with other molecular data, can provide information about gene mutations and interactions and will become crucial to stay ahead of the exponential growth of data generated in biomedical research. Another field that is benefiting from the advances in mining and integration of molecular, clinical and drug analysis is pharmacogenomics. \"In silico\" studies of the relationships between human variations and their effect on diseases will be key to the development of personalized medicine. In summary, Gene Disease Databases have already transformed the search for disease genes and has the potential to become a crucial component of other areas of medical research.",
            "score": 120.0075912475586
        },
        {
            "docid": "149353_13",
            "document": "Computational biology . Computational pharmacology (from a computational biology perspective) is \u201cthe study of the effects of genomic data to find links between specific genotypes and diseases and then screening drug data\u201d. The pharmaceutical industry requires a shift in methods to analyze drug data. Pharmacologists were able to use Microsoft Excel to compare chemical and genomic data related to the effectiveness of drugs. However, the industry has reached what is referred to as the Excel barricade. This arises from the limited number of cells accessible on a spreadsheet. This development led to the need for computational pharmacology. Scientists and researchers develop computational methods to analyze these massive data sets. This allows for an efficient comparison between the notable data points and allows for more accurate drugs to be developed.",
            "score": 117.59505462646484
        },
        {
            "docid": "458970_17",
            "document": "Dominican Republic\u2013Central America Free Trade Agreement . While manufacturing costs of generic drugs are relatively cheap, the costs of human tests are relatively expensive, and tests take months or years. If generic manufacturers had to redo the tests, the generic drug would be more expensive, and generic manufacturers might not be able to do the tests at all. Furthermore, if generic manufacturers had to redo the tests, they would have to compare the new, effective drugs to less-effective drugs, which according to Doctors Without Borders, would be unethical. In the United States, drug manufacturers must make test data public for generic manufacturers. Under CAFTA's test data exclusivity, drug manufacturers could keep test data secret, which would make it more difficult for local companies to produce generic drugs, and enable multinational pharmaceutical companies to keep a monopoly on branded drugs, including those used to treat AIDS, malaria, and tuberculosis.",
            "score": 115.98249053955078
        },
        {
            "docid": "3408731_2",
            "document": "DrugBank . The DrugBank database is a comprehensive, freely accessible, online database containing information on drugs and drug targets. As both a bioinformatics and a cheminformatics resource, DrugBank combines detailed drug (i.e. chemical, pharmacological and pharmaceutical) data with comprehensive drug target (i.e. sequence, structure, and pathway) information. Because of its broad scope, comprehensive referencing and unusually detailed data descriptions, DrugBank is more akin to a drug encyclopedia than a drug database. As a result, links to DrugBank are maintained for nearly all drugs listed in Wikipedia. DrugBank is widely used by the drug industry, medicinal chemists, pharmacists, physicians, students and the general public. Its extensive drug and drug-target data has enabled the discovery and repurposing of a number of existing drugs to treat rare and newly identified illnesses.",
            "score": 115.60355377197266
        },
        {
            "docid": "48841414_5",
            "document": "Multiple instance learning . Keeler et al., in his work in early 1990s was the first one to explore the area of MIL. The actual term multi-instance learning was introduced in the middle of the 1990s, by Dietterich et al. while they were investigating the problem of drug activity prediction. They tried to create a learning systems that could predict whether new molecule was qualified to make some drug, or not, through analyzing a collection of known molecules. Molecules can have many alternative low-energy states, but only one, or some of them, are qualified to make a drug. The problem arose because scientists could only determine if molecule is qualified, or not, but they couldn\u2019t say exactly which of its low-energy shapes are responsible for that. One of the proposed ways to solve this problem was to use supervised learning, and regard all the low-energy shapes of the qualified molecule as positive training instances, while all of the low-energy shapes of unqualified molecules as negative instances. Dietterich et al. showed that such method would have a high false positive noise, from all low-energy shapes that are mislabeled as positive, and thus wasn\u2019t really useful. Their approach was to regard each molecule as a labeled bag, and all the alternative low-energy shapes of that molecule as instances in the bag, without individual labels. Thus formulating multiple-instance learning.  Solution to the multiple instance learning problem that Dietterich et al. proposed is three axis-parallel rectangle (APR) algorithm. It attempts to search for appropriate axis-parallel rectangles constructed by the conjunction of the features. They tested the algorithm on Musk dataset, which is a concrete test data of drug activity prediction and the most popularly used benchmark in multiple-instance learning. APR algorithm achieved the best result, but it should be noted that APR was designed with Musk data in mind.",
            "score": 114.45667266845703
        },
        {
            "docid": "16507549_40",
            "document": "Alzheimer's disease research . The current treatment for AD symptoms are acetylcholinesterase inhibitors and N-methyl-D-aspartate receptor (NMDA) antagonists. Based on the current literature on AD pharmacology research, analyzing differentially expressed genes in drug-drug, disease-disease, and drug-disease models allows the discovery of novel pharmaceutical agents that potentially treat more than AD symptoms. Analytical tools such as Connectivity Map (cMap) were used in drug-disease interaction from publicly available microarray data. Gene signatures from the cMap-based interpretation showed that common anti-AD drugs (tacrine, donepezil, galantamine, memantine, and rivastigmine) were not listed in the final drug list. Rather, other compounds that inhibit downstream effectors of cell proliferation, Wnt and insulin pathways, epigenetic modifications, and cell cycle regulation were among the top in the final anti-AD drug list. These findings further supported the fact that AD is a disease of degeneration and growth dysregulation. In fact, the final list of anti-AD drugs, obtained from analyzing microarray datasets and cMap drug-disease model contained the common effector of AD and diabetes \u2013 glycogen synthase kinase 3 (GSK3-an enzyme that has been found to be related to hyperphosphorylation of tau protein) \u2013 confirmed the link between the two diseases. Further pathway and network interpretation of genes obtained from AD microarray datasets using KEGG, WikiPathways, Reactome, Biocarta, and NetworkAnalyst showed that epidermal growth factor (EGF) and its receptors were strongly associated with pathogenesis of AD. EGFR is a transmembrane protein and a member of the HER/ErbB receptor family that share a common pathway with insulin receptors (Ras/Raf/Mak and PI3K/Akt). Furthermore, amyloid protein precursor (APP) was found to be indirectly related based on network analysis. A\u03b2 (one of the diagnostic findings of AD) activates EGFR and inhibition of the receptor improved memory disorders in A\u03b2-overexpressed drosophila. Drugs that block GSK3 were found to be affecting PI3K/Akt pathway, demonstrating that EGFR could be a new target for pharmaceutical agent in treating AD.",
            "score": 113.97693634033203
        },
        {
            "docid": "44450362_11",
            "document": "Network medicine . Network pharmacology is a developing field based in systems pharmacology that looks at the effect of drugs on both the interactome and the diseasome. The drug-target network (DTN) can play an important role in understanding the mechanisms of action of approved and experimental drugs. The network theory view of pharmaceuticals is based on the effect of the drug in the interactome, especially the region that the drug target occupies. Combination therapy for a complex disease (polypharmacology) is suggested in this field since one active pharmaceutical ingredient (API) aimed at one target may not effect the entire disease module. The concept of disease modules can be used to aid in drug discovery, drug design, and the development of biomarkers for disease detection. There can be a variety of ways to identifying drugs using network pharmacology; a simple example of this is the \"guilt by association\" method. This states if two diseases are treated by the same drug, a drug that treats one disease may treat the other. Drug repurposing, drug-drug interactions and drug side-effects have also been studied in this field.",
            "score": 106.9103012084961
        },
        {
            "docid": "29069615_9",
            "document": "Resistance Database Initiative . The RDI was established in 2002 to pioneer a new approach: to develop computational models using the genotype and a wide range of other clinically relevant data collected from thousands of patients treated with HAART all over the world and to use these models to predict how an individual patient will respond to different combinations of drugs. The RDI\u2019s goal was to make available a free treatment-response prediction tool over the Internet.",
            "score": 105.21923065185547
        },
        {
            "docid": "8715575_15",
            "document": "Phosphoproteomics . Increasing amounts of data are available suggesting that distinctive phosphoproteins exist in various tumors and that phosphorylation profiling could be used to fingerprint cancers from different origins. In addition, systematic cataloguing of tumor-specific phosphoproteins in individual patients could reveal multiple causative players during cancer formation. By correlating this experimental data to clinical data such as drug response and disease outcome, potential cancer markers could be identified for diagnosis, prognosis, prediction of drug response, and potential drug targets.",
            "score": 104.97927856445312
        },
        {
            "docid": "44248347_26",
            "document": "Gene Disease Database . The completion of the human genome has changed the way the search for disease genes is performed. In the past, the approach was to focus on one or a few genes at a time. Now, projects like the DisGeNET exemplify the efforts to systematically analyze all the gene alterations involved in a single or multiple diseases. The next step is to produce a complete picture of the mechanistic aspects of the diseases and the design of drugs against them. For that, a combination of two approaches will be needed: a systematic search and in-depth study of each gene. The future of the field will be defined by new techniques to integrate large bodies of data from different sources and to incorporate functional information into the analysis of large-scale data generated by bioinformatics studies.",
            "score": 104.65676879882812
        },
        {
            "docid": "1677333_5",
            "document": "Toxicogenomics . In pharmaceutical drug discovery and development, toxicogenomics is used to study possible adverse (i.e. toxic) effects of pharmaceutical drugs in defined model systems in order to draw conclusions on the toxic risk to patients or the environment. Both the United States Environmental Protection Agency (EPA) and the Food and Drug Administration (FDA) currently preclude basing regulatory decision-making on genomics data alone. However, they do encourage the voluntary submission of well-documented, quality genomics data. Both agencies are considering the use of submitted data on a case-by-case basis for assessment purposes (e.g., to help elucidate mechanism of action or contribute to a weight-of-evidence approach) or for populating relevant comparative databases by encouraging parallel submissions of genomics data and traditional toxicological test results.",
            "score": 102.78704833984375
        },
        {
            "docid": "41086554_20",
            "document": "Nanoparticles for drug delivery to the brain . In the early 21st century, extensive research is occurring in the field of nanoparticle drug delivery systems to the brain. One of the common diseases being studied in neuroscience today is Alzheimer's disease. Many studies have been done to show how nanoparticles can be used as a platform to deliver therapeutic drugs to these patients suffering from the disease. A few Alzheimer's drugs that have been studied especially are rivastigmine, tacrine, quinoline, piperine, and curcumin. PBCA, chitosan, and PLGA nanoparticles were used as delivery systems for these drugs. Overall, the results from each drug injection with these nanoparticles showed remarkable improvements in the effects of the drug relative to non-nanoparticle delivery systems. This possibly suggests that nanoparticles could provide a promising solution to how these drugs could cross the BBB. One factor that still must be considered and accounted for is nanoparticle accumulation in the body. With long-term and frequent injections that are often required to treat chronic diseases such as Alzheimer's disease, polymeric nanoparticles could potentially build up in the body, causing undesirable effects. This area for concern would have to be further assessed to analyze these possible effects and to improve them.",
            "score": 102.62908935546875
        },
        {
            "docid": "5009_44",
            "document": "Zebrafish . This study of the zebrafish's retinal characteristics has also extrapolated into medical enquiry. In 2007, researchers at University College London grew a type of zebrafish adult stem cell found in the eyes of fish and mammals that develops into neurons in the retina. These could be injected into the eye to treat diseases that damage retinal neurons\u2014nearly every disease of the eye, including macular degeneration, glaucoma, and diabetes-related blindness. The researchers studied M\u00fcller glial cells in the eyes of humans aged from 18 months to 91 years, and were able to develop them into all types of retinal neurons. They were also able to grow them easily in the lab. The stem cells successfully migrated into diseased rats' retinas, and took on the characteristics of the surrounding neurons. The team stated that they intended to develop the same approach in humans. As demonstrated through ongoing research programmes, the zebrafish model enables researchers not only to identify genes that might underlie human disease, but also to develop novel therapeutic agents in drug discovery programmes. Zebrafish embryos have proven to be a rapid, cost-efficient, and reliable teratology assay model. Drug screens in zebrafish can be used to identify novel classes of compounds with biological effects, or to repurpose existing drugs for novel uses; an example of the latter would be a screen which found that a commonly used statin (rosuvastatin) can suppress the growth of prostate cancer To date, 65 small-molecule screens have been carried out and at least one has led to clinical trials. Within these screens, many technical challenges remain to be resolved, including differing rates of drug absorption resulting in levels of internal exposure that cannot be extrapolated from the water concentration, and high levels of natural variation between individual animals. To understand drug effects, the internal drug exposure is essential, as this drives the pharmacological effect. Translating experimental results from zebrafish to higher vertebrates (like humans) requires concentration-effect relationships, which can be derived from pharmacokinetic and pharmacodynamic analysis. To date, only a pharmacokinetic model for paracetamol has been developed in zebrafish larvae. The potential for pharmacological analyses in this organism is however promising.",
            "score": 102.50883483886719
        },
        {
            "docid": "1004486_3",
            "document": "Pharmacogenomics . Pharmacogenomics aims to develop rational means to optimize drug therapy, with respect to the patients' genotype, to ensure maximum efficacy with minimal adverse effects. Through the utilization of pharmacogenomics, it is hoped that pharmaceutical drug treatments can deviate from what is dubbed as the \"one-dose-fits-all\" approach. Pharmacogenomics also attempts to eliminate the trial-and-error method of prescribing, allowing physicians to take into consideration their patient's genes, the functionality of these genes, and how this may affect the efficacy of the patient's current or future treatments (and where applicable, provide an explanation for the failure of past treatments). Such approaches promise the advent of precision medicine and even personalized medicine, in which drugs and drug combinations are optimized for narrow subsets of patients or even for each individual's unique genetic makeup. Whether used to explain a patient's response or lack thereof to a treatment, or act as a predictive tool, it hopes to achieve better treatment outcomes, greater efficacy, minimization of the occurrence of drug toxicities and adverse drug reactions (ADRs). For patients who have lack of therapeutic response to a treatment, alternative therapies can be prescribed that would best suit their requirements. In order to provide pharmacogenomic recommendations for a given drug, two possible types of input can be used: genotyping or exome or whole genome sequencing. Sequencing provides many more data points, including detection of mutations that prematurely terminate the synthesized protein (early stop codon).",
            "score": 102.18199920654297
        },
        {
            "docid": "30916247_20",
            "document": "Neglected tropical disease research and development . One rich area to explore is in the wealth of genomic data resulting from the sequencing of parasite genomes. These data offer opportunities for the exploration of new therapeutic products using computational, and open source collaboration methods for drug discovery. The Tropical Disease Initiative, for example, has used large amounts of computing power to generate the protein structures for ten parasite genomes. An open source drug bank was matched algorithmically to determine compounds with protein interaction activity, and two candidates were identified. In general, such methods may hold important opportunities for off-label use of existing approved drugs.",
            "score": 101.3829116821289
        },
        {
            "docid": "5824073_12",
            "document": "High-content screening . This technology allows a (very) large number of experiments to be performed, allowing explorative screening. Cell-based systems are mainly used in chemical genetics where large, diverse small molecule collections are systematically tested for their effect on cellular model systems. Novel drugs can be found using screens of tens of thousands of molecules, and these have promise for the future of drug development.  Beyond drug discovery, chemical genetics is aimed at functionalizing the genome by identifying small molecules that acts on most of the 21,000 gene products in a cell. High-content technology will be part of this effort which could provide useful tools for learning where and when proteins act by knocking them out chemically. This would be most useful for gene where knock out mice (missing one or several genes) can not be made because the protein is required for development, growth or otherwise lethal when it is not there. Chemical knock out could address how and where these genes work. Further the technology is used in combination with RNAi to identify sets of genes involved in specific mechanisms, for example cell division. Here, libraries of RNAis, covering a whole set of predicted genes inside the target organism's genome can be used to identify relevant subsets, facilitating the annotation of genes for which no clear role has been established beforehand. The large datasets produced by automated cell biology contain spatially resolved, quantitative data which can be used for building for systems level models and simulations of how cells and organisms function. Systems biology models of cell function would permit prediction of why, where and how the cell responds to external changes, growth and disease.",
            "score": 100.85162353515625
        },
        {
            "docid": "20374_50",
            "document": "Metabolism . An idea of the complexity of the metabolic networks in cells that contain thousands of different enzymes is given by the figure showing the interactions between just 43 proteins and 40 metabolites to the right: the sequences of genomes provide lists containing anything up to 45,000 genes. However, it is now possible to use this genomic data to reconstruct complete networks of biochemical reactions and produce more holistic mathematical models that may explain and predict their behavior. These models are especially powerful when used to integrate the pathway and metabolite data obtained through classical methods with data on gene expression from proteomic and DNA microarray studies. Using these techniques, a model of human metabolism has now been produced, which will guide future drug discovery and biochemical research. These models are now used in network analysis, to classify human diseases into groups that share common proteins or metabolites.",
            "score": 100.36553955078125
        },
        {
            "docid": "356382_31",
            "document": "Gene regulatory network . Other work has focused on predicting the gene expression levels in a gene regulatory network. The approaches used to model gene regulatory networks have been constrained to be interpretable and, as a result, are generally simplified versions of the network. For example, Boolean networks have been used due to their simplicity and ability to handle noisy data but lose data information by having a binary representation of the genes. Also, artificial neural networks omit using a hidden layer so that they can be interpreted, losing the ability to model higher order correlations in the data. Using a model that is not constrained to be interpretable, a more accurate model can be produced. Being able to predict gene expressions more accurately provides a way to explore how drugs affect a system of genes as well as for finding which genes are interrelated in a process. This has been encouraged by the DREAM competition which promotes a competition for the best prediction algorithms. Some other recent work has used artificial neural networks with a hidden layer.",
            "score": 99.52643585205078
        },
        {
            "docid": "37783228_41",
            "document": "William A. Haseltine . At the time, the idea that newly isolated human genes of unknown function could prove useful for drug development was widely criticized. Haseltine's experience with HIV taught him that knowledge of the genome without prior knowledge of function was useful and had led to the discovery of new and useful drug targets and new and effective drugs. Haseltine argued that if one new human gene were discovered, the techniques of modern biology would allow its natural function and potential medical use identified. If that were true for one gene, then why not all the human genes? New tools had been developed that allowed what had been tedious hard work of gene isolation and characterization to be replaced by highly automated instruments and the data regarding the structure, tissue and cell location and the results of functional tests to be stored and easily accessed using advanced computer technologies. He summarized these views with the statement \"Genomics is not necessarily Genetics\". It was not until the Human Genome Science approach was validated by its own work and the work of its partners that it was ultimately adopted by the scientific community. Today, the approach pioneered by Human Genome Sciences is one of the principal tools used today for the discovery and characterization of novel human genes and as well as the genes of other species.",
            "score": 98.72636413574219
        },
        {
            "docid": "24720184_20",
            "document": "Scott L. McGregor . In 2000, McGregor joined Data Digest, where he led the engineering team developing of an Bayesian Network predictive analytic engine which analyzed arbitrary databases or tables of transactional data to find hidden predictive relationships. Initially named \"Business Navigator / BN-5\", the product was later sold to Decision-Q Corporation who renamed it FasterAnalytics. The analytic engine is general purpose and was initially used to for analyze data for a wide range of problems, from predicting response levels to offers for a mail order record and video club to predicting protein-folding in drug discovery research. It is notable that with this work, McGregor returned to the roots of his earlier Prescient Agent work of a decade earlier which also relied on Bayesian prediction. However, a decade of computer performance improvements now made technology that had once challenged $100,000 workstations well within the capabilities of desktop office machines.",
            "score": 98.63054656982422
        },
        {
            "docid": "18208306_14",
            "document": "PatientsLikeMe . The company's best known scientific endeavor relates to an online refutation of a clinical trial in ALS. In 2008, a small Italian study was published suggesting that lithium carbonate could slow the progression of ALS. In response, hundreds of members of PatientsLikeMe with the disease began taking the drug off-label. Using the self-reported data of 348 ALS patients and taking just nine months to complete, PatientsLikeMe conducted a study which demonstrated that lithium did not slow the progress of the disease. The team suggested that online collection of patient self-report data was no substitute for randomized placebo-controlled trials, but it might be a useful new form of clinical research in certain circumstances. A later study described how patients attempted to use the same tools to unblind clinical trials in which they were enrolled to try and see whether or not the experimental drugs they were taking were working. A 2016 collaboration with Dr Rick Bedlack of the Duke ALS Clinic aims to overcome some of the burden of traditional ALS trials by allowing patients to take part in a clinical trial of a nutritional supplement, Lunasin, from their own home with just two clinic visits rather than regular monthly appointments.",
            "score": 98.53888702392578
        },
        {
            "docid": "12268846_3",
            "document": "First Databank . First Databank is a leading provider of pharmaceutical data context-relevant products and services. The firm creates and maintains widely used drug database products, software for drug database integration, drug reference products, and other pharmaceutically informatic relevant services. The firm has partnered with pharmaceutical informatic parties and agencies to make drug data useful and relevant for a wide range of drug delivery system applications. The firm's software/service supports pharmacy dispensing, formulary management, drug pricing analysis, medical insurance claims to process computerized physician order entry (CPOE) et al., electronic health records (EHR), electronic medical records (EMR), electronic prescribing (e-Prescribing) and electronic medication administration records (EMAR).",
            "score": 98.24481201171875
        },
        {
            "docid": "3218783_19",
            "document": "Drug development . Candidates for a new drug to treat a disease might, theoretically, include from 5,000 to 10,000 chemical compounds. On average about 250 of these show sufficient promise for further evaluation using laboratory tests, mice and other test animals. Typically, about ten of these qualify for tests on humans. A study conducted by the Tufts Center for the Study of Drug Development covering the 1980s and 1990s found that only 21.5 percent of drugs that started Phase I trials were eventually approved for marketing. In the time period of 2006 to 2015, the success rate was 9.6%. The high failure rates associated with pharmaceutical development are referred to as the \"attrition rate\" problem. Careful decision making during drug development is essential to avoid costly failures. In many cases, intelligent programme and clinical trial design can prevent false negative results. Well-designed, dose-finding studies and comparisons against both a placebo and a gold-standard treatment arm play a major role in achieving reliable data.",
            "score": 97.94700622558594
        },
        {
            "docid": "34939027_5",
            "document": "Pharmacometabolomics . Although the applications of pharmacometabolomics to personalized medicine are largely only being realized now, the study of an individual\u2019s metabolism has been used to treat disease since the Middle Ages. Early physicians employed a primitive form of metabolomic analysis by smelling, tasting and looking at urine to diagnose disease. Obviously the measurement techniques needed to look at specific metabolites were unavailable at that time, but such technologies have evolved dramatically over the last decade to develop precise, high-throughput devices, as well as the accompanying data analysis software to analyze output. Currently, sample purification processes, such as liquid or gas chromatography, are coupled with either mass spectrometry (MS)-based or nuclear magnetic resonance (NMR)-based analytical methods to characterize the metabolite profiles of individual patients. Continually advancing informatics tools allow for the identification, quantification and classification of metabolites to determine which pathways may influence certain pharmaceutical interventions. One of the earliest studies discussing the principle and applications of pharmacometabolomics was conducted in an animal model to look at the metabolism of paracetamol and liver damage. NMR spectroscopy was used to analyze the urinary metabolic profiles of rats pre- and post-treatment with paracetamol. The analysis revealed a certain metabolic profile associated with increased liver damage following paracetamol treatment. At this point, it was eagerly anticipated that such pharmacometabolomics approaches could be applied to personalized human medicine. Since this publication in 2006, the Pharmacometabolomics Research Network led by Duke University researchers and that included partnerships between centers of excellence in metabolomics, pharmacogenomics and informatics (over sixteen academic centers funded by NIGMS) has been able to illustrate for the first time the power of the pharmacometabolomics approach in informing about treatment outcomes in large clinical studies and with use of drugs that include antidepressants, statins, antihypertensives, antiplatelet therapies and antipsychotics. Totally new concepts emerged from these studies on use of pharmacometabolomics as a tool that can bring a paradigm shift in the field of pharmacology. It illustrated how pharmacometabolomics can enable a Quantitative and Systems Pharmacology approach.  Pharmacometabolomics has been applied for the treatment of numerous human diseases, such as schizophrenia, diabetes, neural disease, depression and cancer.",
            "score": 97.52183532714844
        },
        {
            "docid": "23386350_4",
            "document": "BioSim . Diabetes Efforts concentrate on the role of mutations that effect the ion channels of the insulin-producing beta-cells, on the genetic basis for the development of neonatal diabetes, on the study of human (as opposed to mice) pancreatic cells, on the mechanisms underlying the development of insulin resistance, and on the possible role of prenatal nutrition for the development of type-2 diabetes. Models are also developed to analyse the balance between fat and glucose metabolism and to describe the rate of absorption of different insulin variants. Cancer In this area the network uses computer models of the cell cycle and of its coupling to the 24 h day-and-night rhythm to improve the treatment of patients with cancer. The use of chronotherapy implies that the administration of anti-cancer drugs is adjusted in accordance with the circadian rhythm of the patient. For certain forms of cancer this has been found to increase the efficiency of the drug by a factor of five. Efforts are also devoted to the development of new anti-cancer drugs. Hypertension and cardiovascular diseases Activities area focus on the development of 3D heart models that can be used to test how a new drug affects the regularity of the heart rhythm. Work is performed to develop detailed models of the mechanisms by which the individual nephron of the kidney regulates the incoming blood flow and how neighboring nephrons interact. Mental disorders and neuronal systems Work includes application of mathematical models to develop less invasive and demand-controlled electrical stimulation techniques for the treatment of Parkinson's disease. Modelling studies are performed to examine the effect of sleep deprivation in the treatment of depression, and bioinformatic approaches are applied to try to identify forms of depression on the basis of the information available from blood samples. Methodological issues The area encompasses description of complex networks of oscillating biological units, studies of the mechanisms of temperature stabilization in biological feedback regulations, application of new methods of data analysis, and development of modeling software and biomedical search machines. The area includes application of new experimental techniques such as interference microscopy and surface enhanced Raman spectroscopy to study cellular processes. Regulatory issues and dialogue with the public Testing in animal and human subjects is a necessary part of the development of new drugs. Such experiments clearly raises a number of complicated ethical issues that the use of simulation models may reduce. This requires that the regulatory authorities can evaluate computer models and accept them as part of the required documentation.  During the last five years the BioSim Network has published nine books and 800 scientific publications. The network has organized or co-organized 30 conferences and workshops, edited four issues of international journals, and trained about 130 PhD students. New National Centres in Systems Biology have been established in relation to the BioSim partners in Manchester, Warwick, and Edinburgh.",
            "score": 97.32229614257812
        },
        {
            "docid": "30916247_7",
            "document": "Neglected tropical disease research and development . In their 2002 review of the U.S. Food and Drug Administration (FDA) databases and the European Agency for the Evaluation of Medicinal Products, Troullier \"et al\" found that 16 out of 1393 new chemical entities were approved for NTDs between 1975 and 1999 (~1%). Cohen \"et al\" revisited the data and using the same methodology found 32 new chemical entities during the time period. In a second analysis using an expanded list of NTDs based on the G-FINDER survey, the number was slightly higher, with 46 new drugs and vaccines approved (~3% of the total including HIV drugs). Between 2000 and 2009, there has been some increase with an additional 26 newly approved drugs and vaccines for NTDs.",
            "score": 97.08513641357422
        },
        {
            "docid": "46581687_3",
            "document": "Pathway analysis . The data for pathway analysis come from high throughput biology. This includes high throughput sequencing data and microarray data. Before pathway analysis can be done, the omics data should be normalized, and genes should be ranked by differential expression usually with help of Student's t-test, ANOVA or other statistics. In general, any list of statistical ranked genes can be analyzed by pathway analysis. For example, often the functional activity of proteins can be inferred using network enrichment analysis of genes deferentially expressed in the experiment. Such functional activity scores can then be used for pathway analysis to find pathways responsible for observed differential expression. In case when ranking is not available simply list of genes can be analyzed. Also it is possible to integrate multiple microarray data sets from different research groups by meta-analysis and cross-platform normalization. By using pathway analysis software, researchers can determine which gene groups such as pathways, cell processes or diseases are enriched with over and under expressed in experimental data genes. They can also infer associated upstream and downstream regulators, proteins, small molecules, drugs, etc. For example, pathway analysis of several independent microarray experiments (meta-analysis) helped to discover potential biomarkers in a single pathway important for fast-to-slow switch fiber type transition in Duchenne muscular dystrophy. In other study meta-analysis identified two biomarkers in blood of patients with Parkinson's Disease, which can be useful for monitoring the disease.",
            "score": 96.73939514160156
        },
        {
            "docid": "149353_8",
            "document": "Computational biology . Computational biomodeling is a field concerned with building computer models of biological systems. Computational biomodeling aims to develop and use visual simulations in order to assess the complexity of biological systems. This is accomplished through the use of specialized algorithms, and visualization software. These models allow for prediction of how systems will react under different environments. This is useful for determining if a system is robust. A robust biological system is one that \u201cmaintain their state and functions against external and internal perturbations\u201d, which is essential for a biological system to survive. Computational biomodeling generates a large archive of such data, allowing for analysis from multiple users. While current techniques focus on small biological systems, researchers are working on approaches that will allow for larger networks to be analyzed and modeled. A majority of researchers believe that this will be essential in developing modern medical approaches to creating new drugs and gene therapy. A useful modelling approach is to use Petri nets via tools such as esyN",
            "score": 96.67501831054688
        },
        {
            "docid": "4995479_43",
            "document": "Genomic library . Genome-wide association studies are general applications to find specific gene targets and polymorphisms within the human race. In fact, the International HapMap project was created through a partnership of scientists and agencies from several countries to catalog and utilize this data. The goal of this project is to compare genetic sequences of different individuals to elucidate similarities and differences within chromosomal regions. Scientists from all of the participating nations are cataloging these attributes with data from populations of African, Asian, and European ancestry. Such genome-wide assessments may lead to further diagnostic and drug therapies while also helping future teams focus on orchestrating therapeutics with genetic features in mind. These concepts are already being exploited in genetic engineering. For example, a research team has actually constructed a PAC shuttle vector that creates a library representing two-fold coverage of the human genome. This could serve as an incredible resource to identify genes, or sets of genes, causing disease. Moreover, these studies can serve as a powerful way to investigate transcriptional regulation as it has been seen in the study of baculoviruses. Overall, advances in genome library construction and DNA sequencing has allowed for efficient discovery of different molecular targets. Assimilation of these features through such efficient methods can hasten the employment of novel drug candidates.",
            "score": 96.33149719238281
        },
        {
            "docid": "5255433_4",
            "document": "Fiona Brinkman . Brinkman's current research interests center around improving understanding of how microbes evolve and improving computational methods that aid the analysis of microbes and the development of new vaccines, drugs and diagnostics for infectious diseases. Increasingly her methods have been applied for more environmental applications. She is noted for developing PSORTb, the most precise method available for computational protein subcellular localization prediction and the first computational method that exceeded the accuracy of some common high-throughput laboratory methods for such subcellular localization analysis. This method aids the prediction of cell surface and secreted proteins in a bacterial cell that may be suitable drug targets, vaccine components or diagnostics. She has also developed bioinformatics methods that aid the more accurate identification of genomic islands (i.e. IslandViewer) and orthologs (i.e. OrtholugeDB) . Her research has provided new insights into the evolution of pathogens and the role that horizontal gene transfer and genomic islands play. She confirmed the anecdotal assumption that virulence factors (disease-causing genes in pathogens) are disproportionately associated with genomic islands. She was among the first researchers to use whole genome sequencing to aid infectious disease outbreak investigations (\"genomic epidemiology\"), integrating genome sequence data with social network analysis. She was involved in the Pseudomonas Genome Project and is the coordinator of the Pseudomonas Genome Database, a database of Pseudomonas species genomic data and associated annotations that is continually updated. She has also developed databases (i.e. InnateDB and the Allergy and Asthma Portal) to aid more systems-based analysis of immune disorders and the immune response to infections in humans and other animals - databases that have aided the identification of new immune-modulating therapeutics. She has a long-standing interest in bioinformatics training, improving the curation of biological/bioinformatics data, and developing effective bioinformatics data standards and databases. She is a Thomson Reuter's Highly Cited Researcher, a member of national committees and Boards such as the Genome Canada Board of Directors, and has been Research Director for several Genomics projects. She has a growing interest in applying her methods to environmental applications as part of a broader interest in developing approaches for more holistic, sustainable infectious disease control and microbiome conservation - developing approaches that may select less for antimicrobial resistance, improve the tracking of pathogens and their origins, and better factor in the important role of societal changes and the environment in shaping microbiomes",
            "score": 96.13610076904297
        },
        {
            "docid": "37783228_22",
            "document": "William A. Haseltine . The first goal was achieved by understanding the structure and function of the virus. Haseltine's laboratory, working in collaboration with two other groups, determined the complete sequence of the viral genome and discovered the genes that specify the virus capsid, polymerase, protease, ribonuclease H, integrase and envelop genes. The first application of this knowledge was to design a fragment of the virus envelope protein that could be used to accurately detect antibodies to HIV in those infected, forming the basis of an accurate diagnostic test. This protein fragment was used by Cambridge BioSciences (Later named Cambridge BioTech) to develop a rapid test for HIV infection that could be used at home. It was only in 2012, that the US FDA approved a similar home HIV test kit. Haseltine and his laboratory quickly showed that damage to any of the viral genes that specify the virus capsid, polymerase, protease, ribonuclease, integrase and envelope genes killed the virus and therefore that proteins specified by each gene were good targets for anti-viral drugs. Over the next several years his laboratory isolated each of the genes and their proteins in pure form and developed methods that were used by the pharmaceutical companies to discover new anti viral drugs. The first HIV specific protease inhibitor Nelfinavir, was developed as a part of a three way collaboration between the Haseltine laboratory, Cambridge BioSciences, a company Haseltine and his colleagues created, and Agouron Pharmaceuticals. The combination of an HIV polymerase inhibitor such as AZT and an anti protease drug lead to the first long term survival of those infected with HIV. Haseltine proposed the use of combination chemotherapy, the use of multiple drugs targeted against different viral proteins would be the basis for effective therapy. Today those ideas have proven out; The pharmaceutical industry has developed more than forty drugs that inhibit the HIV polymerase, protease, integrase, and envelope proteins. Combinations of these drugs have transformed HIV infection from a near universally fatal disease to one that with proper management can usually be successfully treated for decades.",
            "score": 96.06814575195312
        },
        {
            "docid": "33901120_4",
            "document": "Sean Ekins . From 1996-1998 Ekins continued his research as a Postdoc at Eli Lilly and Company laboratories characterizing the little-known CYP2B6 and applied computational methods to this enzyme. He collected drug-drug interaction Ki data for other P450s and generated pharmacophores. He created test sets to test the models, that were ultimately published. He published seminal ideas on how such models could be used to profile libraries of compounds for predicted drug-drug interactions.",
            "score": 95.77946472167969
        }
    ]
}