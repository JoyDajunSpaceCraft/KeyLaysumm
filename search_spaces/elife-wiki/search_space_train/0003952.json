{
    "q": [
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 211.06556248664856
        },
        {
            "docid": "226722_25",
            "document": "Functional magnetic resonance imaging . Researchers have checked the BOLD signal against both signals from implanted electrodes (mostly in monkeys) and signals of field potentials (that is the electric or magnetic field from the brain's activity, measured outside the skull) from EEG and MEG. The local field potential, which includes both post-neuron-synaptic activity and internal neuron processing, better predicts the BOLD signal. So the BOLD contrast reflects mainly the inputs to a neuron and the neuron's integrative processing within its body, and less the output firing of neurons. In humans, electrodes can be implanted only in patients who need surgery as treatment, but evidence suggests a similar relationship at least for the auditory cortex and the primary visual cortex. Activation locations detected by BOLD fMRI in cortical areas (brain surface regions) are known to tally with CBF-based functional maps from PET scans. Some regions just a few millimeters in size, such as the lateral geniculate nucleus (LGN) of the thalamus, which relays visual inputs from the retina to the visual cortex, have been shown to generate the BOLD signal correctly when presented with visual input. Nearby regions such as the pulvinar nucleus were not stimulated for this task, indicating millimeter resolution for the spatial extent of the BOLD response, at least in thalamic nuclei. In the rat brain, single-whisker touch has been shown to elicit BOLD signals from the somatosensory cortex.",
            "score": 203.79399037361145
        },
        {
            "docid": "4231622_9",
            "document": "Inferior temporal gyrus . These areas must all work together, as well as with the hippocampus, in order to create an array of understanding of the physical world. The hippocampus is key for storing the memory of what an object is/what it looks like for future use so that it can be compared and contrasted with other objects. Correctly being able to recognize an object is highly dependent on this organized network of brain areas that process, share, and store information. In a study by Denys et al., functional magnetic resonance imaging (FMRI) was used to compare the processing of visual shape between humans and macaques. They found, amongst other things, that there was a degree of overlap between shape and motion sensitive regions of the cortex, but that the overlap was more distinct in humans. This would suggest that the human brain is better evolved for a high level of functioning in a distinct, three-dimensional, visual world.",
            "score": 208.0177662372589
        },
        {
            "docid": "11068276_8",
            "document": "Vividness of Visual Imagery Questionnaire . In looking for possible correlations across the entire brain, Amedi et al. ran a correlation analysis between the VVIQ and BOLD on a voxel-by-voxel exploratory basis. Significant negative correlations between VI BOLD and VVIQ were located in auditory or somatosensory cortex, including left HG, STG bilaterally, and right STS. Positive correlations were found between VVIQ and BOLD signal in visual and inferior prefrontal cortex but also in parahippocampal areas bilaterally and left parieto-occipital sulcus. Amedi et al. (2005) concluded that \"...pure visual imagery is characterized by an isolated activation of visual cortical areas with concurrent deactivation of sensory inputs that could potentially disrupt the image created by our mind\u2019s eye\" (p. 867).",
            "score": 168.2736461162567
        },
        {
            "docid": "1038040_5",
            "document": "Semir Zeki . These findings raised the question of how the signals processed in these separate visual areas are integrated to give a unified picture of the visual world. In psychophysical experiments undertaken with colleagues, he showed that we perceive, and become aware of, different visual attributes at different times, with colour preceding motion by about 80 ms and form (orientation) by about 40 ms, leading to the view that there is a temporal asynchrony in vision which is the result of different processing speeds for different attributes. This in turn led him to suggest that visual consciousness is not unified; rather there are many visual micro-consciousness which are distributed in time and space, and that activity in each visual area can acquire a conscious correlate without the necessity of reporting to another cortical area, though acknowledging that there must be other enabling systems, possibly located in the reticular formation. Thus, functional specialisation manifests itself in the temporal sequence with which we see different attributes such as colour",
            "score": 179.9784071445465
        },
        {
            "docid": "484650_7",
            "document": "Functional neuroimaging . Traditional \"activation studies\" focus on determining distributed patterns of brain activity associated with specific tasks. However, scientists are able to more thoroughly understand brain function by studying the interaction of distinct brain regions, as a great deal of neural processing is performed by an integrated network of several regions of the brain. An active area of neuroimaging research involves examining the functional connectivity of spatially remote brain regions. Functional connectivity analyses allow the characterization of interregional neural interactions during particular cognitive or motor tasks or merely from spontaneous activity during rest. FMRI and PET enable creation of functional connectivity maps of distinct spatial distributions of temporally correlated brain regions called functional networks. Several studies using neuroimaging techniques have also established that posterior visual areas in blind individuals may be active during the performance of nonvisual tasks such as Braille reading, memory retrieval, and auditory localization as well as other auditory functions.",
            "score": 133.7850363254547
        },
        {
            "docid": "2630160_22",
            "document": "Visual angle . The brain's primary visual cortex (area V1 or Brodmann area 17) contains a spatially isomorphic representation of the retina (see retinotopy). Loosely speaking, it is a distorted \"map\" of the retina. Accordingly, the size formula_19 of a given retinal image determines the extent of the neural activity pattern eventually generated in area V1 by the associated retinal activity pattern. Murray, Boyaci, & Kersten (2006) recently used Functional magnetic resonance imaging (fMRI) to show that an increase in a viewed target's visual angle, which increases formula_19, also increases the extent of the corresponding neural activity pattern in area V1.",
            "score": 181.10728788375854
        },
        {
            "docid": "35182952_4",
            "document": "Embodied language processing . The overlap between various semantic categories with sensory motor areas suggests that a common mechanism is used by neurons to process action, perception, and semantics. The correlation principle states that neurons that fire together, wire together. Also, neurons out of sync, delink. When an individual pronounces a word, the activation pattern for articulatory motor systems of the speaker leads to activation of auditory and somatosensory systems due to self-perceived sounds and movements. If a word meaning is grounded in the visual shapes of the objects, the word form circuit is active together with neural activity in the ventral-temporal visual stream related to processing of visual object information. Correlation learning links the word and object circuits, resulting in an embodied object-semantic relationship.",
            "score": 135.38308668136597
        },
        {
            "docid": "419595_8",
            "document": "Brodmann area . In visual areas, the maps are retinotopic; this means they reflect the topography of the retina, the layer of light-activated neurons lining the back of the eye. In this case too, the representation is uneven: the fovea\u2014the area at the center of the visual field\u2014is greatly overrepresented compared to the periphery. The visual circuitry in the human cerebral cortex contains several dozen distinct retinotopic maps, each devoted to analyzing the visual input stream in a particular way. The primary visual cortex (Brodmann area 17), which is the main recipient of direct input from the visual part of the thalamus, contains many neurons that are most easily activated by edges with a particular orientation moving across a particular point in the visual field. Visual areas farther downstream extract features such as color, motion, and shape.",
            "score": 185.6839359998703
        },
        {
            "docid": "19557982_16",
            "document": "Default mode network . Diffusion MRI imaging shows white matter tracts connecting different areas of the DMN together. The structural connections found from diffusion MRI imaging and the functional correlations from resting state fMRI show the highest level of overlap and agreement within the DMN areas. This provides evidence that neurons in the DMN regions are linked to each other through large tracts of axons and this causes activity in these areas to be correlated with one another.",
            "score": 78.38112378120422
        },
        {
            "docid": "19557982_25",
            "document": "Default mode network . Raichle coined the term \"default mode\" in 2001 to describe resting state brain function; the concept rapidly became a central theme in neuroscience. Around this time the idea was implanted that this network of brain areas is involved in internally directed thoughts and is suspended during specific goal-directed behaviors. In 2003, Greicius and colleagues examined resting state fMRI scans and looked at how correlated different sections in the brain are to each other and found the correlation maps showed the same areas Raichle found active during rest and that others found to deactivated. It was important because it demonstrated a convergence of methods all lead to the same areas being involved in the DMN. Since then other resting state networks (RSNs) have been found, such as visual, auditory, and attention networks, some of them are often anti-correlated with the default mode network.",
            "score": 150.4097683429718
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 205.70283246040344
        },
        {
            "docid": "7725524_2",
            "document": "Colour centre . The colour centre is a region in the brain primarily responsible for visual perception and cortical processing of colour signals received by the eye, which ultimately results in colour vision. The colour centre in humans is thought to be located in the ventral occipital lobe as part of the visual system, in addition to other areas responsible for recognizing and processing specific visual stimuli, such as faces, words, and objects. Many functional magnetic resonance imaging (fMRI) studies in both humans and macaque monkeys have shown colour stimuli to activate multiple areas in the brain, including the fusiform gyrus and the lingual gyrus. These areas, as well as others identified as having a role in colour vision processing, are collectively labelled visual area 4 (V4). The exact mechanisms, location, and function of V4 are still being investigated.",
            "score": 182.47852218151093
        },
        {
            "docid": "485309_16",
            "document": "Face perception . There are several parts of the brain that play a role in face perception. Rossion, Hanseeuw, and Dricot used BOLD fMRI mapping to identify activation in the brain when subjects viewed both cars and faces. The majority of BOLD fMRI studies use blood oxygen level dependent (BOLD) contrast to determine which areas of the brain are activated by various cognitive functions. They found that the occipital face area, located in the occipital lobe, the fusiform face area, the superior temporal sulcus, the amygdala, and the anterior/inferior cortex of the temporal lobe, all played roles in contrasting the faces from the cars, with the initial face perception beginning in the area and occipital face areas. This entire region links to form a network that acts to distinguish faces. The processing of faces in the brain is known as a \"sum of parts\" perception. However, the individual parts of the face must be processed first in order to put all of the pieces together. In early processing, the occipital face area contributes to face perception by recognizing the eyes, nose, and mouth as individual pieces. Furthermore, Arcurio, Gold, and James used BOLD fMRI mapping to determine the patterns of activation in the brain when parts of the face were presented in combination and when they were presented singly. The occipital face area is activated by the visual perception of single features of the face, for example, the nose and mouth, and preferred combination of two-eyes over other combinations. This research supports that the occipital face area recognizes the parts of the face at the early stages of recognition. On the contrary, the fusiform face area shows no preference for single features, because the fusiform face area is responsible for \"holistic/configural\" information, meaning that it puts all of the processed pieces of the face together in later processing. This theory is supported by the work of Gold et al. who found that regardless of the orientation of a face, subjects were impacted by the configuration of the individual facial features. Subjects were also impacted by the coding of the relationships between those features. This shows that processing is done by a summation of the parts in the later stages of recognition.",
            "score": 175.88884711265564
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 189.68870162963867
        },
        {
            "docid": "1639193_12",
            "document": "Reading comprehension . Comprehension levels are observed through neuroimaging techniques like functional magnetic resonance imaging (fMRI). fMRI's are used to determine the specific neural pathways of activation across two conditions, narrative-level comprehension and sentence-level comprehension. Images showed that there was less brain region activation during sentence-level comprehension, suggesting a shared reliance with comprehension pathways. The scans also showed an enhanced temporal activation during narrative levels tests indicating this approach activates situation and spatial processing. In general, neuroimaging studies have found that reading involves three overlapping neural systems: networks active in visual, orthography-phonology (Angular gyrus), and semantic functions (Anterior temporal lobe with Broca's and Wernicke's area). However, these neural networks are not discrete, meaning these areas have several other functions as well. The Broca's area involved in executive functions helps the a reader to vary depth of reading comprehension and textual engagement in accordance with reading goals.",
            "score": 132.51511490345
        },
        {
            "docid": "4087208_12",
            "document": "David Marks (psychologist) . Rodway, Gillies and Schepman (2006) found that high vividness participants were significantly more accurate at detecting salient changes to pictures compared to low vividness participants, replicating an earlier study by Gur and Hilgard (1975). Recently Cui et al. (2007) found that reported image vividness correlates with increased activity in the visual cortex. This study shows that the subjective experience of forming a mental image is reflected by increased visual cortical activity. Logie, Pernet, Buonocore and Della Sala (2011) used behavioural and fMRI data for mental rotation from individuals reporting vivid and poor imagery on the VVIQ. Groups differed in brain activation patterns suggesting that the groups performed the same tasks in different ways. These findings help to explain the lack of association previously reported between VVIQ scores and mental rotation performance. Lee, Kravitz and Baker (2012) used fMRI and multi-voxel pattern analysis to investigate the specificity, distribution, and similarity of information for individual seen and imagined objects. Participants either viewed or imagined individual named object images on which they had been trained prior to the scan. Correlation between fMRI and VVIQ scores showed that, in both object-selective and early visual cortex, Lee et al.'s (2012) measure of discrimination across imagery and perception correlated with the vividness of imagery.",
            "score": 181.63376641273499
        },
        {
            "docid": "25146378_12",
            "document": "Functional specialization (brain) . One of the most well known examples of functional specialization is the fusiform face area (FFA). Justine Sergent was one of the first researchers that brought forth evidence towards the functional neuroanatomy of face processing. Using positron emission tomography (PET), Sergent found that there were different patterns of activation in response to the two different required tasks, face processing verses object processing. These results can be linked with her studies of brain-damaged patients with lesions in the occipital and temporal lobes. Patients revealed that there was an impairment of face processing but no difficulty recognizing everyday objects, a disorder also known as prosopagnosia. Later research by Nancy Kanwisher using functional magnetic resonance imaging (fMRI), found specifically that the region of the inferior temporal cortex, known as the fusiform gyrus, was significantly more active when subjects viewed, recognized and categorized faces in comparison to other regions of the brain. Lesion studies also supported this finding where patients were able to recognize objects but unable to recognize faces. This provided evidence towards domain specificity in the visual system, as Kanwisher acknowledges the Fusiform Face Area as a module in the brain, specifically the extrastriate cortex, that is specialized for face perception.",
            "score": 178.78258895874023
        },
        {
            "docid": "525667_10",
            "document": "Human echolocation . In a 2014 study by Thaler and colleagues, the researchers first made recordings of the clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, not only did they perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. The brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any auditory area, becomes involved in the computation of echolocation tasks.",
            "score": 219.76347422599792
        },
        {
            "docid": "34042719_6",
            "document": "Visual processing abnormalities in schizophrenia . Eye movements are important behaviors for locating and tracking objects in the visual world. Two of the major types of eye movements are saccades and smooth pursuit. Saccades are very rapid and precise eye movements between two positions, and are important in establishing fixation. Smooth pursuit on the other hand, allows the viewer to track a moving object along its trajectory within the visual field. Deficits in eye movement behavior among patients with schizophrenia have been reported since the beginning of the 20th century. Genetic factors are believed to be involved in these abnormalities, as unaffected relatives of schizophrenia patients show similar dysfunction. Specifically, saccade abnormalities have been observed in this disorder, with patients showing changes in saccade rate, amplitude and accuracy. Such deficits have been linked to medication with lithium, as well as damage in frontal lobe regions. Further, patients with schizophrenia often exhibit errors in smooth pursuit eye movements. The neural correlates of smooth pursuit behavior in schizophrenia have been studied using functional Magnetic Resonance Imaging (fMRI), with abnormal activation having been observed in multiple cortical regions implicated in motion processing, such as Frontal Eye Fields and area MT. Some have speculated that errors in smooth pursuit in this disorder may depend on deficits in frontal lobe processing, such as errors in anticipating the direction of stimulus motion, and that this in turn may be consistent with working memory deficits in schizophrenia. Others have disputed this claim, presenting evidence instead pointing to the aforementioned deficits in motion processing, and abnormalities in cortical area MT as a possible source of smooth pursuit errors. In this experiment, it was found that motion perception and smooth pursuit task performance were correlated, but no relationship between measures of smooth pursuit and attention was observed.",
            "score": 132.38107240200043
        },
        {
            "docid": "4455796_9",
            "document": "Lateral inhibition . Sensory information collected by the peripheral nervous system is transmitted to specific areas of the primary somatosensory area in the parietal cortex according to its origin on any given part of the body. For each neuron in the primary somatosensory area, there is a corresponding region of the skin that is stimulated or inhibited by that neuron. The regions that correspond to a location on the somatosensory cortex are mapped by a homonculus. This corresponding region of the skin is referred to as the neuron's receptive field. The most sensitive regions of the body have the greatest representation in any given cortical area, but they also have the smallest receptive fields. The lips, tongue, and fingers are examples of this phenomenon. Each receptive field is composed of two regions: a central excitatory region and a peripheral inhibitory region. One entire receptive field can overlap with other receptive fields, making it difficult to differentiate between stimulation locations, but lateral inhibition helps to reduce that overlap. When an area of the skin is touched, the central excitatory region activates and the peripheral region is inhibited, creating a contrast in sensation and allowing sensory precision. The person can then pinpoint exactly which part of the skin is being touched. In the face of inhibition, only the neurons that are most stimulated and least inhibited will fire, so the firing pattern tends to concentrate at stimulus peaks. This ability becomes less precise as stimulation moves from areas with small receptive fields to larger receptive fields, e.g. moving from the fingertips to the forearm to the upper arm.",
            "score": 112.14172160625458
        },
        {
            "docid": "34045015_18",
            "document": "History of pain theory . The use of fMRI to study brain activity confirms the link between visual perception and pain perception. It has been found that the brain regions that convey the perception of pain are the same regions that encode the size of visual inputs. One specific area, the magnitude-related insula of the insular cortex, functions to perceive the size of a visual stimulation and integrate the concept of that size across various sensory systems, including the perception of pain. This area also overlaps with the nociceptive-specific insula, part of the insula that selectively processes nociception, leading to the conclusion that there is an interaction and interface between the two areas. This interaction tells the individual how much relative pain they are experiencing, leading to the subjective perception of pain based on the current visual stimulus.",
            "score": 195.1110064983368
        },
        {
            "docid": "11068276_12",
            "document": "Vividness of Visual Imagery Questionnaire . However, the distribution of object information across visual areas was strikingly different during imagery and perception. While there was an obvious posterior\u2013anterior gradient along the ventral visual stream for seen objects, there was an opposite gradient for imagined objects. Correlation between fMRI and VVIQ scores showed that, in both object-selective and early visual cortex, Lee et al.'s (2012) measure of discrimination across imagery and perception correlated with the vividness of imagery. These results suggest that, while imagery and perception have similar neural substrates, they involve different network dynamics.",
            "score": 164.82730078697205
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 206.96646189689636
        },
        {
            "docid": "6082997_22",
            "document": "Filling-in . The neuronal activity in different brain areas can be recorded in humans through non-invasive techniques, like fMRI (functional magnetic resonance imaging). Perna \"et al.\" (2005) used fMRI to investigate the neuronal mechanisms responsible for the Craik\u2013O'Brien\u2013Cornsweet illusion. These authors recorded the activity in different brain areas when observers were presented with a Cornsweet visual stimulus, and compared the activities with those elicited by a similar image, which however did not elicit any brightness filling-in.",
            "score": 165.08712768554688
        },
        {
            "docid": "58686_30",
            "document": "Cerebral cortex . The sensory areas are the cortical areas that receive and process information from the senses. Parts of the cortex that receive sensory inputs from the thalamus are called primary sensory areas. The senses of vision, audition, and touch are served by the primary visual cortex, primary auditory cortex and primary somatosensory cortex respectively. In general, the two hemispheres receive information from the opposite (contralateral) side of the body. For example, the right primary somatosensory cortex receives information from the left limbs, and the right visual cortex receives information from the left visual field. The organization of sensory maps in the cortex reflects that of the corresponding sensing organ, in what is known as a topographic map. Neighboring points in the primary visual cortex, for example, correspond to neighboring points in the retina. This topographic map is called a retinotopic map. In the same way, there exists a tonotopic map in the primary auditory cortex and a somatotopic map in the primary sensory cortex. This last topographic map of the body onto the posterior central gyrus has been illustrated as a deformed human representation, the somatosensory homunculus, where the size of different body parts reflects the relative density of their innervation. Areas with lots of sensory innervation, such as the fingertips and the lips, require more cortical area to process finer sensation.",
            "score": 206.8485984802246
        },
        {
            "docid": "179092_3",
            "document": "Neurolinguistics . Neurolinguistics is historically rooted in the development in the 19th century of aphasiology, the study of linguistic deficits (aphasias) occurring as the result of brain damage. Aphasiology attempts to correlate structure to function by analyzing the effect of brain injuries on language processing. One of the first people to draw a connection between a particular brain area and language processing was Paul Broca, a French surgeon who conducted autopsies on numerous individuals who had speaking deficiencies, and found that most of them had brain damage (or \"lesions\") on the left frontal lobe, in an area now known as Broca's area. Phrenologists had made the claim in the early 19th century that different brain regions carried out different functions and that language was mostly controlled by the frontal regions of the brain, but Broca's research was possibly the first to offer empirical evidence for such a relationship, and has been described as \"epoch-making\" and \"pivotal\" to the fields of neurolinguistics and cognitive science. Later, Carl Wernicke, after whom Wernicke's area is named, proposed that different areas of the brain were specialized for different linguistic tasks, with Broca's area handling the motor production of speech, and Wernicke's area handling auditory speech comprehension. The work of Broca and Wernicke established the field of aphasiology and the idea that language can be studied through examining physical characteristics of the brain. Early work in aphasiology also benefited from the early twentieth-century work of Korbinian Brodmann, who \"mapped\" the surface of the brain, dividing it up into numbered areas based on each area's cytoarchitecture (cell structure) and function; these areas, known as Brodmann areas, are still widely used in neuroscience today.",
            "score": 124.54936516284943
        },
        {
            "docid": "51247656_2",
            "document": "Cortical patterning . Cortical patterning is a field of developmental neuroscience which aims to determine how the various functional areas of the cerebral cortex are generated, what size and shape they will be, and how their spatial pattern across the surface of the cortex is specified. Early brain lesion studies indicated that different parts of the cortex served different cognitive functions, such as visual, somatosensory, and motor functions, beautifully assimilated by Brodmann in 1909. Today the field supports the idea of a 'protomap', which is a molecular pre-pattern of the cortical areas during early embryonic stages. The protomap is a feature of the cortical ventricular zone, which contains the primary stem cells of the cortex known as radial glial cells. A system of signaling centers, positioned strategically at the midline and edges of the cortex, produce secreted signaling proteins that establish concentration gradients in the cortical primordium. This provides positional information for each stem cell, and regulates proliferation, neurogenesis, and areal identity. After the initial establishment of areal identity, axons from the developing thalamus arrive at their correct cortical areal destination through the process of axon guidance and begin to form synapses. Many activity-dependent processes are then thought to play important roles in the maturation of each area.",
            "score": 191.69197249412537
        },
        {
            "docid": "29354346_7",
            "document": "Change deafness . One study used fMRI data to distinguish neural correlates of physical changes in auditory input (independent of conscious change detection), from those of conscious perception of change (independent of an actual physical change). The study made use of a change deafness paradigm in which participants were exposed to complex auditory scenes consisting of six individual auditory streams differing in pitch, rhythm, and sound source location, and received a cue indicating which stream to attend to. Each participant listened to two consecutively presented auditory scenes after which they were prompted to indicate whether both scenes were identical or not. Functional MRI results revealed that physical change in stimulus was correlated with increased BOLD responses in the right auditory cortex, near the lateral portion of Heschl's gyrus, the first cortical structure to process incoming auditory information, but not in hierarchically higher brain regions. Conscious change detection was correlated with increased coupled responses in the ACC and the right insula, consistent with additional evidence that the anterior insula functions to mediate dynamic interactions between other brain networks involved in attention to external stimuli, forming a salience network with the ACC that identifies salient stimulus events and initiates additional processing. In absence of change detection, this salience network was not activated; however increased activity in other cortical areas suggests that undetected changes are still perceived on some level, but fail to trigger conscious change detection, thus producing the change deafness phenomenon.",
            "score": 109.61998617649078
        },
        {
            "docid": "4236583_34",
            "document": "Visual search . Studies have consistently shown that autistic individuals performed better and with lower reaction times in feature and conjunctive visual search tasks than matched controls without autism. Several explanations for these observations have been suggested. One possibility is that people with autism have enhanced perceptual capacity. This means that autistic individuals are able to process larger amounts of perceptual information, allowing for superior parallel processing and hence faster target location. Second, autistic individuals show superior performance in discrimination tasks between similar stimuli and therefore may have an enhanced ability to differentiate between items in the visual search display. A third suggestion is that autistic individuals may have stronger top-down target excitation processing and stronger distractor inhibition processing than controls. Keehn et al. (2008) used an event-related functional magnetic resonance imaging design to study the neurofunctional correlates of visual search in autistic children and matched controls of typically developing children. Autistic children showed superior search efficiency and increased neural activation patterns in the frontal, parietal, and occipital lobes when compared to the typically developing children. Thus, autistic individuals' superior performance on visual search tasks may be due to enhanced discrimination of items on the display, which is associated with occipital activity, and increased top-down shifts of visual attention, which is associated with the frontal and parietal areas.",
            "score": 151.9001442193985
        },
        {
            "docid": "2630160_23",
            "document": "Visual angle . The observers in Murray 'et al.'s' experiment viewed a flat picture with two discs that subtended the same visual angle formula_10 and formed retinal images of the same size formula_19, but the perceived angular size formula_34 of one was about 17% larger than for the other, due to differences in the background patterns for the disks. It was shown that the areas of the activity in V1 related to the disks were of unequal size, despite the fact that the retinal images were the same size. This size difference in area V1 correlated with the 17% illusory difference between the perceived visual angles. This finding has implications for spatial illusions such as the visual angle illusion.",
            "score": 155.86083269119263
        },
        {
            "docid": "53953041_15",
            "document": "Predictive coding . The empirical evidence for predictive coding is most robust for perceptual processing. As early as 1999, Rao and Ballard proposed a hierarchical visual processing model in which higher-order visual cortical area sends down predictions and the feedforward connections carry the residual errors between the predictions and the actual lower-level activities (Rao and Ballard, 1999). According to this model, each level in the hierarchical model network (except the lowest level, which represents the image) attempts to predict the responses at the next lower level via feedback connections, and the error signal is used to correct the estimate of the input signal at each level concurrently (Rao and Ballard, 1999). Emberson et al. established the top-down modulation in infants using a cross-modal audiovisual omission paradigm, determining that even infant brains have expectation about future sensory input that is carried downstream from visual cortices and are capable of expectation-based feedback (Emberson et al., 2015). Functional near-infrared spectroscopy (fNIRS) data showed that infant occipital cortex responded to unexpected visual omission (with no visual information input) but not to expected visual omission. These results establish that in a hierarchically organized perception system, higher-order neurons send down predictions to lower-order neurons, which in turn sends back up the prediction error signal.",
            "score": 172.4526046514511
        }
    ],
    "r": [
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 255.9659881591797
        },
        {
            "docid": "305136_32",
            "document": "Visual system . The visual cortex is the largest system in the human brain and is responsible for processing the visual image. It lies at the rear of the brain (highlighted in the image), above the cerebellum. The region that receives information directly from the LGN is called the primary visual cortex, (also called V1 and striate cortex). Visual information then flows through a cortical hierarchy. These areas include V2, V3, V4 and area V5/MT (the exact connectivity depends on the species of the animal). These secondary visual areas (collectively termed the extrastriate visual cortex) process a wide variety of visual primitives. Neurons in V1 and V2 respond selectively to bars of specific orientations, or combinations of bars. These are believed to support edge and corner detection. Similarly, basic information about color and motion is processed here.",
            "score": 223.20306396484375
        },
        {
            "docid": "525667_10",
            "document": "Human echolocation . In a 2014 study by Thaler and colleagues, the researchers first made recordings of the clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, not only did they perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. The brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any auditory area, becomes involved in the computation of echolocation tasks.",
            "score": 219.7634735107422
        },
        {
            "docid": "176997_20",
            "document": "Blindsight . The discovery of the condition known as blindsight raised questions about how different types of visual information, even unconscious information, may be affected and sometimes even unaffected by damage to different areas of the visual cortex. Previous studies had already demonstrated that even without conscious awareness of visual stimuli that humans could still determine certain visual features such as presence in the visual field, shape, orientation and movement. But, in a newer study evidence showed that if the damage to the visual cortex occurs in areas above the primary visual cortex the conscious awareness of visual stimuli itself is not damaged. Blindsight is a phenomenon that shows that even when the primary visual cortex is damaged or removed a person can still perform actions guided by unconscious visual information. So even when damage occurs in the area necessary for conscious awareness of visual information, other functions of the processing of these visual percepts are still available to the individual. The same also goes for damage to other areas of the visual cortex. If an area of the cortex that is responsible for a certain function is damaged, it will only result in the loss of that particular function or aspect, functions that other parts of the visual cortex are responsible for remain intact.",
            "score": 214.6151580810547
        },
        {
            "docid": "599917_9",
            "document": "Mental image . The biological foundation of the mind's eye is not fully understood. Studies using fMRI have shown that the lateral geniculate nucleus and the V1 area of the visual cortex are activated during mental imagery tasks. Ratey writes: The visual pathway is not a one-way street. Higher areas of the brain can also send visual input back to neurons in lower areas of the visual cortex. [...] As humans, we have the ability to see with the mind's eye \u2013 to have a perceptual experience in the absence of visual input. For example, PET scans have shown that when subjects, seated in a room, imagine they are at their front door starting to walk either to the left or right, activation begins in the visual association cortex, the parietal cortex, and the prefrontal cortex - all higher cognitive processing centers of the brain.",
            "score": 214.5450897216797
        },
        {
            "docid": "4231622_5",
            "document": "Inferior temporal gyrus . The temporal lobe is unique to primates. In humans, the IT cortex is more complex than their relative primate counterparts. The human inferior temporal cortex consists of the inferior temporal gyrus, the middle temporal gyrus, and the fusiform gyrus. When looking at the brain laterally \u2013 that is from the side and looking at the surface of the temporal lobe \u2013 the inferior temporal gyrus is along the bottom portion of the temporal lobe, and is separated from the middle temporal gyrus located directly above by the inferior temporal sulcus. Additionally, some processing of the visual field that corresponds to the ventral stream of visual processing occurs in the lower portion of the superior temporal gyrus closest to the superior temporal sulcus. The medial and ventral view of the brain \u2013 meaning looking at the medial surface from below the brain, facing upwards \u2013 reveals that the inferior temporal gyrus is separated from the fusiform gyrus by the occipital-temporal sulcus. This human inferior temporal cortex is much more complex than that of other primates: non-human primates have an inferior temporal cortex that is not divided into unique regions such as humans' inferior temporal gyrus, fusiform gyrus, or middle temporal gyrus.  This region of the brain corresponds to the inferior temporal cortex and is responsible for visual object recognition and receives processed visual information. The inferior temporal cortex in primates has specific regions dedicated to processing different visual stimuli processed and organized by the different layers of the striate cortex and extra-striate cortex. The information from the V1 \u2013V5 regions of the geniculate and tectopulvinar pathways are radiated to the IT cortex via the ventral stream: visual information specifically related to the color and form of the visual stimuli. Through comparative research between primates \u2013 humans and non-human primates \u2013 results indicate that the IT cortex plays a significant role in visual shape processing. This is supported by functional magnetic resonance imaging (fMRI) data collected by researchers comparing this neurological process between humans and macaques.",
            "score": 212.76712036132812
        },
        {
            "docid": "23483_5",
            "document": "Philosophy of perception . An object at some distance from an observer will reflect light in all directions, some of which will fall upon the corneae of the eyes, where it will be focussed upon each retina, forming an image. The disparity between the electrical output of these two slightly different images is resolved either at the level of the lateral geniculate nucleus or in a part of the visual cortex called 'V1'. The resolved data is further processed in the visual cortex where some areas have specialised functions, for instance area V5 is involved in the modelling of motion and V4 in adding colour. The resulting single image that subjects report as their experience is called a 'percept'. Studies involving rapidly changing scenes show the percept derives from numerous processes that involve time delays. Recent fMRI studies show that dreams, imaginings and perceptions of things such as faces are accompanied by activity in many of the same areas of brain as are involved with physical sight. Imagery that originates from the senses and internally generated imagery may have a shared ontology at higher levels of cortical processing.",
            "score": 212.38059997558594
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 211.0655517578125
        },
        {
            "docid": "176997_27",
            "document": "Blindsight . Visual processing in the brain goes through a series of stages. Destruction of the primary visual cortex leads to blindness in the part of the visual field that corresponds to the damaged cortical representation. The area of blindness \u2013 known as a scotoma \u2013 is in the visual field opposite the damaged hemisphere and can vary from a small area up to the entire hemifield. Visual processing occurs in the brain in a hierarchical series of stages (with much crosstalk and feedback between areas). The route from the retina through V1 is not the only visual pathway into the cortex, though it is by far the largest; it is commonly thought that the residual performance of people exhibiting blindsight is due to preserved pathways into the extrastriate cortex that bypass V1. What is surprising is that activity in these extrastriate areas is apparently insufficient to support visual awareness in the absence of V1.",
            "score": 210.63429260253906
        },
        {
            "docid": "2685232_2",
            "document": "Cortical magnification . Cortical magnification describes how many neurons in an area of the visual cortex are 'responsible' for processing a stimulus of a given size, as a function of visual field location. In the center of the visual field, corresponding to the center of the fovea of the retina, a very large number of neurons process information from a small region of the visual field. If the same stimulus is seen in the periphery of the visual field (i.e. away from the center), it would be processed by a much smaller number of neurons. The reduction of the number of neurons per visual field area from foveal to peripheral representations is achieved in several steps along the visual pathway, starting already in the retina.",
            "score": 209.9868927001953
        },
        {
            "docid": "1038040_3",
            "document": "Semir Zeki . Zeki's early work was mainly anatomical in nature and consisted in charting visual areas in the primate (monkey) brain by studying their connections, leading him to define several visual areas lying anterior to the primary visual cortex (area V1) of the brain. This was followed by recording from single cells in these areas, which led him to the view (a) that there is a functional specialisation in the visual cortex, with different visual areas undertaking different visual tasks, such as the processing of colour, motion and form and (b) that the visual brain processes these different attributes in parallel.",
            "score": 209.6190948486328
        },
        {
            "docid": "4231622_9",
            "document": "Inferior temporal gyrus . These areas must all work together, as well as with the hippocampus, in order to create an array of understanding of the physical world. The hippocampus is key for storing the memory of what an object is/what it looks like for future use so that it can be compared and contrasted with other objects. Correctly being able to recognize an object is highly dependent on this organized network of brain areas that process, share, and store information. In a study by Denys et al., functional magnetic resonance imaging (FMRI) was used to compare the processing of visual shape between humans and macaques. They found, amongst other things, that there was a degree of overlap between shape and motion sensitive regions of the cortex, but that the overlap was more distinct in humans. This would suggest that the human brain is better evolved for a high level of functioning in a distinct, three-dimensional, visual world.",
            "score": 208.01776123046875
        },
        {
            "docid": "5212945_2",
            "document": "Visual neuroscience . Visual Neuroscience is a branch of neuroscience that focuses on the visual system of the human body, mainly located in the brain's visual cortex. The main goal of visual neuroscience is to understand how neural activity results in visual perception, as well as behaviors dependent on vision. In the past, visual neuroscience has focused primarily on how the brain (and in particular the Visual Cortex) responds to light rays projected from static images and onto the retina. While this provides a reasonable explanation for the visual perception of a static image, it does not provide an accurate explanation for how we perceive the world as it really is, an ever-changing, and ever-moving 3-D environment. The topics summarized below are representative of this area, but far from exhaustive.",
            "score": 207.30613708496094
        },
        {
            "docid": "490620_10",
            "document": "Human brain . The cortex is mapped by divisions into about fifty different functional areas known as Brodmann's areas. These areas are distinctly different when seen under a microscope. The cortex is divided into two main functional areas \u2013 a motor cortex and a sensory cortex. The primary motor cortex, which sends axons down to motor neurons in the brainstem and spinal cord, occupies the rear portion of the frontal lobe, directly in front of the somatosensory area. The primary sensory areas receive signals from the sensory nerves and tracts by way of relay nuclei in the thalamus. Primary sensory areas include the visual cortex of the occipital lobe, the auditory cortex in parts of the temporal lobe and insular cortex, and the somatosensory cortex in the parietal lobe. The remaining parts of the cortex, are called the association areas. These areas receive input from the sensory areas and lower parts of the brain and are involved in the complex cognitive processes of perception, thought, and decision-making. The main functions of the frontal lobe are to control attention, abstract thinking, behaviour, problem solving tasks, and physical reactions and personality. The occipital lobe is the smallest lobe; its main functions are visual reception, visual-spatial processing, movement, and colour recognition. There is a smaller occipital lobule in the lobe known as the cuneus. The temporal lobe controls auditory and visual memories, language, and some hearing and speech.",
            "score": 207.1466827392578
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 206.96646118164062
        },
        {
            "docid": "58686_30",
            "document": "Cerebral cortex . The sensory areas are the cortical areas that receive and process information from the senses. Parts of the cortex that receive sensory inputs from the thalamus are called primary sensory areas. The senses of vision, audition, and touch are served by the primary visual cortex, primary auditory cortex and primary somatosensory cortex respectively. In general, the two hemispheres receive information from the opposite (contralateral) side of the body. For example, the right primary somatosensory cortex receives information from the left limbs, and the right visual cortex receives information from the left visual field. The organization of sensory maps in the cortex reflects that of the corresponding sensing organ, in what is known as a topographic map. Neighboring points in the primary visual cortex, for example, correspond to neighboring points in the retina. This topographic map is called a retinotopic map. In the same way, there exists a tonotopic map in the primary auditory cortex and a somatotopic map in the primary sensory cortex. This last topographic map of the body onto the posterior central gyrus has been illustrated as a deformed human representation, the somatosensory homunculus, where the size of different body parts reflects the relative density of their innervation. Areas with lots of sensory innervation, such as the fingertips and the lips, require more cortical area to process finer sensation.",
            "score": 206.84860229492188
        },
        {
            "docid": "15559385_11",
            "document": "Tactile discrimination . When a person has become blind, in order to \u201csee\u201d the world, their other senses become heightened. An important sense for the blind is their sense of touch, which becomes more frequently used to help them perceive the world. People that are blind have displayed that their visual cortices become more responsive to auditory and tactile stimulation. Braille allows the blind to be able to use their sense of touch to feel the roughness, and distance of various patterns to be used as a form of language. Within the brain, the activation of the occipital cortex is functionally relevant for tactile braille reading, as well as the somatosensory cortex. These various parts of the brain function in their own way, in which they each contribute to the effectiveness of how braille is read by the blind. People that are blind also rely heavily on Tactile Gnosis, Spatial discrimination, Graphesthesia, and Two-point discrimination. Essentially, the occipital cortex allows one to effectively make judgements on the distance of braille patterns, which is related to spatial discrimination. Meanwhile, the somatosensory cortex allows one to effectively make judgements on the roughness of braille patterns, which is related to two-point discrimination. The various visual areas in the brain are very essential for a blind person to read braille, just as much as it is for a person that has sight. Essentially, whether one is blind or not, the perception of objects that involves tactile discrimination is not impaired if one cannot see. When comparing people that are blind to people that have sight, the amount of activity within the their somatosensory and visual areas of the brain do differ. The activity in the somatosensory and visual areas are not as high in tactile gnosis for people that are not blind, and are more-so active for more visual related stimuli that does not involve touch. Nonetheless, there is a difference in these various areas within the brain when comparing the blind to the sighted, which is that shape discrimination causes a difference in brain activity, as well as tactile gnosis. The visual cortices of blind individuals are active during various vision related tasks including tactile discrimination, and the function of the cortices resemble the activity of adults with sight.",
            "score": 206.2205047607422
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 205.7028350830078
        },
        {
            "docid": "226722_25",
            "document": "Functional magnetic resonance imaging . Researchers have checked the BOLD signal against both signals from implanted electrodes (mostly in monkeys) and signals of field potentials (that is the electric or magnetic field from the brain's activity, measured outside the skull) from EEG and MEG. The local field potential, which includes both post-neuron-synaptic activity and internal neuron processing, better predicts the BOLD signal. So the BOLD contrast reflects mainly the inputs to a neuron and the neuron's integrative processing within its body, and less the output firing of neurons. In humans, electrodes can be implanted only in patients who need surgery as treatment, but evidence suggests a similar relationship at least for the auditory cortex and the primary visual cortex. Activation locations detected by BOLD fMRI in cortical areas (brain surface regions) are known to tally with CBF-based functional maps from PET scans. Some regions just a few millimeters in size, such as the lateral geniculate nucleus (LGN) of the thalamus, which relays visual inputs from the retina to the visual cortex, have been shown to generate the BOLD signal correctly when presented with visual input. Nearby regions such as the pulvinar nucleus were not stimulated for this task, indicating millimeter resolution for the spatial extent of the BOLD response, at least in thalamic nuclei. In the rat brain, single-whisker touch has been shown to elicit BOLD signals from the somatosensory cortex.",
            "score": 203.7939910888672
        },
        {
            "docid": "2566333_9",
            "document": "Lobes of the brain . The occipital lobe is the visual processing center of the mammalian brain containing most of the anatomical region of the visual cortex. The primary visual cortex is Brodmann area 17, commonly called V1 (visual one). Human V1 is located on the medial side of the occipital lobe within the calcarine sulcus; the full extent of V1 often continues onto the posterior pole of the occipital lobe. V1 is often also called striate cortex because it can be identified by a large stripe of myelin, the Stria of Gennari. Visually driven regions outside V1 are called extrastriate cortex. There are many extrastriate regions, and these are specialized for different visual tasks, such as visuospatial processing, color differentiation, and motion perception.",
            "score": 203.70701599121094
        },
        {
            "docid": "3380919_3",
            "document": "David Heeger . In the fields of perceptual psychology, systems neuroscience, cognitive neuroscience, and computational neuroscience, Heeger has developed computational theories of neuronal processing in the visual system, and he has performed psychophysics (perceptual psychology) and neuroimaging (functional magnetic resonance imaging, fMRI) experiments on human vision. His contributions to computational neuroscience include theories for how the brain can sense optic flow and egomotion, and a theory of neural processing called the normalization model. His empirical research has contributed to our understanding of the topographic organization of visual cortex (retinotopy), visual awareness, visual pattern detection/discrimination, visual motion perception, stereopsis (depth perception), attention, working memory, the control of eye and hand movements, neural processing of complex audio-visual and emotional experiences (movies, music, narrative), abnormal visual processing in dyslexia, and neurophysiological characteristics of autism.",
            "score": 202.8416748046875
        },
        {
            "docid": "305122_13",
            "document": "Peripheral vision . The distinctions between foveal (sometimes also called central) and peripheral vision are reflected in subtle physiological and anatomical differences in the visual cortex. Different visual areas contribute to the processing of visual information coming from different parts of the visual field, and a complex of visual areas located along the banks of the interhemispheric fissure (a deep groove that separates the two brain hemispheres) has been linked to peripheral vision. It has been suggested that these areas are important for fast reactions to visual stimuli in the periphery, and monitoring body position relative to gravity.",
            "score": 202.41915893554688
        },
        {
            "docid": "1903855_7",
            "document": "Sensory substitution . In a regular visual system, the data collected by the retina is converted into an electrical stimulus in the optic nerve and relayed to the brain, which re-creates the image and perceives it. Because it is the brain that is responsible for the final perception, sensory substitution is possible. During sensory substitution an intact sensory modality relays information to the visual perception areas of the brain so that the person can perceive to see. With sensory substitution, information gained from one sensory modality can reach brain structures physiologically related to other sensory modalities. Touch-to-visual sensory substitution transfers information from touch receptors to the visual cortex for interpretation and perception. For example, through fMRI, we can determine which parts of the brain are activated during sensory perception. In blind persons, we can see that while they are only receiving tactile information, their visual cortex is also activated as they perceive to \"see\" objects. We can also have touch to touch sensory substitution where information from touch receptors of one region can be used to perceive touch in another region. For example, in one experiment by Bach-y-Rita, he was able to restore the touch perception in a patient who lost peripheral sensation from leprosy.",
            "score": 201.83560180664062
        },
        {
            "docid": "599917_31",
            "document": "Mental image . As cognitive neuroscience approaches to mental imagery continued, research expanded beyond questions of serial versus parallel or topographic processing to questions of the relationship between mental images and perceptual representations. Both brain imaging (fMRI and ERP) and studies of neuropsychological patients have been used to test the hypothesis that a mental image is the reactivation, from memory, of brain representations normally activated during the perception of an external stimulus. In other words, if perceiving an apple activates contour and location and shape and color representations in the brain\u2019s visual system, then imagining an apple activates some or all of these same representations using information stored in memory. Early evidence for this idea came from neuropsychology. Patients with brain damage that impairs perception in specific ways, for example by damaging shape or color representations, seem to generally to have impaired mental imagery in similar ways. Studies of brain function in normal human brains support this same conclusion, showing activity in the brain\u2019s visual areas while subjects imagined visual objects and scenes.",
            "score": 201.50411987304688
        },
        {
            "docid": "472212_2",
            "document": "Occipital lobe . The occipital lobe is one of the four major lobes of the cerebral cortex in the brain of mammals. The occipital lobe is the visual processing center of the mammalian brain containing most of the anatomical region of the visual cortex. The primary visual cortex is Brodmann area 17, commonly called V1 (visual one). Human V1 is located on the medial side of the occipital lobe within the calcarine sulcus; the full extent of V1 often continues onto the posterior pole of the occipital lobe. V1 is often also called striate cortex because it can be identified by a large stripe of myelin, the Stria of Gennari. Visually driven regions outside V1 are called extrastriate cortex. There are many extrastriate regions, and these are specialized for different visual tasks, such as visuospatial processing, color differentiation, and motion perception. The name derives from the overlying occipital bone, which is named from the Latin ob, \"behind\", and caput, \"the head\". Bilateral lesions of the occipital lobe can lead to cortical blindness (See Anton's syndrome).",
            "score": 199.651611328125
        },
        {
            "docid": "51462681_3",
            "document": "Objective vision . This is the story of what's happening when you see a picture, even too fast, the brain's visual cortex recognizes what it sees immediately. The visual cortex has a critical job in processing and it's the most complex part of brain. The human brain is much more aware of how it solves complex problems such as playing chess or solving algebra equations, which is why computer programmers have had so much success building machines that emulate this type of activity. but when entities visionary system starts to convert the signals to image(actually the separated shapes and colors) to find a relation between brain's information and those images. The system actually is concentrating on the separable sections, this separation gives the brain a visionary system the excellence processing result, because with this method the system do not waste much time on processing non significant sections and signals. this operation in the Objective Vision project called objective processing and because the O.V. mission is around human visionary simulation, so the developer refers with Objective Vision.",
            "score": 199.6311798095703
        },
        {
            "docid": "5664_46",
            "document": "Consciousness . A number of studies have shown that activity in primary sensory areas of the brain is not sufficient to produce consciousness: it is possible for subjects to report a lack of awareness even when areas such as the primary visual cortex show clear electrical responses to a stimulus. Higher brain areas are seen as more promising, especially the prefrontal cortex, which is involved in a range of higher cognitive functions collectively known as executive functions. There is substantial evidence that a \"top-down\" flow of neural activity (i.e., activity propagating from the frontal cortex to sensory areas) is more predictive of conscious awareness than a \"bottom-up\" flow of activity. The prefrontal cortex is not the only candidate area, however: studies by Nikos Logothetis and his colleagues have shown, for example, that visually responsive neurons in parts of the temporal lobe reflect the visual perception in the situation when conflicting visual images are presented to different eyes (i.e., bistable percepts during binocular rivalry).",
            "score": 199.4580535888672
        },
        {
            "docid": "24965027_11",
            "document": "Cognitive neuroscience of visual object recognition . The visual processing of objects in the brain can be divided into two processing pathways: the dorsal stream (how/where), which extends from the visual cortex to the parietal lobes, and ventral stream (what), which extends from the visual cortex to the inferotemporal cortex (IT). The existence of these two separate visual processing pathways was first proposed by Ungerleider and Mishkin (1982) who, based on their lesion studies, suggested that the dorsal stream is involved in the processing of visual spatial information, such as object localization (where), and the ventral stream is involved in the processing of visual object identification information (what). Since this initial proposal, it has been alternatively suggested that the dorsal pathway should be known as the 'How' pathway as the visual spatial information processed here provides us with information about how to interact with objects, For the purpose of object recognition, the neural focus is on the ventral stream.",
            "score": 198.91639709472656
        },
        {
            "docid": "49189913_4",
            "document": "MOVIE Index . The MOVIE index is a neuroscience-based model for predicting the perceptual quality of a (possibly compressed or otherwise distorted) motion picture or video against a pristine reference video. Thus, the MOVIE index is a full-reference metric. The MOVIE model is quite different from many other models since it uses neuroscience-based models of how the human brain processes visual signals at various stages along the visual pathway, including the lateral geniculate nucleus, primary visual cortex, and in the motion-sensitive extrastriate cortex visual area MT.",
            "score": 197.9902801513672
        },
        {
            "docid": "1038040_4",
            "document": "Semir Zeki . He later showed, using brain imaging techniques, that the same principles apply to the organisation of the human visual brain. In recent work he has shown that parallel processing appears to extend beyond the mere processing of visual signals to their grouping in parietal cortex. His work on colour vision was influenced by the work and methods of Edwin H. Land, whose techniques he employed in his physiological and brain imaging experiments, and which led him to the view that colour is constructed by the brain and that a specialised visual area, area V4, is critical to this process.",
            "score": 197.23785400390625
        },
        {
            "docid": "34004373_4",
            "document": "Sensory maps and brain development . The computational map is the \u201ckey building block in the infrastructure of information processing by the nervous system.\u201d Computation defined as the transformation in the representation of information is the essence of brain function. Computational maps are involved in processing sensory information and motor programming, and they contain derived information that is accessible to higher-order processing regions. The first computational map to be proposed was the Jeffress model (1948) which stated that the computation of sound localization was dependent upon timing differences of sensory input. Since the introduction of the Jeffress model, more general guiding principles for relating brain maps to the properties of the computations they perform have been proposed. One of the proposed models is that computations are distributed across parallel processors like computers; with this model, computer processing is a model for computations performed by the brain. More recently, the \u201celastic net\u201d model has been proposed after studying how the primary visual cortex overlaps multiple visual maps, such as visual field position, orientation, direction, ocular dominance, and spatial frequency. The elastic net uses parallel algorithms to analyze the visual field and allows for optimized trade-off between coverage and continuity.",
            "score": 196.62936401367188
        },
        {
            "docid": "599917_34",
            "document": "Mental image . Recent studies have found that individual differences in VVIQ scores can be used to predict changes in a person's brain while visualizing different activities. Functional magnetic resonance imaging (fMRI) was used to study the association between early visual cortex activity relative to the whole brain while participants visualized themselves or another person bench pressing or stair climbing. Reported image vividness correlates significantly with the relative fMRI signal in the visual cortex. Thus, individual differences in the vividness of visual imagery can be measured objectively.",
            "score": 196.47596740722656
        }
    ]
}