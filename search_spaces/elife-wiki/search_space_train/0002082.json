{
    "q": [
        {
            "docid": "25146378_15",
            "document": "Functional specialization (brain) . During the 1960s, Roger Sperry conducted a natural experiment on epileptic patients who had previously had their corpora callosa cut. The corpus callosum is the area of the brain dedicated to linking both the right and left hemisphere together. Sperry et al.'s experiment was based on flashing images in the right and left visual fields of his participants. Because the participant's corpus callosum was cut, the information processed by each visual field could not be transmitted to the other hemisphere. In one experiment, Sperry flashed images in the right visual field (RVF), which would subsequently be transmitted to the left hemisphere (LH) of the brain. When asked to repeat what they had previously seen, participants were fully capable of remembering the image flashed. However, when the participants were then asked to draw what they had seen, they were unable to. When Sperry et al. flashed images in the left visual field (LVF), the information processed would be sent to the right hemisphere (RH) of the brain. When asked to repeat what they had previously seen, participants were unable to recall the image flashed, but were very successful in drawing the image. Therefore, Sperry concluded that the left hemisphere of the brain was dedicated to language as the participants could clearly speak the image flashed. On the other hand, Sperry concluded that the right hemisphere of the brain was involved in more creative activities such as drawing.",
            "score": 140.33890664577484
        },
        {
            "docid": "23416874_29",
            "document": "Sense . Recognition memory is sometimes divided into two functions by neuroscientists: familiarity and recollection. A strong sense of familiarity can occur without any recollection, for example in cases of deja vu. The temporal lobe, in particular the perirhinal cortex, responds differently to stimuli which feel novel than to things which feel familiar. Firing rates in the perirhinal cortex are connected with the sense of familiarity in humans and other mammals. In tests, stimulating this area at 10\u201315\u00a0Hz caused animals to treat even novel images as familiar, and stimulation at 30\u201340\u00a0Hz caused novel images to be partially treated as familiar. Specifically, stimulation at 30\u201340\u00a0Hz led to animals looking at a familiar image for longer periods, as they would for an unfamiliar one; but it did not lead to the same exploration behavior normally associated with novelty. Recent studies on lesions in the area concluded that rats with a damaged perirhinal cortex were still more interested in exploring when novel objects were present, but seemed unable to tell novel objects from familiar ones \u2014 they examined both equally. Thus, other brain regions are involved with noticing unfamiliarity, but the perirhinal cortex is needed to associate the feeling with a specific source.",
            "score": 153.45553421974182
        },
        {
            "docid": "739262_12",
            "document": "Neural correlate . Using such design, Nikos Logothetis and colleagues discovered perception-reflecting neurons in the temporal lobe. They created an experimental situation in which conflicting images were presented to different eyes (\"i.e.\", binocular rivalry). Under such conditions, human subjects report bistable percepts: they perceive alternatively one or the other image. Logothetis and colleagues trained the monkeys to report with their arm movements which image they perceived. Interestingly, temporal lobe neurons in Logothetis experiments often reflected what the monkeys' perceived. Neurons with such properties were less frequently observed in the primary visual cortex that corresponds to relatively early stages of visual processing. Another set of experiments using binocular rivalry in humans showed that certain layers of the cortex can be excluded as candidates of the neural correlate of consciousness. Logothetis and colleagues switched the images between eyes during the percept of one of the images. Surprisingly the percept stayed stable. This means that the conscious percept stayed stable and at the same time the primary input to layer 4, which is the input layer, in the visual cortex changed. Therefore layer 4 can not be a part of the neural correlate of consciousness. Mikhail Lebedev and their colleagues observed a similar phenomenon in monkey prefrontal cortex. In their experiments monkeys reported the perceived direction of visual stimulus movement (which could be an illusion) by making eye movements. Some prefrontal cortex neurons represented actual and some represented perceived displacements of the stimulus. Observation of perception related neurons in prefrontal cortex is consistent with the theory of Christof Koch and Francis Crick who postulated that neural correlate of consciousness resides in prefrontal cortex. Proponents of distributed neuronal processing may likely dispute the view that consciousness has a precise localization in the brain.",
            "score": 183.58499228954315
        },
        {
            "docid": "2727254_7",
            "document": "Mnemonist . The method of loci is \"the use of an orderly arrangement of locations into which one could place the images of things or people that are to be remembered\". The encoding process happens in three steps. First, an architectural area, such as the houses on a street, must be memorized. Second, each item to be remembered must be associated with a separate image. Finally, this set of images can be distributed in a \"locus,\" or place within the architectural area in a pre-determined order. Then, as one tries to recall the information, the mnemonists simply has to \"walk\" down the street, see each symbol, and recall the associated information. An example of mnemonists who used this is Solomon Shereshevsky; he would use Gorky Street, a street he lived on. When he read, each word would form a graphic image. He would then place this image in a place along the street; later, when he needed to recall the information, he would simply \"stroll\" down the street again to recall the necessary information. Neuroimaging studies have shown results that support the method of loci as the retrieval method in world-class memory performers. An fMRI recorded brain activity in memory experts and a control group as they were memorizing selected data. Previous studies have shown that teaching a control group the method of loci leads to changes in brain activation during memorization. Consistent with their use of the method of loci, memory experts had higher activity in the medial parietal cortex, retrospenial cortex, and right posterior hippocampus; these brain areas have been linked to spatial memory and navigation. These differences were observable even when the memory experts were trying to memorize stimuli, such as snowflakes, where they showed no superior ability to the control group.",
            "score": 155.89268290996552
        },
        {
            "docid": "1841851_20",
            "document": "Stereopsis . In the 1960s, Bela Julesz invented random-dot stereograms. Unlike previous stereograms, in which each half image showed recognizable objects, each half image of the first random-dot stereograms showed a square matrix of about 10,000 small dots, with each dot having a 50% probability of being black or white. No recognizable objects could be seen in either half image. The two half images of a random-dot stereogram were essentially identical, except that one had a square area of dots shifted horizontally by one or two dot diameters, giving horizontal disparity. The gap left by the shifting was filled in with new random dots, hiding the shifted square. Nevertheless, when the two half images were viewed one to each eye, the square area was almost immediately visible by being closer or farther than the background. Julesz whimsically called the square a Cyclopean image after the mythical Cyclops who had only one eye. This was because it was as though we have a cyclopean eye inside our brains that can see cyclopean stimuli hidden to each of our actual eyes. Random-dot stereograms highlighted a problem for stereopsis, the correspondence problem. This is that any dot in one half image can realistically be paired with many same-coloured dots in the other half image. Our visual systems clearly solve the correspondence problem, in that we see the intended depth instead of a fog of false matches. Research began to understand how.",
            "score": 124.26068389415741
        },
        {
            "docid": "33702464_5",
            "document": "Extrastriate body area . The experiment had subjects view images of different objects, including faces (as a control group), body parts, animals, parts of the face and intimate objects. While viewing the images, the subjects were scanned with an fMRI to see what area of the brain was activated. Through the trials a compilation of the fMRI\u2019s was made. From this compilation image a specific region was determined to have increased activity when shown visual stimuli of body parts and even more activity when viewing whole bodies. There have been no studies involving brain damage to the EBA. Thus far, only scans of brain activity, as well as transcranial magnetic stimulation, have been used to study the EBA. To find the specific functions of the EBA, Comimo Urgesi, Giovanni Berlucchi and Salvatore M. Aglioti used repetitive transcranial magnetic stimulation (rTMS) to disrupt part of the brain, making the brain less responsive in the target area. The study used event-related rTMS to disrupt the EBA, resulting in inactivation of cortical areas. This inactivation caused a slower response time in discriminating body parts. The study used facial features and motorcycle parts as non human parts for control groups. The facial features and motorcycle body parts did not display any change in response time. The neural activity data shows the EBA handles some of the visual processing of human body and parts but is not related to the processing of the face or other objects.",
            "score": 129.83705008029938
        },
        {
            "docid": "4087208_12",
            "document": "David Marks (psychologist) . Rodway, Gillies and Schepman (2006) found that high vividness participants were significantly more accurate at detecting salient changes to pictures compared to low vividness participants, replicating an earlier study by Gur and Hilgard (1975). Recently Cui et al. (2007) found that reported image vividness correlates with increased activity in the visual cortex. This study shows that the subjective experience of forming a mental image is reflected by increased visual cortical activity. Logie, Pernet, Buonocore and Della Sala (2011) used behavioural and fMRI data for mental rotation from individuals reporting vivid and poor imagery on the VVIQ. Groups differed in brain activation patterns suggesting that the groups performed the same tasks in different ways. These findings help to explain the lack of association previously reported between VVIQ scores and mental rotation performance. Lee, Kravitz and Baker (2012) used fMRI and multi-voxel pattern analysis to investigate the specificity, distribution, and similarity of information for individual seen and imagined objects. Participants either viewed or imagined individual named object images on which they had been trained prior to the scan. Correlation between fMRI and VVIQ scores showed that, in both object-selective and early visual cortex, Lee et al.'s (2012) measure of discrimination across imagery and perception correlated with the vividness of imagery.",
            "score": 132.8687391281128
        },
        {
            "docid": "35543733_7",
            "document": "Bilingual lexicon . With years of researches, how languages are stored and processed by bilinguals is still a main theme that many psycholinguists. One main topic is that bilinguals possess one or two internal lexicons, and even more with three stores. One for each language and the third one is for corresponding two languages. Reaction time of recognizing words in different languages is the most used method to figure out how our lexicon been activated. Researches in 1980s by Soares and Grosjean on English-Portuguese bilingual had two main findings. One is that although bilingual can access real words in English as quickly as English monolinguals, but they are slower at responding to non-words. The other finding is that bilingual took longer to access code-switched words than they did base-language words in the monolingual mode. These two findings can be seen as the evidence for more than one lexicon are existed in bilinguals' brains. As technology develops, functional magnetic resonance imaging (fMRI) is also used to study how brain activity is different in bilinguals' brain when both language are interact. Imaging studies have yielded that specific brain areas are involved in bilingual switching, which means this part of the brain can be said as the \"third lexicon\", the interconnected part of two lexicons for each language, where stores the guest words. Other research suggests only one combined lexicon is exists.",
            "score": 97.02209627628326
        },
        {
            "docid": "18345264_14",
            "document": "Neural correlates of consciousness . Logothetis and colleagues recorded a variety of visual cortical areas in awake macaque monkeys performing a binocular rivalry task. Macaque monkeys can be trained to report whether they see the left or the right image. The distribution of the switching times and the way in which changing the contrast in one eye affects these leaves little doubt that monkeys and humans experience the same basic phenomenon. In the primary visual cortex (V1) only a small fraction of cells weakly modulated their response as a function of the percept of the monkey while most cells responded to one or the other retinal stimulus with little regard to what the animal perceived at the time. But in a high-level cortical area such as the inferior temporal cortex along the ventral stream almost all neurons responded only to the perceptually dominant stimulus, so that a \"face\" cell only fired when the animal indicated that it saw the face and not the pattern presented to the other eye. This implies that NCC involve neurons active in the inferior temporal cortex: it is likely that specific reciprocal actions of neurons in the inferior temporal and parts of the prefrontal cortex are necessary.",
            "score": 157.89467477798462
        },
        {
            "docid": "3883287_8",
            "document": "Tranquillity . Within tranquillity studies, much of the emphasis has been placed on understanding the role of vision in the perception of natural environments, which is probably not surprising, considering that upon first viewing a scene its configurational coherence can be established with incredible speed. Indeed, scene information can be captured in a single glance and the gist of a scene determined in as little as 100ms. The speed of processing of complex natural images was tested by Thorpe \"et al.\" using colour photographs of a wide range of animals (mammals, birds, reptiles and fish), in their natural environments, mixed with distracters that included pictures of forests, mountains, lakes, buildings and fruit. During this experiment, subjects were shown an image for 20ms and asked to determine whether it contained an animal or not. The electrophysiological brain responses obtained in this study showed that a decision could be made within 150ms of the image being seen, indicating the speed at which cognitive visual processing occurs. However, audition, and in particular the individual components that collectively comprise the soundscape, a term coined by Schafer to describe the ever-present array of sounds that constitute the sonic environment, also significantly inform the various schemata used to characterise differing landscape types. This interpretation is supported by the auditory reaction times, which are 50 to 60ms faster than that of the visual modality. It is also known that sound can alter visual perception and that under certain conditions areas of the brain involved in processing auditory information can be activated in response to visual stimuli.  Research conducted by Pheasant \"et al.\" has shown that when individuals make tranquillity assessments based on a uni-modal auditory or visual sensory input, they characterise the environment by drawing upon a number of key landscape and soundscape characteristics. For example, when making assessments in response to visual-only stimuli the percentage of water, flora and geological features present within a scene, positively influence how tranquil a location is perceived to be. Likewise when responding to uni-modal auditory stimuli, the perceived loudness of biological sounds positively influences the perception of tranquillity, whilst the perceived loudness of mechanical sounds have a negative effect. However, when presented with bi-modal auditory-visual stimuli the individual soundscape and landscape components alone no longer influenced the perception of tranquillity. Rather configurational coherence was provided by the percentage of natural and contextual features present within the scene and the equivalent continuous sound pressure level (LAeq).",
            "score": 130.61465203762054
        },
        {
            "docid": "9325864_16",
            "document": "Imagination . Memory and mental imagery, often seen as a part of the process of imagination, have been shown to be affected by one another. \"Images made by functional magnetic resonance imaging technology show that remembering and imagining sends blood to identical parts of the brain.\" Various psychological factors can influence the mental processing of and can heighten the chance of the brain to retain information as either long-term memories or short-term memories. John Sweller indicated that experiences stored as long-term memories are easier to recall, as they are ingrained deeper in the mind. Each of these forms require information to be taught in a specific manner so as to use various regions of the brain when being processed. This information can potentially help develop programs for young students to cultivate or further enhance their creative abilities from a young age. The neocortex and thalamus are responsible for controlling the brain's imagination, along with many of the brain's other functions such as consciousness and abstract thought. Since imagination involves many different brain functions, such as emotions, memory, thoughts, etc., portions of the brain where multiple functions occur\u2014such as the thalamus and neocortex\u2014are the main regions where imaginative processing has been documented. The understanding of \"how\" memory and imagination are linked in the brain, paves the way to better understand one's ability to link significant past experiences with their imagination.",
            "score": 151.6304031610489
        },
        {
            "docid": "26685721_34",
            "document": "Methods used to study memory . In experiments with the macaque monkey, Earl Miller and his colleagues used the delayed matching to sample (DMS) task to assess working memory in monkeys. The monkey was required to fixate on a computer screen while coloured images were displayed serially for 0.5\u00a0seconds, and separated by a one-second delay. The first image shown was the sample, and the monkey was trained to pull a lever when the sample object was shown a second time. In this experiment single-cell recordings were taken from the prefrontal cortex, an area thought to be involved with working memory. In order to verify the location of the recording device, MRI and stereotaxic instruments were used. The ability to use single cell recordings solely for experimental purposes is exclusive to animal testing and has greatly increased our understanding of memory systems.",
            "score": 138.58257675170898
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 229.57549560070038
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 183.49670016765594
        },
        {
            "docid": "24965027_8",
            "document": "Cognitive neuroscience of visual object recognition . This model, proposed by Marr and Nishihara (1978), states that object recognition is achieved by matching 3-D model representations obtained from the visual object with 3-D model representations stored in memory as veridical shape precepts. Through the use of computer programs and algorithms, Yi Yungfeng (2009) was able to demonstrate the ability for the human brain to mentally construct 3D images using only the 2D images that appear on the retina. Their model also demonstrates a high degree of shape constancy conserved between 2D images, which allow the 3D image to be recognized. The 3-D model representations obtained from the object are formed by first identifying the concavities of the object, which separate the stimulus into individual parts. Recent research suggests that an area of the brain, known as the caudal intraparietal area (CIP), is responsible for storing the slant and tilt of a plan surface that allow for concavity recognition. Rosenburg et al. implanted monkeys with a scleral search coil for monitoring eye position while simultaneously recording single neuron activation from neurons within the CIP. During the experiment, monkeys sat 30\u00a0cm away from an LCD screen that displayed the visual stimuli. Binocular disparity cues were displayed on the screen by rendering stimuli as green-red anaglyphs and the slant-tilt curves ranged from 0 to 330. A single trial consisted of a fixation point and then the presentation of a stimulus for 1 second. Neuron activations were then recorded using the surgically inserted microelectrodes. These single neuron activations for specific concavities of objects lead to the discovery that each axis of an individual part of an object containing concavity are found in memory stores. Identifying the principal axis of the object assists in the normalization process via mental rotation that is required because only the canonical description of the object is stored in memory. Recognition is acquired when the observed object viewpoint is mentally rotated to match the stored canonical description.[11] An extension of Marr and Nishihara's model, the recognition-by-components theory, proposed by Biederman (1987), proposes that the visual information gained from an object is divided into simple geometric components, such as blocks and cylinders, also known as \"geons\" (geometric ions), and are then matched with the most similar object representation that is stored in memory to provide the object's identification (see Figure 1).",
            "score": 177.53092873096466
        },
        {
            "docid": "31133385_20",
            "document": "Misattribution of memory . T. Awipi and L. Davachi sought to provide evidence of competing subregions in the medial temporal lobe (MTL) that differed on the type of content they encoded. The researchers conducted a study in which subjects were asked to perform an encoding task in a functional magnetic resonance imaging (FMRI) scanner, where they were presented with 192 full colour photographs of scenes (containing a centrally presented novel scene and a smaller image of one of six objects). Participants were also instructed to imagine using the presented object in each scene, and were asked to report whether they were successful. A memory test was administered after participants were removed from the scanner. The test consisted of all previously viewed scenes (old) and an equal number of novel scenes (new). They were asked to make an old/new judgement, and if the scene was responded as being old, they were asked to report is as being \"remembered\" or \"familiar\". They were then asked to pick an object that was paired with that scene. The researchers were trying to determine the levels of activation for source recollection for the objects paired with the scene during encoding.",
            "score": 106.96231317520142
        },
        {
            "docid": "2438760_26",
            "document": "Change blindness . Other studies using fMRI (functional magnetic resonance imaging) scanners have shown that when change is not consciously detected, there was a significant decrease in the dorsolateral prefrontal and parietal lobe regions. These results further the importance of the dorsolateral prefrontal and parietal cortext in the detection of visual change. In addition to fMRI studies, recent research has used transcranial magnetic stimulation (TMS) in order to inhibit areas of the brain while participants were instructed to try to detect the change between two images. The results show that when the posterior parietal cortex (PPC) is inhibited, individuals are significantly slower at detecting change. The PPC is critical for encoding and maintaining visual images in short term working memory, which demonstrates the importance of the PPC in terms of detecting changes between images. For a change to be detected, the information of the first picture needs to be held in working memory and compared to the second picture. If the PPC is inhibited, the area of the brain responsible for encoding visual images will not function properly. The information will not be encoded and will not be held in working memory and compared to the second picture, thus inducing change blindness.",
            "score": 166.46736073493958
        },
        {
            "docid": "30601657_12",
            "document": "Response priming . Response-priming effects have been demonstrated for a large number of stimuli and discrimination tasks, including geometric stimuli, color stimuli, various types of arrows, natural images (animals vs. objects), vowels and consonants, letters, and digits. In one study, chess configurations were presented as primes and targets, and participants had to decide whether the king was in check. Mattler (2003) could show that response priming can not only influence motor responses, but also works for cognitive operations like a spatial shift of visual attention or a shift between two different response time tasks. Different types of masking have been employed as well. Instead of measuring keypress responses (commonly with two response alternatives), some studies use more than two response alternatives or record speech responses, speeded finger pointing movements, eye movements, or so-called readiness potentials which reflect the degree of motor activation in the brain's motor cortex and can be measured by electro-encephalographic methods. Brain imaging methods like functional magnetic resonance imaging (fMRI) have been employed as well.",
            "score": 123.56599640846252
        },
        {
            "docid": "987320_19",
            "document": "Neurotechnology . Magnetic resonance imaging is a vital tool in neurological research in showing activation in the brain as well as providing a comprehensive image of the brain being studied. While MRIs are used clinically for showing brain size, it still has relevance in the study of brains because it can be used to determine extent of injuries or deformation. These can have a significant effect on personality, sense perception, memory, higher order thinking, movement, and spatial understanding. However, current research tends to focus more so on fMRI or real-time functional MRI (rtfMRI). These two methods allow the scientist or the participant, respectively, to view activation in the brain. This is incredibly vital in understanding how a person thinks and how their brain reacts to a person's environment, as well as understanding how the brain works under various stressors or dysfunctions. Real-time functional MRI is a revolutionary tool available to neurologists and neuroscientists because patients can see how their brain reacts to stressors and can perceive visual feedback. CT scans are very similar to MRI in their academic use because they can be used to image the brain upon injury, but they are more limited in perceptual feedback. CTs are generally used in clinical studies far more than in academic studies, and are found far more often in a hospital than a research facility. PET scans are also finding more relevance in academia because they can be used to observe metabolic uptake of neurons, giving researchers a wider perspective about neural activity in the brain for a given condition. Combinations of these methods can provide researchers with knowledge of both physiological and metabolic behaviors of loci in the brain and can be used to explain activation and deactivation of parts of the brain under specific conditions.",
            "score": 144.6827815771103
        },
        {
            "docid": "7725524_15",
            "document": "Colour centre . Sakai et al. used fMRI to observe whether activation of the fusiform gyrus correlated with the perception of colour and the after image. The subjects in the Sakai study were placed in the fMRI machine and were subsequently subjected to various visual stimuli. A series of three images were shown to subjects while fMRI was used to focus on the haemodynamics of the fusiform gyrus. The first image was a pattern of six coloured circles. The next two images were achromatic. One of the images had a grey cross, and the other image had the same six circles as the first image, except they were six shades of grey that correlated with the coloured images. The subjects were cycled between the circle and cross images. During the cross images, the subjected perceived an after-image. The results of the experiment showed that there was a significant increase of activity in the fusiform gyrus when the subject viewed the colour image. This provided more evidence to the existence of the colour centre outside of the primary visual cortex.",
            "score": 106.95363593101501
        },
        {
            "docid": "8165347_53",
            "document": "Psychology of art . In another study using eye-movement patterns to investigate how experts view art, participants were shown realistic and abstract works of art under two conditions: one asking them to free scan the works, and the other asking them to memorize them. Participants' eye movements were tracked as they either looked at the images or tried to memorize them, and their recall for the memorized images was recorded. The researchers found no differences in the fixation frequency or time between picture types for experts and nonexperts. However, across sessions, the non-experts had more short fixations while free scanning the works, and fewer long fixations while trying to memorize; experts followed the opposite pattern. There was no significant difference in the recall of the images across groups, except experts recalled abstract images better that non-experts, and more pictorial details. These results show that people with arts expertise view repeated images less than non-experts, and can recall more details about images they have previously seen.",
            "score": 80.39045345783234
        },
        {
            "docid": "393535_12",
            "document": "Coolidge effect . Though there is no single reason for why males will choose a novel partner, there have been experiments that show that the major determining factor for detecting a novel partner is through olfactory preference. An experiment using Long-Evans rats, showed that odour played a major role in distinguishing the difference between a novel partner and familiar partner. In their experiment, Carr et al. paired each male rat with a female rat and allowed them to mate. Male rats were then tested for preference through the use of an apparatus which had two cylinders that were attached to their home cage, and contained the familiar female and the novel female in each cylinder. Caps at the end of these cylinders prevented access to the females, but had a hole in them to allow their odours to pass through to the male's cage. Before the testing phase, the females were removed, and then the caps were removed to allow the male to explore both cylinders. From this experiment, they found that males preferred the scent of the novel female. While these males did not have access to these females to demonstrate mating preferences, this odour preference is believed to reflect promiscuous behaviour, and therefore be important to the male mating strategy. In an earlier experiment, also conducted by Carr et al., they found that unlike male rats, female rats preferred the odour of a familiar partner rather than the odour of a novel partner. Another study also examined not only olfactory preference, but what part of the brain targeted the olfactory preference. In this study, male hamsters were given lesions to either the hippocampus or the perirhinal-entorhinal cortex, or received a sham treatment. Then the hamsters were allowed to mate with a female hamster until they became satiated. All subjects were then presented with two anesthetized females, one was the female they had previously copulated with, and the other was a novel female. Hamsters with sham and hippocampal lesions investigated the anogenital region of the novel females for a significantly longer period of time in comparison to the familiar female. Males with lesions to the perirhinal-entorhinal cortex did not show a preference for either a familiar or novel female, and spent a similar amount of time investigating the anogenital region of both females. The results from this study revealed that the perirhinal-entorhinal cortex region of the brain in golden hamsters is crucial for the recognition of familiar conspecifics and certain social behaviors. The conclusion from this experiment was also consistent in rats and monkeys, since damage to this region of the brain impaired standard recognition memory, which would suggest that the hippocampal region of the brain is not crucial in social behavior memory, but rather, the perirhinal-entorhinal cortex.",
            "score": 120.7576812505722
        },
        {
            "docid": "1215674_21",
            "document": "Visual memory . During encoding, participants are typically exposed to 1\u201310 visual patterns while connected to a brain imaging device. As the subject encodes the visual patterns researchers are able to directly view the activation of areas involved in visual memory encoding. During recall subjects again need to have all visual stimuli removed by means of a dark room or blindfolding to avoid interfering activation of other visual areas in the brain. Subjects are asked to recall each image clearly in their mind's eye. While recalling the images researchers are able view the areas activated by the visual memory task. Comparing the control 'baseline' state to the activated areas during the visual memory task allows researchers to view which areas are used during visual memory.",
            "score": 161.23800611495972
        },
        {
            "docid": "599917_31",
            "document": "Mental image . As cognitive neuroscience approaches to mental imagery continued, research expanded beyond questions of serial versus parallel or topographic processing to questions of the relationship between mental images and perceptual representations. Both brain imaging (fMRI and ERP) and studies of neuropsychological patients have been used to test the hypothesis that a mental image is the reactivation, from memory, of brain representations normally activated during the perception of an external stimulus. In other words, if perceiving an apple activates contour and location and shape and color representations in the brain\u2019s visual system, then imagining an apple activates some or all of these same representations using information stored in memory. Early evidence for this idea came from neuropsychology. Patients with brain damage that impairs perception in specific ways, for example by damaging shape or color representations, seem to generally to have impaired mental imagery in similar ways. Studies of brain function in normal human brains support this same conclusion, showing activity in the brain\u2019s visual areas while subjects imagined visual objects and scenes.",
            "score": 146.94500541687012
        },
        {
            "docid": "1095131_20",
            "document": "Kinesthetic learning . The cerebral cortex is the brain tissue covering the top and sides of the brain in most vertebrates. It is involved in storing and processing of sensory inputs and motor outputs. In the human brain, the cerebral cortex is actually a sheet of neural tissue about 1/8th inch thick. The sheet is folded so that it can fit inside the skull. The neural circuits in this area of the brain expand with practice of an activity, just like the synaptic plasticity grows with practice. Clarification of some of the mechanisms of learning by neuro science has been advanced, in part, by the advent of non-invasive imaging technologies, such as positron emission tomography (PET) and functional magnetic resonance imaging (FMRI). These technologies have allowed researchers to observe human learning processes directly. Through these types of technologies, we are now able to see and study what happens in the process of learning. In different tests performed the brain being imaged showed a greater blood flow and activation to that area of the brain being stimulated through different activities such as finger tapping in a specific sequence. It has been revealed that the process at the beginning of learning a new skill happens quickly, and later on slows down to almost a plateau. This process can also be referred to as The Law of Learning. The slower learning showed in the FMRI that in the cerebral cortex this was when the long term learning was occurring, suggesting that the structural changes in the cortex reflect the enhancement of skill memories during later stages of training. When a person studies a skill for a longer duration of time, but in a shorter amount of time they will learn quickly, but also only retain the information into their short-term memory. Just like studying for an exam; if a student tries to learn everything the night before, it will not stick in the long run. If a person studies a skill for a shorter duration of time, but more frequently and long-term, their brain will retain this information much longer as it is stored in the long-term memory. Functional and structural studies of the brain have revealed a vast interconnectivity between diverse regions of the cerebral cortex. For example, large numbers of axons interconnect the posterior sensory areas serving vision, audition, and touch with anterior motor regions. Constant communication between sensation and movement makes sense, because to execute smooth movement through the environment, movement must be continuously integrated with knowledge about one's surroundings obtained via sensory perception. The cerebral cortex plays a role in allowing humans to do this.",
            "score": 159.01365554332733
        },
        {
            "docid": "1316947_4",
            "document": "Ambiguous image . When we see an image, the first thing we do is attempt to organize all the parts of the scene into different groups. To do this, one of the most basic methods used is finding the edges. Edges can include obvious perceptions such as the edge of a house, and can include other perceptions that the brain needs to process deeper, such as the edges of a person's facial features. When finding edges, the brain's visual system detects a point on the image with a sharp contrast of lighting. Being able to detect the location of the edge of an object aids in recognizing the object. In ambiguous images, detecting edges still seems natural to the person perceiving the image. However, the brain undergoes deeper processing to resolve the ambiguity. For example, consider an image that involves an opposite change in magnitude of luminance between the object and the background (e.g. From the top, the background shifts from black to white, and the object shifts from white to black). The opposing gradients will eventually come to a point where there is an equal degree of luminance of the object and the background. At this point, there is no edge to be perceived. To counter this, the visual system connects the image as a whole rather than a set of edges, allowing one to see an object rather than edges and non-edges. Although there is no complete image to be seen, the brain is able to accomplish this because of its understanding of the physical world and real incidents of ambiguous lighting. In ambiguous images, an illusion is often produced from illusory contours. An illusory contour is a perceived contour without the presence of a physical gradient. In examples where a white shape appears to occlude black objects on a white background, the white shape appears to be brighter than the background, and the edges of this shape produce the illusory contours. These illusory contours are processed by the brain in a similar way as real contours. The visual system accomplishes this by making inferences beyond the information that is presented in much the same way as the luminance gradient.",
            "score": 130.06810176372528
        },
        {
            "docid": "10269587_2",
            "document": "Echoic memory . Echoic memory is the sensory memory register specific to auditory information (sounds). The sensory memory for sounds that people have just perceived is the form of echoic memory. Unlike visual memory, in which our eyes can scan the stimuli over and over, the auditory stimuli cannot be scanned over and over, although from a classical physics definition they both can and can not be so equally. Imaging input will always be at least slightly different due to other stray bits of light, just as a recorded sound will almost never have an identical total sound profile when played at different times. Time itself affects the sound every bit as much as photons such as in things seen. etc. even when the image being looked at is the same. So true with sound. Playing a digital music selection for example, through noise controlling headphones over and over again, is every bit as accurate with relation to sound as reading the same few words over and over again. Overall, echoic memories are stored for slightly longer periods of time than iconic memories (visual memories). Auditory stimuli are received by the ear one at a time before they can be processed and understood. For instance, hearing the radio is very different from reading a magazine. A person can only hear the radio once at a given time, while the magazine can be read over and over again. It can be said that the echoic memory is like a \"holding tank\" concept, because a sound is unprocessed (or held back) until the following sound is heard, and only then can it be made meaningful. This particular sensory store is capable of storing large amounts of auditory information that is only retained for a short period of time (3\u20134 seconds). This echoic sound resonates in the mind and is replayed for this brief amount of time shortly after the presentation of auditory stimuli. Echoic memory encrypts only moderately primitive aspects of the stimuli, for example pitch, which specifies localization to the non-association brain regions.",
            "score": 151.13972532749176
        },
        {
            "docid": "907554_25",
            "document": "History of neuroimaging . It is interesting to see how advances are split between those seeking a completely mapped brain by utilizing single neuron imaging and those utilizing images of brains as subjects perform various high-level tasks. Single neuron imaging (SNI) uses a combination of genetic engineering and optical imaging techniques to insert tiny electrodes into the brain for the purpose of measuring a single neuron's firing. Due to its damaging repercussions, this technique has only been used on animals, but it has shed a lot of light on basic emotional and motivational processes. The goal of studies in higher-level activities is to determine how a network of brain areas collaborates to perform each task. This higher-level imaging is much easier to do because researchers can easily use subjects who have a disease such as Alzheimer's. The SNI technology seems to be going after the possibility for AI while the network-probing technology seems to be more for medical purposes.",
            "score": 116.96736907958984
        },
        {
            "docid": "38523090_36",
            "document": "Statistical learning in language acquisition . Further evidence for domain general statistical learning was suggested in a study run through the University of Cornell Department of Psychology concerning visual statistical learning in infancy. Researchers in this study questioned whether domain generality of statistical learning in infancy would be seen using visual information. After first viewing images in statistically predictable patterns, infants were then exposed to the same familiar patterns in addition to novel sequences of the same identical stimulus components. Interest in the visuals was measured by the amount of time the child looked at the stimuli in which the researchers named \u201clooking time.\u201d All ages of infant participants showed more interest in the novel sequence relative to the familiar sequence. In demonstrating a preference for the novel sequences (which violated the transitional probability that defined the grouping of the original stimuli) the results of the study support the likelihood of domain general statistical learning in infancy.",
            "score": 93.48780965805054
        },
        {
            "docid": "1008632_18",
            "document": "Baddeley's model of working memory . However, visuo-spatial short-term memory can retain visual and/or spatial information over brief periods of time. When this memory is in use, individuals are able to momentarily create and revisit a mental image that can be manipulated in complex or difficult tasks of spatial orientation.There are some who have disparities in the areas of the brain that allow for this to happen from different types of brain damage. There can also be a misunderstanding here in the differences between transient memories such as the visual sensory memory. A transient memory is merely a fleeting type of sensory memory. Therefore, as the visual sensory memory is a type of sensory memory, there is a store for the information, but the store last for only a second or so. A common effect of the visual sensory memory is that individuals may remember seeing things that weren't really there or not remembering particular things that were in their line of sight. The memory is only momentary, and if it isn't attended to within a matter of seconds, it is gone.",
            "score": 183.8528038263321
        },
        {
            "docid": "410804_20",
            "document": "Hindsight bias . The SARA model, created by R\u00fcdiger Pohl and associates, explains hindsight bias for descriptive information in memory and hypothetical situations. SARA assumes that people have a set of images to draw their memories from. They suffer from the hindsight bias due to selective activation or biased sampling of that set of images. Basically, people only remember small, select amounts of information\u2014and when asked to recall it later, use that biased image to support their own opinions about the situation. The set of images is originally processed in the brain when first experienced. When remembered, this image reactivates, and the mind can edit and alter the memory, which takes place in hindsight bias when new and correct information is presented, leading one to believe that this new information when remembered at a later time is the persons original memory. Due to this reactivation in the brain, a more permanent memory trace can be created. The new information acts as a memory anchor causing retrieval impairment.",
            "score": 146.78242671489716
        },
        {
            "docid": "27179535_7",
            "document": "Leah Krubitzer . The parietal cortex is another area of interest for Krubitzer. The parietal cortex allows us to coordinate movements between our eyes and our hands. This ability allows for smooth reaching movements, as well as, grasping. Past research has been done on Old and New World monkeys, as well as humans, to see how the parietal cortex functions in hand use. Imaging used on humans shows that there are similar cortical patterns shared across human and non-human primates, but the extent to which these pathways are used depends on the somatosensory organization and connectivity in the parietal cortex. Krubitzer and her team took this information and investigated a little deeper. Because humans have an opposable thumb, our ability to grip objects and reach for objects is much greater than monkeys. For this reason, the connectivity in the human parietal cortex is much more complex than that of a non-human primate. In Krubitzer's lab, her team investigated different areas of the parietal cortex in order to better pin point which part controls which motor movement. Krubitzer found that when one area of the cortex responsible for a certain motor movement is compromised, the rest of the cortex will reorganize itself to make up for the loss. This finding shows how the parietal cortex can rewire itself in order to maintain functional motor capabilities. Currently in the lab, Krubitzer and colleagues are testing a microchip that may be placed in the posterior parietal cortex of the brain to deactivate certain areas at a time. Using this technique, they are able to see how deactivation of a certain portion of the cortex impacts hand grasping and reaching in monkeys. This technique is performed while the monkeys are performing different manual tasks in order to see the action of the cortex live.",
            "score": 132.36063611507416
        }
    ],
    "r": [
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 229.57550048828125
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 210.43865966796875
        },
        {
            "docid": "32528_24",
            "document": "Visual cortex . It is argued that the entire ventral visual-to-hippocampal stream is important for visual memory. This theory, unlike the dominant one, predicts that object-recognition memory (ORM) alterations could result from the manipulation in V2, an area that is highly interconnected within the ventral stream of visual cortices. In the monkey brain, this area receives strong feedforward connections from the primary visual cortex (V1) and sends strong projections to other secondary visual cortices (V3, V4, and V5). Most of the neurons of this area are tuned to simple visual characteristics such as orientation, spatial frequency, size, color, and shape. Anatomical studies implicate layer 3 of area V2 in visual-information processing. In contrast to layer 3, layer 6 of the visual cortex is composed of many types of neurons, and their response to visual stimuli is more complex.",
            "score": 190.4688720703125
        },
        {
            "docid": "26685721_33",
            "document": "Methods used to study memory . The textbook \"Fundamentals of Human Neuropsychology\" by Kolb and Whishaw describes some designs used to study memory in the macaque monkey. Elizabeth Murray and her colleagues trained monkeys to reach through the bars of their cage after a brief delay in order to displace objects under which a reward may be located. During the brief delay the monkey had to use either object recognition memory, or contextual memory to remember where the reward was located. Object recognition is tested with a matching-to-sample task where the monkey had to remember visual characteristics of the object in order to obtain the reward. Alternatively, in the non-matching-to-sample design the monkey must remember the location of the previously seen object. The monkey must then use context and spatial memory in order to correctly displace an object in the same location as previous, in order to obtain the food reward. These two tasks can be used to differentiate between object recognition memory and contextual memory. Murray and her colleagues were able to show that hippocampal lesions impaired contextual memory whereas rhinal cortex lesions impaired object recognition memory. This experimental design allowed for the dissociation of two mutually exclusive brain regions devoted to specific types of memory.",
            "score": 184.426513671875
        },
        {
            "docid": "1008632_18",
            "document": "Baddeley's model of working memory . However, visuo-spatial short-term memory can retain visual and/or spatial information over brief periods of time. When this memory is in use, individuals are able to momentarily create and revisit a mental image that can be manipulated in complex or difficult tasks of spatial orientation.There are some who have disparities in the areas of the brain that allow for this to happen from different types of brain damage. There can also be a misunderstanding here in the differences between transient memories such as the visual sensory memory. A transient memory is merely a fleeting type of sensory memory. Therefore, as the visual sensory memory is a type of sensory memory, there is a store for the information, but the store last for only a second or so. A common effect of the visual sensory memory is that individuals may remember seeing things that weren't really there or not remembering particular things that were in their line of sight. The memory is only momentary, and if it isn't attended to within a matter of seconds, it is gone.",
            "score": 183.85281372070312
        },
        {
            "docid": "739262_12",
            "document": "Neural correlate . Using such design, Nikos Logothetis and colleagues discovered perception-reflecting neurons in the temporal lobe. They created an experimental situation in which conflicting images were presented to different eyes (\"i.e.\", binocular rivalry). Under such conditions, human subjects report bistable percepts: they perceive alternatively one or the other image. Logothetis and colleagues trained the monkeys to report with their arm movements which image they perceived. Interestingly, temporal lobe neurons in Logothetis experiments often reflected what the monkeys' perceived. Neurons with such properties were less frequently observed in the primary visual cortex that corresponds to relatively early stages of visual processing. Another set of experiments using binocular rivalry in humans showed that certain layers of the cortex can be excluded as candidates of the neural correlate of consciousness. Logothetis and colleagues switched the images between eyes during the percept of one of the images. Surprisingly the percept stayed stable. This means that the conscious percept stayed stable and at the same time the primary input to layer 4, which is the input layer, in the visual cortex changed. Therefore layer 4 can not be a part of the neural correlate of consciousness. Mikhail Lebedev and their colleagues observed a similar phenomenon in monkey prefrontal cortex. In their experiments monkeys reported the perceived direction of visual stimulus movement (which could be an illusion) by making eye movements. Some prefrontal cortex neurons represented actual and some represented perceived displacements of the stimulus. Observation of perception related neurons in prefrontal cortex is consistent with the theory of Christof Koch and Francis Crick who postulated that neural correlate of consciousness resides in prefrontal cortex. Proponents of distributed neuronal processing may likely dispute the view that consciousness has a precise localization in the brain.",
            "score": 183.58499145507812
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 183.4967041015625
        },
        {
            "docid": "226722_25",
            "document": "Functional magnetic resonance imaging . Researchers have checked the BOLD signal against both signals from implanted electrodes (mostly in monkeys) and signals of field potentials (that is the electric or magnetic field from the brain's activity, measured outside the skull) from EEG and MEG. The local field potential, which includes both post-neuron-synaptic activity and internal neuron processing, better predicts the BOLD signal. So the BOLD contrast reflects mainly the inputs to a neuron and the neuron's integrative processing within its body, and less the output firing of neurons. In humans, electrodes can be implanted only in patients who need surgery as treatment, but evidence suggests a similar relationship at least for the auditory cortex and the primary visual cortex. Activation locations detected by BOLD fMRI in cortical areas (brain surface regions) are known to tally with CBF-based functional maps from PET scans. Some regions just a few millimeters in size, such as the lateral geniculate nucleus (LGN) of the thalamus, which relays visual inputs from the retina to the visual cortex, have been shown to generate the BOLD signal correctly when presented with visual input. Nearby regions such as the pulvinar nucleus were not stimulated for this task, indicating millimeter resolution for the spatial extent of the BOLD response, at least in thalamic nuclei. In the rat brain, single-whisker touch has been shown to elicit BOLD signals from the somatosensory cortex.",
            "score": 181.77655029296875
        },
        {
            "docid": "1215674_34",
            "document": "Visual memory . Studies have shown that there is an effect of alcohol on visual memory. In a recent study visual working memory and its neutral correlates was assessed in university students who partake in binge drinking, the intermittent consumption of large amounts of alcohol. The findings revealed that there may be binge-drinking related functional alteration in recognition working memory processes. This suggests that impaired prefrontal cortex function may occur at an early age in binge drinkers. Another study conducted in 2004 examined the level of response to alcohol and brain response during visual working memory. This study looked at the neural correlated of the low level of response to alcohol using functional magnetic resonance imaging during a challenging visual memory task. The results were that young people who report having needed more alcohol to feel the effects showed higher levels of brain response during visual working memory, this suggests that the individual\u2019s capacity to adjust to cognitive processing decreases, they are less able to adjust cognitive processing to contextual demands.",
            "score": 181.27024841308594
        },
        {
            "docid": "1215674_37",
            "document": "Visual memory . These parts are the sustained and transient visual processing systems. The sustained system is responsible for fine detail such as word and letter recognition and is very important in encoding words in their correct order. The transient system is responsible for controlling eye movements, and processing the larger visual environment around us. When these two processes do not work in synchronization this can cause reading disabilities. This has been tested by having children with and without reading disabilities perform on tasks related to the transient systems, where the children with reading disabilities did very poorly. It has also been found in postmortem examinations of the brains of people with reading disabilities that they have fewer neurons and connections in the areas representing the transient visual systems. However there is debate over whether this is the only reason for reading disabilities, scotopic sensitivity syndrome, deficits in verbal memory and orthographic knowledge are other proposed factors.  Deficits in visual memory can also be caused by disease and/or trauma to the brain. These can lead to the patient losing their spatial memory, and/or their visual memory for specific things. For example a patient \u201cL.E.\u201d suffered brain damage and her ability to draw from memory was severely diminished, whilst her spatial memory remained normal. Other patients represent the opposite, where memory for colors and shapes is unaffected but spatial memory for previously known places is greatly impaired. These case studies show that these two types of visual memory are located in different parts of the brain and are somewhat unrelated in terms of functioning in daily life.",
            "score": 180.34860229492188
        },
        {
            "docid": "24965027_8",
            "document": "Cognitive neuroscience of visual object recognition . This model, proposed by Marr and Nishihara (1978), states that object recognition is achieved by matching 3-D model representations obtained from the visual object with 3-D model representations stored in memory as veridical shape precepts. Through the use of computer programs and algorithms, Yi Yungfeng (2009) was able to demonstrate the ability for the human brain to mentally construct 3D images using only the 2D images that appear on the retina. Their model also demonstrates a high degree of shape constancy conserved between 2D images, which allow the 3D image to be recognized. The 3-D model representations obtained from the object are formed by first identifying the concavities of the object, which separate the stimulus into individual parts. Recent research suggests that an area of the brain, known as the caudal intraparietal area (CIP), is responsible for storing the slant and tilt of a plan surface that allow for concavity recognition. Rosenburg et al. implanted monkeys with a scleral search coil for monitoring eye position while simultaneously recording single neuron activation from neurons within the CIP. During the experiment, monkeys sat 30\u00a0cm away from an LCD screen that displayed the visual stimuli. Binocular disparity cues were displayed on the screen by rendering stimuli as green-red anaglyphs and the slant-tilt curves ranged from 0 to 330. A single trial consisted of a fixation point and then the presentation of a stimulus for 1 second. Neuron activations were then recorded using the surgically inserted microelectrodes. These single neuron activations for specific concavities of objects lead to the discovery that each axis of an individual part of an object containing concavity are found in memory stores. Identifying the principal axis of the object assists in the normalization process via mental rotation that is required because only the canonical description of the object is stored in memory. Recognition is acquired when the observed object viewpoint is mentally rotated to match the stored canonical description.[11] An extension of Marr and Nishihara's model, the recognition-by-components theory, proposed by Biederman (1987), proposes that the visual information gained from an object is divided into simple geometric components, such as blocks and cylinders, also known as \"geons\" (geometric ions), and are then matched with the most similar object representation that is stored in memory to provide the object's identification (see Figure 1).",
            "score": 177.5309295654297
        },
        {
            "docid": "24965027_25",
            "document": "Cognitive neuroscience of visual object recognition . Loss of object recognition is called \"visual object agnosia\". There are two broad categories of visual object agnosia: apperceptive and associative. When object agnosia occurs from a lesion in the dominant hemisphere, there is often a profound associated language disturbance, including loss of word meaning.  Object recognition is a complex task and involves several different areas of the brain \u2013 not just one. If one area is damaged then object recognition can be impaired. The main area for object recognition takes place in the temporal lobe. For example, it was found that lesions to the perirhinal cortex in rats causes impairments in object recognition especially with an increase in feature ambiguity. Neonatal aspiration lesions of the amygdaloid complex in monkeys appear to have resulted in a greater object memory loss than early hippocampal lesions. However, in adult monkeys, the object memory impairment is better accounted for by damage to the perirhinal and entorhinal cortex than by damage to the amygdaloid nuclei. Combined amygdalohippocampal (A + H) lesions in rats impaired performance on an object recognition task when the retention intervals were increased beyond 0s and when test stimuli were repeated within a session. Damage to the amygdala or hippocampus does not affect object recognition, whereas A + H damage produces clear deficits. In an object recognition task, the level of discrimination was significantly lower in the electrolytic lesions of globus pallidus (part of the basal ganglia) in rats compared to the Substantia- Innominata/Ventral Pallidum which was in turn worse compared to Control and Medial Septum/Vertical Diagonal Band of Broca groups; however, only globus pallidus did not discriminate between new and familiar objects. These lesions damage the ventral (what) pathway of the visual processing of objects in the brain.",
            "score": 172.33876037597656
        },
        {
            "docid": "1215674_2",
            "document": "Visual memory . Visual memory describes the relationship between perceptual processing and the encoding, storage and retrieval of the resulting neural representations. Visual memory occurs over a broad time range spanning from eye movements to years in order to visually navigate to a previously visited location. Visual memory is a form of memory which preserves some characteristics of our senses pertaining to visual experience. We are able to place in memory visual information which resembles objects, places, animals or people in a mental image. The experience of visual memory is also referred to as the mind's eye through which we can retrieve from our memory a mental image of original objects, places, animals or people. Visual memory is one of several cognitive systems, which are all interconnected parts that combine to form the human memory. Types of palinopsia, the persistence or recurrence of a visual image after the stimulus has been removed, is a dysfunction of visual memory.",
            "score": 171.52223205566406
        },
        {
            "docid": "31217535_31",
            "document": "Memory . Declarative memory can be further sub-divided into semantic memory, concerning principles and facts taken independent of context; and episodic memory, concerning information specific to a particular context, such as a time and place. Semantic memory allows the encoding of abstract knowledge about the world, such as \"Paris is the capital of France\". Episodic memory, on the other hand, is used for more personal memories, such as the sensations, emotions, and personal associations of a particular place or time. Episodic memories often reflect the \"firsts\" in life such as a first kiss, first day of school or first time winning a championship. These are key events in one's life that can be remembered clearly. Autobiographical memory \u2013 memory for particular events within one's own life \u2013 is generally viewed as either equivalent to, or a subset of, episodic memory. Visual memory is part of memory preserving some characteristics of our senses pertaining to visual experience. One is able to place in memory information that resembles objects, places, animals or people in sort of a mental image. Visual memory can result in priming and it is assumed some kind of perceptual representational system underlies this phenomenon.",
            "score": 169.25439453125
        },
        {
            "docid": "21312318_27",
            "document": "Recognition memory . Recognition memory is critically dependent on a hierarchically organized network of brain areas including the visual ventral stream, medial temporal lobe structures, frontal lobe and parietal cortices along with the hippocampus. As mentioned previously, the processes of recollection and familiarity are represented differently in the brain. As such, each of the regions listed above can be further subdivided according to which part is primarily involved in recollection or in familiarity. In the temporal cortex, for instance, the medial region is related to recollection whereas the anterior region is related to familiarity. Similarly, in the parietal cortex, the lateral region is related to recollection whereas the superior region is related to familiarity. An even more specific account divides the medial parietal region, relating the posterior cingulate to recollection and the precuneus to familiarity. The hippocampus plays a prominent role in recollection whereas familiarity depends heavily on the surrounding medial-temporal regions, especially the perirhinal cortex. Finally, it is not yet clear what specific regions of the prefrontal lobes are associated with recollection versus familiarity, although there is evidence that the left prefrontal cortex is correlated more strongly with recollection whereas the right prefrontal cortex is involved more in familiarity. Though left-side activation involved in recollection was originally hypothesized to result from semantic processing of words (many of these earlier studies used written words for stimuli) subsequent studies using nonverbal stimuli produced the same finding\u2014suggesting that prefrontal activation in the left hemisphere results from any kind of detailed remembering.  As previously mentioned, recognition memory is not a stand-alone concept; rather it is a highly interconnected and integrated sub-system of memory. Perhaps misleadingly, the regions of the brain listed above correspond to an abstract and highly generalized understanding of recognition memory, in which the stimuli or items-to-be-recognized are not specified. In reality, however, the location of brain activation involved in recognition is highly dependent on the nature of the stimulus itself. Consider the conceptual differences in recognizing written words compared to recognizing human faces. These are two qualitatively different tasks and as such it is not surprising that they involve additional, distinct regions of the brain. Recognizing words, for example, involves the visual word form area, a region in the left fusiform gyrus, which is believed to specialized in recognizing written words. Similarly, the fusiform face area, located in the right hemisphere, is linked specifically to the recognition of faces.",
            "score": 169.2210693359375
        },
        {
            "docid": "33106911_5",
            "document": "Misinformation effect . Functional magnetic resonance imaging (fMRI) from 2010 pointed to certain brain areas which were especially active when false memories were retrieved. participants studied photos during an fMRI. Later, they viewed sentences describing the photographs, some of which contained information conflicting with the photographs, i.e. misinformation. One day later, participants returned for a surprise item memory recognition test on the content of the photographs. Results showed that some participants created false memories, reporting the verbal misinformation conflicting with the photographs. During the original event phase, increased activity in left fusiform gyrus and right temporal/occipital cortex was found which may have reflected the attention to visual detail,associated with later accurate memory for the critical item(s) and thus resulted in resistance to the effects of later misinformation. Retrieval of true memories was associated with greater reactivation of sensory-specific cortices, for example, the occipital cortex for vision.. Electroencephalography research on this issue also suggests that the retrieval of false memories is associated with reduced attention and recollection related processing relative to true memories.",
            "score": 168.74156188964844
        },
        {
            "docid": "2438760_26",
            "document": "Change blindness . Other studies using fMRI (functional magnetic resonance imaging) scanners have shown that when change is not consciously detected, there was a significant decrease in the dorsolateral prefrontal and parietal lobe regions. These results further the importance of the dorsolateral prefrontal and parietal cortext in the detection of visual change. In addition to fMRI studies, recent research has used transcranial magnetic stimulation (TMS) in order to inhibit areas of the brain while participants were instructed to try to detect the change between two images. The results show that when the posterior parietal cortex (PPC) is inhibited, individuals are significantly slower at detecting change. The PPC is critical for encoding and maintaining visual images in short term working memory, which demonstrates the importance of the PPC in terms of detecting changes between images. For a change to be detected, the information of the first picture needs to be held in working memory and compared to the second picture. If the PPC is inhibited, the area of the brain responsible for encoding visual images will not function properly. The information will not be encoded and will not be held in working memory and compared to the second picture, thus inducing change blindness.",
            "score": 166.4673614501953
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 165.77838134765625
        },
        {
            "docid": "7151320_17",
            "document": "Recovery from blindness . The effect of visual loss has an impact in the development of the visual cortex of the brain. The visual impairment causes the occipital lobe to lose its sensitivity in perceiving spatial processing. Sui and Morley (2008) proposed that after 7 days of visual deprivation, a potential decrease in vision may occur. They also found an increasing visual impairment with deprivation after 30 days and 120 days. This study suggests that the function of the brain depends on visual input. Michael lost his eyesight at age 3, when his vision was still not fully developed to distinguish shapes, drawings or images clearly. It would be difficult for him to be able to describe the world compared to a normal sighted person. For instance, Michael would have trouble differentiating complex shapes, dimension and orientations of objects. Hannan (2006) hypothesized that the temporal visual cortex uses prior memory and experiences to make sense of shapes, colours and forms. She proposed that the long-term effect of blindness in the visual cortex is the lack of recognition of spatial cues.",
            "score": 164.13088989257812
        },
        {
            "docid": "2872287_26",
            "document": "Neural binding . Cognitive binding is associated with the different states of human consciousness. Two of the most studied states of consciousness are the wakefulness and REM sleep. There have been multiple studies showing, electrophysiologically, that these two states are quite similar in nature. This has led some neural binding theorists to study the modes of cognitive awareness in each state. Certain observations have even led these scientists to hypothesize that since there is little cognition going on during REM sleep, the increased thalamocortical responses show the action of processing in the waking preconscious. The thalamus and cortex are important anatomical features in cognitive and sensory awareness. The understanding of how these neurons fire and relate to one other in each of these states (REM and Waking) is paramount to understanding awareness and its relation to neural binding. In the waking state, neuronal activity in animals is subject to changes based on the current environment. Changes in environment act as a form of stress on the brain so that when sensory neurons are then fired synchronously, they acclimate to the new state. This new state can then be moved to the hippocampus where it can be stored for later use. In the words of James Newman and Anthony A. Grace in their article, \"Binding Across Time\" this idea is put forth: \"The hippocampus is the primary recipient of inferotemporal outputs and is known to be the substrate for the consolidation of working memories to long term, episodic memories.\" The logging of \"episodes\" is then used for \"streaming\", which can mediate by the selective gating of certain information reentering sensory awareness. Streaming and building of episodic memories would not be possible if neural binding did not unconsciously connect the two synchronous oscillations. The pairing of these oscillations can then help input the correct sensory material. If these paired oscillations are not new, then cognitively these firings will be easily understood. If there are new firings, the brain will have to acclimate to the new understanding. In REM sleep, the only extreme difference from the waking state is that the brain does not have the actual waking amount of sensory firings, so cognitively, there is not as much awareness here, although the activity of the \"brain\u2019s eye\" is still quite significant and very similar to the waking state. Studies have shown that during sleep there are still 40\u00a0Hz Oscillation firings. These firings are due to the perceived stimuli happening in dreams. \"",
            "score": 163.52064514160156
        },
        {
            "docid": "2920040_2",
            "document": "Neuronal tuning . Neuronal tuning refers to the hypothesized property of brain cells by which they selectively represent a particular type of sensory, association, motor, or cognitive information. Some neuronal responses have been hypothesized to be optimally tuned to specific patterns through experience. Neuronal tuning can be strong and sharp, as observed in primary visual cortex (area V1) (but see Carandini et al 2005 ), or weak and broad, as observed in neural ensembles. Single neurons are hypothesized to be simultaneously tuned to several modalities, such as visual, auditory, and olfactory. Neurons hypothesized to be tuned to different signals are often hypothesized to integrate information from the different sources. In computational models called neural networks, such integration is the major principle of operation. The best examples of neuronal tuning can be seen in the visual, auditory, olfactory, somatosensory, and memory systems, although due to the small number of stimuli tested the generality of neuronal tuning claims is still an open question.",
            "score": 163.14358520507812
        },
        {
            "docid": "3717_68",
            "document": "Brain . One of the most influential early contributions was a 1959 paper titled \"What the frog's eye tells the frog's brain\": the paper examined the visual responses of neurons in the retina and optic tectum of frogs, and came to the conclusion that some neurons in the tectum of the frog are wired to combine elementary responses in a way that makes them function as \"bug perceivers\". A few years later David Hubel and Torsten Wiesel discovered cells in the primary visual cortex of monkeys that become active when sharp edges move across specific points in the field of view\u2014a discovery for which they won a Nobel Prize. Follow-up studies in higher-order visual areas found cells that detect binocular disparity, color, movement, and aspects of shape, with areas located at increasing distances from the primary visual cortex showing increasingly complex responses. Other investigations of brain areas unrelated to vision have revealed cells with a wide variety of response correlates, some related to memory, some to abstract types of cognition such as space.",
            "score": 163.0105743408203
        },
        {
            "docid": "5664_64",
            "document": "Consciousness . In neuroscience, a great deal of effort has gone into investigating how the perceived world of conscious awareness is constructed inside the brain. The process is generally thought to involve two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals arising from sensory organs are transmitted to the brain and then processed in a series of stages, which extract multiple types of information from the raw input. In the visual system, for example, sensory signals from the eyes are transmitted to the thalamus and then to the primary visual cortex; inside the cerebral cortex they are sent to areas that extract features such as three-dimensional structure, shape, color, and motion. Memory comes into play in at least two ways. First, it allows sensory information to be evaluated in the context of previous experience. Second, and even more importantly, working memory allows information to be integrated over time so that it can generate a stable representation of the world\u2014Gerald Edelman expressed this point vividly by titling one of his books about consciousness \"The Remembered Present\". In computational neuroscience, Bayesian approaches to brain function have been used to understand both the evaluation of sensory information in light of previous experience, and the integration of information over time. Bayesian models of the brain are probabilistic inference models, in which the brain takes advantage of prior knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian models have successfully predicted many perceptual phenomena in vision and the nonvisual senses.",
            "score": 162.76242065429688
        },
        {
            "docid": "734667_10",
            "document": "Iconic memory . Iconic memory enables integrating visual information along a continuous stream of images, for example when watching a movie. In the primary visual cortex new stimuli do not erase information about previous stimuli. Instead the responses to the most recent stimulus contain about equal amounts of information about both this and the preceding stimulus. This one-back memory may be the main substrate for both the integration processes in iconic memory and masking effects. The particular outcome depends on whether the two subsequent component images (i.e., the \"icons\") are meaningful only when isolated (masking) or only when superimposed (integration).",
            "score": 162.7445526123047
        },
        {
            "docid": "21312318_28",
            "document": "Recognition memory . Strictly speaking, recognition is a process of memory \"retrieval\". But how a memory is formed in the first place affects how it is retrieved. An interesting area of study related to recognition memory deals with how memories are initially learned or encoded in the brain. This encoding process is an important aspect of recognition memory because it determines not only whether or not a previously introduced item is recognized, but \"how\" that item is retrieved through memory. Depending on the strength of the memory, the item may either be 'remembered' (i.e. a recollection judgment) or simply 'known' (i.e. a familiarity judgment). Of course, the strength of the memory depends on many factors, including whether or not the person was giving their full attention to memorizing the information or whether they were distracted, whether they are actively attempting to learn (intentional learning) or only learning passively, whether they were allowed to rehearse the information or not, etc., although these contextual details are beyond the scope of this entry. Several studies have shown that when an individual is devoting his/her full attention to the memorization process, the strength of the successful memory is related to the magnitude of bilateral activation in the prefrontal cortex, hippocampus, and parahippocampal gyrus. The greater the activation in these areas during learning, the better the memory. Thus, these areas are involved in the formation of detailed, recollective memories. In contrast, when subjects are distracted during the memory-encoding process, only the right prefrontal cortex and left parahippocampal gyrus are activated. These regions are associated with \"a sense of knowing\" or familiarity. Given that the areas involved in familiarity are also involved in recollection, this conforms to a single-process theory of recognition, at least insofar as the encoding of memories is concerned.",
            "score": 162.23931884765625
        },
        {
            "docid": "7725524_14",
            "document": "Colour centre . Functional magnetic resonance imaging, or fMRI for short, has been key in determining the colour selective regions in the visual cortex. fMRI is able to track brain activity by measuring blood flow throughout the brain. Areas that have more blood flowing to them indicates an occurrence of neuronal activity. This change in blood flow is called haemodynamic response. Among the benefits of fMRI includes dynamic, real-time mapping of cortical processes. However, fMRI cannot track the actual firing of neurons, which happen on a millisecond timescale, but it can track the haemodynamic response, which happens on a seconds timescale. This method is ideal for tracking colour selective neurons because colour perception results in a visual after-image that can be observed in the neurons, which lasts about 15 seconds.",
            "score": 161.96754455566406
        },
        {
            "docid": "1215674_21",
            "document": "Visual memory . During encoding, participants are typically exposed to 1\u201310 visual patterns while connected to a brain imaging device. As the subject encodes the visual patterns researchers are able to directly view the activation of areas involved in visual memory encoding. During recall subjects again need to have all visual stimuli removed by means of a dark room or blindfolding to avoid interfering activation of other visual areas in the brain. Subjects are asked to recall each image clearly in their mind's eye. While recalling the images researchers are able view the areas activated by the visual memory task. Comparing the control 'baseline' state to the activated areas during the visual memory task allows researchers to view which areas are used during visual memory.",
            "score": 161.23800659179688
        },
        {
            "docid": "5664_46",
            "document": "Consciousness . A number of studies have shown that activity in primary sensory areas of the brain is not sufficient to produce consciousness: it is possible for subjects to report a lack of awareness even when areas such as the primary visual cortex show clear electrical responses to a stimulus. Higher brain areas are seen as more promising, especially the prefrontal cortex, which is involved in a range of higher cognitive functions collectively known as executive functions. There is substantial evidence that a \"top-down\" flow of neural activity (i.e., activity propagating from the frontal cortex to sensory areas) is more predictive of conscious awareness than a \"bottom-up\" flow of activity. The prefrontal cortex is not the only candidate area, however: studies by Nikos Logothetis and his colleagues have shown, for example, that visually responsive neurons in parts of the temporal lobe reflect the visual perception in the situation when conflicting visual images are presented to different eyes (i.e., bistable percepts during binocular rivalry).",
            "score": 160.28526306152344
        },
        {
            "docid": "29806557_6",
            "document": "Vision restoration therapy . The cerebrum is involved with higher brain function, and one component of the cerebrum is the primary visual cortex. The primary visual cortex is a region in the occipital lobe that can be altered by neuroplasticity to create new neuronal pathways around damaged areas to help regain lost visual functions. Sensory visual information is sent from the retina of the eye to the Lateral geniculate nucleus (LGN) in the Thalamus, which relays the visual information to the primary visual cortex by the fibers of the optic radiation. Lesions or damage to parts of the brain that cause visual field defects usually occur posterior to the optic chiasm. Although the exact mechanisms that underlie regaining visual field functions through visual neuroplasticity and VRT are not yet fully known, the reorganization of the primary visual cortex is thought to make new connections and pathways in the optic radiation to the LGN to help regain visual field functions. The stimulation of existing neurons near a damaged site in the brain can form new synapses with other functional neurons to help take on and compensate for the function lost due to the damaged neurons. This is what is theorized to occur during VRT treatment.",
            "score": 160.24452209472656
        },
        {
            "docid": "24965027_11",
            "document": "Cognitive neuroscience of visual object recognition . The visual processing of objects in the brain can be divided into two processing pathways: the dorsal stream (how/where), which extends from the visual cortex to the parietal lobes, and ventral stream (what), which extends from the visual cortex to the inferotemporal cortex (IT). The existence of these two separate visual processing pathways was first proposed by Ungerleider and Mishkin (1982) who, based on their lesion studies, suggested that the dorsal stream is involved in the processing of visual spatial information, such as object localization (where), and the ventral stream is involved in the processing of visual object identification information (what). Since this initial proposal, it has been alternatively suggested that the dorsal pathway should be known as the 'How' pathway as the visual spatial information processed here provides us with information about how to interact with objects, For the purpose of object recognition, the neural focus is on the ventral stream.",
            "score": 159.50071716308594
        },
        {
            "docid": "1095131_20",
            "document": "Kinesthetic learning . The cerebral cortex is the brain tissue covering the top and sides of the brain in most vertebrates. It is involved in storing and processing of sensory inputs and motor outputs. In the human brain, the cerebral cortex is actually a sheet of neural tissue about 1/8th inch thick. The sheet is folded so that it can fit inside the skull. The neural circuits in this area of the brain expand with practice of an activity, just like the synaptic plasticity grows with practice. Clarification of some of the mechanisms of learning by neuro science has been advanced, in part, by the advent of non-invasive imaging technologies, such as positron emission tomography (PET) and functional magnetic resonance imaging (FMRI). These technologies have allowed researchers to observe human learning processes directly. Through these types of technologies, we are now able to see and study what happens in the process of learning. In different tests performed the brain being imaged showed a greater blood flow and activation to that area of the brain being stimulated through different activities such as finger tapping in a specific sequence. It has been revealed that the process at the beginning of learning a new skill happens quickly, and later on slows down to almost a plateau. This process can also be referred to as The Law of Learning. The slower learning showed in the FMRI that in the cerebral cortex this was when the long term learning was occurring, suggesting that the structural changes in the cortex reflect the enhancement of skill memories during later stages of training. When a person studies a skill for a longer duration of time, but in a shorter amount of time they will learn quickly, but also only retain the information into their short-term memory. Just like studying for an exam; if a student tries to learn everything the night before, it will not stick in the long run. If a person studies a skill for a shorter duration of time, but more frequently and long-term, their brain will retain this information much longer as it is stored in the long-term memory. Functional and structural studies of the brain have revealed a vast interconnectivity between diverse regions of the cerebral cortex. For example, large numbers of axons interconnect the posterior sensory areas serving vision, audition, and touch with anterior motor regions. Constant communication between sensation and movement makes sense, because to execute smooth movement through the environment, movement must be continuously integrated with knowledge about one's surroundings obtained via sensory perception. The cerebral cortex plays a role in allowing humans to do this.",
            "score": 159.01365661621094
        },
        {
            "docid": "599917_9",
            "document": "Mental image . The biological foundation of the mind's eye is not fully understood. Studies using fMRI have shown that the lateral geniculate nucleus and the V1 area of the visual cortex are activated during mental imagery tasks. Ratey writes: The visual pathway is not a one-way street. Higher areas of the brain can also send visual input back to neurons in lower areas of the visual cortex. [...] As humans, we have the ability to see with the mind's eye \u2013 to have a perceptual experience in the absence of visual input. For example, PET scans have shown that when subjects, seated in a room, imagine they are at their front door starting to walk either to the left or right, activation begins in the visual association cortex, the parietal cortex, and the prefrontal cortex - all higher cognitive processing centers of the brain.",
            "score": 157.9788055419922
        }
    ]
}