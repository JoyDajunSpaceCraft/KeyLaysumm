{
    "q": [
        {
            "docid": "4548229_17",
            "document": "Interaural time difference . The lateral lemniscus (LL) is the main auditory tract in the brainstem connecting SOC to the inferior colliculus. The dorsal nucleus of the lateral lemniscus (DNLL) is a group of neurons separated by lemniscus fibres, these fibres are predominantly destined for the inferior colliculus (IC). In studies using an unanesthetized rabbit the DNLL was shown to alter the sensitivity of the IC neurons and may alter the coding of interaural timing differences (ITDs) in the IC.(Kuwada et al., 2005) The ventral nucleus of the lateral lemniscus (VNLL) is a chief source of input to the inferior colliculus. Research using rabbits shows the discharge patterns, frequency tuning and dynamic ranges of VNLL neurons supply the inferior colliculus with a variety of inputs, each enabling a different function in the analysis of sound.(Batra & Fitzpatrick, 2001)  In the inferior colliculus (IC) all the major ascending pathways from the olivary complex and the central nucleus converge. The IC is situated in the midbrain and consists of a group of nuclei the largest of these is the central nucleus of inferior colliculus (CNIC). The greater part of the ascending axons forming the lateral lemniscus will terminate in the ipsilateral CNIC however a few follow the commissure of Probst and terminate on the contralateral CNIC. The axons of most of the CNIC cells form the brachium of IC and leave the brainstem to travel to the ipsilateral thalamus. Cells in different parts of the IC tend to be monaural, responding to input from one ear, or binaural and therefore respond to bilateral stimulation.",
            "score": 122.99128270149231
        },
        {
            "docid": "32116125_4",
            "document": "Amblyaudia . Amblyaudia is a deficit in binaural integration of environmental information entering the auditory system. It is a disorder related to brain organization and function rather than what is typically considered a \u201chearing loss\u201d (damage to the cochlea). It may be genetic or developmentally acquired or both. When animals are temporarily deprived of hearing from an early age, profound changes occur in the brain. Specifically, cell sizes in brainstem nuclei are reduced, the configuration of brainstem dendrites are altered and neurons respond in different ways to sounds presented to both the deprived and non-deprived ears (in cases of asymmetric deprivation). This last point is particularly important for listening tasks that require inputs from two ears to perform well. There are multiple auditory functions that rely on the computation of well calibrated inputs from the two ears. Chief among these is the ability to localize sound sources and separate what we want to hear from a background of noise. In the brainstem, the auditory system compares the timing and levels of sounds between the two ears to encode the location of sound sources (sounds that originate from our right as opposed to left side are louder and arrive earlier in our right ear). This ability to separate sound sources not only helps us locate the trajectories of moving objects, but also to separate different sound sources in noisy environments.",
            "score": 143.91086554527283
        },
        {
            "docid": "635490_7",
            "document": "Auditory system . Simplified, nerve fibers\u2019 signals are transported by bushy cells to the binaural areas in the olivary complex, while signal peaks and valleys are noted by stellate cells, and signal timing is extracted by octopus cells. The lateral lemniscus has three nuclei: dorsal nuclei respond best to bilateral input and have complexity tuned responses; intermediate nuclei have broad tuning responses; and ventral nuclei have broad and moderately complex tuning curves. Ventral nuclei of lateral lemniscus help the inferior colliculus (IC) decode amplitude modulated sounds by giving both phasic and tonic responses (short and long notes, respectively). IC receives inputs not shown, including visual (pretectal area: moves eyes to sound. superior colliculus: orientation and behavior toward objects, as well as eye movements (saccade)) areas, Pons (superior cerebellar peduncle: thalamus to cerebellum connection/hear sound and learn behavioral response), spinal cord (periaqueductal grey: hear sound and instinctually move), and thalamus. The above are what implicate IC in the \u2018startle response\u2019 and ocular reflexes. Beyond multi-sensory integration IC responds to specific amplitude modulation frequencies, allowing for the detection of pitch. IC also determines time differences in binaural hearing. The medial geniculate nucleus divides into ventral (relay and relay-inhibitory cells: frequency, intensity, and binaural info topographically relayed), dorsal (broad and complex tuned nuclei: connection to somatosensory info), and medial (broad, complex, and narrow tuned nuclei: relay intensity and sound duration). The auditory cortex (AC) brings sound into awareness/perception. AC identifies sounds (sound-name recognition) and also identifies the sound\u2019s origin location. AC is a topographical frequency map with bundles reacting to different harmonies, timing and pitch. Right-hand-side AC is more sensitive to tonality, left-hand-side AC is more sensitive to minute sequential differences in sound. Rostromedial and ventrolateral prefrontal cortices are involved in activation during tonal space and storing short-term memories, respectively. The Heschl\u2019s gyrus/transverse temporal gyrus includes Wernicke\u2019s area and functionality, it is heavily involved in emotion-sound, emotion-facial-expression, and sound-memory processes. The entorhinal cortex is the part of the \u2018hippocampus system\u2019 that aids and stores visual and auditory memories. The supramarginal gyrus (SMG) aids in language comprehension and is responsible for compassionate responses. SMG links sounds to words with the angular gyrus and aids in word choice. SMG integrates tactile, visual, and auditory info.",
            "score": 104.40040040016174
        },
        {
            "docid": "5051081_4",
            "document": "Eric Knudsen . In 1978, Knudsen and Konishi presented the discovery of an auditory map of space in the midbrain of the barn owl. This discovery was groundbreaking because it unearthed the first non-somatotopic space map in the brain. The map was found in the owl\u2019s midbrain, in the lateral and anterior mesencephalicus lateralis dorsalis (MLD), a structure now referred to as the inferior colliculus. Unlike most sound-localization maps, this map was found to be two-dimensional, with units arranged spatially to represent both the vertical and horizontal location of sound. Knudsen and Konishi discovered that units in this structure respond preferentially to sounds originating in a particular region in space. In the 1978 paper, elevation and azimuth (location in the horizontal plane) were shown to be the two coordinates of the map. Using a speaker set on a rotatable hemispherical track, Knudsen and Konishi presented owls with auditory stimulus from various locations in space and recorded the resulting neuronal activity. They found that neurons in this part of the MLD were organized according to the location of their receptive field, with azimuth varying along the horizontal plane of the space map and elevation varying vertically.  Knudsen followed this discovery with research into specific sound localization mechanisms. Two main auditory cues used by the barn owl to localize sound are interaural time difference (ITD) and interaural intensity difference (IID). The owl\u2019s ears are asymmetric, with the right ear\u2019s opening being directed higher than that of the left. This asymmetry allows the barn owl to determine the elevation of a sound by comparing sound levels between its two ears. Interaural time differences provide the owl with information regarding a sound\u2019s azimuth; sound will reach the ear closer to the sound source before reaching the farther ear, and this time difference can be detected and interpreted as an azimuthal direction. At low frequencies, the wavelength of a sound is wider than the owl's facial ruff, and the ruff does not affect detection of azimuth. At high frequencies, the ruff plays a role in reflecting sound for heightened sensitivity to vertical elevation. Therefore, with wide-band noise, containing both high and low frequencies, the owl could use interaural spectrum difference to obtain information about both azimuth and elevation. In 1979, Knudsen and Konishi showed that the barn owl uses interaural spectrum information in sound localization. They presented owls with both wide-bandwidth noise and pure tones. The birds were able to successfully locate pure tones (since they could still gather information from IID and ITD), but their error rate was much lower when localizing wide-bandwidth noise. This indicates that the birds utilize interaural spectrum differences to improve their accuracy.",
            "score": 142.16646671295166
        },
        {
            "docid": "14532984_7",
            "document": "Coincidence detection in neurobiology . Coincidence detection has been shown to be a major factor in sound localization along the azimuth plane in several organisms. In 1948, Lloyd A. Jeffress proposed that some organisms may have a collection of neurons that receive auditory input from each ear. The neural pathways to these neurons are called delay lines. Jeffress claimed that the neurons that the delay lines link act as coincidence detectors by firing maximally when receiving simultaneous inputs from both ears. When a sound is heard, sound waves may reach the ears at different times. This is referred to as the interaural time difference (ITD). Due to differing lengths and a finite conduction speed within the axons of the delay lines, different coincidence detector neurons will fire when sound comes from different positions along the azimuth. Jeffress' model proposes that two signals even from an asynchronous arrival of sound in the cochlea of each ear will converge synchronously on a coincidence detector in the auditory cortex based on the magnitude of the ITD (Fig. 2). Therefore, the ITD should correspond to an anatomical map that can be found within the brain. Masakazu Konishi's study on barn owls shows that this is true. Sensory information from the hair cells of the ears travels to the ipsilateral nucleus magnocellularis. From here, the signals project ipsilaterally and contralaterally to two nucleus laminari. Each nucleus laminaris contains coincidence detectors that receive auditory input from the left and the right ear. Since the ipsilateral axons enter the nucleus laminaris dorsally while the contralateral axons enter ventrally, sounds from various positions along the azimuth correspond directly to stimulation of different depths of the nucleus laminaris. From this information, a neural map of auditory space was formed. The function of the nucleus laminaris parallels that of the medial superior olive in mammals.",
            "score": 121.38420796394348
        },
        {
            "docid": "32105732_4",
            "document": "Spatial hearing loss . Sound streams arriving from the left or right (the horizontal plane) are localised primarily by the small time differences of the same sound arriving at the two ears. A sound straight in front of the head is heard at the same time by both ears. A sound to the side of the head is heard approximately 0.0005 seconds later by the ear furthest away. A sound halfway to one side is heard approximately 0.0003 seconds later. This is the interaural time difference (ITD) cue and is measured by signal processing in the two central auditory pathways that begin after the cochlea and pass through the brainstem and mid-brain. Some of those with spatial hearing loss are unable to process ITD (low frequency) cues.",
            "score": 108.75928139686584
        },
        {
            "docid": "17523336_13",
            "document": "Olivocochlear system . Using acoustic stimuli to activate the MOC reflex pathway, recordings have been made from single efferent fibres in guinea pigs and cats. Both studies confirmed that MOC neurons are sharply tuned to frequency, as previously suggested by Cody and Johnstone (1982), and Robertson (1984). They also showed that the firing rate of MOC neurons increased as the intensity of sound increased from 0 to 100\u00a0dB SPL, and have comparable thresholds (within ~15\u00a0dB) to afferent neurons. Furthermore, both studies showed that most MOC neurons responded to sound presented in the ipsilateral ear, consistent with the majority of mammalian MOC neurons being contralaterally located. No recordings have been made from MOC fibres in humans. because invasive \"in vivo\" experiments are not possible. In other primate species however, it has been shown that about 50-60% of MOC fibres are crossed (Bodian and Gucer, 1980; Thompson and Thompson, 1986).",
            "score": 76.36669945716858
        },
        {
            "docid": "2367309_8",
            "document": "State-dependent memory . At its most basic, state-dependent memory is the product of the strengthening of a particular synaptic pathway in the brain. A neural synapse is the space between brain cells, or neurons, that allows chemical signals to be passed from one neuron to another. Chemicals called neurotransmitters leave one cell, travel across the synapse, and are taken in by the next neuron through a neurotransmitter receptor. This creates a connection between the two neurons called a neural pathway. Memory relies on the strengthening of these neural pathways, associating one neuron with another. When we learn something, new pathways are made between neurons in the brain which then communicate through chemical signals. If these cells have a history of sending out certain signals under specific chemical conditions within the brain, they are then primed to work most effectively under similar circumstances. State-dependent memory happens when a new neural connection is made while the brain is in a specific chemical state - for instance, a child with ADHD learns their multiplication tables while on stimulant medication. Because their brain created these new connections related to multiplication tables while the brain was chemically affected by the stimulant medication, their neurons will be primed in the future to remember these facts best when the same levels of medication are present in the brain.",
            "score": 75.06355798244476
        },
        {
            "docid": "39265695_8",
            "document": "Stimulus filtering . When looking at the nervous systems of flies, researchers found three auditory afferents. Type one fires only one spike to the stimulus onset, has low jitter (variability in timing over stimulus presentations), no spontaneous activity, and is the most common type. Type two fires two to four spikes to the stimulus onset, has increased jitter with subsequent spikes, and has low spontaneous activity. Finally, type three has tonic spiking to the presented stimulus, has low jitter only with the first spikes, has low spontaneous activity, and is the least common type. Researchers discovered that neurons responded the strongest to sound frequencies between 4 and 9\u00a0kHz, which includes the frequencies present in cricket songs. Also, neurons were found to have responded strongest at 4.5\u00a0kHz, which is the frequency of the Gryllus song. Despite the type of auditory afferent, all observed neurons revealed an inverse/latency relationship. The stronger the stimulus, the shorter the time until the neuron begins to respond. The difference in the number of afferents above the threshold on a side of the animal is called population code and can be used to account for sound localization.",
            "score": 70.06863987445831
        },
        {
            "docid": "462393_14",
            "document": "Olfactory bulb . The AOB is divided into two main subregions, anterior and posterior, which receive segregated synaptic inputs from two main categories of vomeronasal sensory neurons, V1R and V2R, respectively. This appears as a clear functional specialization, given the differential role of the two populations of sensory neurons in detecting chemical stimuli of different type and molecular weight. Although it doesn't seem to be maintained centrally, where mitral cell projections from both sides of the AOB converge. A clear difference of the AOB circuitry, compared to the rest of the bulb, is its heterogeneous connectivity between mitral cells and vomeronasal sensory afferents within neuropil glomeruli. AOB mitral cells indeed contact through apical dendritic processes glomeruli formed by afferents of different receptor neurons, thus breaking the one-receptor-one-neuron rule which generally holds for the main olfactory system. This implies that stimuli sensed through the VNO and elaborated in the AOB are subjected to a different and probably more complex level of elaboration. Accordingly, AOB mitral cells show clearly different firing patterns compared to other bulbar projection neurons. Additionally, top down input to the olfactory bulb differentially affects olfactory outputs.",
            "score": 70.76055788993835
        },
        {
            "docid": "4833512_4",
            "document": "Mu wave . The mirror neuron system consists of a class of neurons that was first studied in the 1990s in macaque monkeys. Studies have found sets of neurons that fire when these monkeys perform simple tasks and also when the monkeys view others performing the same simple tasks. This suggests they play a role in mapping others' movements into the brain without actually physically performing the movements. These sets of neurons are called mirror neurons and together make up the mirror neuron system. Mu waves are suppressed when these neurons fire, a phenomenon which allows researchers to study mirror neuron activity in humans. There is evidence that mirror neurons exist in humans as well as in non-human animals. The right fusiform gyrus, left inferior parietal lobule, right anterior parietal cortex, and left inferior frontal gyrus are of particular interest. Some researchers believe that mu wave suppression can be a consequence of mirror neuron activity throughout the brain, and represents a higher-level integrative processing of mirror neuron activity. Tests in both monkeys (using invasive measuring techniques) and humans (using EEG and fMRI) have found that these mirror neurons not only fire during basic motor tasks, but also have components that deal with intention. There is evidence of an important role for mirror neurons in humans, and mu waves may represent a high level coordination of those mirror neurons.",
            "score": 70.31582260131836
        },
        {
            "docid": "47338295_9",
            "document": "Sound localization in owls . In the sound level pathway, the posterior lateral lemniscal nucleus (mammalian lateral superior olive) is the site of binaural convergence and where IID is processed. Stimulation of the contralateral ear inhibits and that of the ipsilateral ear excites the neurons of the nuclei in each brain hemisphere independently. The degree of excitation and inhibition depends on sound pressure, and the difference between the strength of the inhibitory input and that of the excitatory input determines the rate at which neurons of the lemniscal nucleus fire. Thus the response of these neurons is a function of the difference in sound pressure between the two ears.",
            "score": 97.5582582950592
        },
        {
            "docid": "29354346_7",
            "document": "Change deafness . One study used fMRI data to distinguish neural correlates of physical changes in auditory input (independent of conscious change detection), from those of conscious perception of change (independent of an actual physical change). The study made use of a change deafness paradigm in which participants were exposed to complex auditory scenes consisting of six individual auditory streams differing in pitch, rhythm, and sound source location, and received a cue indicating which stream to attend to. Each participant listened to two consecutively presented auditory scenes after which they were prompted to indicate whether both scenes were identical or not. Functional MRI results revealed that physical change in stimulus was correlated with increased BOLD responses in the right auditory cortex, near the lateral portion of Heschl's gyrus, the first cortical structure to process incoming auditory information, but not in hierarchically higher brain regions. Conscious change detection was correlated with increased coupled responses in the ACC and the right insula, consistent with additional evidence that the anterior insula functions to mediate dynamic interactions between other brain networks involved in attention to external stimuli, forming a salience network with the ACC that identifies salient stimulus events and initiates additional processing. In absence of change detection, this salience network was not activated; however increased activity in other cortical areas suggests that undetected changes are still perceived on some level, but fail to trigger conscious change detection, thus producing the change deafness phenomenon.",
            "score": 122.39375948905945
        },
        {
            "docid": "25935238_9",
            "document": "Educational neuroscience . Almost all of the neurons in the brain are generated before birth, during the first three months of pregnancy, and the newborn child\u2019s brain has a similar number of neurons to that of an adult. Many more neurons form than are needed, and only those that form active connections with other neurons survive. In the first year after birth the infant brain undergoes an intense phase of development, during which excessive numbers of connections between neurons are formed, and many of these excess connections must be cut back through the process of synaptic pruning that follows. This pruning process is just as important a stage of development as the early rapid growth of connections between brain cells. The process during which large numbers of connections between neurons are formed is called synaptogenesis. For vision and hearing (visual and auditory cortex), there is extensive early synaptogenesis. The density of connections peaks at around 150% of adult levels between four and 12 months, and the connections are then extensively pruned. Synaptic density returns to adult levels between two and four years in the visual cortex. For other areas such as prefrontal cortex (thought to underpin planning and reasoning), density increases more slowly and peaks after the first year. Reduction to adult levels of density takes at least another 10\u201320 years; hence there is significant brain development in the frontal areas even in adolescence. Brain metabolism (glucose uptake, which is an approximate index of synaptic functioning) is also above adult levels in the early years. Glucose uptake peaks at about 150% of adult levels somewhere around four to five years. By the age of around ten years, brain metabolism has reduced to adult levels for most cortical regions. Brain development consists of bursts of synaptogenesis, peaks of density, and then synapse rearrangement and stabilisation. This occurs at different times and different rates for different brain regions, which implies that there may be different sensitive periods for the development of different types of knowledge. Neuroscience research into early brain development has informed government education policy for children under three years old in many countries including the USA and the United Kingdom. These policies have focused on enriching the environment of children during nursery and preschool years, exposing them to stimuli and experiences thought to maximise the learning potential of the young brain.",
            "score": 101.9922878742218
        },
        {
            "docid": "53116300_19",
            "document": "The Tale of the Dueling Neurosurgeons . Another thing that concerns wiring and rewiring is the neurological phenomenon of synesthesia. There are over 60 known types of synesthesia. An example would be a synesthesiat hearing a sound and colors flooding their vision or someone reading a passage of words and each letter evokes a different color or a different smell or a different taste. Certain sounds cause the person to feel certain things in turn, or see spots of color dance across their vision. Neurologists agree that this occurs of faulty wiring in the brain, that \"neuron circuits that process a sense accidentally strum circuits of another sense, causing both to go off simultaneously\". It is debated how this happens. As a child, one possesses more neurons than necessary and the unnecessary ones are pruned away and die when not used. Some believe that synesthesia is a result of poor pruning.",
            "score": 64.6430094242096
        },
        {
            "docid": "7913402_16",
            "document": "Paul Baltes . Neuronal plasticity, or the capability of the brain to adapt to new requirements, is a prime example of plasticity stressing that the individual\u2019s ability to change is a lifelong process. Recently, researchers have been analyzing how the spared senses compensate for the loss of vision. Without visual input, blind humans have demonstrated that tactile and auditory functions still fully develop. A superiority of the blind has even been observed when they are presented with tactile and auditory tasks. This superiority may suggest that the specific sensory experiences of the blind may influence the development of certain sensory functions, namely tactile and auditory. One experiment was designed by R\u00f6der and colleagues to clarify the auditory localization skills of the blind in comparison to the sighted. They examined both blind human adults\u2019 and sighted human adults\u2019 abilities to locate sounds presented either central or peripheral (lateral) to them. Both congenitally blind adults and sighted adults could locate a sound presented in front of them with precision but the blind were clearly superior in locating sounds presented laterally. Currently, brain-imaging studies have revealed that the sensory cortices in the brain are reorganized after visual deprivation. These findings suggest that when vision is absent in development, the auditory cortices in the brain recruit areas that are normally devoted to vision, thus becoming further refined.",
            "score": 106.83947217464447
        },
        {
            "docid": "53983908_5",
            "document": "Al's Brain . The short film includes a brand new song entitled \"The Brain Song,\" which happens near the end of the film, in many different styles of animation. It starts with a picture of the brain which then starts to move. It shows you that he brain is \"divided into two hemispheres\" and that the left side \"controls your right side and your left controls your right side\" which happen to be \"tied together\" by the Corpus Callosum, as well showing that the brain is covered with a meninges layer, cerebral spinal fluid and afterwards you are looking at the four lobes of the brain, which compose of the Frontal, the temporal, the parietal and the occipital lobes and that they are all important. It shows you that the reason we can see things is because \"eyes cones are sending stimuli to your thalamus, which joins up to your occipital lobe,\" and that you can hear things when the \"scilia down in your ear\" vibrate and send \"those impulses along to your temporal lobe.\" Al then shows through a telescope how the different parts of the brain can \"communicate with each other.\" It shows a school of neuron, \"a funky funky neuron,\" which has an axxon on one side and a denox on the other side. It then shows what happens when a neuron's denox gets a signal from another neuron, it \"sparks a chemical reaction in the nucleus,\" which creates a \"nerve impulse which travels down a long long myelin coated strand.\" The neurotransmitter molecules then enter the vesicle of the axon terminal, and then the neurotransmitters \"jump a millionth of an inch across the synaptic gap\" which then enter into \"the receptors of the dendrox of another neuron,\" which connects \"neuron to neuron to neuron to neuron all across your entire brain.\" This also explains that the more you use your brain, the smarter you'll be. The video/film ends with Al saying, \"...Always, always, ALWAYS... ...wear a helmet. That's all I'm really trying to say here.\" He then waves goodbye to everyone.",
            "score": 84.85201478004456
        },
        {
            "docid": "404084_26",
            "document": "Hebbian theory . Christian Keysers and David Perrett suggested that, while an individual performs a particular action, the individual will see, hear, and feel himself perform the action. These re-afferent sensory signals will trigger activity in neurons responding to the sight, sound, and feel of the action. Because the activity of these sensory neurons will consistently overlap in time with those of the motor neurons that caused the action, Hebbian learning would predict that the synapses connecting neurons responding to the sight, sound, and feel of an action and those of the neurons triggering the action should be potentiated. The same is true while people look at themselves in the mirror, hear themselves babble, or are imitated by others. After repeated experience of this re-afference, the synapses connecting the sensory and motor representations of an action would be so strong that the motor neurons would start firing to the sound or the vision of the action, and a mirror neuron would have been created.",
            "score": 32.838149309158325
        },
        {
            "docid": "47338295_7",
            "document": "Sound localization in owls . The fibers of the auditory nerve innervate both cochlear nuclei in the brainstem, the cochlear nucleus magnocellularis (mammalian anteroventral cochlear nucleus) and the cochlear nucleus angularis (see figure; mammalian posteroventral and dorsal cochlear nuclei). The neurons of the nucleus magnocellularis phase-lock, but are fairly insensitive to variations in sound pressure, while the neurons of the nucleus angularis phase-lock poorly, if at all, but are sensitive to variations in sound pressure. These two nuclei are the starting points of two separate but parallel pathways to the inferior colliculus: the pathway from nucleus magnocellularis processes ITDs, and the pathway from nucleus angularis processes IID.",
            "score": 107.42525672912598
        },
        {
            "docid": "25429544_5",
            "document": "Sleep onset . Von Economo, in his studies, noticed that lesions in the connection between the midbrain and the diencephalon caused prolonged sleepiness and therefore proposed the idea of an ascending arousal system. During the past few decades major ascending pathways have been discovered with located neurons and respective neurotransmitters. This pathway divides into two branches: one that ascends to the thalamus and activates the thalamus relay neurons, and another one that activates neurons in the lateral part of the hypothalamus and the basal forebrain, and throughout the cerebral cortex. The cell group involved in the first pathway is an acetylcholine-producing cell group called pedunculopontine and laterodorsal tegmental nucleus(PPT/LDT). These neurons play a crucial role in bridging information in between the thalamus and the cerebral cortex. These neurons have high activation during wakefulness and during REM sleep and a low activation during NREM sleep. The second branch originates from monoaminorgenic neurons. These neurons are located in the locus coeruleus, dorsal and median raphe nuclei, ventral periaqueductal grey matter, and tuberomammillary nucleus. Each group produces a different neurotransmitter. The neurons in the locus coeruleus produce noradrenaline, as fore the neurons in the dorsal and median raphe nuclei, ventral periaqueductal grey matter, and tuberomammillary nucleus produce serotonin, dopamine and histamine respectively. They then project onto the hypothalamic peptidergic neurons, which contain melanin-concentrated hormones or orexin, and basal forebrain neurons which contain GABA and acetylcholine. These neurons then project onto the cerebral cortex. It has also been discovered that lesions to this part of the brain cause prolonged sleep or may produce coma.",
            "score": 87.03008460998535
        },
        {
            "docid": "3339030_5",
            "document": "Allodynia . The cell types involved in nociception and mechanical sensation are the cells responsible for allodynia. In healthy individuals, nociceptors sense information about cell stress or damage and temperature at the skin and transmit it to the spinal cord. The cell bodies of these neurons lie in dorsal root ganglia, important structures located on both sides of the spinal cord. The axons then pass through the dorsal horn to make connections with secondary neurons. The secondary neurons cross over to the other (contralateral) side of the spinal cord and reach nuclei of the thalamus. From there, the information is carried through one or more neurons to the somatosensory cortex of the brain. Mechanoreceptors follow the same general pathway. However, they do not cross over at the level of the spinal cord, but at the lower medulla instead. In addition, they are grouped in tracts that are spatially distinct from the nociceptive tracts.",
            "score": 94.16970038414001
        },
        {
            "docid": "33767830_10",
            "document": "Conspecific song preference . Neurons in both Field L and CM have sophisticated filter properties, selective for both the spectral-temporal modulations and phase relationships of conspecific songs. Furthermore, different neurons are selective for different features of syllables and songs. In Field L, neurons have one of four different tuning strategies\u2014they are either tightly tuned a particular frequency, or they are sensitive to frequency edges, frequency sweeps or combined frequencies. When exposed to natural song as a stimulus, different ensembles of these of neurons respond to different components of sound, and together they demonstrate the ability to perform sensitive discrimination between conspecific and heterospecific syllable types. As in nucleus ovoidalis, the spectral-temporal filter properties of Field L and CM neurons are a function of the particular ion channels and receptor proteins driving their synaptic dynamics. The complex and sophisticated tuning of these higher order processing centers for conspecific sounds may rely on the integrated inputs from the entire ascending auditory pathway, from the hair cells through the thalamus and forebrain, but this challenging synthetic question remains to be investigated.",
            "score": 72.71622347831726
        },
        {
            "docid": "5128182_13",
            "document": "Encoding (memory) . Encoding is achieved using a combination of chemicals and electricity. Neurotransmitters are released when an electrical pulse crosses the synapse which serves as a connection from nerve cells to other cells. The dendrites receive these impulses with their feathery extensions. A phenomenon called long-term potentiation allows a synapse to increase strength with increasing numbers of transmitted signals between the two neurons. For that to happen, NMDA receptor, which influences the flow of information between neurons by controlling the initiation of long-term potentiation in most hippocampal pathways, need to come to the play. For these NMDA receptors to be activated, there must be two conditions. Firstly, glutamate has to be released and bound to the NMDA receptor site on postsynaptic neurons. Secondly, excitation has to take place in postsynaptic neurons. These cells also organise themselves into groups specializing in different kinds of information processing. Thus, with new experiences the brain creates more connections and may 'rewire'. The brain organizes and reorganizes itself in response to one's experiences, creating new memories prompted by experience, education, or training. Therefore, the use of a brain reflects how it is organised. This ability to re-organize is especially important if ever a part of the brain becomes damaged. Scientists are unsure of whether the stimuli of what we do not recall are filtered out at the sensory phase or if they are filtered out after the brain examines their significance.",
            "score": 95.38112127780914
        },
        {
            "docid": "27169449_13",
            "document": "Auditory spatial attention . Further evidence as to the modality specificity of the 'what' and 'where' pathways has been provided in a recent study by Diaconescu et al., who suggest that while 'what' processes have discrete pathways for vision and audition, the 'where' pathway may be supra-modal, shared by both modalities. Participants were asked in randomly alternating trials to respond to either the feature or spatial elements of stimuli, which varied between the auditory and visual domain in set blocks. Between two experiments, the modality of the cue was also varied; the first experiment contained auditory cues as to which element (feature or spatial) of the stimuli to respond to, while the second experiment utilized visual cues. During the period between cue and target, when participants were presumably attending to the cued feature to be presented, both auditory and vision spatial attention conditions elicited greater positivity in source space from a centro-medial location at 600-1200 ms following cue onset, which the authors of the study propose may be the result of a supra-modal pathway for spatial information. Conversely, source space activity for feature attention were not consistent between modalities, with auditory feature attention associated with greater positivity at the right auditory radial dipole around 300-600 ms, and spatial feature attention associated with greater negativity at the left-visual central-inferior dipole at 700-1050ms, suggested as evidence for separate feature or 'what' pathways for vision and audition.",
            "score": 98.40757167339325
        },
        {
            "docid": "490620_3",
            "document": "Human brain . The cerebrum is connected by the brainstem to the spinal cord. The brainstem consists of the midbrain, the pons, and the medulla oblongata. The cerebellum is connected to the brainstem by pairs of tracts. Within the cerebrum is the ventricular system, consisting of four interconnected ventricles in which cerebrospinal fluid is produced and circulated. Underneath the cerebral cortex are several important structures, including the thalamus, the epithalamus, the pineal gland, the hypothalamus, the pituitary gland, and the subthalamus; the limbic structures, including the amygdala and the hippocampus; the claustrum, the various nuclei of the basal ganglia; the basal forebrain structures, and the three circumventricular organs. The cells of the brain include neurons and supportive glial cells. There are more than 86 billion neurons in the brain, and a more or less equal number of other cells. Brain activity is made possible by the interconnections of neurons and their release of neurotransmitters in response to nerve impulses. Neurons connect to form neural pathways, neural circuits, and elaborate network systems. The whole circuitry is driven by the process of neurotransmission.",
            "score": 97.76451706886292
        },
        {
            "docid": "490620_36",
            "document": "Human brain . From the skin, the brain receives information about fine touch, pressure, pain, vibration and temperature. From the joints, the brain receives information about joint position. The sensory cortex is found just near the motor cortex, and, like the motor cortex, has areas related to sensation from different body parts. Sensation collected by a sensory receptor on the skin is changed to a nerve signal, that is passed up a series of neurons through tracts in the spinal cord. The dorsal column\u2013medial lemniscus pathway contains information about fine touch, vibration and position of joints. Neurons travel up the back part of the spinal cord to the back part of the medulla, where they connect with \"second order\" neurons that immediately swap sides. These neurons then travel upwards into the ventrobasal complex in the thalamus where they connect with \"third order\" neurons, and travel up to the sensory cortex.The spinothalamic tract carries information about pain, temperature, and gross touch. Neurons travel up the spinal cord and connect with second-order neurons in the reticular formation of the brainstem for pain and temperature, and also at the ventrobasal complex of the medulla for gross touch.",
            "score": 99.20401525497437
        },
        {
            "docid": "2503592_2",
            "document": "Medial geniculate nucleus . The medial geniculate nucleus (MGN) or medial geniculate body (MGB) is part of the auditory thalamus and represents the thalamic relay between the inferior colliculus (IC) and the auditory cortex (AC). It is made up of a number of sub-nuclei that are distinguished by their neuronal morphology and density, by their afferent and efferent connections, and by the coding properties of their neurons. It is thought that the MGB influences the direction and maintenance of attention.",
            "score": 77.02046751976013
        },
        {
            "docid": "12142270_3",
            "document": "GENESIS (software) . GENESIS works by creating simulation environments for constructing models of neurons or neural systems. \"Nerve cells are capable of communicating with each other in such a highly structured manner as to form neuronal networks. To understand neural networks, it is necessary to understand the ways in which one neuron communicates with another through synaptic connections and the process called synaptic transmission\". Neurons have a specialized structure for their function, they \"are different from most other cells in the body in that they are polarized and have distinct morphological regions, each with specific functions\". The two important regions of a neuron are the dendrite and the axon. \"Dendrites are the region where one neuron receives connections from other neurons. The cell body or soma contains the nucleus and the other organelles necessary for cellular function. The axon is a key component of nerve cells over which information is transmitted from one part of the neuron (e.g., the cell body) to the terminal regions of the neuron\". The third important piece of a neuron is the synapse. \"The synapse is the terminal region of the axon this is where one neuron forms a connection with another and conveys information through the process of synaptic transmission\".",
            "score": 82.46644854545593
        },
        {
            "docid": "7527647_19",
            "document": "Binaural fusion . MSO neurons are excited bilaterally, meaning that they are excited by inputs from both ears, and they are therefore referred to as EE neurons. Fibers from the left cochlear nucleus terminate on the left of MSO neurons, and fibers from the right cochlear nucleus terminate on the right of MSO neurons. Excitatory inputs to the MSO from spherical bushy cells are mediated by glutamate, and inhibitory inputs to the MSO from globular bushy cells are mediated by glycine. MSO neurons extract ITD information from binaural inputs and resolve small differences in the time of arrival of sounds at each ear. Outputs from the MSO and LSO are sent via the lateral lemniscus to the IC, which integrates the spatial localization of sound. In the IC, acoustic cues have been processed and filtered into separate streams, forming the basis of auditory object recognition.",
            "score": 85.69606900215149
        },
        {
            "docid": "1085361_2",
            "document": "Inferior colliculus . The inferior colliculus (IC) (Latin for \"lower hill\") is the principal midbrain nucleus of the auditory pathway and receives input from several peripheral brainstem nuclei in the auditory pathway, as well as inputs from the auditory cortex. The inferior colliculus has three subdivisions: the central nucleus, a dorsal cortex by which it is surrounded, and an external cortex which is located laterally. Its bimodal neurons are implicated in auditory-somatosensory interaction, receiving projections from somatosensory nuclei. This multisensory integration may underlie a filtering of self-effected sounds from vocalization, chewing, or respiration activities.",
            "score": 157.36617588996887
        },
        {
            "docid": "3665897_3",
            "document": "Lateralization of brain function . Lateralization of brain structures is based on general trends expressed in healthy patients; however, there are numerous counterexamples to each generalization. Each human\u2019s brain develops differently leading to unique lateralization in individuals. This is different from specialization as lateralization refers only to the function of one structure divided between two hemispheres. Specialization is much easier to observe as a trend since it has a stronger anthropological history. The best example of an established lateralization is that of Broca's and Wernicke's areas where both are often found exclusively on the left hemisphere. These areas frequently correspond to handedness, however, meaning that the localization of these areas is regularly found on the hemisphere corresponding to the dominant hand (anatomically on the opposite side). Function lateralization such as semantics, intonation, accentuation, prosody, etc. has since been called into question and largely been found to have a neuronal basis in both hemispheres. Another example is that each hemisphere in the brain tends to represent one side of the body. In the cerebellum this is the same bodyside, but in the forebrain this is predominantly the contralateral side.",
            "score": 83.98579430580139
        },
        {
            "docid": "39265695_7",
            "document": "Stimulus filtering . Female flies of the genus \"Ormia ochracea\" possess organs in their bodies that can detect frequencies of cricket sounds from meters away. This process is important for the survival of their species because females will lay their first instar larvae into the body of the cricket, where they will feed and molt for approximately seven days. After this period, the larvae grow into flies and the cricket usually perishes. Researchers were puzzled about how precise hearing ability could arise from a small ear structure. Normal animals detect and locate sounds using the interaural time difference (ITD) and the interaural level difference (ILD). The ITD is the difference in the time it takes sound to reach the ear. ILD is the difference in sound intensity measure between both ears. At maximum, the ITD would only reach about 1.5 microseconds and the ILD would be less than one decibel. These small values make it hard to sense the differences. To solve these issues, researchers studied the mechanical aspects of flies\u2019 ears. They found that they have a presternum structure linking both tympanal membranes that is critical in detecting sound and localization. The structure acts as a lever by transferring and amplifying vibrational energy between the membranes. After sound hits the membranes at different amplitudes, the presternum sets up symmetrical vibration modes through bending and rocking. This effect helps the nervous system distinguish which side the sound is coming from. Because the presternum acts as an intertympanal bridge, the ITD is increased from 1.5 us to 55 us and the ILD is increased from less than one decibel to over 10 decibels.",
            "score": 82.72136735916138
        }
    ],
    "r": [
        {
            "docid": "1085361_2",
            "document": "Inferior colliculus . The inferior colliculus (IC) (Latin for \"lower hill\") is the principal midbrain nucleus of the auditory pathway and receives input from several peripheral brainstem nuclei in the auditory pathway, as well as inputs from the auditory cortex. The inferior colliculus has three subdivisions: the central nucleus, a dorsal cortex by which it is surrounded, and an external cortex which is located laterally. Its bimodal neurons are implicated in auditory-somatosensory interaction, receiving projections from somatosensory nuclei. This multisensory integration may underlie a filtering of self-effected sounds from vocalization, chewing, or respiration activities.",
            "score": 157.36618041992188
        },
        {
            "docid": "233528_5",
            "document": "Brainstem . The midbrain is divided into three parts: tectum, tegmentum, and the ventral tegmentum. The tectum (Latin:roof), which forms the ceiling. The tectum comprises the paired structure of the superior and inferior colliculi and is the dorsal covering of the cerebral aqueduct. The inferior colliculus, is the principal midbrain nucleus of the auditory pathway and receives input from several peripheral brainstem nuclei, as well as inputs from the auditory cortex. Its inferior brachium (arm-like process) reaches to the medial geniculate nucleus of the diencephalon. Superior to the inferior colliculus, the superior colliculus marks the rostral midbrain. It is involved in the special sense of vision and sends its superior brachium to the lateral geniculate body of the diencephalon. The tegmentum which forms the floor of the midbrain, and is ventral to the cerebral aqueduct. Several nuclei, tracts, and the reticular formation are contained here. The ventral tegmentum is composed of paired cerebral peduncles. These transmit axons of upper motor neurons.",
            "score": 152.99053955078125
        },
        {
            "docid": "21282020_10",
            "document": "Hearing . The sound information from the cochlea travels via the auditory nerve to the cochlear nucleus in the brainstem. From there, the signals are projected to the inferior colliculus in the midbrain tectum. The inferior colliculus integrates auditory input with limited input from other parts of the brain and is involved in subconscious reflexes such as the auditory startle response.",
            "score": 148.00205993652344
        },
        {
            "docid": "32116125_4",
            "document": "Amblyaudia . Amblyaudia is a deficit in binaural integration of environmental information entering the auditory system. It is a disorder related to brain organization and function rather than what is typically considered a \u201chearing loss\u201d (damage to the cochlea). It may be genetic or developmentally acquired or both. When animals are temporarily deprived of hearing from an early age, profound changes occur in the brain. Specifically, cell sizes in brainstem nuclei are reduced, the configuration of brainstem dendrites are altered and neurons respond in different ways to sounds presented to both the deprived and non-deprived ears (in cases of asymmetric deprivation). This last point is particularly important for listening tasks that require inputs from two ears to perform well. There are multiple auditory functions that rely on the computation of well calibrated inputs from the two ears. Chief among these is the ability to localize sound sources and separate what we want to hear from a background of noise. In the brainstem, the auditory system compares the timing and levels of sounds between the two ears to encode the location of sound sources (sounds that originate from our right as opposed to left side are louder and arrive earlier in our right ear). This ability to separate sound sources not only helps us locate the trajectories of moving objects, but also to separate different sound sources in noisy environments.",
            "score": 143.91087341308594
        },
        {
            "docid": "69274_35",
            "document": "Animal echolocation . In the Inferior colliculus, a structure in the bat's midbrain, information from lower in the auditory processing pathway is integrated and sent on to the auditory cortex. As George Pollak and others showed in a series of papers in 1977, the interneurons in this region have a very high level of sensitivity to time differences, since the time delay between a call and the returning echo tells the bat its distance from the target object. While most neurons respond more quickly to stronger stimuli, collicular neurons maintain their timing accuracy even as signal intensity changes.",
            "score": 142.7270050048828
        },
        {
            "docid": "5051081_4",
            "document": "Eric Knudsen . In 1978, Knudsen and Konishi presented the discovery of an auditory map of space in the midbrain of the barn owl. This discovery was groundbreaking because it unearthed the first non-somatotopic space map in the brain. The map was found in the owl\u2019s midbrain, in the lateral and anterior mesencephalicus lateralis dorsalis (MLD), a structure now referred to as the inferior colliculus. Unlike most sound-localization maps, this map was found to be two-dimensional, with units arranged spatially to represent both the vertical and horizontal location of sound. Knudsen and Konishi discovered that units in this structure respond preferentially to sounds originating in a particular region in space. In the 1978 paper, elevation and azimuth (location in the horizontal plane) were shown to be the two coordinates of the map. Using a speaker set on a rotatable hemispherical track, Knudsen and Konishi presented owls with auditory stimulus from various locations in space and recorded the resulting neuronal activity. They found that neurons in this part of the MLD were organized according to the location of their receptive field, with azimuth varying along the horizontal plane of the space map and elevation varying vertically.  Knudsen followed this discovery with research into specific sound localization mechanisms. Two main auditory cues used by the barn owl to localize sound are interaural time difference (ITD) and interaural intensity difference (IID). The owl\u2019s ears are asymmetric, with the right ear\u2019s opening being directed higher than that of the left. This asymmetry allows the barn owl to determine the elevation of a sound by comparing sound levels between its two ears. Interaural time differences provide the owl with information regarding a sound\u2019s azimuth; sound will reach the ear closer to the sound source before reaching the farther ear, and this time difference can be detected and interpreted as an azimuthal direction. At low frequencies, the wavelength of a sound is wider than the owl's facial ruff, and the ruff does not affect detection of azimuth. At high frequencies, the ruff plays a role in reflecting sound for heightened sensitivity to vertical elevation. Therefore, with wide-band noise, containing both high and low frequencies, the owl could use interaural spectrum difference to obtain information about both azimuth and elevation. In 1979, Knudsen and Konishi showed that the barn owl uses interaural spectrum information in sound localization. They presented owls with both wide-bandwidth noise and pure tones. The birds were able to successfully locate pure tones (since they could still gather information from IID and ITD), but their error rate was much lower when localizing wide-bandwidth noise. This indicates that the birds utilize interaural spectrum differences to improve their accuracy.",
            "score": 142.16647338867188
        },
        {
            "docid": "1222458_3",
            "document": "Tonotopy . Tonotopy in the auditory system begins at the cochlea, the small snail-like structure in the inner ear that sends information about sound to the brain. Different regions of the basilar membrane in the organ of Corti, the sound-sensitive portion of the cochlea, vibrate at different sinusoidal frequencies due to variations in thickness and width along the length of the membrane. Nerves that transmit information from different regions of the basilar membrane therefore encode frequency tonotopically. This tonotopy then projects through the vestibulocochlear nerve and associated midbrain structures to the primary auditory cortex via the auditory radiation pathway. Throughout this radiation, organization is linear with relation to placement on the organ of Corti, in accordance to the best frequency response (that is, the frequency at which that neuron is most sensitive) of each neuron. However, binaural fusion in the superior olivary complex onward adds significant amounts of information encoded in the signal strength of each ganglion. Thus, the number of tonotopic maps varies between species and the degree of binaural synthesis and separation of sound intensities; in humans, six tonotopic maps have been identified in the primary auditory cortex. their anatomical locations along the auditory cortex.",
            "score": 140.31858825683594
        },
        {
            "docid": "32105732_6",
            "document": "Spatial hearing loss . By the time sound stream representations reach the end of the auditory pathways brainstem inhibition processing ensures that the right pathway is solely responsible for the left ear sounds and the left pathway is solely responsible for the right ear sounds. It is then the responsibility of the auditory cortex (AC) of the right hemisphere (on its own) to map the whole auditory scene. Information about the right auditory hemifield joins with the information about the left hemifield once it has passed through the corpus callosum (CC) - the brain white matter that connects homologous regions of the left and right hemispheres. Some of those with spatial hearing loss are unable to integrate the auditory representations of the left and right hemifields, and consequently are unable to maintain any representation of auditory space.",
            "score": 138.6414337158203
        },
        {
            "docid": "78227_14",
            "document": "Thalamus . The thalamus has multiple functions, generally believed to act as a relay station, or hub, relaying information between different subcortical areas and the cerebral cortex. In particular, every sensory system (with the exception of the olfactory system) includes a thalamic nucleus that receives sensory signals and sends them to the associated primary cortical area. For the visual system, for example, inputs from the retina are sent to the lateral geniculate nucleus of the thalamus, which in turn projects to the visual cortex in the occipital lobe. The thalamus is believed to both process sensory information as well as relay it\u2014each of the primary sensory relay areas receives strong feedback connections from the cerebral cortex. Similarly the medial geniculate nucleus acts as a key auditory relay between the inferior colliculus of the midbrain and the primary auditory cortex. The ventral posterior nucleus is a key somatosensory relay, which sends touch and proprioceptive information to the primary somatosensory cortex.",
            "score": 138.41635131835938
        },
        {
            "docid": "2534964_14",
            "document": "Sensory processing . Perhaps one of the most studied sensory integrations is the relationship between vision and audition. These two senses perceive the same objects in the world in different ways, and by combining the two, they help us understand this information better. Vision dominates our perception of the world around us. This is because visual spatial information is one of the most reliable sensory modalities. Visual stimuli are recorded directly onto the retina, and there are few, if any, external distortions that provide incorrect information to the brain about the true location of an object. Other spatial information is not as reliable as visual spatial information. For example, consider auditory spatial input. The location of an object can sometimes be determined solely on its sound, but the sensory input can easily be modified or altered, thus giving a less reliable spatial representation of the object. Auditory information therefore is not spatially represented unlike visual stimuli. But once one has the spatial mapping from the visual information, multisensory integration helps bring the information from both the visual and auditory stimuli together to make a more robust mapping.",
            "score": 138.34971618652344
        },
        {
            "docid": "6766895_8",
            "document": "Topographic map (neuroanatomy) . The auditory system is the sensory system for hearing in which the brain interprets information from the frequency of sound waves, yielding the perception of tones. Sound waves enter the ear through the auditory canal. These waves arrive at the eardrum where the properties of the waves are transduced into vibrations. The vibrations travel through the bones of the inner ear to the cochlea. In the cochlea, the vibrations are transduced into electrical information through the firing of hair cells in the organ of Corti. The organ of Corti projects in an orderly fashion to structures in the brainstem (namely, the cochlear nuclei and the inferior colliculus), and from there to the medial geniculate nucleus of the thalamus and the primary auditory cortex. Adjacent sites on the organ of Corti, which are themselves selective for the sound frequency, are represented by adjacent neurons in the aforementioned CNS structures. This projection pattern has been termed tonotopy.",
            "score": 136.15296936035156
        },
        {
            "docid": "35075711_26",
            "document": "Spontaneous recovery . The pathway of recall associated with the retrieval of sound memories is the auditory system. Within the auditory system is the auditory cortex, which can be broken down into the primary auditory cortex and the belt areas. The primary auditory cortex is the main region of the brain that processes sound and is located on the superior temporal gyrus in the temporal lobe where it receives point-to-point input from the medial geniculate nucleus. From this, the primary auditory complex had a topographic map of the cochlea. The belt areas of the auditory complex receive more diffuse input from peripheral areas of the medial geniculate nucleus and therefore are less precise in tonotopic organization compared to the primary visual cortex. A 2001 study by Trama examined how different kinds of brain damage interfere with normal perception of music. One of his studied patients lost most of his auditory cortex to strokes, allowing him to still hear but making it difficult to understand music since he could not recognize harmonic patterns. Detecting a similarity between speech perception and sound perception, spontaneous recovery of lost auditory information is possible in those patients who have experienced a stroke or other major head trauma. Amusia is a disorder manifesting itself as a defect in processing pitch but also affects one's memory and recognition for music.",
            "score": 133.99057006835938
        },
        {
            "docid": "25140_41",
            "document": "Perception . Hearing (or \"audition\") is the ability to perceive sound by detecting vibrations. Frequencies capable of being heard by humans are called audio or \"sonic\". The range is typically considered to be between 20\u00a0Hz and 20,000\u00a0Hz. Frequencies higher than audio are referred to as ultrasonic, while frequencies below audio are referred to as infrasonic. The auditory system includes the outer ears which collect and filter sound waves, the middle ear for transforming the sound pressure (impedance matching), and the inner ear which produces neural signals in response to the sound. By the ascending auditory pathway these are led to the primary auditory cortex within the temporal lobe of the human brain, which is where the auditory information arrives in the cerebral cortex and is further processed there.",
            "score": 131.34132385253906
        },
        {
            "docid": "4455796_10",
            "document": "Lateral inhibition . Similarities between sensory processes of the skin and the auditory system suggest lateral inhibition could play a role in auditory processing. The basilar membrane in the cochlea has receptive fields similar to the receptive fields of the skin and eyes. Also, neighboring cells in the auditory cortex have similar specific frequencies that cause them to fire, creating a map of sound frequencies similar to that of the somatosensory cortex. Lateral inhibition in tonotopic channels can be found in the inferior colliculus and at higher levels of auditory processing in the brain. However, the role that lateral inhibition plays in auditory sensation is unclear. Some scientists found that lateral inhibition could play a role in sharpening spatial input patterns and temporal changes in sensation, others propose it plays an important role in processing low or high tones.",
            "score": 131.22682189941406
        },
        {
            "docid": "32116125_2",
            "document": "Amblyaudia . Amblyaudia (amblyos- blunt; audia-hearing) is a term coined by Dr. Deborah Moncrieff from the University of Pittsburgh to characterize a specific pattern of performance from dichotic listening tests. Dichotic listening tests are widely used to assess individuals for binaural integration, a type of auditory processing skill. During the tests, individuals are asked to identify different words presented simultaneously to the two ears. Normal listeners can identify the words fairly well and show a small difference between the two ears with one ear slightly dominant over the other. For the majority of listeners, this small difference is referred to as a \"right-ear advantage\" because their right ear performs slightly better than their left ear. But some normal individuals produce a \"left-ear advantage\" during dichotic tests and others perform at equal levels in the two ears. Amblyaudia is diagnosed when the scores from the two ears are significantly different with the individual's dominant ear score much higher than the score in the non-dominant ear  Researchers interested in understanding the neurophysiological underpinnings of amblyaudia consider it to be a brain based hearing disorder that may be inherited or that may result from auditory deprivation during critical periods of brain development. Individuals with amblyaudia have normal hearing sensitivity (in other words they hear soft sounds) but have difficulty hearing in noisy environments like restaurants or classrooms. Even in quiet environments, individuals with amblyaudia may fail to understand what they are hearing, especially if the information is new or complicated. Amblyaudia can be conceptualized as the auditory analog of the better known central visual disorder amblyopia. The term \u201clazy ear\u201d has been used to describe amblyaudia although it is currently not known whether it stems from deficits in the auditory periphery (middle ear or cochlea) or from other parts of the auditory system in the brain, or both. A characteristic of amblyaudia is suppression of activity in the non-dominant auditory pathway by activity in the dominant pathway which may be genetically determined and which could also be exacerbated by conditions throughout early development.",
            "score": 130.87884521484375
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 130.55010986328125
        },
        {
            "docid": "1619306_6",
            "document": "Multisensory integration . However, considerations of how unified conscious representations are formed are not the full focus of multisensory Integration research. It is obviously important for the senses to interact in order to maximize how efficiently people interact with the environment. For perceptual experience and behavior to benefit from the simultaneous stimulation of multiple sensory modalities, integration of the information from these modalities is necessary. Some of the mechanisms mediating this phenomenon and its subsequent effects on cognitive and behavioural processes will be examined hereafter. Perception is often defined as one's conscious experience, and thereby combines inputs from all relevant senses and prior knowledge. Perception is also defined and studied in terms of feature extraction, which is several hundred milliseconds away from conscious experience. Notwithstanding the existence of Gestalt psychology schools that advocate a holistic approach to the operation of the brain, the physiological processes underlying the formation of percepts and conscious experience have been vastly understudied. Nevertheless, burgeoning neuroscience research continues to enrich our understanding of the many details of the brain, including neural structures implicated in multisensory integration such as the superior colliculus (SC) and various cortical structures such as the superior temporal gyrus (GT) and visual and auditory association areas. Although the structure and function of the SC are well known, the cortex and the relationship between its constituent parts are presently the subject of much investigation. Concurrently, the recent impetus on integration has enabled investigation into perceptual phenomena such as the ventriloquism effect, rapid localization of stimuli and the McGurk effect; culminating in a more thorough understanding of the human brain and its functions.",
            "score": 128.09698486328125
        },
        {
            "docid": "251010_24",
            "document": "Whiskers . A large part of the brain of whisker-specialist mammals is involved in the processing of nerve impulses from vibrissae, a fact that presumably corresponds to the important position the sense occupies for the animal. Information from the vibrissae arrives in the brain via the trigeminal nerve and is delivered first into the trigeminal sensory complex of brainstem. From there, the most studied pathways are those leading up through parts of thalamus and into barrel cortex, though other major pathways through the superior colliculus in midbrain (a major visual structure in visual animals) and the cerebellum, to name but a couple, are increasingly coming under scrutiny. Neuroscientists, and other researchers, studying sensory systems favour the whisker system for a number of reasons (see Barrel cortex), not least the simple fact that laboratory rats and mice are whisker, rather than visual, specialists.",
            "score": 127.64533996582031
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 126.55989837646484
        },
        {
            "docid": "4231622_5",
            "document": "Inferior temporal gyrus . The temporal lobe is unique to primates. In humans, the IT cortex is more complex than their relative primate counterparts. The human inferior temporal cortex consists of the inferior temporal gyrus, the middle temporal gyrus, and the fusiform gyrus. When looking at the brain laterally \u2013 that is from the side and looking at the surface of the temporal lobe \u2013 the inferior temporal gyrus is along the bottom portion of the temporal lobe, and is separated from the middle temporal gyrus located directly above by the inferior temporal sulcus. Additionally, some processing of the visual field that corresponds to the ventral stream of visual processing occurs in the lower portion of the superior temporal gyrus closest to the superior temporal sulcus. The medial and ventral view of the brain \u2013 meaning looking at the medial surface from below the brain, facing upwards \u2013 reveals that the inferior temporal gyrus is separated from the fusiform gyrus by the occipital-temporal sulcus. This human inferior temporal cortex is much more complex than that of other primates: non-human primates have an inferior temporal cortex that is not divided into unique regions such as humans' inferior temporal gyrus, fusiform gyrus, or middle temporal gyrus.  This region of the brain corresponds to the inferior temporal cortex and is responsible for visual object recognition and receives processed visual information. The inferior temporal cortex in primates has specific regions dedicated to processing different visual stimuli processed and organized by the different layers of the striate cortex and extra-striate cortex. The information from the V1 \u2013V5 regions of the geniculate and tectopulvinar pathways are radiated to the IT cortex via the ventral stream: visual information specifically related to the color and form of the visual stimuli. Through comparative research between primates \u2013 humans and non-human primates \u2013 results indicate that the IT cortex plays a significant role in visual shape processing. This is supported by functional magnetic resonance imaging (fMRI) data collected by researchers comparing this neurological process between humans and macaques.",
            "score": 125.6700668334961
        },
        {
            "docid": "4301708_10",
            "document": "Cochlear nucleus . The cochlear nuclear complex is the first integrative, or processing, stage in the auditory system. Information is brought to the nuclei from the ipsilateral cochlea via the cochlear nerve. Several tasks are performed in the cochlear nuclei. By distributing acoustic input to multiple types of principal cells, the auditory pathway is subdivided into parallel ascending pathways, which can simultaneously extract different types of information. The cells of the ventral cochlear nucleus extract information that is carried by the auditory nerve in the timing of firing and in the pattern of activation of the population of auditory nerve fibers. The cells of the dorsal cochlear nucleus perform a non-linear spectral analysis and place that spectral analysis into the context of the location of the head, ears and shoulders and that separate expected, self-generated spectral cues from more interesting, unexpected spectral cues using input from the auditory cortex, pontine nuclei, trigeminal ganglion and nucleus, dorsal column nuclei and the second dorsal root ganglion. It is likely that these neurons help mammals to use spectral cues for orienting toward those sounds. The information is used by higher brainstem regions to achieve further computational objectives (such as sound source location or improvement in signal to noise ratio). The inputs from these other areas of the brain probably play a role in sound localization.",
            "score": 124.86534118652344
        },
        {
            "docid": "3619450_4",
            "document": "Sensory gating . Information from sensory receptors make their way to the brain through neurons and synapse at the thalamus. The pulvinar nuclei in the thalamus function as the gatekeeper, deciding which information should be inhibited, and which should be sent to further cortical areas. Sensory gating is mediated by a network in the brain which involves the auditory cortex (AC), prefrontal cortex and hippocampus. Other areas of the brain associated with sensory gating include the amygdala, striatum, medial prefrontal cortex, and midbrain dopamine cell region (GABAergic neurons only). Research of sensory gating primarily occurs in cortical areas where the stimulus is consciously identified because it is a less invasive means of studying sensory gating. Studies on rats show the brain stem, thalamus, and primary auditory cortex play a role in sensory gating for auditory stimuli.",
            "score": 124.34607696533203
        },
        {
            "docid": "2101485_11",
            "document": "Beat (acoustics) . Binaural-beat perception originates in the inferior colliculus of the midbrain and the superior olivary complex of the brainstem, where auditory signals from each ear are integrated and precipitate electrical impulses along neural pathways through the reticular formation up the midbrain to the thalamus, auditory cortex, and other cortical regions.",
            "score": 123.74858093261719
        },
        {
            "docid": "31251362_5",
            "document": "Beat deafness . When sound waves reach the ears, the energy they contain is converted into electrical signals, which are sent via the auditory nerves to the brain. Sound processing begins when these electrical signals reach the primary auditory receiving area in the core part of the temporal lobe. Signals then travel to the area surrounding the core, known as the belt area, and are then transmitted to the parabelt area, which is located next to the belt. Simple sounds such as pure tones are able to activate the core area of the brain, but both the belt and parabelt areas are activated by only complex sounds, such as those found in speech and music. The auditory cortex in the left hemisphere of the brain is responsible for processing beat and rhythm in music. The right auditory cortex is primarily used in distinguishing between different harmonics, which are simple pure tones that combine to create complex tones.",
            "score": 123.56692504882812
        },
        {
            "docid": "4548229_17",
            "document": "Interaural time difference . The lateral lemniscus (LL) is the main auditory tract in the brainstem connecting SOC to the inferior colliculus. The dorsal nucleus of the lateral lemniscus (DNLL) is a group of neurons separated by lemniscus fibres, these fibres are predominantly destined for the inferior colliculus (IC). In studies using an unanesthetized rabbit the DNLL was shown to alter the sensitivity of the IC neurons and may alter the coding of interaural timing differences (ITDs) in the IC.(Kuwada et al., 2005) The ventral nucleus of the lateral lemniscus (VNLL) is a chief source of input to the inferior colliculus. Research using rabbits shows the discharge patterns, frequency tuning and dynamic ranges of VNLL neurons supply the inferior colliculus with a variety of inputs, each enabling a different function in the analysis of sound.(Batra & Fitzpatrick, 2001)  In the inferior colliculus (IC) all the major ascending pathways from the olivary complex and the central nucleus converge. The IC is situated in the midbrain and consists of a group of nuclei the largest of these is the central nucleus of inferior colliculus (CNIC). The greater part of the ascending axons forming the lateral lemniscus will terminate in the ipsilateral CNIC however a few follow the commissure of Probst and terminate on the contralateral CNIC. The axons of most of the CNIC cells form the brachium of IC and leave the brainstem to travel to the ipsilateral thalamus. Cells in different parts of the IC tend to be monaural, responding to input from one ear, or binaural and therefore respond to bilateral stimulation.",
            "score": 122.99127960205078
        },
        {
            "docid": "29354346_7",
            "document": "Change deafness . One study used fMRI data to distinguish neural correlates of physical changes in auditory input (independent of conscious change detection), from those of conscious perception of change (independent of an actual physical change). The study made use of a change deafness paradigm in which participants were exposed to complex auditory scenes consisting of six individual auditory streams differing in pitch, rhythm, and sound source location, and received a cue indicating which stream to attend to. Each participant listened to two consecutively presented auditory scenes after which they were prompted to indicate whether both scenes were identical or not. Functional MRI results revealed that physical change in stimulus was correlated with increased BOLD responses in the right auditory cortex, near the lateral portion of Heschl's gyrus, the first cortical structure to process incoming auditory information, but not in hierarchically higher brain regions. Conscious change detection was correlated with increased coupled responses in the ACC and the right insula, consistent with additional evidence that the anterior insula functions to mediate dynamic interactions between other brain networks involved in attention to external stimuli, forming a salience network with the ACC that identifies salient stimulus events and initiates additional processing. In absence of change detection, this salience network was not activated; however increased activity in other cortical areas suggests that undetected changes are still perceived on some level, but fail to trigger conscious change detection, thus producing the change deafness phenomenon.",
            "score": 122.39376068115234
        },
        {
            "docid": "25260196_25",
            "document": "Neuronal encoding of sound . Primary auditory neurons carry action potentials from the cochlea into the transmission pathway shown in the adjacent image. Multiple relay stations act as integration and processing centers. The signals reach the first level of cortical processing at the primary auditory cortex (A1), in the superior temporal gyrus of the temporal lobe. Most areas up to and including A1 are tonotopically mapped (that is, frequencies are kept in an ordered arrangement). However, A1 participates in coding more complex and abstract aspects of auditory stimuli without coding well the frequency content, including the presence of a distinct sound or its echoes.  Like lower regions, this region of the brain has combination-sensitive neurons that have nonlinear responses to stimuli.",
            "score": 122.10692596435547
        },
        {
            "docid": "35988494_3",
            "document": "Selective auditory attention . The cocktail party problem was first brought up in 1953 by Colin Cherry. This common problem is how our minds solves the issue of knowing what in the auditory scene is important and combining those in a coherent whole, such as the problem of how we can perceive our friend talking in the midst of a crowded cocktail party. He suggested that the auditory system can filter sounds being heard. Physical characteristics of the auditory information such as speaker's voice or location can improve a person's ability to focus on certain stimuli even if there is other auditory stimuli present. Cherry also did work with shadowing which involves different information being played into both ears and only one ear's information can be processed and remembered (Eysneck, 2012, p.\u00a084). Another psychologist, Albert Bregman, came up with the auditory scene analysis model. The model has three main characteristics: segmentation, integration, and segregation. Segmentation involves the division of auditory messages into segments of importance. The process of combining parts of an auditory message to form a whole is associated with integration. Segregation is the separation of important auditory messages and the unwanted information in the brain. It is important to note that Bregman also makes a link back to the idea of perception. He states that it is essential for one to make a useful representation of the world from sensory inputs around us. Without perception, an individual will not recognize or have the knowledge of what is going on around them. While Begman's seminal work is critical to understanding selective auditory attention, his studies did not focus on the way in which an auditory message is selected, if and when it was correctly segregated from other sounds in a mixture, which is a critical stage of selective auditory attention. Inspired in part by Bregman's work, a number of researchers then set out to link directly work on auditory scene analysis to the processes governing attention, including Maria Chait, Mounya Elhilali, Shihab Shamma, and Barbara Shinn-Cunningham.",
            "score": 121.39136505126953
        },
        {
            "docid": "14532984_7",
            "document": "Coincidence detection in neurobiology . Coincidence detection has been shown to be a major factor in sound localization along the azimuth plane in several organisms. In 1948, Lloyd A. Jeffress proposed that some organisms may have a collection of neurons that receive auditory input from each ear. The neural pathways to these neurons are called delay lines. Jeffress claimed that the neurons that the delay lines link act as coincidence detectors by firing maximally when receiving simultaneous inputs from both ears. When a sound is heard, sound waves may reach the ears at different times. This is referred to as the interaural time difference (ITD). Due to differing lengths and a finite conduction speed within the axons of the delay lines, different coincidence detector neurons will fire when sound comes from different positions along the azimuth. Jeffress' model proposes that two signals even from an asynchronous arrival of sound in the cochlea of each ear will converge synchronously on a coincidence detector in the auditory cortex based on the magnitude of the ITD (Fig. 2). Therefore, the ITD should correspond to an anatomical map that can be found within the brain. Masakazu Konishi's study on barn owls shows that this is true. Sensory information from the hair cells of the ears travels to the ipsilateral nucleus magnocellularis. From here, the signals project ipsilaterally and contralaterally to two nucleus laminari. Each nucleus laminaris contains coincidence detectors that receive auditory input from the left and the right ear. Since the ipsilateral axons enter the nucleus laminaris dorsally while the contralateral axons enter ventrally, sounds from various positions along the azimuth correspond directly to stimulation of different depths of the nucleus laminaris. From this information, a neural map of auditory space was formed. The function of the nucleus laminaris parallels that of the medial superior olive in mammals.",
            "score": 121.38420867919922
        },
        {
            "docid": "58686_30",
            "document": "Cerebral cortex . The sensory areas are the cortical areas that receive and process information from the senses. Parts of the cortex that receive sensory inputs from the thalamus are called primary sensory areas. The senses of vision, audition, and touch are served by the primary visual cortex, primary auditory cortex and primary somatosensory cortex respectively. In general, the two hemispheres receive information from the opposite (contralateral) side of the body. For example, the right primary somatosensory cortex receives information from the left limbs, and the right visual cortex receives information from the left visual field. The organization of sensory maps in the cortex reflects that of the corresponding sensing organ, in what is known as a topographic map. Neighboring points in the primary visual cortex, for example, correspond to neighboring points in the retina. This topographic map is called a retinotopic map. In the same way, there exists a tonotopic map in the primary auditory cortex and a somatotopic map in the primary sensory cortex. This last topographic map of the body onto the posterior central gyrus has been illustrated as a deformed human representation, the somatosensory homunculus, where the size of different body parts reflects the relative density of their innervation. Areas with lots of sensory innervation, such as the fingertips and the lips, require more cortical area to process finer sensation.",
            "score": 120.13353729248047
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 119.95335388183594
        },
        {
            "docid": "305136_25",
            "document": "Visual system . The information about the image via the eye is transmitted to the brain along the optic nerve. Different populations of ganglion cells in the retina send information to the brain through the optic nerve. About 90% of the axons in the optic nerve go to the lateral geniculate nucleus in the thalamus. These axons originate from the M, P, and K ganglion cells in the retina, see above. This parallel processing is important for reconstructing the visual world; each type of information will go through a different route to perception. Another population sends information to the superior colliculus in the midbrain, which assists in controlling eye movements (saccades) as well as other motor responses.",
            "score": 118.58561706542969
        }
    ]
}