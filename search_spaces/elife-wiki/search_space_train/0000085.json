{
    "q": [
        {
            "docid": "889172_4",
            "document": "Selective perception . Selective perception may refer to any number of cognitive biases in psychology related to the way expectations affect perception. Human judgment and decision making is distorted by an array of cognitive, perceptual and motivational biases, and people tend not to recognise their own bias, though they tend to easily recognise (and even overestimate) the operation of bias in human judgment by others. One of the reasons this might occur might be because people are simply bombarded with too much stimuli every day to pay equal attention to everything, therefore, they pick and choose according to their own needs.",
            "score": 135.92432713508606
        },
        {
            "docid": "26565579_50",
            "document": "Neuroscience of free will . Multivariate pattern analysis using EEG has suggested that an evidence based perceptual decision model may be applicable to free will decisions. It was found that decisions could be predicted by neural activity immediately after stimulus perception. Furthermore, when the participant was unable to determine the nature of the stimulus the recent decision history predicted the neural activity (decision). The starting point of evidence accumulation was in effect shifted towards a previous choice (suggesting a priming bias). Another study has found that subliminally priming a participant for a particular decision outcome (showing a cue for 13ms) could be used to influence free decision outcomes. Likewise, it has been found that decision history alone can be used to predict future decisions. The prediction capacities of the Soon et al. (2008) experiment were successfully replicated using a linear SVM model based on participant decision history alone (without any brain activity data). Despite this, a recent study has sought to confirm the applicability of a perceptual decision model to free will decisions. When shown a masked and therefore invisible stimulus, participants were asked to either guess between a category or make a free decision for a particular category. Multivariate pattern analysis using fMRI could be trained on \"free decision\" data to successfully predict \"guess decisions\", and trained on \"guess data\" in order to predict \"free decisions\" (in the precuneus and cuneus region).",
            "score": 76.96967005729675
        },
        {
            "docid": "48258936_5",
            "document": "Debiasing . Changing incentives can be an effective means to debias judgment and decision making. This approach is generally derived from economic theories suggesting that people act in their self-interest by seeking to maximize their utility over their lifetime. Many decision making biases may occur simply because they are more costly to eliminate than to ignore. Making people more accountable for their decisions (increasing incentives), for example, can increase the extent to which they invest cognitive resources in making decisions, leading to less biased decision making when people generally have an idea of how a decision should be made. However, \"bias\" might not be the appropriate term for these types of decision making errors. These \"strategy-based\" errors occur simply because the necessary effort outweighs the benefit. If a person makes a suboptimal choice based on an actual bias, then incentives may exacerbate the issue. An incentive in this case may simply cause the person to perform the suboptimal behavior more enthusiastically.",
            "score": 109.590092420578
        },
        {
            "docid": "2999259_3",
            "document": "Choice-supportive bias . What is remembered about a decision can be as important as the decision itself, especially in determining how much regret or satisfaction one experiences. Research indicates that the process of making and remembering choices yields memories that tend to be distorted in predictable ways. In cognitive science, one predictable way that memories of choice options are distorted is that positive aspects tend to be remembered as part of the chosen option, whether or not they originally were part of that option, and negative aspects tend to be remembered as part of rejected options. Once an action has been taken, the ways in which we evaluate the effectiveness of what we did may be biased. It is believed this may influence our future decision-making. These biases may be stored as memories, which are attributions that we make about our mental experiences based on their subjective qualities, our prior knowledge and beliefs, our motives and goals, and the social context. True and false memories arise by the same mechanism because when the brain processes and stores information, it cannot tell the difference from where they came from.",
            "score": 102.56853604316711
        },
        {
            "docid": "59160_11",
            "document": "Confirmation bias . Similar studies have demonstrated how people engage in a biased search for information, but also that this phenomenon may be limited by a preference for genuine diagnostic tests. In an initial experiment, participants rated another person on the introversion\u2013extroversion personality dimension on the basis of an interview. They chose the interview questions from a given list. When the interviewee was introduced as an introvert, the participants chose questions that presumed introversion, such as, \"What do you find unpleasant about noisy parties?\" When the interviewee was described as extroverted, almost all the questions presumed extroversion, such as, \"What would you do to liven up a dull party?\" These loaded questions gave the interviewees little or no opportunity to falsify the hypothesis about them. A later version of the experiment gave the participants less presumptive questions to choose from, such as, \"Do you shy away from social interactions?\" Participants preferred to ask these more diagnostic questions, showing only a weak bias towards positive tests. This pattern, of a main preference for diagnostic tests and a weaker preference for positive tests, has been replicated in other studies.",
            "score": 85.34046244621277
        },
        {
            "docid": "17258308_5",
            "document": "Two-alternative forced choice . It is possible to introduce biases in decision making in the 2AFC task. For example, if one stimulus occurs with more frequency than the other, then the frequency of exposure to the stimuli may influence the participant's beliefs about the probability of the occurrence of the alternatives. Introducing biases in the 2AFC task is used to modulate decision making and examine the underlying processes.",
            "score": 101.4633457660675
        },
        {
            "docid": "893668_5",
            "document": "Bias blind spot . Self-enhancement biases may play a role, in that people are motivated to view themselves in a positive light. Biases are generally seen as undesirable, so people tend to think of their own perceptions and judgments as being rational, accurate, and free of bias. The self-enhancement bias also applies when analyzing our own decisions, in that people are likely to think of themselves as better decision makers than others.",
            "score": 99.7719898223877
        },
        {
            "docid": "1050551_7",
            "document": "Multiple-criteria decision analysis . \"Solving\" can be interpreted in different ways. It could correspond to choosing the \"best\" alternative from a set of available alternatives (where \"best\" can be interpreted as \"the most preferred alternative\" of a decision-maker). Another interpretation of \"solving\" could be choosing a small set of good alternatives, or grouping alternatives into different preference sets. An extreme interpretation could be to find all \"efficient\" or \"nondominated\" alternatives (which we will define shortly). The difficulty of the problem originates from the presence of more than one criterion. There is no longer a unique optimal solution to an MCDM problem that can be obtained without incorporating preference information. The concept of an optimal solution is often replaced by the set of nondominated solutions. A nondominated solution has the property that it is not possible to move away from it to any other solution without sacrificing in at least one criterion. Therefore, it makes sense for the decision-maker to choose a solution from the nondominated set. Otherwise, she/he could do better in terms of some or all of the criteria, and not do worse in any of them. Generally, however, the set of nondominated solutions is too large to be presented to the decision-maker for the final choice. Hence we need tools that help the decision-maker focus on the preferred solutions (or alternatives). Normally one has to \"tradeoff\" certain criteria for others.",
            "score": 78.5868148803711
        },
        {
            "docid": "40786_5",
            "document": "Bias . A cognitive bias is a repeating or basic misstep in thinking, assessing, recollecting, or other cognitive processes. That is, a pattern of deviation from standards in judgment, whereby inferences may be created unreasonably. People create their own \"subjective social reality\" from their own perceptions, their view of the world may dictate their behaviour. Thus, cognitive biases may sometimes lead to perceptual distortion, inaccurate judgment, illogical interpretation, or what is broadly called irrationality. However some cognitive biases are taken to be adaptive, and thus may lead to success in the appropriate situation. Furthermore, cognitive biases may allow speedier choices when speed is more valuable than precision. Other cognitive biases are a \"by-product\" of human processing limitations, coming about because of an absence of appropriate mental mechanisms, or just from human limitations in information processing.",
            "score": 98.48492884635925
        },
        {
            "docid": "13987523_3",
            "document": "Distinction bias . One writer has presented what he called \"a simplistic view\" of distinction bias: When asked if someone would like an apple, they may say \"Yes\". So, an apple is placed before them and they begin to eat it and are happy. But what if two apples were placed on the table - one was the one they would have happily eaten and the other which is slightly fresher looking. The individual will choose the fresher apple and eat it and be happy but if asked, \"would you have enjoyed eating that other apple\", they would likely say \"No\". Even though in the alternate, no-choice reality they were perfectly happy with the apple. Moreover, if presented with five apples on a table, they might examine each apple so that they would be sure they had the best one, even though the time spent making that decision would be wasted. The reason for this is that distinction bias causes individuals to \"over-examine and over-value the differences between things as we scrutinize them.\"",
            "score": 95.12866449356079
        },
        {
            "docid": "10929505_12",
            "document": "Unstructured interview . It is important to understand that bias or the use of bias during an interview from the researcher is an important aspect that greatly affects validity of the interview's gathered knowledge. Since the interview is more like an everyday conversation, some claim that there are opportunities for the interviewer\u2019s bias to be brought into discussion and to intervene than with the structured interview. Others maintain that \u201cAlthough there is invariable potential for the interviewer bias in qualitative interviews, it is offset, at least to some extent, by the greater participation and involvement of the interviewer in the interaction aimed at reaching greater depth\u201d. While the unstructured interview can be seen to be unreliable due to the interviewer, bias can be easily be built into a highly structured interview. However, it is important to find where one stands with their bias, acknowledging their biases rather than trying to do away with it. The notion of bias is evident in that anything quantitative already holds bias and biases are already built into everyday form. \"Although typical of the selection process, the research on interviews suggests that unstructured procedures are vulnerable to a variety of biases that can lower the quality of decisions,\" such as gathering information on an applicant's traits during a job interview and selecting applicants determined by their qualifications. Any interview can also be subject to stereotypes and discrimination. Newell and Rice suggest that many of the problems involved with predictive validity during interviews are due to interpersonal perception, the interpretation of the interviewee's personality or social identity. Race, gender, class, religion, [and forms of disabilities] are all aspects of society that feed into the development of our social identity, however these can also be factors which bias people's interpretations in an interview.",
            "score": 105.62293612957001
        },
        {
            "docid": "31881841_46",
            "document": "Implicit stereotype . Studies have shown that racial bias predicts in-group health outcomes among minority populations. In countries where blacks had more implicit bias towards whites, blacks died at higher rates, and vice versa. Implicit biases effect daily perceptions and legal judgments. Stereotyping is more likely to occur when an individual is making a subjective decision, is busy or distracted, is overwhelmed by a heavy workload, or in a situation where they feel threatened or insecure. Biases tint our outlook, and as a result, our judgments and actions. Everyday people run legal systems, which makes it likely for legal decisions to be bias. For many, crime is linked with certain races. Bias training can help here, but is not always effective.",
            "score": 112.16618323326111
        },
        {
            "docid": "40786_9",
            "document": "Bias . An attribution bias can happen when individuals assess or attempt to discover explanations behind their own and others' behaviors. People make attributions about the causes of their own and others\u2019 behaviors; but these attributions don't necessarily precisely reflect reality. Rather than operating as objective perceivers, individuals are inclined to perceptual slips that prompt biased understandings of their social world. When judging others we tend to assume their actions are the result of internal factors such as personality, whereas we tend to assume our own actions arise because of the necessity of external circumstances. There are a wide range of sorts of attribution biases, such as the ultimate attribution error, fundamental attribution error, actor-observer bias, and self-serving bias.",
            "score": 98.09631371498108
        },
        {
            "docid": "893668_7",
            "document": "Bias blind spot . When made aware of various biases acting on our perception, decisions, or judgments, research has shown that we are still unable to control them. This contributes to the bias blind spot in that even if one is told that they are biased, they are unable to alter their biased perception.",
            "score": 105.93176603317261
        },
        {
            "docid": "893668_13",
            "document": "Bias blind spot . Initial evidence suggests that the bias blind spot is not related to actual decision-making ability. Participants who scored better or poorer on various tasks associated with decision making competence were no more or less likely to be higher or lower in their susceptibility to bias blind spot. Bias blind spot does, however, appear to increase susceptibility to related biases. People who are high in bias blind spot are more likely to ignore the advice of other people, and are less likely to benefit from training geared to reduce their commission of other biases.",
            "score": 107.41320848464966
        },
        {
            "docid": "20467381_6",
            "document": "Overchoice . Decision-makers in large choice situations enjoy the decision process more than those with smaller choice sets, but feel more responsible for their decisions. Despite this, more choices result with more dissatisfaction and regret in decisions. The feeling of responsibility causes cognitive dissonance when presented with large array situations. In this situation, cognitive dissonance results when there is a mental difference between the choice made and the choice that should have been made. More choices lead to more cognitive dissonance because it increases the chance that the decision-maker made the wrong decision. These large array situations cause the chooser to feel both enjoyment as well as feel overwhelmed with their choices. These opposing emotions contribute to cognitive dissonance, and causes the chooser to feel less motivated to make a decision. This also disables them from using psychological processes to enhance the attractiveness of their own choices. Choosers in large array situations do enjoy their decision-making process more than those in small array situations. The amount of time allotted to make a decision also has an effect on an individual's perception of their choice. Larger choice sets with a small amount of time results in more regret with the decision. When more time is provided, the process of choosing is more enjoyable in large array situations and results in less regret after the decision has been made.",
            "score": 72.66418635845184
        },
        {
            "docid": "34987714_19",
            "document": "Na\u00efve realism (psychology) . One consequence of na\u00efve realism is referred to as the bias blind spot, which is the ability to recognize cognitive and motivational biases in others while failing to recognize the impact of bias on the self. In a study conducted by Pronin, Lin, and Ross (2002), Stanford students completed a questionnaire about various biases in social judgment. They indicated how susceptible they thought they were to these biases compared to the average student. The researchers found that the participants consistently believed that they were less likely to be biased than their peers. In a follow-up study, students answered questions about their personal attributes (e.g. how considerate they were) compared to those of other students. The majority of students saw themselves as falling above average on most traits, which provided support for a cognitive bias known as the better-than-average effect. Next, the students learned that 70 to 80 percent of people fall prey to this bias. When asked about the accuracy of their self-assessments, 63 percent of the students argued that their ratings had been objective, while 13 percent of students indicated they thought their ratings had been too modest.",
            "score": 94.83160281181335
        },
        {
            "docid": "20666057_17",
            "document": "Framing effect (psychology) . The framing effect is greater in older adults than in younger adults or adolescents. This may be a result of enhanced negativity bias, though some sources claim that the negativity bias actually decreases with age. Another possible cause is that older adults have fewer cognitive resources available to them and are more likely to default to less cognitively demanding strategies when faced with a decision. They tend to rely on easily accessible information, or frames, regardless of whether that information is relevant to making the decision in question. Several studies have shown that younger adults will make less biased decisions than older adults because they base their choices on interpretations of patterns of events and can better employ decision making strategies that require cognitive resources like working-memory skills. Older adults, on the other hand, make choices based on immediate reactions to gains and losses.",
            "score": 106.95155215263367
        },
        {
            "docid": "36971783_20",
            "document": "Re Shankar Alan s/o Anant Kulkarni . In coming to his decision in the present case, Menon highlighted the principle upon which apparent bias stands as a ground for judicial review, separate from that of actual bias. Since justice is rooted in public confidence, it is imperative that \"right-minded people\" not hold the impression that \"the judge was biased\". The appearance of impartiality is as important as actual impartiality, because there is public interest in ensuring that justice is seen to be done. The reasonable suspicion test upholds this principle as it \"safeguards not only the \"fact\" but also the \"appearance\" of justice being done\". Thus he held this to be the more appropriate test because the inquiry is focused on whether a reasonable member of the public would have the impression that the public authority acted with bias, regardless of whether the court thought it likely or possible. On the other hand, the adoption of the real likelihood test would shift the focus of the inquiry from the perspective of a reasonable person to that of a judge who is no longer concerned strictly with the appearance of bias but rather with establishing whether there is in fact a sufficient possibility of bias. Menon added that the real likelihood test poses an \"inherent difficulty\" because it is \"utterly imprecise\". This is because the standard of proof, being a question with respect to \"possibility\", is lower than that on a balance of probabilities which requires the court to be satisfied that \"more likely than not\" there was bias. Although in \"Gough\" Lord Goff of Chieveley stated that the test is satisfied if there is a sufficient degree of possibility of bias, what is \"sufficient\" is often subjective. The reasonable suspicion test, however, avoids this problem because the court is not inquiring into the degree of possibility of bias but toward the impression which a fair-minded member of the public could reasonably form on the facts presented. Finally, Menon noted that Justice Chan Sek Keong previously suggested a different standard should apply to judicial decisions as opposed to administrative decisions, that is, those made by public authorities. He declined to make a definitive ruling on this point, although he opined that there was \"much to commend this\".",
            "score": 96.36981189250946
        },
        {
            "docid": "8165347_44",
            "document": "Psychology of art . Further research investigating perceptual fluency has found a gender bias towards neutral stimuli. Studies pertaining to generalizing symmetry preference to real-world versus abstract objects allow us to further examine the possible influence meaning may have on preference for a given stimuli. In order to determine whether meaning mattered for a given stimuli, participants were asked to view pairs of objects and make a forced-choice decision, evaluating their preference. The findings suggest that an overall preference for symmetric features of visual objects existed. Furthermore, a main effect for gender preference existed in the males that consistently indicated a preference for symmetry in both abstract and real objects. This finding did not transcend in the female participants. Further studies need to be conducted to investigate the factors that influence female preferences for visual stimuli as well as for why males showed a preference for symmetry in both abstract and real world objects.",
            "score": 73.57858347892761
        },
        {
            "docid": "510791_4",
            "document": "List of cognitive biases . There are also controversies over some of these biases as to whether they count as useless or irrational, or whether they result in useful attitudes or behavior. For example, when getting to know others, people tend to ask leading questions which seem biased towards confirming their assumptions about the person. However, this kind of confirmation bias has also been argued to be an example of social skill: a way to establish a connection with the other person.",
            "score": 100.17830228805542
        },
        {
            "docid": "491696_9",
            "document": "Awareness . The ability to consciously detect an image when presented at near-threshold stimulus varies across presentations. One factor is \"baseline shifts\" due to top down attention that modulates ongoing brain activity in sensory cortex areas that affects the neural processing of subsequent perceptual judgments. Such top down biasing can occur through two distinct processes: an attention driven baseline shift in the alpha waves, and a decision bias reflected in gamma waves.",
            "score": 102.59942507743835
        },
        {
            "docid": "511043_16",
            "document": "Egocentric bias . People who exhibit the false consensus effect take egocentric bias a step further: they not only forgo thinking of other perspectives, but they believe that their viewpoints are those accepted by the majority of people. Nevertheless, some psychologists do not distinguish between egocentric bias and the false consensus effect. For example, in the paper published by Ross, Greene, and House, the terms \"false consensus\" and \"egocentric attribution bias\" are used interchangeably. In the second part of their study, they gave out a questionnaire which asked participants which option (out of two choices) they would choose in specified situations, and what percentage of the population would choose which option. In all four scenarios that were given, subjects rated the option that they chose as the most probable. Ross, Greene, and House conclude that their results support the false consensus hypothesis, and that \"intuitive estimates of deviance and normalcy, and the host of social inferences and interpersonal responses that accompany such estimates, are systematically and egocentrically biased in accord with his own behavioral choices.\"",
            "score": 90.6941306591034
        },
        {
            "docid": "35005736_2",
            "document": "Memory and decision-making . The memory system plays a key role in the decision-making process because individuals constantly choose among alternative options. Due to the volume of decisions made, much of the decision-making process is unconscious and automatic. Information about how a decision is made is remembered and used for future decisions. Memory is susceptible to biases, but it is integral to the formation of preferences and to differentiation between choices.",
            "score": 85.82050514221191
        },
        {
            "docid": "35005736_5",
            "document": "Memory and decision-making . Memory integration dictates one's preferences for a given alternative. The PAM model suggests that preferences are formed when individuals retrieve from memory a set of queries regarding the attributes of the alternative choices. These queries are believed to be an automatic, unconscious process. Many individuals think largely in terms of emotions when asked to make a decision, and so the way in which a question is posed as well as the manner in which it is asked impacts the decision-making process. If asked to choose where to go for dinner, one will select a series of possible restaurants, consider each option, and determine the positive attributes of each. The restaurant chosen will be the one with the greatest number of positive attributes.",
            "score": 59.283710956573486
        },
        {
            "docid": "439598_12",
            "document": "Natural justice . One form of imputed bias is based on the decision-maker being a party to a suit, or having a pecuniary or proprietary interest in the outcome of the decision. Once this fact has been established, the bias is irrebuttable and disqualification is automatic \u2013 the decision-maker will be barred from adjudicating the matter without the need for any investigation into the likelihood or suspicion of bias. A classic case is \"Dimes v Grand Junction Canal\" (1852), which involved an action between Dimes, a local landowner, and the proprietors of the Grand Junction Canal, in which the Lord Chancellor, Lord Cottenham, had affirmed decrees made to the proprietors. However, it was discovered by Dimes that Lord Cottenham in fact owned several pounds worth of shares in the Grand Junction Canal. This eventually led to the judge being disqualified from deciding the case. There was no inquiry as to whether a reasonable person would consider Lord Cottenham to be biased, or as to the circumstances which led Lord Cottenham to hear the case.",
            "score": 89.14983415603638
        },
        {
            "docid": "1051310_9",
            "document": "Response bias . Acquiescence bias, which is also referred to as \"yea-saying\", is a category of response bias in which respondents to a survey have a tendency to agree with all the questions in a measure. This bias in responding may represent a form of dishonest reporting because the participant automatically endorses any statements, even if the result is contradictory responses. For example, a participant could be asked whether they endorse the following statement, \"I prefer to spend time with others\" but then later on in the survey also endorses \"I prefer to spend time alone,\" which are contradictory statements. This is a distinct problem for self-report research because it does not allow a researcher to understand or gather accurate data from any type of question that asks for a participant to endorse or reject statements. Researchers have approached this issue by thinking about the bias in two different ways. The first deals with the idea that participants are trying to be agreeable, in order to avoid the disapproval of the researcher. A second cause for this type of bias was proposed by Lee Cronbach, when he argued that it is likely due to a problem in the cognitive processes of the participant, instead of the motivation to please the researcher. He argues that it may be due to biases in memory where an individual recalls information that supports endorsement of the statement, and ignores contradicting information.",
            "score": 109.89510226249695
        },
        {
            "docid": "59160_4",
            "document": "Confirmation bias . A series of psychological experiments in the 1960s suggested that people are biased toward confirming their existing beliefs. Later work re-interpreted these results as a tendency to test ideas in a one-sided way, focusing on one possibility and ignoring alternatives. In certain situations, this tendency can bias people's conclusions. Explanations for the observed biases include wishful thinking and the limited human capacity to process information. Another explanation is that people show confirmation bias because they are weighing up the costs of being wrong, rather than investigating in a neutral, scientific way. However, even scientists can be prone to confirmation bias.",
            "score": 102.63890719413757
        },
        {
            "docid": "15752931_16",
            "document": "Aversive racism . Aversive racism can have serious implications for selection decisions. According to the aversive racism framework, discrimination should occur in situations in which decision can be ostensibly be based on factors other than race. Dovidio and Gaertner (2000) created just such a condition. College students were asked to make hiring recommendations for a campus position. In the first condition, one candidate was clearly more qualified than the other. In the second condition, candidates' credentials were more evenly matched with no clear optimal choice. As expected, the first condition revealed no racial bias. Participants consistently chose the more qualified candidate. However, in the latter condition, as predicted, participants recommended the white candidate over the black in substantially more cases. Even in the face of similar credentials, participants ostensibly justified their discrimination on the grounds of other, non-racial factors.",
            "score": 61.973783016204834
        },
        {
            "docid": "1051310_7",
            "document": "Response bias . The second group argues against Hyman's point, saying that response bias has a significant effect, and that researchers need to take steps to reduce response bias in order to conduct sound research. They argue that the impact of response bias is a systematic error inherent to this type of research and that it needs to be addressed in order for studies to be able to produce accurate results. In psychology, there are many studies exploring the impact of response bias in many different settings and with many different variables. For example, some studies have found effects of response bias in the reporting of depression in elderly patients. Other researchers have found that there are serious issues when responses to a given survey or questionnaire have responses that may seem desirable or undesirable to report, and that a person's responses to certain questions can be biased by their culture. Additionally, there is support for the idea that simply being part of an experiment can have dramatic effects on how participants act, thus biasing anything that they may do in a research or experimental setting when it comes to self-reporting. One of the most influential studies was one which found that social desirability bias, a type of response bias, can account for as much as 10\u201370% of the variance in participant response. Essentially, because of several findings that illustrate the dramatic effects response bias has on the outcomes of self-report research, this side supports the idea that steps need to be taken to mitigate the effects of response bias to maintain the accuracy of research.",
            "score": 94.2646131515503
        },
        {
            "docid": "26565579_55",
            "document": "Neuroscience of free will . Some research suggests that TMS can be used to manipulate the perception of authorship of a specific choice. Experiments showed that neurostimulation could affect which hands people move, even though the experience of free will was intact. An early TMS study revealed that activation of one side of the neocortex could be used to bias the selection of one's opposite side hand in a forced-choice decision task. Ammon and Gandevia found that it was possible to influence which hand people move by stimulating frontal regions that are involved in movement planning using transcranial magnetic stimulation in the left or right hemisphere of the brain.",
            "score": 95.78300833702087
        },
        {
            "docid": "37940820_23",
            "document": "Emotion perception . Researchers employ several methods designed to examine biases toward emotional stimuli to determine the salience of particular emotional stimuli, population differences in emotion perception, and also attentional biases toward or away from emotional stimuli. Tasks commonly utilized include the modified Stroop task, the dot probe task, visual search tasks, and spatial cuing tasks.  The Stroop task, or modified Stroop task, displays different types of words (e.g., threatening and neutral) in varying colors. The participant is then asked to identify the color of the word while ignoring the actual semantic content. Increased response time to indicate the color of threat words relative to neutral words suggests an attentional bias toward such threat. The Stroop task, however, has some interpretational difficulties in addition to the lack of allowance for the measurement of spatial attention allocation. To address some of the limitations of the Stroop task, the dot probe task displays two words or pictures on a computer screen (either one at the top or left and the other on the bottom or right, respectively) and after a brief stimuli presentation, often less than 1000ms, a probe appears in the location of one of the two stimuli and participants are asked to press a button indicating the location of the probe. Different response times between target (e.g., threat) and neutral stimuli infer attentional biases to the target information with shorter response times for when the probe is in the place of the target stimuli indicating an attention bias for that type of information. In another task that examines spatial attentional allocation, the visual search task asks participants to detect a target stimulus embedded in a matrix of distractors (e.g., an angry face among several neutral or other emotional faces or vice versa). Faster detection times to find emotional stimuli among neutral stimuli or slower detection times to find neutral stimuli among emotional distractors infer an attentional bias for such stimuli. The spatial cuing task asks participants to focus on a point located between two rectangles at which point a cue is presented, either in the form of one of the rectangles lighting up or some emotional stimuli appearing within one of the rectangles and this cue either directs attention toward or away from the actual location of the target stimuli. Participants then press a button indicating the location of the target stimuli with faster response times indicating an attention bias toward such stimuli.",
            "score": 107.08804595470428
        }
    ],
    "r": [
        {
            "docid": "889172_4",
            "document": "Selective perception . Selective perception may refer to any number of cognitive biases in psychology related to the way expectations affect perception. Human judgment and decision making is distorted by an array of cognitive, perceptual and motivational biases, and people tend not to recognise their own bias, though they tend to easily recognise (and even overestimate) the operation of bias in human judgment by others. One of the reasons this might occur might be because people are simply bombarded with too much stimuli every day to pay equal attention to everything, therefore, they pick and choose according to their own needs.",
            "score": 135.92433166503906
        },
        {
            "docid": "3704475_29",
            "document": "Executive functions . Miller and Cohen draw explicitly upon an earlier theory of visual attention that conceptualises perception of visual scenes in terms of competition among multiple representations \u2013 such as colors, individuals, or objects. Selective visual attention acts to 'bias' this competition in favour of certain selected features or representations. For example, imagine that you are waiting at a busy train station for a friend who is wearing a red coat. You are able to selectively narrow the focus of your attention to search for red objects, in the hope of identifying your friend. Desimone and Duncan argue that the brain achieves this by selectively increasing the gain of neurons responsive to the color red, such that output from these neurons is more likely to reach a downstream processing stage, and, as a consequence, to guide behaviour. According to Miller and Cohen, this selective attention mechanism is in fact just a special case of cognitive control \u2013 one in which the biasing occurs in the sensory domain. According to Miller and Cohen's model, the PFC can exert control over input (sensory) or output (response) neurons, as well as over assemblies involved in memory, or emotion. Cognitive control is mediated by reciprocal PFC connectivity with the sensory and motor cortices, and with the limbic system. Within their approach, thus, the term 'cognitive control' is applied to any situation where a biasing signal is used to promote task-appropriate responding, and control thus becomes a crucial component of a wide range of psychological constructs such as selective attention, error monitoring, decision-making, memory inhibition, and response inhibition.",
            "score": 127.38717651367188
        },
        {
            "docid": "45355308_4",
            "document": "Implicit leadership theory . The social world is solely understood in terms of perceptions, thus people use these perceptions intuitively to effectively organize and guide social interactions. We observe the actions of other people, take note of their personal characteristics, compare them to our own ILTs, and make decisions regarding whether they make an appropriate or inappropriate leader. Additionally, we use ILTs to evaluate the suitability and effectiveness of a group's leader. For example, if you believe that a good leader exerts control over the group, you may focus on this specific characteristic. Consequently, bias can result from noting only the instances when the leader was or was not in control. In a study by Foti and Lord (1987), participants were shown a videotape of a leader-group interaction. The participants were told to report the behaviors that the leader had or had not performed. The results of this study indicated that people are quicker to respond, more accurate, and more confident when they are judging behaviors that are both part of their ILTs and performed by the leader, in comparison to behaviors that were part of their ILTs and were not performed by the leader. Since ILTs are implicit theories, meaning the individual is likely unaware of their biases, it is difficult for ineffective ILTs to be recognized and discarded. For example, Offermann et al. (1994) found that masculinity was a stable ILT across participants, sex, and stimuli. However, males tend to be more autocratic and task-oriented in leadership style, while females tend to adopt a more participative and relationship-oriented style. Consequently, females generally tend to make better leaders as they have a more collaborative approach. This bias would be difficult to correct, as people are typically not aware of their implicit assumptions.",
            "score": 121.83118438720703
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 120.44532012939453
        },
        {
            "docid": "51547415_3",
            "document": "Interindividual differences in perception . A motion quartet is a bistable stimulus - it consists of two dots that change their position from frame to frame. This position change can either be interpreted as horizontal or vertical movement by viewers, and this experience can switch during viewing between interpretations. Depending on the aspect ratio of the two dots' positions, one or the other state is perceived longer or more often. At an aspect ratio of one, the illusion is biased towards the vertical perception. The reason for this might be the way the human brain processes the signals from both eyes in the visual system. The right half of an eye's field of view is processed by the left hemisphere, and the left half by the right hemisphere. A stimulus moving vertically only involves one field of view and so one hemisphere, while a stimulus moving vertically from one field of view to the other involves both hemispheres, and requires communication between them. The delay caused by this additional signalling might be the cause for the bias. There are also individual differences in the way the motion quartet is perceived: Some people require a different aspect ratio to perceive both axes of movement than others. A study using diffusion tensor imaging further showed differences in the structure of the corpus callosum, the primary connection between the two hemispheres, might be the origin of these differences.",
            "score": 118.71034240722656
        },
        {
            "docid": "26475187_13",
            "document": "Criticism of science . While many scientists and skeptics point out cognitive biases that may permeate commonsense thinking and cause illogical conclusions, the same biases are much less likely to be examined within the scientific community. Critics argue that the biggest bias within science is motivated reasoning, whereby scientists are more likely to accept evidence that supports their hypothesis and more likely to scrutinize findings that do not. Scientists do not practice pure induction but instead often come into science with preconceived ideas and often will, unconsciously or consciously, interpret observations to support their own hypotheses through confirmation bias. For example, scientists may re-run trials when they do not support a hypothesis but use results from the first trial when they do support their hypothesis. It is often argued that while each individual has cognitive biases, these biases are corrected for when scientific evidence converges. However, systematic issues in the publication system of academic journals can often compound these biases. Issues like publication bias, where studies with non-significant results are less likely to be published, and selective outcome reporting bias, where only the significant outcomes out of a variety of outcomes are likely to be published, are common within academic literature. These biases have widespread implications, such as the distortion of meta-analyses where only studies that include positive results are likely to be included. Statistical outcomes can be manipulated as well, for example large numbers of participants can be used and trials overpowered so that small difference cause significant effects or inclusion criteria can be changed to include those are most likely to respond to a treatment. Whether produced on purpose or not, all of these issues need to be taken into consideration within scientific research, and peer-reviewed published evidence should not be assumed to be outside of the realm of bias and error; some critics are now claiming that many results in scientific journals are false or exaggerated.",
            "score": 117.71735382080078
        },
        {
            "docid": "739262_10",
            "document": "Neural correlate . Neurophysiological studies in animals provided some insights on the neural correlates of conscious behavior. Vernon Mountcastle, in the early 1960s, set up to study this set of problems, which he termed \"the Mind/Brain problem\", by studying the neural basis of perception in the somatic sensory system. His labs at Johns Hopkins were among the first, along with Edward V.Evarts at NIH, to record neural activity from behaving monkeys. Struck with the elegance of SS Stevens approach of magnitude estimation, Mountcastle's group discovered three different modalities of somatic sensation shared one cognitive attribute: in all cases the firing rate of peripheral neurons was linearly related to the strength of the percept elicited. More recently, Ken H. Britten, William T. Newsome, and C. Daniel Salzman have shown that in area MT of monkeys, neurons respond with variability that suggests they are the basis of decision making about direction of motion. They first showed that neuronal rates are predictive of decisions using signal detection theory, and then that stimulation of these neurons could predictably bias the decision. Such studies were followed by Ranulfo Romo in the somatic sensory system, to confirm, using a different percept and brain area, that a small number of neurons in one brain area underlie perceptual decisions.",
            "score": 116.24960327148438
        },
        {
            "docid": "2426547_43",
            "document": "Affective forecasting . Affective forecasting is an important component of studying human decision making. Research in affective forecasts and economic decision making include investigations of durability bias in consumers and predictions of public transit satisfaction. In relevance to the durability bias in consumers, a study was conducted by Wood and Bettman, that showed that people make decisions regarding the consumption of goods based on the predicted pleasure, and the duration of that pleasure, that the goods will bring them. Overestimation of such pleasure, and its duration, increases the likelihood that the good will be consumed. Knowledge on such an effect can aid in the formation of marketing strategies of consumer goods. Studies regarding the predictions of public transit satisfaction reveal the same bias. However, with a negative impact on consumption, due to their lack of experience with public transportation, car users predict that they will receive less satisfaction with the use of public transportation than they actually experience. This can lead them to refrain from the use of such services, due to inaccurate forecasting. Broadly, the tendencies people have to make biased forecasts deviate from rational models of decision making. Rational models of decision making presume an absence of bias, in favor of making comparisons based on all relevant and available information. Affective forecasting may cause consumers to rely on the feelings associated with consumption rather than the utility of the good itself. One application of affective forecasting research is in economic policy. Knowledge that forecasts, and therefore, decisions, are affected by biases as well as other factors (such as framing effects), can be used to design policies that maximize the utility of people's choices. This approach is not without its critics, however, as it can also be seen to justify economic paternalism.",
            "score": 116.20140075683594
        },
        {
            "docid": "1051310_14",
            "document": "Response bias . While demand characteristics cannot be completely removed from an experiment, there are steps that researchers can take to minimize the impact they may have on the results. One way to mitigate response bias is to use deception to prevent the participant from discovering the true hypothesis of the experiment and then debrief the participants. For example, research has demonstrated that repeated deception and debriefing is useful in preventing participants from becoming familiar with the experiment, and that participants do not significantly alter their behaviors after being deceived and debriefed multiple times. Another way that researchers attempt to reduce demand characteristics is by being as neutral as possible, or training those conducting the experiment to be as neutral as possible. For example, studies show that extensive one-on-one contact between the experimenter and the participant makes it more difficult to be neutral, and go on to suggest that this type of interaction should be limited when designing an experiment. Another way to prevent demand characteristics is to use blinded experiments with placebos or control groups. This prevents the experimenter from biasing the participant, because the researcher does not know in which way the participant should respond. Although not perfect, these methods can significantly reduce the effect of demand characteristics on a study, thus making the conclusions drawn from the experiment more likely to accurately reflect what they were intended to measure.",
            "score": 115.55570220947266
        },
        {
            "docid": "23469564_40",
            "document": "Introspection illusion . A study that investigated the effect of educating people about unconscious biases on their subsequent self-ratings of susceptibility to bias showed that those who were educated did not exhibit the bias blind spot, in contrast with the control group. This finding provides hope that being informed about unconscious biases such as the introspection illusion may help people to avoid making biased judgments, or at least make them aware that they are biased. Findings from other studies on correction of the bias yielded mixed results. In a later review of the introspection illusion, Pronin suggests that the distinction is that studies that merely provide a warning of unconscious biases will not see a correction effect, whereas those that inform about the bias and emphasize its unconscious nature do yield corrections. Thus, knowledge that bias can operate during conscious awareness, is the defining factor in leading people to correct for it.",
            "score": 114.67735290527344
        },
        {
            "docid": "12664042_8",
            "document": "Sex-limited genes . John Parsch and Hans Ellegren defined \"genes that differ in expression between females and males\" as sex-biased genes. While this definition is more broad, sex-limited genes are certainly included in this category. One of the key principles of sex-biased gene expression that Parsch and Ellegren stressed in their paper in February 2013 is that of rapid evolution. They assert that a gene's sex bias can vary among different types of tissues throughout the body or throughout development, making the level of sex bias a fluid, rather than static, property. This makes it possible, then, that the rapid evolution seen in sex-biased genes is not an inherent property of their sex bias, but a property of some other feature. The paper offers expression breadth, the number of tissue types in which the genes are expressed, as an example of a feature correlated to sex-biased genes. It is known that genes with limited expression (in only one type of tissue) generally evolve faster than those with a higher expression breadth, and sex-biased genes are often restricted in their expression, such as to only the testes or ovaries. Thus, it is likely that sex-biased (including sex-limited) genes will evolve faster than the average genetic information. Parsch and Ellegren also assert that \"sex-biased genes expressed only in sex-limited reproductive tissues evolve faster than unbiased genes that are expressed only in a single, non-reproductive tissue.\" That is, genes that have a bias toward any kind of reproductive tissue (testes or ovaries) seem to show faster evolution than genes expressed in non-gonadal tissues, despite the number of tissues in which they are expressed. This makes sense in the context of genes with reproductive function evolving more quickly, a generally observed pattern in evolutionary biology.",
            "score": 113.7086181640625
        },
        {
            "docid": "35982062_9",
            "document": "Biased Competition Theory . A Top-down process is characterized by a high level of direction of sensory processing by more cognition; Top-down processing is based on pre-existing knowledge when interpreting sensory information. Top-down guidance of attention refers to when the properties of an object (i.e. color, shape) are activated and held in working memory to facilitate the visual search for that object. This controls visual search by guiding attention only to objects that could be the target and avoiding attention on irrelevant objects. Top-down processes are not a complete representation of the object but are coarse, which is why objects similar in color, shape or meaning are often attended to in the process of discriminating irrelevant objects. There is evidence that observers have Top-down control over the locations that will benefit from biased competition in spatial selection visual tasks. Evidence supports that observers can make voluntary decision about which locations are selected. or features that capture the attention in a stimulus-driven manner. Neurophysiology studies have showed that the neural mechanisms in Top-down processing are also seen in attention and working memory, suggesting Top-down processes play an important role in those functions as well. Additionally, Top-down processes can modulate Bottom-up processes by suppressing the \u201cpop-out\u201d features of Bottom-up processing from distracting from the visual search. fMRI studies have investigated the Top-down and Bottom-up processes involved in biased competition theory. Results of fMRI suggest that both Bottom-up and Top-down processes work in parallel to bias competition. Multiple studies have shown that stimuli in the visual field suppress each other when presented together, but not when each stimulus is presented alone. Kastner and colleagues also found that directing attention to the specific location of a stimulus reduces the suppressive effect. Increased activity in the visual cortex was also observed; this was the result of Top-down biasing due to the favoring of the attended location.",
            "score": 113.70104217529297
        },
        {
            "docid": "54830261_9",
            "document": "Unconscious bias training . However, Gawronski, Deutsch, Mbirkou, Seibt, and Strack(2006) hypothesized that negation training was not only ineffective, but could actually strengthen unconscious biases. They stated that Kawakami and colleagues only produced positive results because when the participants responded, \"YES\" to stereotype-inconsistent word-picture pairings, they were using counterstereotyping rather than negation. To test these claims, the researchers created separate counterstereotype and negation conditions. The counterstereotype condition was instructed to press \"YES\" for stereotype-inconsistent information, while the negation condition was told to press \"NO\" for stereotype-consistent information. The results showed that the counterstereotype condition decreased implicit bias, but the negation condition increased bias. A possible explanation for the increase in bias with negation training is the level of control required during memory retrieval. During negation training, the memory of a previously held stereotype is activated and then you have to purposefully reject the meaning of the memory. The participants were repeatedly activating the memory of the stereotype, which made it stronger, and they were not able to replace the stereotype with a positive counterstereotype. Alternatively, in counterstereotyping, you do not have to exhibit control to reject a memory because a new and separate memory for stereotype-inconsistent information is formed.<br> Recently, Johnson, Kopp, and Petty (2018) attempted to reconcile the discrepant results of the previous research. They argued the negation was not meaningful and participants were not adequately motivated to get rid of their unconscious biases. The researchers introduced a condition in which participants were told to think, \"That's wrong!\" in response to stereotype-consistent information. Other participants were told, instead, to continue to use the typical form of negation and simply responded \"No\" to stereotype-consistent information. The researchers hypothesized that \"No\" is an ambiguous and weak response to stereotypes, but \"That's wrong!\" is a specific and morally tied response that is hard to ignore. When participants were told to think, \"that's wrong!\" in response stereotype-consistent information, there was a decrease in unconscious bias that was not observed in the condition that simply thought \"no\". Additionally, the researchers discovered that motivation plays a role in the effectiveness of unconscious bias training programs. After the negation training tasks, participants took the Motivation to Control for Prejudiced Reactions Scale (MCPR) to measure the participants' drive to change their unconscious biases. People who scored particularly high on the MCPR showed a reduction in bias regardless of the condition. Therefore, if people feel determined to reduce their unconscious biases and think \"that's wrong\" rather than \"no\", negation training shows promising results for decreasing implicit racial bias.",
            "score": 113.53041076660156
        },
        {
            "docid": "511014_13",
            "document": "Attribution bias . Although psychologists agreed that people are prone to these cognitive biases, there existed disagreement concerning the cause of such biases. On one hand, supporters of a \"cognitive model\" argued that biases were a product of human information processing constraints. One major proponent of this view was Yale psychologist Michael Storms, who proposed this cognitive explanation following his 1973 study of social perception. In his experiment, participants viewed a conversation between two individuals; we'll call them Actor one and Actor two. Some participants viewed the conversation while facing Actor one, such that they were unable to see the front of Actor two, while other participants viewed the conversation while facing Actor two, obstructed from the front of Actor one. Following the conversation, participants were asked to make attributions about the conversationalists. He found that participants ascribed more causal influence to the person they were looking at. In other words, participants made different attributions about people depending on the information they had access to. Storms used these results to bolster his theory of cognitively driven attribution biases; because we have no access to the world except for through our own eyes, we are inevitably constrained and consequently prone to biases. Similarly, social psychologist Anthony Greenwald described humans as possessing a \"totalitarian ego\", meaning that we view the world through our own personal selves. Therefore, different people inevitably interpret the world differently and in turn reach different conclusions.",
            "score": 112.68150329589844
        },
        {
            "docid": "15092946_16",
            "document": "Impact evaluation . With that said, randomized field experiments are not always feasible to carry out and in these situations there are alternative research designs that are at the disposal of an evaluator. The main problem though is that regardless of which design an evaluator chooses, they are prone to a common problem: Regardless of how well thought through or well implemented the design is, each design is subject to yielding biased estimates of the program effects. These biases play the role of exaggerating or diminishing program effects. Not only that, but the direction the bias may take cannot usually be known in advance (Rossi et al., 2004). These biases affect the interest of the stakeholder. Furthermore, it is possible that program participants are disadvantaged if the bias is in such a way that it contributes to making an ineffective or harmful program seem effective. There is also the possibility that a bias can make an effective program seem ineffective or even as far as harmful. This could possibly make the accomplishments of program seem small or even insignificant therefore forcing the personnel and even cause the program's sponsors to reduce or eliminate the funding for the program (Rossi et al., 2004).",
            "score": 112.25617980957031
        },
        {
            "docid": "31881841_46",
            "document": "Implicit stereotype . Studies have shown that racial bias predicts in-group health outcomes among minority populations. In countries where blacks had more implicit bias towards whites, blacks died at higher rates, and vice versa. Implicit biases effect daily perceptions and legal judgments. Stereotyping is more likely to occur when an individual is making a subjective decision, is busy or distracted, is overwhelmed by a heavy workload, or in a situation where they feel threatened or insecure. Biases tint our outlook, and as a result, our judgments and actions. Everyday people run legal systems, which makes it likely for legal decisions to be bias. For many, crime is linked with certain races. Bias training can help here, but is not always effective.",
            "score": 112.16618347167969
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 111.55560302734375
        },
        {
            "docid": "893668_2",
            "document": "Bias blind spot . The bias blind spot is the cognitive bias of recognizing the impact of biases on the judgment of others, while failing to see the impact of biases on one's own judgment. The term was created by Emily Pronin, a social psychologist from Princeton University's Department of Psychology, with colleagues Daniel Lin and Lee Ross. The bias blind spot is named after the visual blind spot. Most people appear to exhibit the bias blind spot. In a sample of more than 600 residents of the United States, more than 85% believed they were less biased than the average American. Only one participant believed that he or she was more biased than the average American. People do vary with regard to the extent to which they exhibit the bias blind spot. It appears to be a stable individual difference that is measurable (for a scale, see Scopelliti et al. 2015).",
            "score": 111.2794189453125
        },
        {
            "docid": "54830261_6",
            "document": "Unconscious bias training . The researchers did a follow up study with a slightly different procedure to determine why bias was increased in some conditions and decreased in others. They followed the same counterstereotype training procedure, but divided the job application task into two distinct parts. Participants were either asked to first pick the best candidate for the job and then rank each candidate on sixteen traits (half were female stereotypes and the other half were male stereotypes) or they were asked to complete the tasks in the opposite order. Regardless of the order, participants consistently were biased against women in the first task, but not in the second task. The researchers hypothesized that the participants were able to discern that the purpose of the study was to reduce gender bias, so they showed an increase bias in the first task to compensate for the researcher\u2019s attempt to influence their behaviors. Further research is necessary to determine why participants showed decreased bias on the second task and if the decreased has an enduring effect.",
            "score": 111.02226257324219
        },
        {
            "docid": "53095115_9",
            "document": "Factors contributing to racial bias in threat perception . There are two race effects that lead to Blacks being incorrectly shot at more than Whites: After being tasked to shoot individuals who held guns, and not to shoot if they were carrying any other object, race should technically be irrelevant to the decision to shoot or not shoot because the correct response solely depends on the object being held. Even as a nondiagnostic component to the evaluation of one\u2019s perceived threat value race was still factored in to the overall judgment of threat perception. The only information the participants were obligated to attend to was the identification of a weapon or non-weapon. Racial cues promote biased behavior as well as false threat perception. Any cue that implies danger, not just race, may create a predisposition to shoot, however race and the stereotype associated with it lead to a higher evaluation of threat perception, which impacted biased responses.",
            "score": 110.89576721191406
        },
        {
            "docid": "19337310_45",
            "document": "Rodent . Because laboratory mice (house mice) and rats (brown rats) are widely used as scientific models to further our understanding of biology, a great deal has come to be known about their cognitive capacities. Brown rats exhibit cognitive bias, where information processing is biased by whether they are in a positive or negative affective state. For example, laboratory rats trained to respond to a specific tone by pressing a lever to receive a reward, and to press another lever in response to a different tone so as to avoid receiving an electric shock, are more likely to respond to an intermediate tone by choosing the reward lever if they have just been tickled (something they enjoy), indicating \"a link between the directly measured positive affective state and decision making under uncertainty in an animal model.\"",
            "score": 110.43350982666016
        },
        {
            "docid": "1051310_9",
            "document": "Response bias . Acquiescence bias, which is also referred to as \"yea-saying\", is a category of response bias in which respondents to a survey have a tendency to agree with all the questions in a measure. This bias in responding may represent a form of dishonest reporting because the participant automatically endorses any statements, even if the result is contradictory responses. For example, a participant could be asked whether they endorse the following statement, \"I prefer to spend time with others\" but then later on in the survey also endorses \"I prefer to spend time alone,\" which are contradictory statements. This is a distinct problem for self-report research because it does not allow a researcher to understand or gather accurate data from any type of question that asks for a participant to endorse or reject statements. Researchers have approached this issue by thinking about the bias in two different ways. The first deals with the idea that participants are trying to be agreeable, in order to avoid the disapproval of the researcher. A second cause for this type of bias was proposed by Lee Cronbach, when he argued that it is likely due to a problem in the cognitive processes of the participant, instead of the motivation to please the researcher. He argues that it may be due to biases in memory where an individual recalls information that supports endorsement of the statement, and ignores contradicting information.",
            "score": 109.89510345458984
        },
        {
            "docid": "48258936_5",
            "document": "Debiasing . Changing incentives can be an effective means to debias judgment and decision making. This approach is generally derived from economic theories suggesting that people act in their self-interest by seeking to maximize their utility over their lifetime. Many decision making biases may occur simply because they are more costly to eliminate than to ignore. Making people more accountable for their decisions (increasing incentives), for example, can increase the extent to which they invest cognitive resources in making decisions, leading to less biased decision making when people generally have an idea of how a decision should be made. However, \"bias\" might not be the appropriate term for these types of decision making errors. These \"strategy-based\" errors occur simply because the necessary effort outweighs the benefit. If a person makes a suboptimal choice based on an actual bias, then incentives may exacerbate the issue. An incentive in this case may simply cause the person to perform the suboptimal behavior more enthusiastically.",
            "score": 109.590087890625
        },
        {
            "docid": "7743915_16",
            "document": "Need for cognition . NFC is associated with the amount of thought that goes into making a decision. Both high and low levels of the trait may be associated with particular biases in judgment. People low in need for cognition tend to show more bias when this bias is due to relying on mental shortcuts, that is, heuristic biases. People high in this trait tend to be more affected by biases that are generated by effortful thought.",
            "score": 108.76010131835938
        },
        {
            "docid": "2671343_49",
            "document": "Criticism of religion . Some studies show positive links in the relationship between religiosity and moral behavior, altruism and crime. A meta-analysis of 60 studies on religion and crime concluded that \"The existing evidence surrounding the effect of religion on crime is varied, contested, and inconclusive, and currently no persuasive answer exists as to the empirical relationship between religion and crime.\" One study revealed that at least in the United States forty percent of worship service attenders volunteer regularly to help the poor and elderly as opposed to 15% of Americans who never attend services. Some studies have shown similar correlations between religiosity and giving. However membership of a religious group can accentuate biases in behavior toward in group versus out group members, which may explain the lower number of interracial friends and greater approval of torture among church members. Furthermore, some studies have shown that religious prosociality is primarily motivated by wanting to appear prosocial, which may be related to the desire to further ones religious group. The egoistically motivated prosociality may also affect self-reports, resulting in biased results. Peer ratings can be biased by stereotypes, and indications of a persons group affiliation are sufficient to bias reporting.",
            "score": 108.0779800415039
        },
        {
            "docid": "893668_13",
            "document": "Bias blind spot . Initial evidence suggests that the bias blind spot is not related to actual decision-making ability. Participants who scored better or poorer on various tasks associated with decision making competence were no more or less likely to be higher or lower in their susceptibility to bias blind spot. Bias blind spot does, however, appear to increase susceptibility to related biases. People who are high in bias blind spot are more likely to ignore the advice of other people, and are less likely to benefit from training geared to reduce their commission of other biases.",
            "score": 107.4132080078125
        },
        {
            "docid": "37940820_23",
            "document": "Emotion perception . Researchers employ several methods designed to examine biases toward emotional stimuli to determine the salience of particular emotional stimuli, population differences in emotion perception, and also attentional biases toward or away from emotional stimuli. Tasks commonly utilized include the modified Stroop task, the dot probe task, visual search tasks, and spatial cuing tasks.  The Stroop task, or modified Stroop task, displays different types of words (e.g., threatening and neutral) in varying colors. The participant is then asked to identify the color of the word while ignoring the actual semantic content. Increased response time to indicate the color of threat words relative to neutral words suggests an attentional bias toward such threat. The Stroop task, however, has some interpretational difficulties in addition to the lack of allowance for the measurement of spatial attention allocation. To address some of the limitations of the Stroop task, the dot probe task displays two words or pictures on a computer screen (either one at the top or left and the other on the bottom or right, respectively) and after a brief stimuli presentation, often less than 1000ms, a probe appears in the location of one of the two stimuli and participants are asked to press a button indicating the location of the probe. Different response times between target (e.g., threat) and neutral stimuli infer attentional biases to the target information with shorter response times for when the probe is in the place of the target stimuli indicating an attention bias for that type of information. In another task that examines spatial attentional allocation, the visual search task asks participants to detect a target stimulus embedded in a matrix of distractors (e.g., an angry face among several neutral or other emotional faces or vice versa). Faster detection times to find emotional stimuli among neutral stimuli or slower detection times to find neutral stimuli among emotional distractors infer an attentional bias for such stimuli. The spatial cuing task asks participants to focus on a point located between two rectangles at which point a cue is presented, either in the form of one of the rectangles lighting up or some emotional stimuli appearing within one of the rectangles and this cue either directs attention toward or away from the actual location of the target stimuli. Participants then press a button indicating the location of the target stimuli with faster response times indicating an attention bias toward such stimuli.",
            "score": 107.08804321289062
        },
        {
            "docid": "20666057_17",
            "document": "Framing effect (psychology) . The framing effect is greater in older adults than in younger adults or adolescents. This may be a result of enhanced negativity bias, though some sources claim that the negativity bias actually decreases with age. Another possible cause is that older adults have fewer cognitive resources available to them and are more likely to default to less cognitively demanding strategies when faced with a decision. They tend to rely on easily accessible information, or frames, regardless of whether that information is relevant to making the decision in question. Several studies have shown that younger adults will make less biased decisions than older adults because they base their choices on interpretations of patterns of events and can better employ decision making strategies that require cognitive resources like working-memory skills. Older adults, on the other hand, make choices based on immediate reactions to gains and losses.",
            "score": 106.95155334472656
        },
        {
            "docid": "41626302_5",
            "document": "Brogrammer . In companies like Google, Yahoo, Facebook, and Apple women make up less than 20 percent of employees. In a recent interview with Megan Smith, Obama's top policy adviser on technology, she states to an audience gathered at Capitol Hill that Tech Companies acknowledge the fact that their hiring of women is less than stellar; however, \"despite promises to do better, only those that make it a top priority will see progress.\" Not everyone is willing to let go of their biases against women. Not only are there biases among men, but there are also biases among women themselves. Studies show that women often underestimate and undervalue their own abilities. One such study exemplifies this by giving men and women a list of criteria that they have to meet in order to apply for a job, and results show that, out of 10 characteristics required for a job, men will usually apply if they meet three of those criteria, while women will only apply if they meet at least seven. \"So biases will just be part of any decision we make. One of the big research fields right now is how to mitigate bias, and there are software tools being created and other things that can help address this challenge.\"",
            "score": 106.90559387207031
        },
        {
            "docid": "244119_14",
            "document": "Androcentrism . Three studies by Mykol Hamilton show that there is not only a male\u200a\u2192\u200apeople bias but also a people\u200a\u2192\u200amale bias. In other words, a masculine bias remains even when people are exposed to only gender neutral language (although the bias is lessened). In two of her studies, half of the participants (after exposure to gender neutral language) had male-biased imagery but the rest of the participants displayed no gender bias at all. In her third study, only males showed a masculine-bias (after exposure to gender neutral language) \u2014 the female species showed no gender bias. Hamilton asserted that this may be due to the fact that males have grown up being able to think more easily than females of \"any person\" as generic \"he,\" since \"he\" applies to them. Further, of the two options for neutral language, neutral language that explicitly names women (e.g., \"he or she\") reduces androcentrism more effectively than neutral language that makes no mention of gender whatsoever (e.g., \"human\").",
            "score": 106.000244140625
        },
        {
            "docid": "32344_74",
            "document": "Variance . Secondly, the sample variance does not generally minimize mean squared error between sample variance and population variance. Correcting for bias often makes this worse: one can always choose a scale factor that performs better than the corrected sample variance, though the optimal scale factor depends on the excess kurtosis of the population (see mean squared error: variance), and introduces bias. This always consists of scaling down the unbiased estimator (dividing by a number larger than \"n\"\u00a0\u2212\u00a01), and is a simple example of a shrinkage estimator: one \"shrinks\" the unbiased estimator towards zero. For the normal distribution, dividing by \"n\"\u00a0+\u00a01 (instead of \"n\"\u00a0\u2212\u00a01 or \"n\") minimizes mean squared error. The resulting estimator is biased, however, and is known as the biased sample variation.",
            "score": 105.97429656982422
        },
        {
            "docid": "893668_7",
            "document": "Bias blind spot . When made aware of various biases acting on our perception, decisions, or judgments, research has shown that we are still unable to control them. This contributes to the bias blind spot in that even if one is told that they are biased, they are unable to alter their biased perception.",
            "score": 105.9317626953125
        }
    ]
}