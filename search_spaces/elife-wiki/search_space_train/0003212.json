{
    "q": [
        {
            "docid": "21312318_27",
            "document": "Recognition memory . Recognition memory is critically dependent on a hierarchically organized network of brain areas including the visual ventral stream, medial temporal lobe structures, frontal lobe and parietal cortices along with the hippocampus. As mentioned previously, the processes of recollection and familiarity are represented differently in the brain. As such, each of the regions listed above can be further subdivided according to which part is primarily involved in recollection or in familiarity. In the temporal cortex, for instance, the medial region is related to recollection whereas the anterior region is related to familiarity. Similarly, in the parietal cortex, the lateral region is related to recollection whereas the superior region is related to familiarity. An even more specific account divides the medial parietal region, relating the posterior cingulate to recollection and the precuneus to familiarity. The hippocampus plays a prominent role in recollection whereas familiarity depends heavily on the surrounding medial-temporal regions, especially the perirhinal cortex. Finally, it is not yet clear what specific regions of the prefrontal lobes are associated with recollection versus familiarity, although there is evidence that the left prefrontal cortex is correlated more strongly with recollection whereas the right prefrontal cortex is involved more in familiarity. Though left-side activation involved in recollection was originally hypothesized to result from semantic processing of words (many of these earlier studies used written words for stimuli) subsequent studies using nonverbal stimuli produced the same finding\u2014suggesting that prefrontal activation in the left hemisphere results from any kind of detailed remembering.  As previously mentioned, recognition memory is not a stand-alone concept; rather it is a highly interconnected and integrated sub-system of memory. Perhaps misleadingly, the regions of the brain listed above correspond to an abstract and highly generalized understanding of recognition memory, in which the stimuli or items-to-be-recognized are not specified. In reality, however, the location of brain activation involved in recognition is highly dependent on the nature of the stimulus itself. Consider the conceptual differences in recognizing written words compared to recognizing human faces. These are two qualitatively different tasks and as such it is not surprising that they involve additional, distinct regions of the brain. Recognizing words, for example, involves the visual word form area, a region in the left fusiform gyrus, which is believed to specialized in recognizing written words. Similarly, the fusiform face area, located in the right hemisphere, is linked specifically to the recognition of faces.",
            "score": 89.77570450305939
        },
        {
            "docid": "6265123_13",
            "document": "Stanislas Dehaene . In addition, Dehaene has used brain imaging to study language processing in monolingual and bilingual subjects, and in collaboration with Laurent Cohen, the neural basis of reading. Dehaene and Cohen initially focused on the role of ventral stream regions in visual word recognition, and in particular the role of the left inferior temporal cortex for reading written words. They identified a region they called the \"visual word form area\" (VWFA) that was consistently activated during reading, and also found that when this region was surgically removed to treat patients with intractable epilepsy, reading abilities were severely impaired.",
            "score": 76.33922028541565
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 121.04177331924438
        },
        {
            "docid": "25146378_12",
            "document": "Functional specialization (brain) . One of the most well known examples of functional specialization is the fusiform face area (FFA). Justine Sergent was one of the first researchers that brought forth evidence towards the functional neuroanatomy of face processing. Using positron emission tomography (PET), Sergent found that there were different patterns of activation in response to the two different required tasks, face processing verses object processing. These results can be linked with her studies of brain-damaged patients with lesions in the occipital and temporal lobes. Patients revealed that there was an impairment of face processing but no difficulty recognizing everyday objects, a disorder also known as prosopagnosia. Later research by Nancy Kanwisher using functional magnetic resonance imaging (fMRI), found specifically that the region of the inferior temporal cortex, known as the fusiform gyrus, was significantly more active when subjects viewed, recognized and categorized faces in comparison to other regions of the brain. Lesion studies also supported this finding where patients were able to recognize objects but unable to recognize faces. This provided evidence towards domain specificity in the visual system, as Kanwisher acknowledges the Fusiform Face Area as a module in the brain, specifically the extrastriate cortex, that is specialized for face perception.",
            "score": 116.55684161186218
        },
        {
            "docid": "4231622_5",
            "document": "Inferior temporal gyrus . The temporal lobe is unique to primates. In humans, the IT cortex is more complex than their relative primate counterparts. The human inferior temporal cortex consists of the inferior temporal gyrus, the middle temporal gyrus, and the fusiform gyrus. When looking at the brain laterally \u2013 that is from the side and looking at the surface of the temporal lobe \u2013 the inferior temporal gyrus is along the bottom portion of the temporal lobe, and is separated from the middle temporal gyrus located directly above by the inferior temporal sulcus. Additionally, some processing of the visual field that corresponds to the ventral stream of visual processing occurs in the lower portion of the superior temporal gyrus closest to the superior temporal sulcus. The medial and ventral view of the brain \u2013 meaning looking at the medial surface from below the brain, facing upwards \u2013 reveals that the inferior temporal gyrus is separated from the fusiform gyrus by the occipital-temporal sulcus. This human inferior temporal cortex is much more complex than that of other primates: non-human primates have an inferior temporal cortex that is not divided into unique regions such as humans' inferior temporal gyrus, fusiform gyrus, or middle temporal gyrus.  This region of the brain corresponds to the inferior temporal cortex and is responsible for visual object recognition and receives processed visual information. The inferior temporal cortex in primates has specific regions dedicated to processing different visual stimuli processed and organized by the different layers of the striate cortex and extra-striate cortex. The information from the V1 \u2013V5 regions of the geniculate and tectopulvinar pathways are radiated to the IT cortex via the ventral stream: visual information specifically related to the color and form of the visual stimuli. Through comparative research between primates \u2013 humans and non-human primates \u2013 results indicate that the IT cortex plays a significant role in visual shape processing. This is supported by functional magnetic resonance imaging (fMRI) data collected by researchers comparing this neurological process between humans and macaques.",
            "score": 84.81529915332794
        },
        {
            "docid": "7725524_2",
            "document": "Colour centre . The colour centre is a region in the brain primarily responsible for visual perception and cortical processing of colour signals received by the eye, which ultimately results in colour vision. The colour centre in humans is thought to be located in the ventral occipital lobe as part of the visual system, in addition to other areas responsible for recognizing and processing specific visual stimuli, such as faces, words, and objects. Many functional magnetic resonance imaging (fMRI) studies in both humans and macaque monkeys have shown colour stimuli to activate multiple areas in the brain, including the fusiform gyrus and the lingual gyrus. These areas, as well as others identified as having a role in colour vision processing, are collectively labelled visual area 4 (V4). The exact mechanisms, location, and function of V4 are still being investigated.",
            "score": 104.63312423229218
        },
        {
            "docid": "2640086_28",
            "document": "Affective neuroscience . Instead of investigating specific emotions, Kober, et al. 2008 reviewed 162 neuroimaging studies published between 1990-2005 to determine if groups of brain regions show consistent patterns of activation during emotional experience (that is, actively experiencing an emotion first-hand) and during emotion perception (that is, perceiving a given emotion as experienced by another). This meta-analysis used multilevel kernal density analysis (MKDA) to examine fMRI and PET studies, a technique that prevents single studies from dominating the results (particularly if they report multiple nearby peaks) and that enables studies with large sample sizes (those involving more participants) to exert more influence upon the results. MKDA was used to establish a neural reference space that includes the set of regions showing consistent increases across all studies (for further discussion of MDKA see Wager et al. 2007). Next, this neural reference space was partitioned into functional groups of brain regions showing similar activation patterns across studies by first using multivariate techniques to determine co-activation patterns and then using data-reduction techniques to define the functional groupings (resulting in six groups). Consistent with a psychological construction approach to emotion, the authors discuss each functional group in terms more basic psychological operations. The first \u201cCore Limbic\u201d group included the left amygdala, hypothalamus, periaqueductal gray/thalamus regions, and amygdala/ventral striatum/ventral globus pallidus/thalamus regions, which the authors discuss as an integrative emotional center that plays a general role in evaluating affective significance. The second \u201cLateral Paralimbic\u201d group included the ventral anterior insula/frontal operculum/right temporal pole/ posterior orbitofrontal cortex, the anterior insula/ posterior orbitofrontal cortex, the ventral anterior insula/ temporal cortex/ orbitofrontal cortex junction, the midinsula/ dorsal putamen, and the ventral striatum /mid insula/ left hippocampus, which the authors suggest plays a role in motivation, contributing to the general valuation of stimuli and particularly in reward. The third \u201cMedial Prefrontal Cortex\u201d group included the dorsal medial prefrontal cortex, pregenual anterior cingulate cortex, and rostral dorsal anterior cingulate cortex, which the authors discuss as playing a role in both the generation and regulation of emotion. The fourth \u201cCognitive/ Motor Network\u201d group included right frontal operculum, the right interior frontal gyrus, and the pre-supplementray motor area/ left interior frontal gyrus, regions that are not specific to emotion, but instead appear to play a more general role in information processing and cognitive control. The fifth \u201cOccipital/ Visual Association\u201d group included areas V8 and V4 of the primary visual cortex, the medial temporal lobe, and the lateral occipital cortex, and the sixth \u201cMedial Posterior\u201d group included posterior cingulate cortex and area V1 of the primary visual cortex. The authors suggest that these regions play a joint role in visual processing and attention to emotional stimuli.",
            "score": 61.11574733257294
        },
        {
            "docid": "21571449_7",
            "document": "Prosopamnesia . Within the brain, visual stimuli are processed along many different neural circuits. Due to the evolutionary importance of being able to recognize faces and associate information with others based on this recognition, humans have evolved a distinct neural circuit for the processing of facial stimuli. Since the discovery of this distinct circuit, the anatomical structures involved have been studied in depth. The initial processing of visual stimuli occurs in the prefrontal cortex (PFC), postparietal cortex (PPC), and precuneus. The stimuli are then identified as being facial and more refined processing occurs within the fusiform face area (FFA), the occipital face area (OFA), and the face-selective region of the superior temporal sulcus (fSTS). The FFA serves low level tasks, such as distinguishing details between similar well-known objects. The OFA and fSTS serve higher level processing tasks, such as connecting a person's identity to their face and processing emotions based on the arrangement of facial features, respectively. Once facial stimuli have been processed, they are then encoded into memory. This involves many brain structures including the medial temporal lobe (MTL), and the hippocampus. Storage and retrieval of these memories involves the same regions of the FFA, PFA, and PPC that performed the initial processing tasks.",
            "score": 89.80272161960602
        },
        {
            "docid": "6572488_8",
            "document": "Neural basis of synesthesia . Functional neuroimaging studies using positron emission tomography (PET) and functional magnetic resonance imaging (fMRI) have demonstrated significant differences between the brains of synesthetes and non-synesthetes (although some studies failed to find such differences). The first such study used PET to demonstrate that some regions of the visual cortex (but not V4) were more active when auditory word \u2192 color synesthetes listened to words compared to tones . More recent studies using fMRI have demonstrated that V4 is more active in both word \u2192 color and grapheme \u2192 color synesthetes (; ; ). However, these neuroimaging studies do not have the spatial and temporal resolution to distinguish between the pruning and disinhibited feedback theories. Future research will continue to examine these questions using not only fMRI but also diffusion tensor imaging (DTI), which allows researchers to directly investigate neural connectivity in the human brain and magnetic resonance spectroscopy (MRS) which allows researchers to measure the amounts of different neurotransmitters in the brain.",
            "score": 103.40823793411255
        },
        {
            "docid": "5212945_3",
            "document": "Visual neuroscience . A recent study using Event-Related Potentials (ERPs) linked an increased neural activity in the occipito-temporal region of the brain to the visual categorization of facial expressions. Results focus on a negative peak in the ERP that occurs 170 milliseconds after the stimulus onset. This action potential, called the N170, was measured using electrodes in the occipito-temporal region, an area already known to be changed by face stimuli. Studying by using the EEG, and ERP methods allow for an extremely high temporal resolution of 4 milliseconds, which makes these kinds of experiments extremely well suited for accurately estimating and comparing the time it takes the brain to perform a certain function. Scientists used classification image techniques, to determine what parts of complex visual stimuli (such as a face) will be relied on when patients are asked to assign them to a category, or emotion. They computed the important features when the stimulus face exhibited one of five different emotions. Stimulus faces exhibiting fear had the distinguishing feature of widening eyes, and stimuli exhibiting happiness exhibited a change in the mouth to make a smile. Regardless of the expression of the stimuli's face, the region near the eyes affected the EEG before the regions near the mouth. This revealed a sequential, and predetermined order to the perception and processing of faces, with the eye being the first, and the mouth, and nose being processed after. This process of downward integration only occurred when the inferior facial features were crucial to the categorization of the stimuli. This is best explained by comparing what happens when participants were shown a face exhibiting fear, versus happiness. The N170 peaked slightly earlier for the fear stimuli at about 175 milliseconds, meaning that it took a participants less time to recognize the facial expression. This is expected because only the eyes need to be processed to recognize the emotion. However, when processing a happy expression, where the mouth is crucial to categorization, downward integration must take place, and thus the N170 peak occurred later at around 185 milliseconds. Eventually visual neuroscience aims to completely explain how the visual system processes all changes in faces as well as objects. This will give a complete view to how the world is constantly visually perceived, and may provide insight into a link between perception and consciousness.",
            "score": 118.53361141681671
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 97.1527293920517
        },
        {
            "docid": "485309_16",
            "document": "Face perception . There are several parts of the brain that play a role in face perception. Rossion, Hanseeuw, and Dricot used BOLD fMRI mapping to identify activation in the brain when subjects viewed both cars and faces. The majority of BOLD fMRI studies use blood oxygen level dependent (BOLD) contrast to determine which areas of the brain are activated by various cognitive functions. They found that the occipital face area, located in the occipital lobe, the fusiform face area, the superior temporal sulcus, the amygdala, and the anterior/inferior cortex of the temporal lobe, all played roles in contrasting the faces from the cars, with the initial face perception beginning in the area and occipital face areas. This entire region links to form a network that acts to distinguish faces. The processing of faces in the brain is known as a \"sum of parts\" perception. However, the individual parts of the face must be processed first in order to put all of the pieces together. In early processing, the occipital face area contributes to face perception by recognizing the eyes, nose, and mouth as individual pieces. Furthermore, Arcurio, Gold, and James used BOLD fMRI mapping to determine the patterns of activation in the brain when parts of the face were presented in combination and when they were presented singly. The occipital face area is activated by the visual perception of single features of the face, for example, the nose and mouth, and preferred combination of two-eyes over other combinations. This research supports that the occipital face area recognizes the parts of the face at the early stages of recognition. On the contrary, the fusiform face area shows no preference for single features, because the fusiform face area is responsible for \"holistic/configural\" information, meaning that it puts all of the processed pieces of the face together in later processing. This theory is supported by the work of Gold et al. who found that regardless of the orientation of a face, subjects were impacted by the configuration of the individual facial features. Subjects were also impacted by the coding of the relationships between those features. This shows that processing is done by a summation of the parts in the later stages of recognition.",
            "score": 89.79906296730042
        },
        {
            "docid": "1061157_11",
            "document": "Dual-coding theory . Two different methods have been used to identify the regions involved in visual perception and visual imagery. First, functional magnetic resonance imaging (fMRI) is used to measure cerebral blood flow, which allows researchers to identify the amount of glucose and oxygen being consumed by a specific part of the brain, with an increase in blood flow providing a measure of brain activity. Second, an event related potential (ERP) can be used to show the amount of electrical brain activity that is occurring due to a particular stimulus. Researchers have used both methods to determine which areas of the brain are active with different stimuli, and results have supported the dual-coding theory. Other research has been done with positron emission tomography (PET) scans and fMRI to show that participants had improved memory for spoken words and sentences when paired with an image, imagined or real, and showed increased brain activation to process abstract words not easily paired with an image.",
            "score": 116.05373644828796
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 114.52298712730408
        },
        {
            "docid": "35891793_2",
            "document": "Visual word form area . The visual word form area (VWFA) is a functional region of the left fusiform gyrus and surrounding cortex (right-hand side being part of the fusiform face area) that is hypothesized to be involved in identifying words and letters from lower-level shape images, prior to association with phonology or semantics. Because the alphabet is relatively new in human evolution, it is unlikely that this region developed as a result of selection pressures related to word recognition per se; however, this region may be highly specialized for certain types of shapes that occur naturally in the environment and are therefore likely to surface within written language.",
            "score": 57.85717010498047
        },
        {
            "docid": "226722_25",
            "document": "Functional magnetic resonance imaging . Researchers have checked the BOLD signal against both signals from implanted electrodes (mostly in monkeys) and signals of field potentials (that is the electric or magnetic field from the brain's activity, measured outside the skull) from EEG and MEG. The local field potential, which includes both post-neuron-synaptic activity and internal neuron processing, better predicts the BOLD signal. So the BOLD contrast reflects mainly the inputs to a neuron and the neuron's integrative processing within its body, and less the output firing of neurons. In humans, electrodes can be implanted only in patients who need surgery as treatment, but evidence suggests a similar relationship at least for the auditory cortex and the primary visual cortex. Activation locations detected by BOLD fMRI in cortical areas (brain surface regions) are known to tally with CBF-based functional maps from PET scans. Some regions just a few millimeters in size, such as the lateral geniculate nucleus (LGN) of the thalamus, which relays visual inputs from the retina to the visual cortex, have been shown to generate the BOLD signal correctly when presented with visual input. Nearby regions such as the pulvinar nucleus were not stimulated for this task, indicating millimeter resolution for the spatial extent of the BOLD response, at least in thalamic nuclei. In the rat brain, single-whisker touch has been shown to elicit BOLD signals from the somatosensory cortex.",
            "score": 110.02405273914337
        },
        {
            "docid": "26685741_28",
            "document": "Sleep and memory . A blood-oxygen-level dependent (BOLD) fMRI was used in a study by Drummond et al. to measure the brain's response to verbal learning following sleep deprivation. An fMRI recorded brain activity during a verbal learning task of participants either having a normal night of sleep or those deprived of 34.7 (\u00b1 1.2) hours of sleep. The task alternated between a baseline condition of determining whether nouns were upper or lower case and an experimental condition of memorizing a list of nouns. The results of the study indicate that performance is significantly worse on free recall of the list of nouns when sleep deprived (an average of 2.8 \u00b1 2 words) compared to having a normal night of sleep (4.7 \u00b1 4 words). In terms of brain regions activated, the left prefrontal cortex, premotor cortex, and temporal lobes were found to be activated during the task in the rested state and discrete regions of the prefrontal cortex were even more activated during the task in the sleep deprived state. As well, the bilateral parietal lobe, left middle frontal gyrus, and right interior frontal gyrus were found to be activated for those sleep deprived. The implication of these findings are that the brain can initially compensate for the effects of sleep deprivation while maintaining partially intact performance, which declines with an increasing time-on-task. This initial compensation may be found in the bilateral regions of both frontal and parietal lobes and the activation of the prefrontal cortex is significantly correlated with sleepiness.",
            "score": 79.61793601512909
        },
        {
            "docid": "4231622_9",
            "document": "Inferior temporal gyrus . These areas must all work together, as well as with the hippocampus, in order to create an array of understanding of the physical world. The hippocampus is key for storing the memory of what an object is/what it looks like for future use so that it can be compared and contrasted with other objects. Correctly being able to recognize an object is highly dependent on this organized network of brain areas that process, share, and store information. In a study by Denys et al., functional magnetic resonance imaging (FMRI) was used to compare the processing of visual shape between humans and macaques. They found, amongst other things, that there was a degree of overlap between shape and motion sensitive regions of the cortex, but that the overlap was more distinct in humans. This would suggest that the human brain is better evolved for a high level of functioning in a distinct, three-dimensional, visual world.",
            "score": 90.32801580429077
        },
        {
            "docid": "33702464_5",
            "document": "Extrastriate body area . The experiment had subjects view images of different objects, including faces (as a control group), body parts, animals, parts of the face and intimate objects. While viewing the images, the subjects were scanned with an fMRI to see what area of the brain was activated. Through the trials a compilation of the fMRI\u2019s was made. From this compilation image a specific region was determined to have increased activity when shown visual stimuli of body parts and even more activity when viewing whole bodies. There have been no studies involving brain damage to the EBA. Thus far, only scans of brain activity, as well as transcranial magnetic stimulation, have been used to study the EBA. To find the specific functions of the EBA, Comimo Urgesi, Giovanni Berlucchi and Salvatore M. Aglioti used repetitive transcranial magnetic stimulation (rTMS) to disrupt part of the brain, making the brain less responsive in the target area. The study used event-related rTMS to disrupt the EBA, resulting in inactivation of cortical areas. This inactivation caused a slower response time in discriminating body parts. The study used facial features and motorcycle parts as non human parts for control groups. The facial features and motorcycle body parts did not display any change in response time. The neural activity data shows the EBA handles some of the visual processing of human body and parts but is not related to the processing of the face or other objects.",
            "score": 134.6599886417389
        },
        {
            "docid": "39151518_10",
            "document": "Neuronal recycling hypothesis . As was stated in the neuronal recycling hypothesis, brain circuits bias what we are able to learn. One bias identified involves the preference of central versus peripheral images at different points along the cerebral cortex. It was observed that in all individuals, the visual word form area fell on the region of the cortex with a massive preference for fine-grained, central images. This area is most suitable to accommodate reading ability, due to the high degree of visual precision necessary to perform this function effectively. Another cortical bias relevant to reading comes from the lateralization of cerebral hemispheres. Reading consistently activates the left hemisphere, which is associated with language abilities and discriminating between small shapes, showing a clear bias towards reading functions. There is a preadaptation of the inferior temporal cortex that we use when learning to read. It is the area activated during invariant object recognition, and it's sufficient plasticity allows it to accommodate the new shapes and symbols necessary for reading.",
            "score": 93.98896920681
        },
        {
            "docid": "1809033_23",
            "document": "Stereotype threat . Another study used functional magnetic resonance imaging (fMRI) to investigate brain activity associated with stereotype threat. The researchers found that women experiencing stereotype threat while taking a math test showed heightened activation in the ventral stream of the anterior cingulate cortex (ACC), a neural region thought to be associated with social and emotional processing. Wraga and colleagues found that women under stereotype threat showed increased activation in the ventral ACC and that the amount of this activation predicted performance decrements on the task. When individuals were made aware of performance-related stimuli, they were more likely to experience stereotype threat.",
            "score": 79.77635598182678
        },
        {
            "docid": "23836909_39",
            "document": "Hypostatic model of personality . Research using functional magnetic resonance imaging of the brain suggests that cognitive and affective-expressive forms of communication and self-reflection have distinct neural bases. Clinical findings have long suggested that verbalizations are often very incoherent when the individual is trying to put into words something deeply emotional. Identification of words naming emotions (happy, neutral, sad) was found to be faster than identification of corresponding facial expressions. Recognition of face expressions was more difficult to suppress in favor of the recognition of words than vice versa, the two conditions presenting different patterns of brain activation. These experimental results suggest that reading and recognition of face expressions are stimulus-dependent and perhaps hierarchical behaviors, hence recruiting distinct regions of the medial prefrontal cortex.",
            "score": 106.67286324501038
        },
        {
            "docid": "4231622_3",
            "document": "Inferior temporal gyrus . The inferior temporal gyrus is the anterior region of the temporal lobe located underneath the central temporal sulcus. The primary function of the occipital temporal gyrus \u2013 otherwise referenced as IT cortex \u2013 is associated with visual stimuli processing, namely visual object recognition, and has been suggested by recent experimental results as the final location of the ventral cortical visual system. The IT cortex in humans is also known as the Inferior Temporal Gyrus since it has been located to a specific region of the human temporal lobe. The IT processes visual stimuli of objects in our field of vision, and is involved with memory and memory recall to identify that object; it is involved with the processing and perception created by visual stimuli amplified in the V1, V2, V3, and V4 regions of the occipital lobe. This region processes the color and form of the object in the visual field and is responsible for producing the \u201cwhat\u201d from this visual stimuli, or in other words identifying the object based on the color and form of the object and comparing that processed information to stored memories of objects to identify that object.",
            "score": 49.99479126930237
        },
        {
            "docid": "21312301_12",
            "document": "Context-dependent memory . A number of neuroanatomical structures are thought to play a role in context-dependent memory, These include the hippocampus and prefrontal cortex. For example, functional magnetic resonance imaging (fMRI) has been used to demonstrate elevated activation in the hippocampus when contextual information matches from encoding to retrieval, suggesting that the hippocampus may be important in mediating context-dependent memory processes. Kalisch et al. provide further support for this role by demonstrating that context-dependent extinction memory is correlated with activation in both the hippocampus and ventromedial prefrontal cortex. Similarly, an experiment by Wagner et al. using fMRI demonstrated that activation of the right prefrontal cortex depended on contextual information. The authors of this study suggest that differential activation of the prefrontal cortex occurs because the different contexts require unique attempt processes for retrieval. In other words, depending on the retrieval context, participants used different strategies to recall information. Overall, the patterns of activation in the hippocampus and the prefrontal cortex following changes in contextual information suggest that these brain regions play an important role in context-dependent memory.",
            "score": 67.92614078521729
        },
        {
            "docid": "484650_7",
            "document": "Functional neuroimaging . Traditional \"activation studies\" focus on determining distributed patterns of brain activity associated with specific tasks. However, scientists are able to more thoroughly understand brain function by studying the interaction of distinct brain regions, as a great deal of neural processing is performed by an integrated network of several regions of the brain. An active area of neuroimaging research involves examining the functional connectivity of spatially remote brain regions. Functional connectivity analyses allow the characterization of interregional neural interactions during particular cognitive or motor tasks or merely from spontaneous activity during rest. FMRI and PET enable creation of functional connectivity maps of distinct spatial distributions of temporally correlated brain regions called functional networks. Several studies using neuroimaging techniques have also established that posterior visual areas in blind individuals may be active during the performance of nonvisual tasks such as Braille reading, memory retrieval, and auditory localization as well as other auditory functions.",
            "score": 101.03502750396729
        },
        {
            "docid": "7725524_14",
            "document": "Colour centre . Functional magnetic resonance imaging, or fMRI for short, has been key in determining the colour selective regions in the visual cortex. fMRI is able to track brain activity by measuring blood flow throughout the brain. Areas that have more blood flowing to them indicates an occurrence of neuronal activity. This change in blood flow is called haemodynamic response. Among the benefits of fMRI includes dynamic, real-time mapping of cortical processes. However, fMRI cannot track the actual firing of neurons, which happen on a millisecond timescale, but it can track the haemodynamic response, which happens on a seconds timescale. This method is ideal for tracking colour selective neurons because colour perception results in a visual after-image that can be observed in the neurons, which lasts about 15 seconds.",
            "score": 97.7215428352356
        },
        {
            "docid": "6009072_2",
            "document": "Seiji Ogawa . Seiji Ogawa (\u5c0f\u5ddd \u8aa0\u4e8c \"Ogawa Seiji\", born January 19, 1934) is a Japanese researcher known for discovering the technique that underlies Functional Magnetic Resonance Imaging (fMRI). He is regarded as the father of modern functional brain imaging. He determined that the changes in blood oxygen levels cause its magnetic resonance imaging properties to change, allowing a map of blood, and hence, functional, activity in the brain to be created. This map reflected which neurons of the brain responded with electrochemical signals to mental processes. He was the first scientist who demonstrated that the functional brain imaging is depended on the oxygenation status of the blood, the BOLD effect. The technique was therefore called Blood oxygenation level-dependent or BOLD contrast. Functional MRI (fMRI) has been used to map the visual, auditory and sensory regions and moving toward higher brain functions such as cognitive functions in the brain.",
            "score": 108.38056337833405
        },
        {
            "docid": "1215674_19",
            "document": "Visual memory . Neuroimaging studies focus on the neural networks involved in visual memory using methods designed to activate brain areas involved in encoding, storage, and recall. These studies involve the use of one or multiple types of brain imaging techniques designed to measure timing or activation within the brain. The data collected from neuroimaging studies gives researchers the ability to visualize which brain regions are activated in specific cognitive visual memory tasks. With the use of brain imaging devices researchers able to further investigate memory performance above and beyond standard tests based on exact response times, and activation.",
            "score": 112.57931876182556
        },
        {
            "docid": "37689507_19",
            "document": "Neuroimaging intelligence testing . A 2012 study from Washington University, St. Louis described the global connectivity of the prefrontal cortex. Global connectivity is the mechanism by which components of the frontoparietal brain network might coordinate control of other tasks. Cole et al. wrote that: \"A lateral prefrontal cortex (LPFC) region's activity was found to predict performance in a high control demand working memory task and also to exhibit high global connectivity. Critically, global connectivity in this LPFC region, involving connections both within and outside the frontoparietal network, showed a highly selective relationship with individual differences in fluid intelligence.\" The lateral prefrontal cortex is a region of interest because those who have injuries to that part of the brain often have issues with common, every day tasks such as planning their day. The LPFC is thought to be important for \"cognitive control capacity,\" which can be used to predict future outcomes such as success in school and the workplace. It was found by van den Heuvel et al. that higher intelligence individuals employ more efficient whole-brain network organization. This had led to the thought that cognitive control capacity may be supported by these whole-brain network properties. The 2012 study used a theoretic approach to neuroimage data known as global brain connectivity (GBC) or weighted degree centrality. GBC let the researches look closely at specific regions and their range of connectivity. It was then possible to examine each region's role in human cognitive control and intelligence. The study used fMRI to acquire data and examine each region's connectivity.",
            "score": 82.87837636470795
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 105.04608905315399
        },
        {
            "docid": "806023_22",
            "document": "Sympathy . Social and emotional stimuli, particularly those related to the well-being of another person, are being more directly studied with advent of technology that can track brain activity (such as Electroencephalograms and functional Magnetic Resonance Imaging). Amygdala and insula activation occur when a person experiences emotions, such as fear and disgust respectively. Primary motor regions are also activated during sympathy. This could be caused by humans' reaction to emotional faces, reflecting the expressions on their own faces, which seems to help people better understand the other person's emotion. In addition, researchers have also suggested that the neural mechanisms that are activated when personally experiencing emotions are also activated when viewing another person experiencing the same emotions (mirror neurons). Pain seems to specifically activate a region known as the cingulate cortex, in addition to activation that is mentioned earlier. The temporal parietal junction, orbitofrontal cortex, and ventral striatum are also thought to play a role in the production of emotion.",
            "score": 79.37178611755371
        },
        {
            "docid": "33702464_6",
            "document": "Extrastriate body area . The actual experiment had people make a \u201ctwo-choice matching-to-sample task. Fourteen right handed participants were required to decide which of two similar upper-limb images matched a single sample previously seen during a tachistoscopic exposure. Photos of face parts and motorcycle parts served as control stimuli in two-matching-to-sample tasks that were comparable to the former task.\u201d rTMS was then applied 150 ms after each sample exposure. The section of the graph, Body Parts, shows the response time while using rTMS. The SHAM category refers to measuring the EBA without rTMS while viewing the images. The Visual Cortex category measures the response of the FFA to be used as the control of the experiment. This measurement of response time, occurring while rTMS was effecting the EBA, further shows that the two areas process visual data of the human form, yet respond to different stimuli. While the magnetic stimulation was temporarily disabling the extrastraite body area, reaction time decreased by about 100 ms. The data from the Sham and Visual Cortex categories on the graph show what was the expected normal results from the experiment. This evidence reveals that applying rTMS to the EBA slowed the response of recognizing images of body parts.",
            "score": 102.77668964862823
        }
    ],
    "r": [
        {
            "docid": "1894873_16",
            "document": "Eye movement . The visual system in the brain is too slow to process that information if the images are slipping across the retina at more than a few degrees per second. Thus, to be able to see while we are moving, the brain must compensate for the motion of the head by turning the eyes. Another specialisation of visual system in many vertebrate animals is the development of a small area of the retina with a very high visual acuity. This area is called the fovea, and covers about 2 degrees of visual angle in people. To get a clear view of the world, the brain must turn the eyes so that the image of the object of regard falls on the fovea. Eye movement is thus very important for visual perception, and any failure can lead to serious visual disabilities. To see a quick demonstration of this fact, try the following experiment: hold your hand up, about one foot (30\u00a0cm) in front of your nose. Keep your head still, and shake your hand from side to side, slowly at first, and then faster and faster. At first you will be able to see your fingers quite clearly. But as the frequency of shaking passes about 1 Hz, the fingers will become a blur. Now, keep your hand still, and shake your head (up and down or left and right). No matter how fast you shake your head, the image of your fingers remains clear. This demonstrates that the brain can move the eyes opposite to head motion much better than it can follow, or pursue, a hand movement. When your pursuit system fails to keep up with the moving hand, images slip on the retina and you see a blurred hand.",
            "score": 142.8266143798828
        },
        {
            "docid": "30525054_7",
            "document": "Anders Dale . In a 2003 interview, Dale explained that he had \u201calways been interested in using quantitative modeling methods and simulations to answer biological questions,\u201d and that as a Harvard student he had been \u201cinterested in approaching connectionist neural networks from a more biological angle.\u201d When he went to UCSD to continue his graduate work his interest \u201cshifted to learning how to test models of how the brain works. Ideally you'd like to test your models not in anesthetized animals and brain slices, but by measuring brain activity in humans non-invasively. I wanted to study normal people doing normal tasks. That was what brought me to imaging. My goal was to see what kind of things we can measure non-invasively that can be quantitatively related to the models we want to build...I wanted to know what exactly we are measuring, how can you model it, and how can you relate the signal to what is going on in the brain physiologically...at a level that say you could measure invasively and that you could relate to parameters of quantitative models.\u201d His thesis work at UCSD, he said, \u201cwas on the EEG and MEG forward and inverse problems, and how to use anatomical information to constrain the solutions. It is clear that if you only use EEG or MEG measures, the spatial precision is not good enough to make inferences at a scale that's most useful to neuroscience. That led us into trying to use information with higher spatial resolution to constrain or bias our estimations of the signal sources in the brain.\u201d",
            "score": 140.16590881347656
        },
        {
            "docid": "1215674_22",
            "document": "Visual memory . The visuo-spatial sketchpad is part of Baddeley and Hitch\u2019s model of working memory. It is responsible for temporarily storing visual and spatial information, which is currently being used or encoded. It is thought of as a three-dimensional cognitive map, which contains spatial features about where the person is and visual images of the area, or an object being concentrated on. It is used in tasks such as mental image manipulation where a person imagines how a real object would look if it were changed in some way (rotated, flipped, moved, change of colour, etc.). It is also responsible for representing how vivid an image is. A vivid image is one which you have a high potential for retrieving its sensory details. The visuo-spatial sketchpad is responsible for holding onto the visual and spatial qualities of a vivid image in your working memory, and the degree of vividness is directly affected by the limits of the sketchpad.",
            "score": 136.98342895507812
        },
        {
            "docid": "41578765_18",
            "document": "Paul Glimcher . Glimcher\u2019s research aims to describe the neural events that underlie behavioral decision-making using tools from neuroscience, psychology, and economics. His research merges psychological and economic models with computational neuroscience, including pioneering uses of fMRI (function magnetic resonance imaging) for behavioral science, to understand how value is encoded in the brain and how the brain uses those neural representations of value to guide decision-making; for example, how the brain carries out delay discounting or action-selection in the face of both risk and ambiguity. His laboratory in NYU\u2019s Center for Neural Science uses a wide range of methods including cohort studies in experimental economics, brain imaging, and single-neuron studies in non-human animals.",
            "score": 135.54721069335938
        },
        {
            "docid": "33702464_5",
            "document": "Extrastriate body area . The experiment had subjects view images of different objects, including faces (as a control group), body parts, animals, parts of the face and intimate objects. While viewing the images, the subjects were scanned with an fMRI to see what area of the brain was activated. Through the trials a compilation of the fMRI\u2019s was made. From this compilation image a specific region was determined to have increased activity when shown visual stimuli of body parts and even more activity when viewing whole bodies. There have been no studies involving brain damage to the EBA. Thus far, only scans of brain activity, as well as transcranial magnetic stimulation, have been used to study the EBA. To find the specific functions of the EBA, Comimo Urgesi, Giovanni Berlucchi and Salvatore M. Aglioti used repetitive transcranial magnetic stimulation (rTMS) to disrupt part of the brain, making the brain less responsive in the target area. The study used event-related rTMS to disrupt the EBA, resulting in inactivation of cortical areas. This inactivation caused a slower response time in discriminating body parts. The study used facial features and motorcycle parts as non human parts for control groups. The facial features and motorcycle body parts did not display any change in response time. The neural activity data shows the EBA handles some of the visual processing of human body and parts but is not related to the processing of the face or other objects.",
            "score": 134.6599884033203
        },
        {
            "docid": "389579_2",
            "document": "Cognitive neuropsychology . Cognitive neuropsychology is a branch of cognitive psychology that aims to understand how the structure and function of the brain relates to specific psychological processes. Cognitive psychology is the science that looks at how mental processes are responsible for our cognitive abilities to store and produce new memories, produce language, recognize people and objects, as well as our ability to reason and problem solve. Cognitive neuropsychology places a particular emphasis on studying the cognitive effects of brain injury or neurological illness with a view to inferring models of normal cognitive functioning. Evidence is based on case studies of individual brain damaged patients who show deficits in brain areas and from patients who exhibit double dissociations. Double dissociations involve two patients and two tasks. One patient is impaired at one task but normal on the other, while the other patient is normal on the first task and impaired on the other. For example, patient A would be poor at reading printed words while still being normal at understanding spoken words, while the patient B would be normal at understanding written words and be poor at understanding spoken words. Scientists can interpret this information to explain how there is a single cognitive module for word comprehension. From studies like these, researchers infer that different areas of the brain are highly specialised. Cognitive neuropsychology can be distinguished from cognitive neuroscience, which is also interested in brain damaged patients, but is particularly focused on uncovering the neural mechanisms underlying cognitive processes.",
            "score": 134.04356384277344
        },
        {
            "docid": "3557219_18",
            "document": "Neuroimaging . Functional magnetic resonance imaging (fMRI) and arterial spin labeling (ASL) relies on the paramagnetic properties of oxygenated and deoxygenated hemoglobin to see images of changing blood flow in the brain associated with neural activity. This allows images to be generated that reflect which brain structures are activated (and how) during performance of different tasks or at resting state. According to the oxygenation hypothesis, changes in oxygen usage in regional cerebral blood flow during cognitive or behavioral activity can be associated with the regional neurons as being directly related to the cognitive or behavioral tasks being attended.",
            "score": 132.08738708496094
        },
        {
            "docid": "24965027_6",
            "document": "Cognitive neuroscience of visual object recognition . A significant aspect of object recognition is that of object constancy: the ability to recognize an object across varying viewing conditions. These varying conditions include object orientation, lighting, and object variability (size, colour, and other within-category differences). For the visual system to achieve object constancy, it must be able to extract a commonality in the object description across different viewpoints and the retinal descriptions.[9] Participants who did categorization and recognition tasks while undergoing a functional magnetic found as increased blood flow indicating activation in specific regions of the brain. The categorization task consisted of participants placing objects from canonical or unusual views as either indoor or outdoor objects. The recognition task occurs by presenting the participants with images that they had viewed previously. Half of these images were in the same orientation as previously shown, while the other half were presented in the opposing viewpoint. The brain regions implicated in mental rotation, such as the ventral and dorsal visual pathways and the prefrontal cortex, showed the greatest increase in blood flow during these tasks, demonstrating that they are critical for the ability to view objects from multiple angles. Several theories have been generated to provide insight on how object constancy may be achieved for the purpose of object recognition including, viewpoint-invariant, viewpoint-dependent and multiple views theories.",
            "score": 131.23741149902344
        },
        {
            "docid": "1726672_11",
            "document": "Neural circuit . Different neuroimaging techniques have been developed to investigate the activity of neural circuits and networks. The use of \"brain scanners\" or functional neuroimaging to investigate the structure or function of the brain is common, either as simply a way of better assessing brain injury with high resolution pictures, or by examining the relative activations of different brain areas. Such technologies may include functional magnetic resonance imaging (fMRI), brain positron emission tomography (brain PET), and computed axial tomography (CAT) scans. Functional neuroimaging uses specific brain imaging technologies to take scans from the brain, usually when a person is doing a particular task, in an attempt to understand how the activation of particular brain areas is related to the task. In functional neuroimaging, especially fMRI, which measures hemodynamic activity that is closely linked to neural activity, PET, and electroencephalography (EEG) is used.",
            "score": 129.9311065673828
        },
        {
            "docid": "10152418_4",
            "document": "Neurolaw . New insights into the psychology and cognition of the brain have been made available by functional magnetic resonance imaging (fMRI). These new technologies were a break from the conventional and primitive views of the brain that have been prevalent in the legal system for centuries. Brain imaging has provided a much deeper insight into thought processes, and will have an effect on the law because it contests customary beliefs about mental development. Because the science is still developing and because there is substantial opportunity for misuse, the legal realm recognizes the need to proceed cautiously. Neurolaw proponents are quickly finding means to apply neuroscience to a variety of different contexts. For example, intellectual property could be better evaluated through neuroscience. Major areas of current research include applications in the courtroom, how neuroscience can and should be used legally, and how the law is created and applied.",
            "score": 127.88079833984375
        },
        {
            "docid": "226722_59",
            "document": "Functional magnetic resonance imaging . Neuroimaging methods such as fMRI offer a measure of the activation of certain brain areas in response to cognitive tasks engaged in during the scanning process. Data obtained during this time allow cognitive neuroscientists to gain information regarding the role of particular brain regions in cognitive function. However, an issue arises when certain brain regions are alleged by researchers to identify the activation of previously labeled cognitive processes. Poldrack clearly describes this issue: Reverse inference demonstrates the logical fallacy of affirming what you just found, although this logic could be supported by instances where a certain outcome is generated solely by a specific occurrence. With regard to the brain and brain function it is seldom that a particular brain region is activated solely by one cognitive process. Some suggestions to improve the legitimacy of reverse inference have included both increasing the selectivity of response in the brain region of interest and increasing the prior probability of the cognitive process in question. However, Poldrack suggests that reverse inference should be used merely as a guide to direct further inquiry rather than a direct means to interpret results.",
            "score": 127.79695129394531
        },
        {
            "docid": "987320_19",
            "document": "Neurotechnology . Magnetic resonance imaging is a vital tool in neurological research in showing activation in the brain as well as providing a comprehensive image of the brain being studied. While MRIs are used clinically for showing brain size, it still has relevance in the study of brains because it can be used to determine extent of injuries or deformation. These can have a significant effect on personality, sense perception, memory, higher order thinking, movement, and spatial understanding. However, current research tends to focus more so on fMRI or real-time functional MRI (rtfMRI). These two methods allow the scientist or the participant, respectively, to view activation in the brain. This is incredibly vital in understanding how a person thinks and how their brain reacts to a person's environment, as well as understanding how the brain works under various stressors or dysfunctions. Real-time functional MRI is a revolutionary tool available to neurologists and neuroscientists because patients can see how their brain reacts to stressors and can perceive visual feedback. CT scans are very similar to MRI in their academic use because they can be used to image the brain upon injury, but they are more limited in perceptual feedback. CTs are generally used in clinical studies far more than in academic studies, and are found far more often in a hospital than a research facility. PET scans are also finding more relevance in academia because they can be used to observe metabolic uptake of neurons, giving researchers a wider perspective about neural activity in the brain for a given condition. Combinations of these methods can provide researchers with knowledge of both physiological and metabolic behaviors of loci in the brain and can be used to explain activation and deactivation of parts of the brain under specific conditions.",
            "score": 127.74663543701172
        },
        {
            "docid": "389579_13",
            "document": "Cognitive neuropsychology . With improved neuroimaging techniques, it has been possible to correlate patterns of impairment with a knowledge of exactly which parts of the nervous system are damaged, allowing previously undiscovered functional relationships to be explored (the \"lesion method\"). Contemporary cognitive neuropsychology uses many of the same techniques and technologies from the wider science of neuropsychology and fields such as cognitive neuroscience. These may include neuroimaging, electrophysiology and neuropsychological tests to measure either brain function or psychological performance. Useful technology in cognitive neuropsychology includes positron-emission tomography (PET) and functional magnetic resonance imaging (fMRI). These techniques make it possible to identify the areas of the brain responsible for performing certain cognitive tasks by measuring blood flow in the brain. PET scans sense the low-level radiation in the brain and produce 3-D images, whereas an fMRI works on a magnetic signal and is used to \u201cmap the brain\u201d. Electroencephalography (EEG) records the brain\u2019s electrical activity and can identify changes that occur over milliseconds. EEG is often used in patients with epilepsy to detect seizure activity.",
            "score": 127.19904327392578
        },
        {
            "docid": "47511015_2",
            "document": "Large scale brain networks . Large scale brain networks are collections of widespread brain regions showing functional connectivity by statistical analysis of the fMRI BOLD signal or other signal fluctuations. An emerging paradigm in neuroscience is that cognitive tasks are performed not by individual brain regions working in isolation, but by networks consisting of several discrete brain regions that are said to be \"functionally connected\" due to tightly coupled activity. Functional connectivity may be measured as long-range synchronization of the EEG, MEG, or other dynamic brain signals. Synchronized brain regions may also be identified using spatial independent component analysis. The set of identified brain areas that are linked together in a large-scale network varies with cognitive function. When the cognitive state is not explicit (i.e., the subject is at \"rest\"), the large scale brain network is a resting state network (RSN). As a physical system with graph-like properties, a large scale brain network has both nodes and edges, and cannot be identified simply by the co-activation of brain areas. In recent decades, the analysis of brain networks was made feasible by advances in imaging techniques as well as new tools from graph theory and dynamical systems. Large scale brain networks are identified by their function, and provide a coherent framework for understanding cognition by offering a neural model of how different cognitive functions emerge when different sets of brain regions join together as self-organized coalitions. Disruptions in activity in various networks have been implicated in neuropsychiatric disorders such as depression, Alzheimer's, autism spectrum disorder, schizophrenia and bipolar disorder.",
            "score": 126.3655776977539
        },
        {
            "docid": "43777942_5",
            "document": "Face on Moon South Pole . Previous scientific studies have concluded that neurons within the fusiform gyrus react better to faces. An experiment by Massachusetts Institute of Technology brain and cognitive sciences professor Pawan Sinha examined why the right and left fusiform gyrus acknowledges a face, especially when an object greatly resembles a face. In the project Sinha and his students gathered images that resembled human faces and images of genuine faces, which they ran through machine vision systems. This scan resulted in the systems wrongly tagging images as containing faces. Random human participants then ranked how face-like each image was while researchers scanned their brains using functional magnetic resonance imaging.",
            "score": 126.19367980957031
        },
        {
            "docid": "3380919_3",
            "document": "David Heeger . In the fields of perceptual psychology, systems neuroscience, cognitive neuroscience, and computational neuroscience, Heeger has developed computational theories of neuronal processing in the visual system, and he has performed psychophysics (perceptual psychology) and neuroimaging (functional magnetic resonance imaging, fMRI) experiments on human vision. His contributions to computational neuroscience include theories for how the brain can sense optic flow and egomotion, and a theory of neural processing called the normalization model. His empirical research has contributed to our understanding of the topographic organization of visual cortex (retinotopy), visual awareness, visual pattern detection/discrimination, visual motion perception, stereopsis (depth perception), attention, working memory, the control of eye and hand movements, neural processing of complex audio-visual and emotional experiences (movies, music, narrative), abnormal visual processing in dyslexia, and neurophysiological characteristics of autism.",
            "score": 125.94711303710938
        },
        {
            "docid": "51462681_3",
            "document": "Objective vision . This is the story of what's happening when you see a picture, even too fast, the brain's visual cortex recognizes what it sees immediately. The visual cortex has a critical job in processing and it's the most complex part of brain. The human brain is much more aware of how it solves complex problems such as playing chess or solving algebra equations, which is why computer programmers have had so much success building machines that emulate this type of activity. but when entities visionary system starts to convert the signals to image(actually the separated shapes and colors) to find a relation between brain's information and those images. The system actually is concentrating on the separable sections, this separation gives the brain a visionary system the excellence processing result, because with this method the system do not waste much time on processing non significant sections and signals. this operation in the Objective Vision project called objective processing and because the O.V. mission is around human visionary simulation, so the developer refers with Objective Vision.",
            "score": 125.36575317382812
        },
        {
            "docid": "12510615_4",
            "document": "Disjunctive cognition . Neurobiological research has identified separate areas of the brain responsible for recognizing faces. In humans, identifying unfamiliar faces activates one region of the brain (the Fusiform face area) while recognizing familiar faces also activates another area of the brain (in the lateral midtemporal cortex). A similar division of function is found in macaque monkeys. Such findings indicate that the process of recognizing faces may be achieved by special parts of the brain that are different from the brain areas involved in analyzing the general visual features of things. Since the brain has separate systems for deciding what a person looks like and who the person is, this division of labor may be responsible not only for disjunctive cognitions, but also the phenomenon of transference. In psychoanalytic treatment, patients frequently experience transference, in which the psychoanalyst is perceived to be very much like someone from the patient's past. As in disjunctive cognitions of dreams, the patient may feel \"You look like Dr. X, but you feel like my mother.\" The separate areas of the brain involved in telling us what the person looks like and who the person is may give a neurobiological basis for transference, the phenomenon in which we know who a person is, yet we react emotionally to that person as if they are someone else.",
            "score": 123.94679260253906
        },
        {
            "docid": "5626_28",
            "document": "Cognitive science . Brain imaging involves analyzing activity within the brain while performing various tasks. This allows us to link behavior and brain function to help understand how information is processed. Different types of imaging techniques vary in their temporal (time-based) and spatial (location-based) resolution. Brain imaging is often used in cognitive neuroscience.",
            "score": 123.06598663330078
        },
        {
            "docid": "20788764_6",
            "document": "Marcel Just . Marcel Just also developed 4CAPS, a cognitive architecture specifies how different cortical regions of the brain collaborate to perform specific tasks. 4CAPS model have been used to explain behavioral and brain imaging data in different experimental tasks.",
            "score": 122.83930206298828
        },
        {
            "docid": "30601657_12",
            "document": "Response priming . Response-priming effects have been demonstrated for a large number of stimuli and discrimination tasks, including geometric stimuli, color stimuli, various types of arrows, natural images (animals vs. objects), vowels and consonants, letters, and digits. In one study, chess configurations were presented as primes and targets, and participants had to decide whether the king was in check. Mattler (2003) could show that response priming can not only influence motor responses, but also works for cognitive operations like a spatial shift of visual attention or a shift between two different response time tasks. Different types of masking have been employed as well. Instead of measuring keypress responses (commonly with two response alternatives), some studies use more than two response alternatives or record speech responses, speeded finger pointing movements, eye movements, or so-called readiness potentials which reflect the degree of motor activation in the brain's motor cortex and can be measured by electro-encephalographic methods. Brain imaging methods like functional magnetic resonance imaging (fMRI) have been employed as well.",
            "score": 121.75724792480469
        },
        {
            "docid": "10152418_13",
            "document": "Neurolaw . Much of neurolaw depends on state-of-the-art medical technology that has been adapted to a new role in the legal system. Among the most prominent technologies and disciplines are functional magnetic resonance imaging (fMRI), positron emission tomography (PET scan), magnetic resonance imaging (MRI), and epigenetics. MRI and fMRI are particularly important because they allow detailed mapping of the human brain, potentially allowing technicians to visualize another person's thoughts. FMRI, a derivative of MRI, allows for oxygen-specific mapping to view the most active areas of a brain at a specific moment. Combined with the knowledge of how the brain works in different situations (lying, remembering, etc.), there is the potential to use functional neuroimaging evidence as a modern form of lie detection. Similarly, PET scans use a radioactive tracer injected into the body to analyze brain tissue.",
            "score": 121.72964477539062
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 121.0417709350586
        },
        {
            "docid": "68753_6",
            "document": "Attention . By the 1990s, psychologists began using positron emission tomography (PET) and later functional magnetic resonance imaging (fMRI) to image the brain while monitoring tasks involving attention. Because this expensive equipment was generally only available in hospitals, psychologists sought cooperation with neurologists. Psychologist Michael Posner (then already renowned for his seminal work on visual selective attention) and neurologist Marcus Raichle pioneered brain imaging studies of selective attention. Their results soon sparked interest from the neuroscience community, which had until then focused on monkey brains. With the development of these technological innovations, neuroscientists became interested in this type of research that combines sophisticated experimental paradigms from cognitive psychology with these new brain imaging techniques. Although the older technique of electroencephalography (EEG) had long been used to study the brain activity underlying selective attention by cognitive psychophysiologists, the ability of the newer techniques to actually measure precisely localized activity inside the brain generated renewed interest by a wider community of researchers.",
            "score": 120.93499755859375
        },
        {
            "docid": "3704475_29",
            "document": "Executive functions . Miller and Cohen draw explicitly upon an earlier theory of visual attention that conceptualises perception of visual scenes in terms of competition among multiple representations \u2013 such as colors, individuals, or objects. Selective visual attention acts to 'bias' this competition in favour of certain selected features or representations. For example, imagine that you are waiting at a busy train station for a friend who is wearing a red coat. You are able to selectively narrow the focus of your attention to search for red objects, in the hope of identifying your friend. Desimone and Duncan argue that the brain achieves this by selectively increasing the gain of neurons responsive to the color red, such that output from these neurons is more likely to reach a downstream processing stage, and, as a consequence, to guide behaviour. According to Miller and Cohen, this selective attention mechanism is in fact just a special case of cognitive control \u2013 one in which the biasing occurs in the sensory domain. According to Miller and Cohen's model, the PFC can exert control over input (sensory) or output (response) neurons, as well as over assemblies involved in memory, or emotion. Cognitive control is mediated by reciprocal PFC connectivity with the sensory and motor cortices, and with the limbic system. Within their approach, thus, the term 'cognitive control' is applied to any situation where a biasing signal is used to promote task-appropriate responding, and control thus becomes a crucial component of a wide range of psychological constructs such as selective attention, error monitoring, decision-making, memory inhibition, and response inhibition.",
            "score": 120.80860900878906
        },
        {
            "docid": "11080148_32",
            "document": "Growing Up in the Universe . Dawkins opens by talking how organisms \u201cgrow up\u201d to understand the universe around them, which requires certain apparatus, such as a brain. But before brains can become large enough to model the universe they must develop from intermediate forms. Dawkins then discusses the digger wasp and the set of experiments conducted by Nikolaas Tinbergen of how the digger wasp models the local geography around its nest. He then talks about the limitations of the digger wasps\u2019 brain and concludes that only the human brain is sufficiently developed to model large-scale phenomena about the world. He then shows a MRI scan of a human brain (later revealed to be his own brain) and describes how an image develops from the eye onto the visual cortex.",
            "score": 120.44520568847656
        },
        {
            "docid": "35543733_7",
            "document": "Bilingual lexicon . With years of researches, how languages are stored and processed by bilinguals is still a main theme that many psycholinguists. One main topic is that bilinguals possess one or two internal lexicons, and even more with three stores. One for each language and the third one is for corresponding two languages. Reaction time of recognizing words in different languages is the most used method to figure out how our lexicon been activated. Researches in 1980s by Soares and Grosjean on English-Portuguese bilingual had two main findings. One is that although bilingual can access real words in English as quickly as English monolinguals, but they are slower at responding to non-words. The other finding is that bilingual took longer to access code-switched words than they did base-language words in the monolingual mode. These two findings can be seen as the evidence for more than one lexicon are existed in bilinguals' brains. As technology develops, functional magnetic resonance imaging (fMRI) is also used to study how brain activity is different in bilinguals' brain when both language are interact. Imaging studies have yielded that specific brain areas are involved in bilingual switching, which means this part of the brain can be said as the \"third lexicon\", the interconnected part of two lexicons for each language, where stores the guest words. Other research suggests only one combined lexicon is exists.",
            "score": 119.86074829101562
        },
        {
            "docid": "987320_7",
            "document": "Neurotechnology . Magnetic resonance imaging (MRI) is used for scanning the brain for topological and landmark structure in the brain, but can also be used for imaging activation in the brain. While detail about how MRI works is reserved for the actual MRI article, the uses of MRI are far reaching in the study of neuroscience. It is a cornerstone technology in studying the mind, especially with the advent of functional MRI (fMRI). Functional MRI measures the oxygen levels in the brain upon activation (higher oxygen content = neural activation) and allows researchers to understand what loci are responsible for activation under a given stimulus. This technology is a large improvement to single cell or loci activation by means of exposing the brain and contact stimulation. Functional MRI allows researchers to draw associative relationships between different loci and regions of the brain and provides a large amount of knowledge in establishing new landmarks and loci in the brain.",
            "score": 119.65937805175781
        },
        {
            "docid": "3557219_24",
            "document": "Neuroimaging . The greatest benefit of PET scanning is that different compounds can show blood flow and oxygen and glucose metabolism in the tissues of the working brain. These measurements reflect the amount of brain activity in the various regions of the brain and allow to learn more about how the brain works. PET scans were superior to all other metabolic imaging methods in terms of resolution and speed of completion (as little as 30 seconds), when they first became available. The improved resolution permitted better study to be made as to the area of the brain activated by a particular task. The biggest drawback of PET scanning is that because the radioactivity decays rapidly, it is limited to monitoring short tasks. Before fMRI technology came online, PET scanning was the preferred method of functional (as opposed to structural) brain imaging, and it continues to make large contributions to neuroscience.",
            "score": 118.5658950805664
        },
        {
            "docid": "5212945_3",
            "document": "Visual neuroscience . A recent study using Event-Related Potentials (ERPs) linked an increased neural activity in the occipito-temporal region of the brain to the visual categorization of facial expressions. Results focus on a negative peak in the ERP that occurs 170 milliseconds after the stimulus onset. This action potential, called the N170, was measured using electrodes in the occipito-temporal region, an area already known to be changed by face stimuli. Studying by using the EEG, and ERP methods allow for an extremely high temporal resolution of 4 milliseconds, which makes these kinds of experiments extremely well suited for accurately estimating and comparing the time it takes the brain to perform a certain function. Scientists used classification image techniques, to determine what parts of complex visual stimuli (such as a face) will be relied on when patients are asked to assign them to a category, or emotion. They computed the important features when the stimulus face exhibited one of five different emotions. Stimulus faces exhibiting fear had the distinguishing feature of widening eyes, and stimuli exhibiting happiness exhibited a change in the mouth to make a smile. Regardless of the expression of the stimuli's face, the region near the eyes affected the EEG before the regions near the mouth. This revealed a sequential, and predetermined order to the perception and processing of faces, with the eye being the first, and the mouth, and nose being processed after. This process of downward integration only occurred when the inferior facial features were crucial to the categorization of the stimuli. This is best explained by comparing what happens when participants were shown a face exhibiting fear, versus happiness. The N170 peaked slightly earlier for the fear stimuli at about 175 milliseconds, meaning that it took a participants less time to recognize the facial expression. This is expected because only the eyes need to be processed to recognize the emotion. However, when processing a happy expression, where the mouth is crucial to categorization, downward integration must take place, and thus the N170 peak occurred later at around 185 milliseconds. Eventually visual neuroscience aims to completely explain how the visual system processes all changes in faces as well as objects. This will give a complete view to how the world is constantly visually perceived, and may provide insight into a link between perception and consciousness.",
            "score": 118.53360748291016
        },
        {
            "docid": "2567511_16",
            "document": "Neural engineering . Neuroimaging techniques are used to investigate the activity of neural networks, as well as the structure and function of the brain. Neuroimaging technologies include functional magnetic resonance imaging (fMRI), magnetic resonance imaging (MRI), positron emission tomography (PET) and computed axial tomography (CAT) scans. Functional neuroimaging studies are interested in which areas of the brain perform specific tasks. fMRI measures hemodynamic activity that is closely linked to neural activity. It probes the brain by tuning the brain scanner to a certain wavelength to see which part of the brain are activated doing different tasks by seeing what lights up doing different things. PET, CT scanners, and electroencephalography (EEG) are currently being improved and used for similar purposes.",
            "score": 118.1729736328125
        },
        {
            "docid": "32018467_7",
            "document": "Christian Keysers . After finishing his master, Christian Keysers decided to concentrate on a subfield of cognitive neuroscience called social neuroscience that uses neuroscience methods to understand how we process the social world. He therefore performed his doctoral studies at the University of St Andrews with David Ian Perrett, one of the founding father of the field, to understand how the brain processes faces and facial expressions. This thesis work led to new insights into how quickly the brain can process the faces of others. During this period, Keysers became fascinated with the question of how the brain can attach meaning to the faces of others. How is it for instance, that we understand that a certain grimace would signal that another person is happy? How do we understand that a certain bodily movement towards a glass indicates that the other person aims to grasp a glass? In 1999, Keysers was exposed to a visit of Vittorio Gallese, who presented his recent discovery of mirror neurons in the Psychology department lecture series. This deeply influenced Keysers who decided to move to the lab of Giacomo Rizzolatti to undertake further studies on how these fascinating neurons could contribute to social perception. In 2000, after finishing his doctorate, Christian Keysers moved to the University of Parma to study mirror neurons. In early work there demonstrated that mirror neurons in the premotor cortex not only respond to the sight of actions, but also when actions can only be deduced or heard, leading to a publication in the journal \"Science\". This work had tremendous impact on the field, as it suggested that the premotor cortex could play a central, modality independent role in perception and may lay the origin for the evolution of speech in humans.  Together this work indicated that brain regions involved in our own actions play a role in how we process the actions of others. Keysers wondered whether a similar principle may underlie how we process the tactile sensations and emotions of others, and became increasingly independent of the research focus on the motor system in Parma. At the time, Keysers had also met his to be wife, Valeria Gazzola, a biologist in the final phases of her studies, and together they decided to explore if the somatosensory system might be involved in perceiving the sensations of others. Via a fruitful collaboration with the French neuroimaging specialist Bruno Wicker, they used functional magnetic resonance imaging, and showed for the first time, that the secondary somatosensory cortex, previously thought only to represent a persons own experiences of touch, is also activated when seeing someone or something else be touched. They also showed that the insula, thought only to respond to the experience of first-hand emotions, was also activated when we see another individual experience similar emotions. Together this indicated a much more general principle than the original mirror neuron theory, in which people process the actions, sensations and emotions of others by vicariously activating owns own actions, sensations and emotions. Jointly, this work laid the foundation of the neuroscientific investigation of empathy.",
            "score": 118.16585540771484
        }
    ]
}