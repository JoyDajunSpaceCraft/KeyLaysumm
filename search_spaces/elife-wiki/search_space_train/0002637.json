{
    "q": [
        {
            "docid": "19146397_16",
            "document": "Adroitness . Because many of the behaviors associated with adroitness are similar to some of the behaviors associated with psychopathy, experiments that delve into the mind of the psychopath can shed light onto some of the brain function involved with the adroitness trait. In 2008, fMRI testing showed that psychopaths are impaired in basic emotional and cognitive functions. Because these functions are controlled by the prefrontal cortex and the temporal lobes of the brain, there must be some problem in these areas. Due to the aforementioned similarities, it follows that people expressing the adroitness trait may also have some kind of problem or damage in these parts of the brain.  The cognitive functions of psychopaths and controls in this study were tested through the use of the Simon paradigm. This test measures reaction time based on stimulus and response locations. In the M\u00fcller et al. study, the stimuli were an X and an O, both of which appeared at different locations on a screen. The participant was required to respond by tapping the right side of a separate screen with their middle finger for X and on the left side with their index finger for O. In the control group, as the task became more difficult, negative emotion interfered with cognition. Essentially, as people became angrier, it became more difficult to accurately complete the task. However, as the psychopaths became angrier, their performance did not change, suggesting that there is a disconnect between the emotional process and cognitive abilities in the psychopathic brain. If psychopaths have trouble connecting emotion to the thinking process, the perhaps those with the adroitness trait do as well. Certainly the ability to manipulate others requires a substantial amount of effort, regardless of emotion. The resource allocation model suggests that negative emotions worsen cognitive performance on difficult tasks because they drain resources that are required for cognitive processes. Manipulation and persuasion are cognitive processes that require a lot of effort due to the number of things that require focus. The art of manipulation requires some element of dishonesty as well as a significant knowledge of both the target as well as the purpose of manipulation, or the ability to fabricate important details. These elements are also required for persuasion. It follows that these processes must require a significant amount of effort, and therefore emotions, especially negative ones, would take resources away from those processes.  Manipulation and persuasion can also be very stressful tasks. Stress is known to cause negative emotions, which are shown to interfere in complex cognitive processes. Therefore, people who express the adroitness trait may suffer from similar damage to the prefrontal cortex and/or temporal lobe as psychopaths.",
            "score": 96.89742839336395
        },
        {
            "docid": "649382_5",
            "document": "Pareidolia . Pareidolia can cause people to interpret random images, or patterns of light and shadow, as faces. A 2009 magnetoencephalography study found that objects perceived as faces evoke an early (165 ms) activation of the fusiform face area at a time and location similar to that evoked by faces, whereas other common objects do not evoke such activation. This activation is similar to a slightly faster time (130 ms) that is seen for images of real faces. The authors suggest that face perception evoked by face-like objects is a relatively early process, and not a late cognitive reinterpretation phenomenon. A functional magnetic resonance imaging (fMRI) study in 2011 similarly showed that repeated presentation of novel visual shapes that were interpreted as meaningful led to decreased fMRI responses for real objects. These results indicate that the interpretation of ambiguous stimuli depends upon processes similar to those elicited by known objects.",
            "score": 67.33247971534729
        },
        {
            "docid": "5505463_3",
            "document": "Bimodal bilingualism . Most modern neurological studies of bilingualism employ functional neuroimaging techniques to elucidate the neurological underpinnings of multilingualism and how multilingualism is beneficial to the brain. Neuroimaging and other neurological studies have demonstrated in recent years that multilingualism has a significant impact on the human brain. The mechanisms required by bilinguals to \"code switch\" (a linguistic term used to describe the rapid alternating between multiple languages within a conversation or discourse), not only demonstrate increased connectivity and density of the neural network in multilinguals, but also appear to provide protection against damage due to age and age-related pathologies, such as Alzheimer's. Multilingualism, especially bimodal multilingualism, can help slow to process of cognitive decline in aging. It is thought that this is a result of the increased work load that the executive system, housed mostly in the frontal cortex, must assume in order to successfully control the use of multiple languages at once. This means that the cortex must be more finely tuned, which results in a \"neural reserve\" that then has neuroprotective benefits. Gray matter volume (GMV) has been shown to be significantly preserved in bimodal bilinguals as compared to monolinguals in multiple brain areas, including the hippocampus, amygdala, anterior temporal lobes, and left insula. Similarly, neuroimaging studies that have compared monolinguals, unimodal bilinguals, and bimodal bilinguals provide evidence that deaf signers exhibit brain activation in patterns different than those of hearing signers, especially in regards to the left superior temporal sulcus. In deaf signers, activation of the superior temporal sulcus is highly lateralized to the left side during facial recognition tasks, while this lateralization was not present in hearing, bimodal signers. Bilinguals also require an effective and fast neural control system to allow them to select and control their languages even while code switching rapidly. Evidence indicates that the left caudate nucleus\u2014a centrally located brain feature that is near the thalamus and the basal ganglia\u2014is an important part of this mechanism, as bilinguals tend to have significantly increased GMV and activation in this region as compared to monolinguals, especially during active code switching tasks. As implied by the significant preservation of gray matter in the hippocampi (an area of the brain largely associated with memory consolidation and higher cognitive function, such as decision-making) of bimodal bilinguals, areas of the brain that help control phonological working memory tend to also have higher activation in those individuals who are proficient in two or more languages. There is also evidence that suggests that the age at which an individual acquires a second language may play a significant role in the varying brain functions associated with bilingualism. For example, individuals who acquired their second language early (before the age of 10) tend to have drastically different activation patterns than do late learners. However, late learners who achieve full proficiency in their second language tend to show similar patterns of activation during auditory tasks regardless of which language is being used, whereas early learners tend to activate different brain areas depending upon which language is being used. Along with the neuroprotective benefits that help to prevent onset of age-related cognitive issues such as dementia, bimodal bilinguals also experience a slightly different pattern of organization of language in the brain. While non-hearing-impaired bimodal bilinguals showed less parietal activation than deaf signers when asked to use only sign language, those same bimodal bilinguals demonstrated greater left parietal activation than did monolinguals. Parietal activation is not typically associated with language production bur rather with motor activity. Therefore, it is logical that bimodal bilinguals, when switching between speech- and sign-based language, stimulate their left parietal areas as a result of their increased need to combine both motor action and language production.",
            "score": 87.39384400844574
        },
        {
            "docid": "25146378_12",
            "document": "Functional specialization (brain) . One of the most well known examples of functional specialization is the fusiform face area (FFA). Justine Sergent was one of the first researchers that brought forth evidence towards the functional neuroanatomy of face processing. Using positron emission tomography (PET), Sergent found that there were different patterns of activation in response to the two different required tasks, face processing verses object processing. These results can be linked with her studies of brain-damaged patients with lesions in the occipital and temporal lobes. Patients revealed that there was an impairment of face processing but no difficulty recognizing everyday objects, a disorder also known as prosopagnosia. Later research by Nancy Kanwisher using functional magnetic resonance imaging (fMRI), found specifically that the region of the inferior temporal cortex, known as the fusiform gyrus, was significantly more active when subjects viewed, recognized and categorized faces in comparison to other regions of the brain. Lesion studies also supported this finding where patients were able to recognize objects but unable to recognize faces. This provided evidence towards domain specificity in the visual system, as Kanwisher acknowledges the Fusiform Face Area as a module in the brain, specifically the extrastriate cortex, that is specialized for face perception.",
            "score": 81.94562602043152
        },
        {
            "docid": "525667_10",
            "document": "Human echolocation . In a 2014 study by Thaler and colleagues, the researchers first made recordings of the clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, not only did they perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. The brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any auditory area, becomes involved in the computation of echolocation tasks.",
            "score": 88.6077208518982
        },
        {
            "docid": "34032792_12",
            "document": "Prediction in language comprehension . Functional magnetic resonance imaging (fMRI) is a neuroimaging technology that uses nuclear magnetic resonance to measure blood oxygenation levels in the brain and spinal cord. Because neural activity affects blood flow, the pattern of the hemodynamic response is thought to correspond closely to the pattern of neural activity. The fine spatial resolution afforded by fMRI allows cognitive neuroscientists to see in detail which areas of the brain are activated in relation to an experimental task. However, the hemodynamic response is much slower than the neural activity measured by EEG and MEG. This poor sensitivity to timing information makes fMRI a less useful technique than EEG or eyetracking for studying linguistic prediction. One exception is an fMRI test of the differences in neural activation between strategic and automatic semantic priming. When the time between the prime and the target word is short (around 150 milliseconds), priming is theorized to rely on automatic neural processes. However, at longer time intervals (approaching 1 second), it is thought that experimental subjects strategically predict related upcoming words and suppress unrelated words, leading to a processing penalty in the event that an unrelated word actually occurs. An fMRI test of this hypothesis showed that at longer intervals, the processing penalty for an incorrect prediction is related to heightened activity in the anterior cingulate gyrus and Broca's area.",
            "score": 61.39945697784424
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 74.52639758586884
        },
        {
            "docid": "21312301_12",
            "document": "Context-dependent memory . A number of neuroanatomical structures are thought to play a role in context-dependent memory, These include the hippocampus and prefrontal cortex. For example, functional magnetic resonance imaging (fMRI) has been used to demonstrate elevated activation in the hippocampus when contextual information matches from encoding to retrieval, suggesting that the hippocampus may be important in mediating context-dependent memory processes. Kalisch et al. provide further support for this role by demonstrating that context-dependent extinction memory is correlated with activation in both the hippocampus and ventromedial prefrontal cortex. Similarly, an experiment by Wagner et al. using fMRI demonstrated that activation of the right prefrontal cortex depended on contextual information. The authors of this study suggest that differential activation of the prefrontal cortex occurs because the different contexts require unique attempt processes for retrieval. In other words, depending on the retrieval context, participants used different strategies to recall information. Overall, the patterns of activation in the hippocampus and the prefrontal cortex following changes in contextual information suggest that these brain regions play an important role in context-dependent memory.",
            "score": 78.85792148113251
        },
        {
            "docid": "37689507_19",
            "document": "Neuroimaging intelligence testing . A 2012 study from Washington University, St. Louis described the global connectivity of the prefrontal cortex. Global connectivity is the mechanism by which components of the frontoparietal brain network might coordinate control of other tasks. Cole et al. wrote that: \"A lateral prefrontal cortex (LPFC) region's activity was found to predict performance in a high control demand working memory task and also to exhibit high global connectivity. Critically, global connectivity in this LPFC region, involving connections both within and outside the frontoparietal network, showed a highly selective relationship with individual differences in fluid intelligence.\" The lateral prefrontal cortex is a region of interest because those who have injuries to that part of the brain often have issues with common, every day tasks such as planning their day. The LPFC is thought to be important for \"cognitive control capacity,\" which can be used to predict future outcomes such as success in school and the workplace. It was found by van den Heuvel et al. that higher intelligence individuals employ more efficient whole-brain network organization. This had led to the thought that cognitive control capacity may be supported by these whole-brain network properties. The 2012 study used a theoretic approach to neuroimage data known as global brain connectivity (GBC) or weighted degree centrality. GBC let the researches look closely at specific regions and their range of connectivity. It was then possible to examine each region's role in human cognitive control and intelligence. The study used fMRI to acquire data and examine each region's connectivity.",
            "score": 93.51315295696259
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 70.7685775756836
        },
        {
            "docid": "19864858_9",
            "document": "Common coding theory . One of the most direct evidence for common coding in the brain now stems from the fact that pattern classifiers that can differentiate based on brain activity whether someone has performed action A or B can also classify, above chance, whether that person heard the sound of action A or B, thereby demonstrating that action execution and perception are represented using a common code. Further support originates in EEG studies investigating the physiological substrate of perception and action in cognitive tasks. Segregating cortical activity by an independent component analysis (ICA) consistently reveals component relating to the processing of sensory stimuli and simultaneously to generating appropriate motor responses. This provides evidence for a common code involved in the whole perception-action loop.",
            "score": 93.03659892082214
        },
        {
            "docid": "5067510_32",
            "document": "Lie detection . Studies using functional magnetic resonance imaging (fMRI) have shown that it has potential to be used as a method of lie detection. While a polygraph detects changes in activity in the peripheral nervous system, fMRI has the potential to catch the lie at the 'source'. To use an MRI as a lie detector, an fMRI should be used by placing a magnetic band as a scanner on a subject's head. However, the neurobiological systems that relate to lying are currently poorly understood. The current consensus is that faced with a forced choice paradigm, in which a subject has the choice of telling the truth or spontaneously generating a lie, lying can be distinguished due to increased prefrontal and parietal lobe activity. More specifically, the superior medial and inferolateral prefrontal cortices show net activation in the process of spontaneous lie generation (which involves suppression of the truthful response as well as generating a conceivable lie). There also is evidence of increased activation in the anterior cingulate cortex when lies are told. The fMRI shows the use of oxygen by the brain, allowing for the identification of which portions of the brain are using more oxygen during a specific task. By studying the brain images, researchers are able to map the systematic procedure the brain went through to produce the action or decision. Subjects are often offered monetary incentive if they can successfully deceive the process in hopes of generating a 'real world' scenario. Using this method, an initial 2005 study on individuals ( not group averages as previous studies) without pattern recognition and automation showed that lies can be distinguished 78% of the time. That statistic has risen, in one study, to 100% when predicting a lie in an individual when baseline lie/truth levels were closely studied with training from pattern recognition technology (machine learning). fMRI does rely upon the individual remaining still and safeguards in the analysis such that the questions can not be gamed by the participant (G. Ganis 2010). Studies have been done on Chinese individuals and their language and cultural differences did not change results. To show the robustness of this fMRI technology, a study (S. Spence 2011) was done that showed fMRI lie detection / truth verification technology worked even in a group of 52 schizophrenic patients, 27 of whom were experiencing delusions at the time of the study.",
            "score": 79.14997589588165
        },
        {
            "docid": "26565579_50",
            "document": "Neuroscience of free will . Multivariate pattern analysis using EEG has suggested that an evidence based perceptual decision model may be applicable to free will decisions. It was found that decisions could be predicted by neural activity immediately after stimulus perception. Furthermore, when the participant was unable to determine the nature of the stimulus the recent decision history predicted the neural activity (decision). The starting point of evidence accumulation was in effect shifted towards a previous choice (suggesting a priming bias). Another study has found that subliminally priming a participant for a particular decision outcome (showing a cue for 13ms) could be used to influence free decision outcomes. Likewise, it has been found that decision history alone can be used to predict future decisions. The prediction capacities of the Soon et al. (2008) experiment were successfully replicated using a linear SVM model based on participant decision history alone (without any brain activity data). Despite this, a recent study has sought to confirm the applicability of a perceptual decision model to free will decisions. When shown a masked and therefore invisible stimulus, participants were asked to either guess between a category or make a free decision for a particular category. Multivariate pattern analysis using fMRI could be trained on \"free decision\" data to successfully predict \"guess decisions\", and trained on \"guess data\" in order to predict \"free decisions\" (in the precuneus and cuneus region).",
            "score": 109.33559894561768
        },
        {
            "docid": "4743980_30",
            "document": "Tip of the tongue . Age is an important factor when considering TOT states. There are complaints that problems recalling information increases with age. The frequency of TOTs increases in adulthood and even more so during the elderly years. Compared with young adults, older adults generally report having more TOT states, fewer alternate words, and less phonological information about the target word. The underpinnings of TOT with regard to age have focused on neurological brain differences. Current research uses neuroimaging methods to access the presence of different brain patterns when a younger and older individual is experiencing a TOT state. It is found that older and younger individuals employ a similar network of brain regions during TOT states such as the prefrontal cortex, left insula, and sensorimotor cortex. However, older individuals show differences in activity in some areas compared to younger individuals. TOTs increase with age-related gray matter loss in the left insula for older individuals. This is accompanied by less activity in the left insula and is related to higher frequency of TOTs. Furthermore, it was found that older individuals have over-activation in their prefrontal cortex when experiencing TOT states. This may indicate a continued search when the retrieval process fails and a TOT state is experienced. More specifically, greater activation in the sensorimotor cortex in older individuals and less in younger adults may reflect differences in the knowledge that is used to retrieve the target information. Priming words during word retrieval tests generally reduces the frequency of TOTs and improves the retrieval of the target word and has been shown to have a larger benefit for older adults. This is consistent with the spreading activation model, where neural connections are strengthened when used more. Although older people experience more tip of the tongue states more often than any other category, recent studies have shown that frequent tip of the tongue states are not linked at all to dementia, which is common in the elderly. Despite the association of increased age with lower levels of episodic memory and more frequent TOT states, the two phenomena seem to be largely independent of one another.",
            "score": 107.76762402057648
        },
        {
            "docid": "2640086_28",
            "document": "Affective neuroscience . Instead of investigating specific emotions, Kober, et al. 2008 reviewed 162 neuroimaging studies published between 1990-2005 to determine if groups of brain regions show consistent patterns of activation during emotional experience (that is, actively experiencing an emotion first-hand) and during emotion perception (that is, perceiving a given emotion as experienced by another). This meta-analysis used multilevel kernal density analysis (MKDA) to examine fMRI and PET studies, a technique that prevents single studies from dominating the results (particularly if they report multiple nearby peaks) and that enables studies with large sample sizes (those involving more participants) to exert more influence upon the results. MKDA was used to establish a neural reference space that includes the set of regions showing consistent increases across all studies (for further discussion of MDKA see Wager et al. 2007). Next, this neural reference space was partitioned into functional groups of brain regions showing similar activation patterns across studies by first using multivariate techniques to determine co-activation patterns and then using data-reduction techniques to define the functional groupings (resulting in six groups). Consistent with a psychological construction approach to emotion, the authors discuss each functional group in terms more basic psychological operations. The first \u201cCore Limbic\u201d group included the left amygdala, hypothalamus, periaqueductal gray/thalamus regions, and amygdala/ventral striatum/ventral globus pallidus/thalamus regions, which the authors discuss as an integrative emotional center that plays a general role in evaluating affective significance. The second \u201cLateral Paralimbic\u201d group included the ventral anterior insula/frontal operculum/right temporal pole/ posterior orbitofrontal cortex, the anterior insula/ posterior orbitofrontal cortex, the ventral anterior insula/ temporal cortex/ orbitofrontal cortex junction, the midinsula/ dorsal putamen, and the ventral striatum /mid insula/ left hippocampus, which the authors suggest plays a role in motivation, contributing to the general valuation of stimuli and particularly in reward. The third \u201cMedial Prefrontal Cortex\u201d group included the dorsal medial prefrontal cortex, pregenual anterior cingulate cortex, and rostral dorsal anterior cingulate cortex, which the authors discuss as playing a role in both the generation and regulation of emotion. The fourth \u201cCognitive/ Motor Network\u201d group included right frontal operculum, the right interior frontal gyrus, and the pre-supplementray motor area/ left interior frontal gyrus, regions that are not specific to emotion, but instead appear to play a more general role in information processing and cognitive control. The fifth \u201cOccipital/ Visual Association\u201d group included areas V8 and V4 of the primary visual cortex, the medial temporal lobe, and the lateral occipital cortex, and the sixth \u201cMedial Posterior\u201d group included posterior cingulate cortex and area V1 of the primary visual cortex. The authors suggest that these regions play a joint role in visual processing and attention to emotional stimuli.",
            "score": 75.2109591960907
        },
        {
            "docid": "25225295_10",
            "document": "Consumer neuroscience . Much of consumer research is devoted to studying the effect of brand associations on consumer preferences and how they manifest into brand memories. Brand memories can be defined as \u201ceverything that exists in the minds of customers with respect to a brand (e.g. thoughts, feelings, experiences, images, perceptions, beliefs and attitudes)\u201d. Several studies have indicated there is not a designated area of the brain devoted to brand recognition. Studies have shown that different areas of the brain are activated when exposed to a brand as opposed to a person, and decisions regarding the evaluation of brands in different product categories activate the area of the brain responsible for semantic object processing rather than areas involved with the judgment of people. These two findings suggest that brands are not processed by the brain in the same manner as human personalities, indicating that personality theory cannot be used to explain brand preferences.",
            "score": 97.85422563552856
        },
        {
            "docid": "2640086_25",
            "document": "Affective neuroscience . In the first neuroimaging meta-analysis of emotion, Phan et al. (2002) analyzed the results of 55 studies published in peer reviewed journal articles between January 1990 and December 2000 to determine if the emotions of fear, sadness, disgust, anger, and happiness were consistently associated with activity in specific brain regions. All studies used fMRI or PET techniques to investigate higher-order mental processing of emotion (studies of low-order sensory or motor processes were excluded). The authors\u2019 analysis approach was to tabulate the number of studies that reported activation in specific brain regions during tasks inducing fear, sadness, disgust, anger, and happiness. For each brain region, statistical chi-squared analysis was conducted to determine if the proportion of studies reporting activation during one emotion was significantly higher than the proportion of studies reporting activation during the other emotions. Two regions showed this statistically significant pattern across studies. In the amygdala, 66% of studies inducing fear reported activity in this region, as compared to ~20% of studies inducing happiness, ~15% of studies inducing sadness (with no reported activations for anger or disgust). In the subcallosal cingulate, 46% of studies inducing sadness reported activity in this region, as compared to ~20% inducing happiness and ~20% inducing anger. This pattern of clear discriminability between emotion categories was in fact rare, with a number of other patterns occurring in limbic regions (including amydala, hippocampus, hypothalamus, and orbitofrontal cortex), paralimbic regions (including subcallosal cingulate, medial prefrontal cortex, anterior cingulate cortex, posterior cingulate cortex, insula, and temporal pole), and uni/heteromodal regions (including lateral prefrontal cortex, primary sensorimotor cortex, temporal cortex, cerebellum, and brainstem). Brain regions implicated across discrete emotion included the basal ganglia (~60% of studies inducing happiness and ~60% of studies inducing disgust reported activity in this region) and medial prefrontal cortex (happiness ~60%, anger ~55%, sadness ~40%, disgust ~40%, and fear ~30%).",
            "score": 68.4814258813858
        },
        {
            "docid": "524233_17",
            "document": "Brodmann area 45 . In the study \"Semantic Encoding and Retrieval in the Left Inferior Prefrontal Cortex: A Functional magnetic resonance imaging Study of Task Difficulty and Process Specificity\", researchers found that pars triangularis (as well as some of its neighbors) increased its activity during semantic encoding, regardless of difficulty of the word being processed. This is consistent with the theory that pars triangularis is involved in semantic processing more than phonological processing. Furthermore, they found that these semantic encoding decisions resulted in less involvement of pars triangularis with repetition of the used words. It may seem intuitive that practice would make the brain better at recognizing the words as they reappeared, but there is something else to be learned from this result, as well. That pars triangularis activity went down with repetition also signifies the movement of the task of recognizing the word from the conscious to the passive. This is called repetition priming, and it occurs independent of intention. This idea, when paired with theories about pt's involvement in conscious retrieval of memory, serves to illustrate the complexity of the brain and its functions. These results together imply the possibility that similar mechanics are required for encoding and retrieving information. Another point of interest was that decreased pars triangularis activation with repetition did not occur with redundant presentation of nonsemantically processed words.",
            "score": 88.41976618766785
        },
        {
            "docid": "37691351_4",
            "document": "Neuroscience and race . Neurotechnology enables studying the brain and racial interactions, though this study can be difficult because these interactions can be hard to replicate. Face recognition tests are the most commonly used method in studying racial interactions. These tests consist of observing own-race and other-race faces, and studying the brain's response to the faces. There are three major neurological techniques used to measure the brain's response to these simulated racial interactions. Functional magnetic resonance imaging (fMRI) measures the brain activity through measuring the blood oxygen level in the brain. This test gives insight into which regions of the brain are active during a certain event. Event-related potentials (ERPs) measure the brain's activity through measuring electrical impulses by electrodes on the head. This test gives insight in rapid changes in the brain. Transcranial magnetic stimulation (TMS) measures the response of a region of the brain once activated through magnetism. This test gives insight into causality of occurrences and gives specific insight in what the brain regions are doing. Brain-damaged patients have also been used to study racial interactions, by studying how racial interactions are affected when specific brain regions are damaged. These studies give insight into how different brain regions are involved in racial interactions once certain regions have been damaged. An implicit association test (IAC) is often used to measure the racial bias of people in studies by testing what objects, whether positive or negative, people associate with same-race or other-race faces.",
            "score": 81.52735197544098
        },
        {
            "docid": "27988760_11",
            "document": "Heuristics in judgment and decision-making . The representativeness heuristic is seen when people use categories, for example when deciding whether or not a person is a criminal. An individual thing has a high \"representativeness\" for a category if it is very similar to a prototype of that category. When people categorise things on the basis of representativeness, they are using the representativeness heuristic. \"Representative\" is here meant in two different senses: the prototype used for comparison is representative of its category, and representativeness is also a relation between that prototype and the thing being categorised. While it is effective for some problems, this heuristic involves attending to the particular characteristics of the individual, ignoring how common those categories are in the population (called the \"base rates\"). Thus, people can overestimate the likelihood that something has a very rare property, or underestimate the likelihood of a very common property. This is called the base rate fallacy. Representativeness explains this and several other ways in which human judgments break the laws of probability.",
            "score": 156.435142993927
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 95.1204754114151
        },
        {
            "docid": "2208074_7",
            "document": "Neurophilosophy . A different problematic methodological assumption within fMRI research is the use of reverse inference A reverse inference is when the activation of a brain region is used to infer the presence of a given cognitive process. Poldrack points out that the strength of this inference depends critically on the likelihood that a given task employs a given cognitive process and the likelihood of that pattern of brain activation given that cognitive process. In other words, the strength of reverse inference is based upon the selectivity of the task used as well as the selectivity of the brain region activation. A 2011 article published in the NY times has been heavily criticized for misusing reverse inference. In the study, participants were shown pictures of their iPhones and the researchers measured activation of the insula. The researches took insula activation as evidence of feelings of love and concluded that people loved their iPhones. Critics were quick to point out that the insula is not a very selective piece of cortex, and therefore not amenable to reverse inference.",
            "score": 76.93812108039856
        },
        {
            "docid": "48739328_3",
            "document": "Semantic processing . Semantic processing is the deepest level of processing and it requires the listener to think about the meaning of the cue. Studies on brain imaging have shown that, when semantic processing occurs, there is increased brain activity in the left prefrontal regions of the brain that does not occur during different kinds of processing. One study used MRI to measure the brain activity of subjects while they made semantic decisions. The participants then took a memory test after a short period of time. When the subjects showed high confidence and correctly retained the information, the fMRI measured increased activity in the left prefrontal regions.",
            "score": 76.09494400024414
        },
        {
            "docid": "37608_24",
            "document": "Putamen . It was found that subjects in the experimental group were impaired while performing rule-based tasks, but not information-integration ones. After statistical testing, it was also hypothesized that the brain began using information-integration techniques to solve the rule-based learning tasks. Since rule-based tasks use the hypothesis-testing system of the brain, it can be concluded that the hypothesis-testing system of the brain was damaged/weakened. It is known that the caudate and working memories are part of this system. Therefore, it was confirmed that the putamen is involved in category learning, competition between the systems, feed-back processing in rule-based tasks, and is involved in the processing of pre-frontal regions (which relate to working memory and executive functioning). Now it is known that not only the basal ganglia and caudate affect category learning.",
            "score": 119.07398796081543
        },
        {
            "docid": "33702464_5",
            "document": "Extrastriate body area . The experiment had subjects view images of different objects, including faces (as a control group), body parts, animals, parts of the face and intimate objects. While viewing the images, the subjects were scanned with an fMRI to see what area of the brain was activated. Through the trials a compilation of the fMRI\u2019s was made. From this compilation image a specific region was determined to have increased activity when shown visual stimuli of body parts and even more activity when viewing whole bodies. There have been no studies involving brain damage to the EBA. Thus far, only scans of brain activity, as well as transcranial magnetic stimulation, have been used to study the EBA. To find the specific functions of the EBA, Comimo Urgesi, Giovanni Berlucchi and Salvatore M. Aglioti used repetitive transcranial magnetic stimulation (rTMS) to disrupt part of the brain, making the brain less responsive in the target area. The study used event-related rTMS to disrupt the EBA, resulting in inactivation of cortical areas. This inactivation caused a slower response time in discriminating body parts. The study used facial features and motorcycle parts as non human parts for control groups. The facial features and motorcycle body parts did not display any change in response time. The neural activity data shows the EBA handles some of the visual processing of human body and parts but is not related to the processing of the face or other objects.",
            "score": 71.1302342414856
        },
        {
            "docid": "10438439_43",
            "document": "Framing (social sciences) . Cognitive neuroscientists have linked the framing-effect to neural activity in the amygdala, and have identified another brain-region, the orbital and medial prefrontal cortex (OMPFC), that appears to moderate the role of emotion on decisions. Using functional magnetic resonance imaging (fMRI) to monitor brain-activity during a financial decision-making task, they observed greater activity in the OMPFC of those research subjects less susceptible to the framing-effect.",
            "score": 44.28458118438721
        },
        {
            "docid": "51547415_15",
            "document": "Interindividual differences in perception . In line with these findings, Hedden and colleagues (2009) used the same visual stimuli to investigate the neural activity with the help of fMRI. Participants of the study were asked to judge the length of a vertical line, either including the contextual information or ignoring it. The results revealed that separate brain regions were employed while performing the task, either incorporating the contextual information or avoiding it, based on one's own culture. The areas associated with attentional control in the frontal and parietal region of the brain were highly activated when the subjects performed the task which was incongruent to their cultural pattern. That is, the activity in the fronto-parietal region enhanced when East Asians had to ignore the contextual information, while similar enhancement happened for Americans when they had to incorporate the contextual information. These findings illustrate that the function of the neural mechanisms are also modulated to some extent by one's own culture.",
            "score": 88.54340863227844
        },
        {
            "docid": "42621632_6",
            "document": "Dual process theory (moral psychology) . The dual process account first grew out of fMRI experiments showing that moral dilemmas such as the trolley problem engaged areas of the brain corresponding to emotional processing when the context involved \"personal\" moral violations (such as direct bodily force). When the context of the dilemma was more \"impersonal\" (the decision maker pulls a switch rather than use bodily force) areas corresponding to working memory and controlled reasoning were engaged instead. Neuropsychological evidence from lesion studies focusing on patients with damage to the ventromedial prefrontal cortex also points to a possible dissociation between emotional and rational decision processes. Damage to this area is typically associated with antisocial personality traits and impairments of moral decision making. Patients with these lesions tend to show more frequent endorsement of the \"utilitarian\" path in trolley problem dilemmas. Greene et al. claim that this shows that when emotional information is removed through context or damage to brain regions necessary to render such information, the process associated with rational, controlled reasoning dominates decision making.",
            "score": 98.19415247440338
        },
        {
            "docid": "41118642_7",
            "document": "Dynamic functional connectivity . One of the first methods ever used to analyze DFC was pattern analysis of fMRI images to show that there are patterns of activation in spatially separated brain regions that tend to have synchronous activity. It has become clear that there is a spatial and temporal periodicity in the brain that probably reflects some of the constant processes of the brain. Repeating patterns of network information have been suggested to account for 25\u201350% of the variance in fMRI BOLD data. These patterns of activity have primarily been seen in rats as a propagating wave of synchronized activity along the cortex. These waves have also been shown to be related to underlying neural activity, and has been shown to be present in humans as well as rats.",
            "score": 49.10207962989807
        },
        {
            "docid": "7800961_5",
            "document": "Fusiform face area . The human FFA was first described by Justine Sergent in 1992 and later named by Nancy Kanwisher in 1997 who proposed that the existence of the FFA is evidence for domain specificity in the visual system. Studies have recently shown that the FFA is composed of functional clusters that are at a finer spatial scale than prior investigations have measured. Electrical stimulation of these functional clusters selectively distorts face perception, which is causal support for the role of these functional clusters in perceiving the facial image. While it is generally agreed that the FFA responds more to faces than to most other categories, there is debate about whether the FFA is uniquely dedicated to face processing, as proposed by Nancy Kanwisher and others, or whether it participates in the processing of other objects. The expertise hypothesis, as championed by Isabel Gauthier and others, offers an explanation for how the FFA becomes selective for faces in most people. The expertise hypothesis suggests that the FFA is a critical part of a network that is important for individuating objects that are visually similar because they share a common configuration of parts. Gauthier et al., in an adversarial collaboration with Kanwisher, tested both car and bird experts, and found some activation in the FFA when car experts were identifying cars and when bird experts were identifying birds. This finding has been replicated, and expertise effects in the FFA have been found for other categories such as chess displays and x-rays. Recently, it was found that the thickness of the cortex in the FFA predicts the ability to recognize faces as well as vehicles.",
            "score": 110.95522880554199
        },
        {
            "docid": "6240358_17",
            "document": "Dual process theory . The dual process has impact on social psychology in such domains as stereotyping, categorization, and judgment. Especially, the study of automaticity and of implicit in dual process theories has the most influence on a person's perception. People usually perceive other people's information and categorize them by age, gender, race, or role. According to Neuberg and Fiske (1987) a perceiver who receives a good amount of information about the target person then will use their formal mental category (Unconscious) as a basis for judging the person. When the perceiver is distracted, the perceiver has to pay more attention to target information (Conscious). Categorization is the basic process of stereotyping in which people are categorized into social groups that have specific stereotypes associated with them. It is able to retrieve people's judgment automatically without subjective intention or effort. Attitude can also be activated spontaneously by the object. John Bargh's study offered an alternative view, holding that essentially all attitudes, even weak ones are capable of automatic activation. Whether the attitude is formed automatically or operates with effort and control, it can still bias further processing of information about the object and direct the perceivers' actions with regard to the target. According to Shelly Chaiken, heuristic processing is the activation and application of judgmental rules and heuristics are presumed to be learned and stored in memory. It is used when people are making accessible decisions such as \"experts are always right\" (system 1) and systematic processing is inactive when individuals make effortful scrutiny of all the relevant information which requires cognitive thinking (system 2). The heuristic and systematic processing then influence the domain of attitude change and social influence. Unconscious thought theory is the counterintuitive and contested view that the unconscious mind is adapted to highly complex decision making. Where most dual system models define complex reasoning as the domain of effortful conscious thought, UTT argues complex issues are best dealt with unconsciously.",
            "score": 98.25541079044342
        },
        {
            "docid": "1677048_16",
            "document": "Inattentional blindness . For example, in an functional magnetic resonance imaging (fMRI) study by Rees and colleagues, brain activity was recorded while participants completed a perceptual task. Here they examined the neural processing of meaningful (words) and meaningless (consonant string) stimuli both when attended to, and when these same items were unattended. While no difference in activation patterns were found between the groups when the stimuli were unattended, differences in neural processing were observed for meaningful versus meaningless stimuli to which participants overtly attended. This pattern of results suggests that ignored stimuli are not processed to the level of meaning, i.e. less extensively than attended stimuli. Participants do not seem to be detecting meaning in stimuli to which they are not consciously attending.",
            "score": 65.78740549087524
        }
    ],
    "r": [
        {
            "docid": "9732182_4",
            "document": "Base rate . A large number of psychological studies have examined a phenomenon called base-rate neglect\" or \"base rate fallacy in which category base rates are not integrated with featural evidence in the normative manner. Mathematician Keith Devlin provides an illustration of the risks of this: He asks us to imagine that there is a type of cancer that afflicts 1% of all people. A doctor then says there is a test for that cancer which is about 80% reliable. He also says that the test provides a positive result for 100% of people who have the cancer, but it also results in a 'false positive' for 20% of people - who do not have the cancer. Now, if we test positive, we may be tempted to think it is 80% likely that we have the cancer. Devlin explains that, in fact, our odds are less than 5%. What is missing from the jumble of statistics is the most relevant base rate information. We should ask the doctor, \"\"Out of the number of people who test positive (this is the base rate group that we care about), how many have the cancer?\"\" In assessing the probability that a given individual is a member of a particular class, we must account for other information besides the base rate. In particular, we must account for featural evidence. For example, when we see a person wearing a white doctor's coat and stethoscope, and prescribing medication, we have evidence which may allow us to conclude that the probability of this \"particular\" individual being a \"medical professional\" is considerably greater than the category base rate of 1%.",
            "score": 160.9576416015625
        },
        {
            "docid": "27988760_11",
            "document": "Heuristics in judgment and decision-making . The representativeness heuristic is seen when people use categories, for example when deciding whether or not a person is a criminal. An individual thing has a high \"representativeness\" for a category if it is very similar to a prototype of that category. When people categorise things on the basis of representativeness, they are using the representativeness heuristic. \"Representative\" is here meant in two different senses: the prototype used for comparison is representative of its category, and representativeness is also a relation between that prototype and the thing being categorised. While it is effective for some problems, this heuristic involves attending to the particular characteristics of the individual, ignoring how common those categories are in the population (called the \"base rates\"). Thus, people can overestimate the likelihood that something has a very rare property, or underestimate the likelihood of a very common property. This is called the base rate fallacy. Representativeness explains this and several other ways in which human judgments break the laws of probability.",
            "score": 156.4351348876953
        },
        {
            "docid": "27797792_25",
            "document": "Construal level theory . We form categories depending on the use of the different construal levels. This shapes how we view things as either alike or different. Generally, when we think of objects, situations, or people in abstract, high-level terms, we tend to categorize them into broader categories (e.g., \"kitchenware\"). When we think in low-level terms, we tend to use narrower more specific subcategories (e.g., \"plates\", \"pots\"). Categories can be of different kinds of people where those who are more physically distant or different from ourselves can be categorized as others or out-groups different from ourselves. This can form group bonds, along with attitudes that differ toward out-groups. We can also categorize ourselves, this is often used when people are thinking about their specific qualities, or more of who they are overall. So when thinking about oneself in the present, people tend to be more focused on their individual concrete qualities in more detail, versus when they think of themselves in the future, they think more of how they will be in the years to come in an overall abstract way.",
            "score": 141.90631103515625
        },
        {
            "docid": "38874612_3",
            "document": "Exemplar theory . Exemplar Theory is often contrasted with prototype theory, which proposes another method of categorization. We use both the exemplar and prototype method in making category judgments, and they often work in tandem to produce the most accurate conclusion. The two theories are similar in that they emphasize the importance of similarity in categorization: only by resembling a prototype or exemplar can a new stimulus be placed into a category. They also both rely on the same general cognitive process: we experience a new stimulus, a concept in memory is triggered, we make a judgment of resemblance, and draw a categorization conclusion. However, the specifics of the two theories are different. Prototype theory suggests that a new stimulus is compared to a single prototype in a category, while exemplar theory suggests that a new stimulus is compared to multiple known exemplars in a category. While a prototype is an abstract average of the members of a category, an exemplar is an actual member of a category, pulled from memory. While prototypes are economical\u2014meaning they are more conducive to quick judgments\u2014exemplars are less so. On the other hand, prototypes are less flexible than exemplars: exemplars can account more easily for atypical category members, such as a penguin being part of the \"bird\" category, because an exemplar does not average out the characteristics of a category like a prototype does. Exemplars can make sense of variable categories\u2014those with less distinguished characteristics\u2014such as \"games\", much more so than prototypes, which rely on typical characteristics to determine membership. Another difference, suggested by research, is that exemplars are more likely to be used than prototypes after long experience with a concept.",
            "score": 141.7659912109375
        },
        {
            "docid": "19442735_14",
            "document": "Psychology of reasoning . Judgment and reasoning involve thinking through the options, making a judgment or conclusion and finally making a decision. Making judgments involves heuristics, or efficient strategies that usually lead you to the right answers. The most common heuristics used are attribute substitution, the availability heuristic, the representativeness heuristic and the anchoring heuristic \u2013 these all aid in quick reasoning and work in most situations. Heuristics allow for errors, a price paid to gain efficiency. Other errors in judgment, therefore affecting reasoning, include errors in judgment about covariation \u2013 a relationship between two variables such that the presence and magnitude of one can predict the presence and magnitude of the other. One cause of covariation is confirmation bias, or the tendency to be more responsive to evidence that confirms your beliefs. But assessing covariation can be pulled off track by neglecting base-rate information \u2013 how frequently something occurs in general. However people often ignore base rates and tend to use other information presented. There are more sophisticated judgment strategies that result in fewer errors. People often reason based on availability but sometimes they look for other, more accurate, information to make judgments. This suggests there are two ways of thinking, known as the Dual-Process Model. The first, System I, is fast, automatic and uses heuristics \u2013 more of intuition. The second, System II, is slower, effortful and more likely to be correct \u2013 more reasoning.",
            "score": 140.62025451660156
        },
        {
            "docid": "2117890_5",
            "document": "Cyberchondria . The first systematic study of cyberchondria, reported in November 2008, was performed by Microsoft researchers Ryen White and Eric Horvitz, who conducted a large-scale study that included several phases of analysis. \"The New York Times\" covered the study. White and Horvitz defined cyberchondria as the \u201cunfounded escalation of concerns about common symptomatology, based on the review of search results and literature on the Web.\u201d They analyzed a representative crawl of the web for co-occurrences of symptoms with diseases in web content as well as the content returned as search results from queries on symptoms and found surprisingly high rates of linkage of rare, concerning diseases (e.g., brain tumor) to common symptoms (e.g., headache). They also analyzed anonymized large-scale logs of queries to all of the popular search engines and noted the commonality of escalations of queries from common complaints to queries on concerning diseases. They characterized the nature of escalations within a specific session and also found that potentially disruptive querying about disorders (arrived at via a search escalation) could continue in other sessions over days, weeks, and months, and that the queries could disrupt non-medical search activities. Finally, the researchers did a survey of over 500 people that confirmed the prevalence of web-induced medical anxieties and that probed several aspects of the phenomenon. The survey noted that a significant portion of subjects considered the ranking of a list of results on a medical query as somehow linked to the likelihood of relevant disorders. The researchers highlight the difference between the information provided by standard approaches to \u201crelevance\u201d used by search engines in ranking results and answers to medical questions, especially when searchers are looking for likelihoods of different explanations. They point out the potential importance of findings drawn from the psychology of judgment in their work. In particular, they point out that previously studied \"biases of judgment\" play a role in cyberchondria. The researchers highlighted the potential biases of availability (the recency and density of exposure of someone to events raises the assessed likelihood of the events) and base-rate neglect (people often do not properly consider the low prior probability of events in assessing the likelihood of events when they review evidence in support of the event) as influencing both search engines and then people searching the web. Confirmation bias, a tendency for people to confirm their preconceptions or hypotheses, may also contribute to cyberchondria.",
            "score": 134.74623107910156
        },
        {
            "docid": "19572217_2",
            "document": "Influenza . Influenza, commonly known as \"the flu\", is an infectious disease caused by an influenza virus. Symptoms can be mild to severe. The most common symptoms include: a high fever, runny nose, sore throat, muscle pains, headache, coughing, and feeling tired. These symptoms typically begin two days after exposure to the virus and most last less than a week. The cough, however, may last for more than two weeks. In children, there may be nausea and vomiting, but these are not common in adults. Nausea and vomiting occur more commonly in the unrelated infection gastroenteritis, which is sometimes inaccurately referred to as \"stomach flu\" or the \"24-hour flu\". Complications of influenza may include viral pneumonia, secondary bacterial pneumonia, sinus infections, and worsening of previous health problems such as asthma or heart failure. Three types of influenza viruses affect people, called Type A, Type B, and Type C. Usually, the virus is spread through the air from coughs or sneezes. This is believed to occur mostly over relatively short distances. It can also be spread by touching surfaces contaminated by the virus and then touching the mouth or eyes. A person may be infectious to others both before and during the time they are showing symptoms. The infection may be confirmed by testing the throat, sputum, or nose for the virus. A number of rapid tests are available; however, people may still have the infection if the results are negative. A type of polymerase chain reaction that detects the virus's RNA is more accurate. Frequent hand washing reduces the risk of viral spread. Wearing a surgical mask is also useful. Yearly vaccinations against influenza are recommended by the World Health Organization for those at high risk. The vaccine is usually effective against three or four types of influenza. It is usually well tolerated. A vaccine made for one year may not be useful in the following year, since the virus evolves rapidly. Antiviral drugs such as the neuraminidase inhibitor oseltamivir, among others, have been used to treat influenza. Their benefits in those who are otherwise healthy do not appear to be greater than their risks. No benefit has been found in those with other health problems. Influenza spreads around the world in a yearly outbreak, resulting in about three to five million cases of severe illness and about 250,000 to 500,000 deaths. In the Northern and Southern parts of the world, outbreaks occur mainly in winter while in areas around the equator outbreaks may occur at any time of the year. Death occurs mostly in the young, the old and those with other health problems. Larger outbreaks known as pandemics are less frequent. In the 20th century, three influenza pandemics occurred: Spanish influenza in 1918 (~50 million deaths), Asian influenza in 1957 (two million deaths), and Hong Kong influenza in 1968 (one million deaths). The World Health Organization declared an outbreak of a new type of influenza A/H1N1 to be a pandemic in June 2009. Influenza may also affect other animals, including pigs, horses, and birds.",
            "score": 132.91629028320312
        },
        {
            "docid": "310898_2",
            "document": "Croup . Croup, also known as laryngotracheobronchitis, is a type of respiratory infection that is usually caused by a virus. The infection leads to swelling inside the trachea, which interferes with normal breathing and produces the classic symptoms of \"barking\" cough, stridor, and a hoarse voice. Fever and runny nose may also be present. These symptoms may be mild, moderate, or severe. Often it starts or is worse at night. It normally lasts one to two days. Croup can be caused by a number of viruses including parainfluenza and influenza virus. Rarely is it due to a bacterial infection. Croup is typically diagnosed based on signs and symptoms after potentially more severe causes, such as epiglottitis or an airway foreign body, have been ruled out. Further investigations\u2014such as blood tests, X-rays, and cultures\u2014are usually not needed. Many cases of croup are preventable by immunization for influenza and diphtheria. Croup is usually treated with a single dose of steroids by mouth. In more severe cases inhaled epinephrine may also be used. Hospitalization is required in one to five percent of cases. Croup is a relatively common condition that affects about 15% of children at some point. It most commonly occurs between 6 months and 5 years of age but may rarely be seen in children as old as fifteen. It is slightly more common in males than females. It occurs most often in autumn. Before vaccination, croup was frequently caused by diphtheria and was often fatal. This cause is now very rare in the Western world due to the success of the diphtheria vaccine.",
            "score": 132.08070373535156
        },
        {
            "docid": "403396_37",
            "document": "Availability heuristic . Much of the criticism against the availability heuristic has claimed that making use of the content that become available in our mind is not based on the ease of recall as suggested by Schwarz et al. For example, it could be argued that recalling more words that begin with K than words with the third letter being K could arise from how we categorize and process words into our memory. If we categorize words by first letter, and recall them through the same process, this would show more support for the representativeness heuristic than the availability heuristic. Based on the possibility of explanations such as these, some researchers have claimed that the classic studies on the availability heuristic are too vague in that they fail to account for people's underlying mental processes. Indeed, a study conducted by Wanke et al. demonstrated this scenario can occur in situations used to test the availability heuristic. Future studies should be conducted to determine if and when this alternative explanation will occur.",
            "score": 131.47659301757812
        },
        {
            "docid": "42345073_75",
            "document": "West African Ebola virus epidemic . No proven Ebola virus-specific treatment presently exists; however, measures can be taken to improve a patient's chances of survival. Ebola symptoms may begin as early as two days or as long as 21 days after one is exposed to the virus. They usually begin with a sudden influenza-like illness characterized by feeling tired, fever, and pain in the muscles and joints. Later symptoms may include headache, nausea, and abdominal pain. This is often followed by severe vomiting and diarrhoea. In past outbreaks, it has been noted that some patients bleed internally and/or externally; however data published in October 2014 showed that this had been a rare symptom in the West African outbreak. Another study published in October 2014 suggested that a person's genetic makeup may play a major role in determining how an infected person's body reacts to the disease, with some infected people experiencing mild or no symptoms while others progress to a very severe stage that includes massive bleeding.",
            "score": 131.3533935546875
        },
        {
            "docid": "38874612_11",
            "document": "Exemplar theory . The work of Kahneman and Tversky illustrated that people use exemplars when making categorizations and decisions. In one of their experiments, it was found that participants estimated the frequency of occurrence of different types of events by finding several exemplars to base their approximation on. For example, when participants were asked if there are more words in the English language that either start with \"k\" or have \"k\" as the third letter, most chose the first option, (even though this is incorrect). Participants presumably did so because they could generate more exemplars of words starting with \"k\" than they could of words with \"k\" as the third letter in the word. (This particular experiment also ties to the availability heuristic, by which we guess probability by the ease with which an example comes to mind.) In categorization studies, participants sometimes conclude that a new stimuli is not a member of a certain category by finding a counter exemplar. For example, participants based their disagreement with the statement, \"all birds are eagles\" on their retrieval of memories of birds that weren't eagles, such as robins. If participants used exemplars to make disagreeing decisions, they also use exemplars to make reaffirming decisions about category membership.",
            "score": 129.5371856689453
        },
        {
            "docid": "22612651_3",
            "document": "Stockpiling antiviral medications for pandemic influenza . There are no evidence-based guidelines to guide the use of these stockpiled drugs, and plans are based on assumed similarities to seasonal influenza. The most common antivirals are neuraminidase inhibitors, which, if begun during the first 48 hours after symptoms appear, will reduce the duration of seasonal influenza by about one day. Taken before symptoms appear, it may prevent disease in about three-quarters of people treated prophylactically. Currently, this is recommended in institutionalized elderly people and other high-risk groups as a form of post-exposure prophylaxis during seasonal influenza outbreaks. However, since pandemic influenza differs somewhat from normal seasonal influenza, it is not clear that these drugs will prove either safe or effective for their intended purpose.",
            "score": 129.4688720703125
        },
        {
            "docid": "92693_3",
            "document": "Common cold . The typical symptoms of a cold include a cough, a runny nose, nasal congestion and a sore throat, sometimes accompanied by muscle ache, fatigue, headache, and loss of appetite. A sore throat is present in about 40% of cases and a cough in about 50%, while muscle ache occurs in about half. In adults, a fever is generally not present but it is common in infants and young children. The cough is usually mild compared to that accompanying influenza. While a cough and a fever indicate a higher likelihood of influenza in adults, a great deal of similarity exists between these two conditions. A number of the viruses that cause the common cold may also result in asymptomatic infections.",
            "score": 128.589111328125
        },
        {
            "docid": "510738_3",
            "document": "Representativeness heuristic . Tversky and Kahneman defined representativeness as \"the degree to which [an event] (i) is similar in essential characteristics to its parent population, and (ii) reflects the salient features of the process by which it is generated\". When people rely on representativeness to make judgments, they are likely to judge wrongly because the fact that something is more representative does not actually make it more likely. The representativeness heuristic is simply described as assessing similarity of objects and organizing them based around the category prototype (e.g., like goes with like, and causes and effects should resemble each other). This heuristic is used because it is an easy computation. The problem is that people overestimate its ability to accurately predict the likelihood of an event. Thus, it can result in neglect of relevant base rates and other cognitive biases.",
            "score": 128.39895629882812
        },
        {
            "docid": "92693_2",
            "document": "Common cold . The common cold, also known simply as a cold, is a viral infectious disease of the upper respiratory tract that primarily affects the nose. The throat, sinuses, and larynx may also be affected. Signs and symptoms may appear less than two days after exposure to the virus. These may include coughing, sore throat, runny nose, sneezing, headache, and fever. People usually recover in seven to ten days, but some symptoms may last up to three weeks. Occasionally those with other health problems may develop pneumonia. Well over 200 virus strains are implicated in causing the common cold, with rhinoviruses being the most common. They spread through the air during close contact with infected people or indirectly through contact with objects in the environment, followed by transfer to the mouth or nose. Risk factors include going to daycare, not sleeping well, and psychological stress. The symptoms are mostly due to the body's immune response to the infection rather than to tissue destruction by the viruses themselves. In contrast, those affected by influenza can show similar symptoms as people with a cold, but symptoms are usually more severe. Additionally, influenza is less likely to result in a runny nose. There is no vaccine for the common cold. The primary methods of prevention are: hand washing; not touching the eyes, nose or mouth with unwashed hands; and staying away from sick people. Some evidence supports the use of face masks. There is also no cure, but the symptoms can be treated. Zinc may reduce the duration and severity of symptoms if started shortly after the onset of symptoms. Nonsteroidal anti-inflammatory drugs (NSAIDs) such as ibuprofen may help with pain. Antibiotics, however, should not be used and there is no good evidence for cough medicines. The common cold is the most frequent infectious disease in humans. The average adult gets two to three colds a year, while the average child may get six to eight. Infections occur more commonly during the winter. These infections have existed throughout human history.",
            "score": 127.95541381835938
        },
        {
            "docid": "732873_16",
            "document": "Base rate fallacy . Psychologists Daniel Kahneman and Amos Tversky attempted to explain this finding in terms of a simple rule or \"heuristic\" called representativeness. They argued that many judgments relating to likelihood, or to cause and effect, are based on how representative one thing is of another, or of a category. Kahneman considers base rate neglect to be a specific form of extension neglect. Richard Nisbett has argued that some attributional biases like the fundamental attribution error are instances of the base rate fallacy: people do not use the \"consensus information\" (the \"base rate\") about how others behaved in similar situations and instead prefer simpler dispositional attributions.",
            "score": 127.32148742675781
        },
        {
            "docid": "33562977_47",
            "document": "Personal knowledge base . In category-based structural frameworks, rather than being described in terms of their relationships to other elements (as with a tree or graph), items are simply grouped together in one or more categories, indicating that they have something in common. This scheme is based on the branch of pure mathematics called set theory, in which each of a body of objects either has, or does not have, membership in each of some number of sets. There is normally no restriction as to how many different categories a given item can belong to, as is the case with mathematical sets.",
            "score": 127.08338165283203
        },
        {
            "docid": "29780_13",
            "document": "Thomas Reid . Thus, for Reid, common sense was based on the innate capacity of man in an earlier epoch to directly participate in nature, and one we find to some extent in the child and artist, but one that from a philosophical and scientific perspective, we must re-awaken at a higher level in the human mind above nature. Why does Reid believe that perception is the way to recognize? Well, to him \u201can experience is purely subjective and purely negative. It supports the validity of a proposition, only on the fact that I find that it is impossible for me not to hold it for true, to suppose it therefore not true\u201d (Reid, 753). To understand this better, it is important to know that Reid divides his definition of perception into two categories: conception, and belief. \u201cConception is Reid\u2019s way of saying to visualize an object, so then we can affirm or deny qualities about that thing. Reid believes that beliefs are our direct thoughts of an object, and what that object is\u201d (Buras, The Functions of Sensations to Reid). So, to Reid, what we see, what we visualize, what we believe of an object, is that object\u2019s true reality. Reid believes in direct objectivity, our senses guide us to what is right since we cannot trust our own thoughts. \u201cThe worlds of common sense and of philosophy are reciprocally the converse of each other\u201d (Reid, 841). Reid believes that Philosophy overcomplicates the question of what is real. So, what does Common Sense actually mean then? Well, \u201ccommon sense is the senses being pulled all together to form one idea\u201d (Cambridge Companion to Thomas Reid, 164). Common sense (all the senses combined) is how we truly identify the reality of an object; since all that can be perceived about an object, are all pulled into one perception. How do people reach the point of accessing common sense? That\u2019s the trick, everyone is born with the ability to access common sense, that is why it is called common sense. \u201cThe principles of common sense are common to all of humanity,\u201d (Nichols, Ryan, Yaffe, and Gideon, Thomas Reid). Common sense works as such: If all men observe an item and believe the same qualities about that item, then the knowledge of that item is universally true. It is common knowledge, with without explanation is held true by other people; so, what is universally seen is universally believed. \u201cThe real, then, is that which, sooner or later, information and reasoning would finally result in, and which is therefore independent of the vagaries of me and you. Thus, the very origin of the conception of reality shows that this conception essentially involves the notion of a community, without definite limits, and capable of a definite increase of knowledge,\u201d (Reid, 155). The combination of the same ideas, of a thing, by multiple people, is what confirms the reality of an object. Reid also believes that the philosophers of his time overexaggerated what is truly real. Where most philosophers believe that what we see is not fully what that thing is, for example, Descartes. Reid counters this argument simply by stating that this assumption \u201cthat such a hypothesis is no more likely to be true than the common-sensical belief that the world is much the way we perceive it to be,\u201d (Nichols, Ryan, Yaffe, and Gideon, Thomas Reid). Reality is what we make it out to be, nothing more.",
            "score": 126.6023178100586
        },
        {
            "docid": "28598_2",
            "document": "Sinusitis . Sinusitis, also known as a sinus infection or rhinosinusitis, is inflammation of the sinuses resulting in symptoms. Common symptoms include thick nasal mucus, a plugged nose, and pain in the face. Other signs and symptoms may include fever, headaches, poor sense of smell, sore throat, and cough. The cough is often worse at night. Serious complications are rare. It is defined as acute rhinosinusitis (ARS) if it lasts less than 4 weeks, and as chronic rhinosinusitis (CRS) if it lasts for more than 12 weeks. Sinusitis can be caused by infection, allergies, air pollution, or structural problems in the nose. Most cases are caused by a viral infection. A bacterial infection may be present if symptoms last more than ten days or if a person worsens after starting to improve. Recurrent episodes are more likely in people with asthma, cystic fibrosis, and poor immune function. X-rays are not typically needed unless complications are suspected. In chronic cases confirmatory testing is recommended by either direct visualization or computed tomography. Some cases may be prevented by hand washing, avoiding smoking, and immunization. Pain killers such as naproxen, nasal steroids, and nasal irrigation may be used to help with symptoms. Recommended initial treatment for ARS is watchful waiting. If symptoms do not improve in 7\u201310 days or get worse, then an antibiotic may be used or changed. In those in whom antibiotics are used, either amoxicillin or amoxicillin/clavulanate is recommended first line. Surgery may occasionally be used in people with chronic disease. Sinusitis is a common condition. It affects between about 10% and 30% of people each year in the United States and Europe. Women are more often affected than men. Chronic sinusitis affects approximately 12.5% of people. Treatment of sinusitis in the United States results in more than 11 billion in costs. The unnecessary and ineffective treatment of viral sinusitis with antibiotics is common. Sinusitis (or rhinosinusitis) is defined as an inflammation of the mucous membrane that lines the paranasal sinuses and is classified chronologically into several categories:",
            "score": 124.7294921875
        },
        {
            "docid": "35197754_6",
            "document": "Daniel T. Willingham . In his book, \"\"Why Don't Students Like School?\"\" he provides nine fundamental principles than can effectively be applied to classroom use by teachers in an effort to help them understand how students' minds work, and to show how to use that knowledge to be a better teacher. He suggests it is more useful to view the human species as bad at thinking rather than as cognitively gifted. He argues the brain is not designed for thinking, it's designed to save you from having to think. He states in his book that this is because thinking is slow, effortful, and uncertain. Instead, we often rely on memory for the vast majority of decisions we make, and while memory is not always reliable, it is much more reliable than having to stop and think about every single step of every decision you need to make (for example, driving a car). He also suggests, despite the fact that our brains are not very good at thinking, we actually \"like\" to think. He reaffirms the well known idea that humans are naturally curious. However, the conditions have to be just right for curiosity to take hold (not too easy, not too hard) similar to Vygotsky's Zone of Proximal Development. For example, a joke is always funnier when you get it without needing it to be explained. He suggests this is because of the dopamine released by the brain's natural reward system whenever we solve a problem.",
            "score": 122.96382141113281
        },
        {
            "docid": "2239339_3",
            "document": "Commonsense knowledge (artificial intelligence) . It is currently an unsolved problem in Artificial General Intelligence and is a focus of the Paul Allen Institute for Artificial Intelligence. Commonsense knowledge can underpin a commonsense reasoning process, to attempt inferences such as \"You might bake a cake because you want people to eat the cake.\" A natural language processing process can be attached to the commonsense knowledge base to allow the knowledge base to attempt to answer commonsense questions about the world. Common sense knowledge also helps to solve problems in the face of incomplete information. Using widely held beliefs about everyday objects, or common sense knowledge, AI systems make common sense assumptions or default assumptions about the unknown similar to the way people do. In an AI system or in english, this is expressed as 'Normally P holds', 'Usually P' or 'Typically P so Assume P'. For example if we know the fact 'tweety is a bird' , because we know the commonly held belief about birds, Typically Birds Fly, without knowing anything else about tweety, we may reasonably assume the fact that 'tweety can fly.' As more knowledge of the world is discovered or learned over time, the AI system can revise its assumptions about tweety using a truth maintenance process. If we later learn that 'tweety is a penguin' then truth maintenance revises this assumption because we also know 'penguins do not fly'.",
            "score": 121.8922119140625
        },
        {
            "docid": "51495200_14",
            "document": "Prosodic bootstrapping . In addition to helping to identify lexical items, a key element of prosodic bootstrapping involves using prosodic cues to identify syntactic knowledge about the language. Because prosodic phrase boundaries are correlated to syntactic boundaries, listeners can determine the syntactic category of a word, using only prosodic boundary information. Christophe et al. (2008) demonstrated that adults could use prosodic phrases to determine the syntactic category of ambiguous words. Listeners were provided two sentences with an ambiguous word [m\u0254\u0280], which could either belong to a verb category (\"mord\", translated as \"it bites\") or a noun category (\"mort\", translated as the adjective \"dead\"). The table above depicts the two sentences heard by French-speaking adults in Christophe et al. (2008), where the emboldened word is the phonetically ambiguous word, and the brackets represent phonological phrase boundaries. Using the position of the prosodic boundaries, adults were able to determine which category the ambiguous word [m\u0254\u0280] belonged to, since the word is assigned to a different phonological phrase, depending on its syntactic category and semantic meaning in the sentence.",
            "score": 121.47559356689453
        },
        {
            "docid": "1701650_32",
            "document": "Cohen's kappa . Here, reporting quantity and allocation disagreement is informative while Kappa obscures information. Furthermore, Kappa introduces some challenges in calculation and interpretation because Kappa is a ratio. It is possible for Kappa\u2019s ratio to return an undefined value due to zero in the denominator. Furthermore, a ratio does not reveal its numerator nor its denominator. It is more informative for researchers to report disagreement in two components, quantity and allocation. These two components describe the relationship between the categories more clearly than a single summary statistic. When predictive accuracy is the goal, researchers can more easily begin to think about ways to improve a prediction by using two components of quantity and allocation, rather than one ratio of Kappa.Some researchers have expressed concern over \u03ba's tendency to take the observed categories' frequencies as givens, which can make it unreliable for measuring agreement in situations such as the diagnosis of rare diseases. In these situations, \u03ba tends to underestimate the agreement on the rare category. For this reason, \u03ba is considered an overly conservative measure of agreement. Others contest the assertion that kappa \"takes into account\" chance agreement. To do this effectively would require an explicit model of how chance affects rater decisions. The so-called chance adjustment of kappa statistics supposes that, when not completely certain, raters simply guess\u2014a very unrealistic scenario.",
            "score": 121.31340026855469
        },
        {
            "docid": "38874612_5",
            "document": "Exemplar theory . Contradictory statements have been made about the accuracy of the exemplar theory for categorization when it is compared to prototype theory. For example, one study at Arizona State University concluded that the exemplar theory is most accurate with minimal category experience and as experience is developed the prototype theory is more accurate. Another study though, shows evidence that the exemplar-based approach is more accurate as you become more familiar with a category because knowledge of the members is greater than that that can be represented by a single prototype. It is clear that there are some situations where the exemplar-based approach is most accurate and others where it may not be the most accurate. This being said, it is evident that the brain naturally uses a combination of categorization approaches in everyday life.",
            "score": 120.56694030761719
        },
        {
            "docid": "3289308_29",
            "document": "Evidence-based practice . A protocol suggested by Saunders et al. assigns research reports to six categories, on the basis of research design, theoretical background, evidence of possible harm, and general acceptance. To be classified under this protocol, there must be descriptive publications, including a manual or similar description of the intervention. This protocol does not consider the nature of any comparison group, the effect of confounding variables, the nature of the statistical analysis, or a number of other criteria. Interventions are assessed as belonging to Category 1, well-supported, efficacious treatments, if there are two or more randomized controlled outcome studies comparing the target treatment to an appropriate alternative treatment and showing a significant advantage to the target treatment. Interventions are assigned to Category 2, supported and probably efficacious treatment, based on positive outcomes of nonrandomized designs with some form of control, which may involve a non-treatment group. Category 3, supported and acceptable treatment, includes interventions supported by one controlled or uncontrolled study, or by a series of single-subject studies, or by work with a different population than the one of interest. Category 4, promising and acceptable treatment, includes interventions that have no support except general acceptance and clinical anecdotal literature; however, any evidence of possible harm excludes treatments from this category. Category 5, innovative and novel treatment, includes interventions that are not thought to be harmful, but are not widely used or discussed in the literature. Category 6, concerning treatment, is the classification for treatments that have the possibility of doing harm, as well as having unknown or inappropriate theoretical foundations.",
            "score": 120.2823715209961
        },
        {
            "docid": "5366050_62",
            "document": "Speech perception . The fuzzy logical theory of speech perception developed by Dominic Massaro proposes that people remember speech sounds in a probabilistic, or graded, way. It suggests that people remember descriptions of the perceptual units of language, called prototypes. Within each prototype various features may combine. However, features are not just binary (true or false), there is a fuzzy value corresponding to how likely it is that a sound belongs to a particular speech category. Thus, when perceiving a speech signal our decision about what we actually hear is based on the relative goodness of the match between the stimulus information and values of particular prototypes. The final decision is based on multiple features or sources of information, even visual information (this explains the McGurk effect). Computer models of the fuzzy logical theory have been used to demonstrate that the theory's predictions of how speech sounds are categorized correspond to the behavior of human listeners.",
            "score": 119.78439331054688
        },
        {
            "docid": "625404_2",
            "document": "Stroke . A stroke is a medical condition in which poor blood flow to the brain results in cell death. There are two main types of stroke: ischemic, due to lack of blood flow, and hemorrhagic, due to bleeding. They result in part of the brain not functioning properly. Signs and symptoms of a stroke may include an inability to move or feel on one side of the body, problems understanding or speaking, dizziness, or loss of vision to one side. Signs and symptoms often appear soon after the stroke has occurred. If symptoms last less than one or two hours it is known as a transient ischemic attack (TIA) or mini-stroke. A hemorrhagic stroke may also be associated with a severe headache. The symptoms of a stroke can be permanent. Long-term complications may include pneumonia or loss of bladder control. The main risk factor for stroke is high blood pressure. Other risk factors include tobacco smoking, obesity, high blood cholesterol, diabetes mellitus, a previous TIA, and atrial fibrillation. An ischemic stroke is typically caused by blockage of a blood vessel, though there are also less common causes. A hemorrhagic stroke is caused by either bleeding directly into the brain or into the space between the brain's membranes. Bleeding may occur due to a ruptured brain aneurysm. Diagnosis is typically based on a physical exam and supported by medical imaging such as a CT scan or MRI scan. A CT scan can rule out bleeding, but may not necessarily rule out ischemia, which early on typically does not show up on a CT scan. Other tests such as an electrocardiogram (ECG) and blood tests are done to determine risk factors and rule out other possible causes. Low blood sugar may cause similar symptoms. Prevention includes decreasing risk factors, as well as possibly aspirin, statins, surgery to open up the arteries to the brain in those with problematic narrowing, and warfarin in those with atrial fibrillation. A stroke or TIA often requires emergency care. An ischemic stroke, if detected within three to four and half hours, may be treatable with a medication that can break down the clot. Aspirin should be used. Some hemorrhagic strokes benefit from surgery. Treatment to try to recover lost function is called stroke rehabilitation and ideally takes place in a stroke unit; however, these are not available in much of the world. In 2013 approximately 6.9 million people had an ischemic stroke and 3.4 million people had a hemorrhagic stroke. In 2015 there were about 42.4\u00a0million people who had previously had a stroke and were still alive. Between 1990 and 2010 the number of strokes which occurred each year decreased by approximately 10% in the developed world and increased by 10% in the developing world. In 2015, stroke was the second most frequent cause of death after coronary artery disease, accounting for 6.3\u00a0million deaths (11% of the total). About 3.0 million deaths resulted from ischemic stroke while 3.3 million deaths resulted from hemorrhagic stroke. About half of people who have had a stroke live less than one year. Overall, two thirds of strokes occurred in those over 65 years old. Strokes can be classified into two major categories: ischemic and hemorrhagic. Ischemic strokes are caused by interruption of the blood supply to the brain, while hemorrhagic strokes result from the rupture of a blood vessel or an abnormal vascular structure. About 87% of strokes are ischemic, the rest being hemorrhagic. Bleeding can develop inside areas of ischemia, a condition known as \"hemorrhagic transformation.\" It is unknown how many hemorrhagic strokes actually start as ischemic strokes.",
            "score": 119.25131225585938
        },
        {
            "docid": "2959528_3",
            "document": "Intracerebral hemorrhage . People with intracerebral bleeding have symptoms that correspond to the functions controlled by the area of the brain that is damaged by the bleed. Other symptoms include those that indicate a rise in intracranial pressure caused by a large mass putting pressure on the brain. Intracerebral bleeds are often misdiagnosed as subarachnoid hemorrhages due to the similarity in symptoms and signs. A severe headache followed by vomiting is one of the more common symptoms of intracerebral hemorrhage. Another common symptom is a patient can collapse. Some people may experience continuous bleeding from the ear. Some patients may also go into a coma before the bleed is noticed.",
            "score": 119.19440460205078
        },
        {
            "docid": "37608_24",
            "document": "Putamen . It was found that subjects in the experimental group were impaired while performing rule-based tasks, but not information-integration ones. After statistical testing, it was also hypothesized that the brain began using information-integration techniques to solve the rule-based learning tasks. Since rule-based tasks use the hypothesis-testing system of the brain, it can be concluded that the hypothesis-testing system of the brain was damaged/weakened. It is known that the caudate and working memories are part of this system. Therefore, it was confirmed that the putamen is involved in category learning, competition between the systems, feed-back processing in rule-based tasks, and is involved in the processing of pre-frontal regions (which relate to working memory and executive functioning). Now it is known that not only the basal ganglia and caudate affect category learning.",
            "score": 119.07398986816406
        },
        {
            "docid": "6968451_10",
            "document": "Concept learning . Exemplars comparison and contrast \u2013 An efficient way to learn new categories and to induce new categorization rules is by comparing a few example objects while being informed about their categorical relation. Comparing two exemplars while being informed that the two are from the same category allows identifying the attributes shared by the category members, as it exemplifies variability within this category. On the other hand, contrasting two exemplars while being informed that the two are from different categories may allow identifying attributes with diagnostic value. Within category comparison and between categories contrast are not similarly useful for category learning (Hammer et al., 2008), and the capacity to use these two forms of comparison-based learning changes at childhood (Hammer et al., 2009).",
            "score": 118.2601547241211
        },
        {
            "docid": "14368827_6",
            "document": "Ideomotor apraxia . The prevailing hypothesis for the pathophysiology of ideomotor apraxia is that the various brain lesions associated with the disorder somehow disrupt portions of the praxis system. The praxis system is the brain regions that are involved in taking processed sensory input, accessing of stored information about tools and gestures, and translating these into a motor output. Buxbaum et al. have proposed that the praxis system involves three distinct parts: stored gesture representations, stored tool knowledge, and a \"dynamic body schema.\" The first two store information about the representation of gestures in the brain and the characteristic movements of tools. The body schema is a brain model of the body and its position in space. The praxis system relates the stored information about a movement type to how the dynamic, i.e. changing, body representation varies as the movement progresses. It is still not clear how this system maps out onto the brain itself, although some research has given indications to possible locations for certain portions. The dynamic body schema has been suggested to be localized in the superior posterior parietal cortex. There is also evidence that the inferior parietal lobule may be the locus for storage of the characteristic movements of a tool. This area showed inverse activation to the cerebellum in a study of tool use and tool mime. If the connections between these areas become severed, the praxis system would be disrupted, possibly resulting in the symptoms observed in ideomotor apraxia. There is no one definitive test for ideomotor apraxia; there are several that are used clinically to make an ideomotor apraxia diagnosis. The criteria for a diagnosis are not entirely conserved among clinicians, for apraxia in general or distinguishing subtypes. Almost all the tests laid out here that enable a diagnosis of ideomotor apraxia share a common feature: assessment of the ability to imitate gestures. A test developed by Georg Goldenberg uses imitation assessment of 10 gestures. The tester demonstrates the gesture to the patient and rates him on how whether the gesture was correctly imitated. If the first attempt to imitate the gesture was unsuccessful, the gesture is presented a second time; a higher score is given for correct imitation on the first trial, then for the second, and the lowest score is for not correctly imitating the gesture. The gestures used here are all meaningless, such as placing the hand flat on the top of the head or flat outward with the fingers towards the ear. This test is specifically designed for ideomotor apraxia. The main variation from this is in the type and number of gestures used. One test uses twenty-four movements with three trials for each and a trial-based scoring system similar to the Goldenberg protocol. The gestures here are also copied by the patient from the tester and are divided into finger movements, e.g. making a scissor movement with the forefinger and middle finger, and hand and arm movements, e.g. doing a salute. This protocol combines meaningful and meaningless gestures. Another test uses five meaningful gestures, such as waving goodbye or scratching your head and five meaningless gestures. Additional differences in this test are a verbal command to initiate the movement and it distinguishes between accurate performance and inaccurate but recognizable performance. One test utilizes tools, including a hammer and a key, with both a verbal command to use the tools and the patient copying the tester's demonstrated use of the tools. These tests have been shown to be individually unreliable, with considerable variability between the diagnoses delivered by each. If a battery of tests is used, however, the reliability and validity may be improved. It is also highly advisable to include assessments of how the patient performs activities in daily life. One of the newer tests that has been developed may provide greater reliability without relying on a multitude of tests. It combines three types of tool use with imitation of gestures. The tool use section includes having the patient pantomime use with no tool present, with visual contact with the tool, and finally with tactile contact with the tool. This test screens for ideational and ideomotor apraxia, with the second portion aimed specifically at ideomotor apraxia. One study showed great potential for this test, but further studies are needed to reproduce these results before this can be said with confidence. This disorder often occurs with other degenerative neurological disorders such as Parkinson's disease and Alzheimer's Disease. These comorbidities can make it difficult to pick out the specific features of ideomotor apraxia. The important point in distinguishing ideomotor apraxia is that basic motor control is intact; it is a high level dysfunction involving tool use and gesturing. Additionally, clinicians must be careful to exclude aphasia as a possible diagnosis, as, in the tests involving verbal command, an aphasic patient could fail to perform a task properly because they do not understand what the directions are.",
            "score": 118.07469177246094
        },
        {
            "docid": "510738_19",
            "document": "Representativeness heuristic . Some research has explored base rate neglect in children, as there was a lack of understanding about how these judgment heuristics develop. The authors of one such study wanted to understand the development of the heuristic, if it differs between social judgments and other judgments, and whether children use base rates when they are not using the representativeness heuristic. The authors found that the use of the representativeness heuristic as a strategy begins early on and is consistent. The authors also found that children use idiosyncratic strategies to make social judgments initially, and use base rates more as they get older, but the use of the representativeness heuristic in the social arena also increase as they get older. The authors found that, among the children surveyed, base rates were more readily used in judgments about objects than in social judgments. After that research was conducted, Davidson (1995) was interested in exploring how the representativeness heuristic and conjunction fallacy in children related to children\u2019s stereotyping. Consistent with previous research, children based their responses to problems off of base rates when the problems contained nonstereotypic information or when the children were older. There was also evidence that children commit the conjunction fallacy. Finally, as students get older, they used the representativeness heuristic on stereotyped problems, and so made judgments consistent with stereotypes. There is evidence that even children use the representativeness heuristic, commit the conjunction fallacy, and disregard base rates.",
            "score": 117.90449523925781
        }
    ]
}