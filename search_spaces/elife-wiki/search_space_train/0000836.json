{
    "q": [
        {
            "docid": "10480026_26",
            "document": "Shock collar . The aim of Salgirli's study was \"...to investigate whether any stress is caused by the use of specific conditioned signal, quitting signal, and/or pinch collars as alternatives to electric training collars, and if they do so, whether the stress produced in the process is comparable to the one with electric training collars.\". The study population were a group of 42 adult police dogs. The quitting signal was a conditioned frustration equivalent to negative punishment. It was conditioned by associating failure to obtain an anticipated food reward with a specific vocal signal. In the test, dogs were walked past a \"provocateur\" who attempted to taunt the dog into a reaction. If the dog reacted, it was punished, and if it failed to react on subsequent provocations then the punishment was deemed to have had a learning effect. The study is therefore a comparison of negative and positive punishment methods, and not a comparison of punishment with positive reinforcement. Learning effect was measured by assessing the number of dogs that learned to quit a behaviour after application of the punishing stimulus. There was no statistical difference in learning effect between the pinch and shock collar, but the quitting signal produced a significantly poorer learning effect compared to shock or pinch collars (p < 0.01 in both cases). \"Although the pinch collar caused more behavioral reactions, in the form of distress, than the electronic training collar, the electronic training collar elicits more vocal reactions in dogs than the pinch collars\"; the explanation for increased vocalisation in the shock collar group was that this was due to a startle response rather than pain reactions.",
            "score": 102.6987977027893
        },
        {
            "docid": "15497991_20",
            "document": "BELBIC . O, the orbitofrontal cortex, operates based on the difference between the \"perceived\" (i.e. expected) reward/punishment and the actual \"received\" reward/punishment. This perceived reward/punishment is the one that has been developed in the brain over time using learning mechanisms and it reaches the orbitofrontal cortex via the sensory cortex and the amygdala. The received reward/punishment on the other hand, comes courtesy of the outside world and is the \"actual\" reward/punishment that the specie has just obtained. If these two are identical, the output is the same as always through E. If not, the orbitofronal cortex inhibits and restrains emotional response to make way for further learning. So the path W is only activated in such conditions.",
            "score": 104.16623973846436
        },
        {
            "docid": "425938_29",
            "document": "Animal cognition . The use of rules has sometimes been considered an ability restricted to humans, but a number of experiments have shown evidence of simple rule learning in primates and also in other animals. Much of the evidence has come from studies of sequence learning in which the \"rule\" consists of the order in which a series of events occurs. Rule use is shown if the animal learns to discriminate different orders of events and transfers this discrimination to new events arranged in the same order. For example, Murphy \"et al.\" (2008) trained rats to discriminate between visual sequences. For one group ABA and BAB were rewarded, where A=\"bright light\" and B=\"dim light\". Other stimulus triplets were not rewarded. The rats learned the visual sequence, although both bright and dim lights were equally associated with reward. More importantly, in a second experiment with auditory stimuli, rats responded correctly to sequences of novel stimuli that were arranged in the same order as those previously learned. Similar sequence learning has been demonstrated in birds and other animals as well.",
            "score": 92.48758351802826
        },
        {
            "docid": "5008639_21",
            "document": "Teaching reading: whole language and phonics . Behaviorist learning theory is based on studies of animal behaviors where animals such as pigeons learned to do tasks when they received rewards and extinguished (stopped) behaviors that were not rewarded or were punished. Most of us can point to things we continue to do because we are rewarded for doing them. Rewards can be the pay we get for jobs we do, desired recognition like \"A\" grades for doing excellent school work, and praise from our friends when they like what we are doing. Likewise, we can point to things we stopped doing because we were not rewarded or were punished for them. Behaviorist learning theory tends to look at extrinsic rewards like money, grades, and gold stars rather than intrinsic rewards like feeling good about successfully accomplishing a difficult task.",
            "score": 54.00378429889679
        },
        {
            "docid": "540025_2",
            "document": "Bobo doll experiment . The Bobo doll experiment was the collective name of experiments conducted by Albert Bandura in 1961 and 1963 when he studied children's behavior after watching an adult model act aggressively towards a Bobo doll, a toy that gets up by itself to a standing position when it is knocked down. There are different variations of the experiment. The most notable experiment measured the children's behavior after seeing the model get rewarded, get punished, or experience no consequence for beating up the bobo doll. The experiments are empirical approaches to test Bandura's social learning theory. The social learning theory claims that people learn through observing, imitating, and modeling. It shows that people not only learn by being rewarded or punished (behaviorism), but they can also learn from watching somebody else being rewarded or punished (observational learning). These experiments are important because they sparked many more studies on the effects of observational learning. The studies not only give us new data, but this data has practical implications, e.g. how children can be influenced by watching violent media.",
            "score": 72.53192675113678
        },
        {
            "docid": "5587038_10",
            "document": "William Winn . This is an example of one of the studies conducted by Winn in which he evaluated the difference of learning in a computer-based environment as opposed to learning through direct experience. In this study, two groups of college students learned oceanography. One group learned using a computer simulation of the ocean which included a three-dimensional (3D) model, and the other group learned by spending a day in a research vessel and used oceanographic tools. In his discussion of this study Winn makes reference to Kolb\u2019s experiential learning theory because it highlights the significance of direct experience with the environment, as well as the need for abstract concepts in order to learn and apply knowledge. According to Winn, the proper use of metaphors in simulations may allow students to learn abstract concepts better than they would in real experiences. This study took place in Seattle and was focused on the oceanography of the Puget Sound estuary system within Washington. There were 25 students in each group and both groups received a total of three lessons. Two of the lessons were taught by the same professors and covered the same material. For the third lesson the groups were separated to their different settings. One of the limitations of this study was that the students taking the \u201cVirtual Puget Sound\u201d (VPS) experience could only control some independent variables but not others, like for example they could not change the salinity of the water. The results of the study showed \u201cno difference in overall learning between students who used the VPS simulation and those who studied the same material in the field\u201d. However, the study found that students with less experience in water learned more from direct experience, while the simulated ocean experience helped students transfer the knowledge they obtained while working in the computer, to the material presented in class.",
            "score": 77.25825452804565
        },
        {
            "docid": "270792_7",
            "document": "Anhedonia . Anhedonia is commonly listed as one component of negative symptoms in schizophrenia. Although five domains are usually used to classify negative symptoms, factor analysis of questionnaires yield two factors, with one including deficits in pleasure and motivation. People with schizophrenia retrospectively report experiencing fewer positive emotions than healthy individuals. However, \"liking\" or consummatory pleasure, is intact in schizophrenics, as they report experiencing the same degree of positive affect when presented with rewarding stimuli. Neuroimaging studies support this behavioral observation, as most studies report intact responses in the reward system (i.e. ventral striatum, VTA) to simple rewards. However, studies on monetary rewards sometimes report reduced responsiveness. More consistent reductions are observed with regard to emotional response during reward anticipation, which is reflected in a reduced responsiveness of both cortical and subcortical components of the reward system. Schizophrenia is associated with reduced positive prediction errors (a normal pattern of response to an unexpected reward), which a few studies have demonstrated to be correlated with negative symptoms. Schizophrenics demonstrate impairment in reinforcement learnings tasks only when the task requires explicit learning, or is sufficiently complex. Implicit reinforcement learning, on the other hand, is relatively intact. These deficits may be related to dysfunction in the ACC, OFC and dlPFC leading to abnormal representation of reward and goals.",
            "score": 73.56392407417297
        },
        {
            "docid": "236809_16",
            "document": "Recall (memory) . The learning curve for cued recall increases systematically with the number of trials completed. This result has caused a debate about whether or not learning is all-or-none. One theory is that learning is incremental and that the recall of each word pair is strengthened with repetition. Another theory suggests that learning is all-or-none, that is one learns the word pair in a single trial and memory performance is due to the average learned pairs, some of which are learned on earlier trials and some on later trials. To examine the validity of these theories researchers have performed memory experiments. In one experiment published in 1959, experimental psychologist Irvin Rock and colleague Walter Heimer of the University of Illinois had both a control group and an experimental group learn pairs of words. The control group studied word pairs that were repeated until the participants learned all the word pairs. In the experimental group, the learned pairs remained in the list while unlearned pairs were substituted with recombinations of previous words. Rock believed that associations between two items would be strengthened if learning were incremental even when pairs are not correctly recalled. His hypothesis was that the control group would have a higher correct recall probability than the experimental group. He thought that repetition would increase the strength of the word pair until the strength reaches a threshold needed to produce an overt response. If learning were all or none, then the control group and the experimental group should learn the word pairs at the same rate. Rock found experimentally there was little difference in learning rates between the two groups. However, Rock's work did not settle the controversy because in his experiment he rearranged replaced word pairs that could be either easier or harder to learn than the original words in the word- digit pair. In further experiments that addressed the question, there were mixed results. The incremental learning hypothesis is supported by the notion that awhile after Ai-Bi pairs are learned, the recall time to recall Bi decreases with continued learning trails.",
            "score": 68.0948052406311
        },
        {
            "docid": "211960_7",
            "document": "Reinforcement . This usage is at odds with some non-technical usages of the four term combinations, especially in the case of the term \"negative reinforcement,\" which is often used to denote what technical parlance would describe as \"positive punishment\" in that the non-technical usage interprets \"reinforcement\" as subsuming both reward and punishment and \"negative\" as referring to the responding operant's evaluation of the factor being introduced. By contrast, technical parlance would use the term \"negative reinforcement\" to describe encouragement of a given behavior by creating a scenario in which an unpleasant factor is or will be present but engaging in the behavior results in either escaping from that factor or preventing its occurrence, as in Martin Seligman's experiments involving dogs' learning processes regarding the avoidance of electric shock.",
            "score": 56.94293808937073
        },
        {
            "docid": "31565681_38",
            "document": "Pain in invertebrates . Studies on crayfish, \"Procambarus clarkia\", demonstrated that they learned to associate the turning on of a light with a shock that was given 10 seconds later. They learned to respond by walking to a safe area in which the shock was not delivered. However, this only occurred if the crayfish were facing the area to which they could retreat to avoid the shock. If they were facing away from the safe area the animal did not walk but responded to the shock by a tail-flick escape response. Despite repeated pairings of light and shock the animals did not learn to avoid the shock by tail-flicking in response to light. Curiously, when the animals that had experienced shocks whilst facing away from the safe area were subsequently tested facing towards the safe area they showed a very rapid avoidance of the shock upon the onset of the light. Thus, they seemed to have learned the association although they had not previously used it to avoid the shock - much like mammalian latent learning. These studies show an ability in decapods that fulfils several criteria for pain experience rather than nociception.",
            "score": 91.74329173564911
        },
        {
            "docid": "30237309_5",
            "document": "Gray's biopsychological theory of personality . Gray had a lot of support for his theories and experimented with animals to test his hypotheses. Using animal subjects allows researchers to test whether different areas of the brain are responsible for different learning mechanisms. Specifically, Gray's theory concentrated on understanding how reward or punishment related to anxiety and impulsivity measures. His research and further studies have found that reward and punishment are under the control of separate systems and as a result people can have different sensitivities to such rewarding or punishing stimuli.",
            "score": 85.70767045021057
        },
        {
            "docid": "425938_16",
            "document": "Animal cognition . Other experiments have shown that after animals have learned to respond to one aspect of the environment responsiveness to other aspects is suppressed. In \"blocking\", for example, an animal is conditioned to respond to one stimulus (\"A\") by pairing that stimulus with reward or punishment. After the animal responds consistently to A, a second stimulus (\"B\") accompanies A on additional training trials. Later tests with the B stimulus alone elicit little response, suggesting that learning about B has been blocked by prior learning about A. This result supports the hypothesis that stimuli are neglected if they fail to provide new information. Thus, in the experiment just cited, the animal failed to attend to B because B added no information to that supplied by A. If true, this interpretation is an important insight into attentional processing, but this conclusion remains uncertain because blocking and several related phenomena can be explained by models of conditioning that do not invoke attention.",
            "score": 78.80220913887024
        },
        {
            "docid": "128027_28",
            "document": "Operant conditioning . The first scientific studies identifying neurons that responded in ways that suggested they encode for conditioned stimuli came from work by Mahlon deLong and by R.T. Richardson. They showed that nucleus basalis neurons, which release acetylcholine broadly throughout the cerebral cortex, are activated shortly after a conditioned stimulus, or after a primary reward if no conditioned stimulus exists. These neurons are equally active for positive and negative reinforcers, and have been shown to be related to neuroplasticity in many cortical regions. Evidence also exists that dopamine is activated at similar times. There is considerable evidence that dopamine participates in both reinforcement and aversive learning. Dopamine pathways project much more densely onto frontal cortex regions. Cholinergic projections, in contrast, are dense even in the posterior cortical regions like the primary visual cortex. A study of patients with Parkinson's disease, a condition attributed to the insufficient action of dopamine, further illustrates the role of dopamine in positive reinforcement. It showed that while off their medication, patients learned more readily with aversive consequences than with positive reinforcement. Patients who were on their medication showed the opposite to be the case, positive reinforcement proving to be the more effective form of learning when dopamine activity is high.",
            "score": 74.97832787036896
        },
        {
            "docid": "540025_22",
            "document": "Bobo doll experiment . These experiments relate empirically to Bandura's social learning theory. This social science theory suggests that people learn through observing, imitating, and modeling; moreover, it specifically suggests that people learn not only by being rewarded or punished (as suggested by theories in behaviorism), but also by watching others being rewarded or punished (observational learning). The experiments are important because they sparked much further study related to observational learning. As well, the data offered further practical working hypotheses, e.g., regarding how children might be influenced from watching violent media.",
            "score": 63.237563371658325
        },
        {
            "docid": "14083964_37",
            "document": "Animal psychopathology . Using dogs, Martin Seligman and his colleagues pioneered the study of depression in the animal model of learned helplessness at the University of Pennsylvania. Dogs were separated into three groups, the control group, group A had control over when they were being shocked and group B had no control over when they were being shocked. After the shocking condition the dogs were tested in a shuttle box where they could escape shock by jumping over a partition. To eliminate an interference effect \u2013 that the dogs did not learn responses while being shocked that would interfere with their normal escape behavior \u2013 the dogs were immobilized using curare, a paralyzing drug while they were being shocked. Both the control group and group A tended to jump over the partition to escape shock while group B dogs did not jump and would passively take the shock. The dogs in group B perceived that the outcome was not related to their efforts. Consequently, a theory emerged that attributed the behavior of the animals to the effects of the shock as a stressor so extreme that it depleted a neurochemical needed by the animals for movement. After the dogs study the effects of helplessness have been tested in species from fish to cats. Most recently learned helplessness has been studied in rhesus macaques using inescapable shock, evoked through stress situations like forced swimming, behavioral despair tasks, tails suspension and pinch induced catalepsy; situations that render the monkey incapable of controlling the environment.",
            "score": 81.2610913515091
        },
        {
            "docid": "28649363_9",
            "document": "Cognitive Surplus . In the third chapter, Shirky explains that the means are platforms, tools, or systems we use that allow us to connect, learn, and share. The combination of time, place, and people which enable us to share and take action, is the opportunity. Shirky discusses the types of motivations that a person who shares would consider. Intrinsic motivations, which Shirky summarizes as a need for 1) increased competence, 2) autonomy over what we do, 3) membership of a group who share our values and beliefs, 4) the sharing of things with that group. Then, extrinsic motivations, like reward and recognition or punishment for certain behaviors. These motivations could also be classified into personal and social motivations. Social motivations include membership and sharing, while personal motivations include competence and autonomy. With the evidence from Benkler and Nissenbaum, it is concluded that social motivations reinforce personal ones. With the tools of today, we see many new groups; most of them large, public, and amateur groups. The goal for these groups is more about scope rather than size. The use of this public access media is to reach audiences that are \"like\" the group. Sharers have always had the same interests-or motivations- it is the opportunity that has changed them, and the ability to connect, share, and learn easily.",
            "score": 56.67881727218628
        },
        {
            "docid": "26685741_42",
            "document": "Sleep and memory . Previous research has shown REM sleep to reactivate cortical neural assemblies post-training on a serial reaction time task (SRT), in other words REM sleep replays the processing that occurred while one learnt an implicit task in the previous waking hours. However, control subjects did not complete a SRT task, thus researchers could not assume the reactivation of certain networks to be a result of the implicitly learned sequence/grammar as it could simply be due to elementary visuomotor processing which was obtained in both groups. To answer this question the experiment was redone and another group was added who also took part in the SRT task. They experienced no sequence to the SRT task (random group), whereas the experimental group did experience a sequence (probabilistic group), although without conscious awareness. Results of PET scans indicate that bilateral cuneus were significantly more activated during SRT practice as well as post-training REM sleep in the Probabilistic group than the Random group. In addition, this activation was significantly increased during REM sleep versus the SRT task. This suggests that specific brain regions are specifically engaged in the post-processing of sequential information. This is further supported by the fact that regional CBF (rCBF) during post-training REM sleep are modulated by the level of high-order, but not low-order learning obtained prior to sleep. Therefore, brain regions that take part in a learning process are modulated by both the sequential structure of the learned material (increased activation in cuneus), and the amount of high-order learning (rCBF).",
            "score": 74.86870789527893
        },
        {
            "docid": "1225841_25",
            "document": "Dog training . Non-associative learning is a change in a response to a stimulus that does not involve associating the presented stimulus with another stimulus or event such as reward or punishment. Habituation is non-associative learning. An example is where a dog that reacts excitedly to a door bell is subjected to repeated ringing without accompanying visitors, and stops reacting to the meaningless stimuli. It becomes habituated to the noise. On the other side of habituation is sensitization. Some dogs' reactions to the stimuli become stronger instead of them habituating to the repeated stimuli or event. Desensitization is the process of pairing positive experiences with an object, person, or situation that causes fear or anxiety. Consistent exposure to the feared object in conjunction with rewards allows the animal to become less stressed, thereby becoming desensitized in the process. This type of training can be effective for dogs who are fearful of fireworks.",
            "score": 87.25399494171143
        },
        {
            "docid": "52324876_8",
            "document": "Distress tolerance . There are several candidate biological neural network mechanisms for distress tolerance. These proposed brain areas are based on the conceptualization of distress tolerance as a function of reward learning. Within this framework, individuals learn to attune to and pursue reward; reduction of tension in escaping from a stressor is similarly framed as a reward and thus can be learned. Individuals differ in how quickly and for how long they display preferences for pursuing reward or in the case of distress tolerance, escaping from a distressful stimulus. Therefore, brain regions that are activated during reward processing and learning are hypothesized to also serve as neurobiological substrates for distress tolerance. For instance, activation intensity of dopamine neurons projecting to the nucleus accumbens, ventral striatum, and prefrontal cortex is associated with an individual's predicted value of an immediate reward during a learning task. As the firing rate for these neurons increases, individuals predict high values of an immediate reward. During instances in which the predicted value is correct, the basal rate of neuronal firing remains the same. When the predicted reward value is below the actual value, neuronal firing rates increase when the reward is received, resulting in a learned response. When the expected reward value is below the actual value, the firing rate of these neurons decreases below baseline levels, resulting in a learned shift that reduces expectancies about reward value. It is posited that these same dopaminergic firing rates are associated with distress tolerance, in that learning the value of escaping a distressing stimulus is analogous to an estimation of an immediate reward There are several potential clinical implications if these posited distress tolerance substrates are corroborated. It may suggest that distress tolerance is malleable among individuals; interventions that change neuronal firing rates may shift predicted values of behaviors intended to escape a distressor and provide relief, thereby increasing distress tolerance.",
            "score": 91.43354439735413
        },
        {
            "docid": "471571_3",
            "document": "Learned helplessness . American psychologist Martin Seligman initiated research on learned helplessness in 1967 at the University of Pennsylvania as an extension of his interest in depression. This research was later expanded through experiments by Seligman and others. One of the first was an experiment by Seligman & Maier: In Part 1 of this study, three groups of dogs were placed in harnesses. Group 1 dogs were simply put in a harnesses for a period of time and were later released. Groups 2 and 3 consisted of \"yoked pairs\". Dogs in Group 2 were given electric shocks at random times, which the dog could end by pressing a lever. Each dog in Group 3 was paired with a Group 2 dog; whenever a Group 2 dog got a shock, its paired dog in Group 3 got a shock of the same intensity and duration, but its lever did not stop the shock. To a dog in Group 3, it seemed that the shock ended at random, because it was his paired dog in Group 2 that was causing it to stop. Thus, for Group 3 dogs, the shock was \"inescapable\".",
            "score": 64.53806912899017
        },
        {
            "docid": "372045_3",
            "document": "Bee learning and communication . Honey bees are adept at associative learning, and many of the phenomena of operant and classical conditioning take the same form in honey bees as they do in the vertebrates. Efficient foraging requires such learning. For example, honey bees make few repeat visits to a plant if it provides little in the way of reward. A single forager will visit different flowers in the morning and, if there is sufficient reward in a particular kind of flower, she will make visits to that type of flower for most of the day, unless the plants stop producing nectar or weather conditions change.  A relatively recent experiment demonstrates several aspects of bee learning. Foragers were trained to enter a simple Y-shaped maze that had been marked at the entrance with a particular color. Inside the maze was a branching point where the bee was required to choose between two paths. One path, which led to the food reward, was marked with the same color that had been used at the entrance to the maze, while the other was marked with a different color. Foragers learned to choose the correct path, and continued to do so when a different kind of marker (black and white stripes oriented in various directions) was substituted for the colored markers. When the experimental conditions were reversed, rewarding bees for choosing the inner passage marked with a symbol that was different from the entrance symbol, the bees again learned to choose the correct path. Variations in the length of the tunnel between the stimulus markers showed that bees retain information in working memory for about 5 seconds, equivalent to the short-term memory of birds. Altogether, the experiments demonstrated that bees can to choose between alternatives, determine if a stimulus is the same or different than one seen earlier, remember the earlier one for a short period, and generalize this performance to new pairs of stimuli.",
            "score": 75.5061765909195
        },
        {
            "docid": "3766002_17",
            "document": "Orbitofrontal cortex . The human OFC is among the least-understood regions of the human brain; but it has been proposed that the OFC is involved in sensory integration, in representing the affective value of reinforcers, and in decision-making and expectation. In particular, the OFC seems to be important in signaling the expected rewards/punishments of an action given the particular details of a situation. In doing this, the brain is capable of comparing the expected reward/punishment with the actual delivery of reward/punishment, thus, making the OFC critical for adaptive learning. This is supported by research in humans, non-human primates, and rodents.",
            "score": 76.34758472442627
        },
        {
            "docid": "24245898_57",
            "document": "Pain in fish . Early experiments provided evidence that fish learn to respond to putatively noxious stimuli. For instance, toadfish (\"Batrachoididae\") grunt when they are electrically shocked, but after repeated shocks, they grunt simply at the sight of the electrode. More recent studies show that both goldfish and trout learn to avoid locations in which they receive electric shocks. Furthermore, this avoidance learning is flexible and is related to the intensity of the stimulus.",
            "score": 66.77884078025818
        },
        {
            "docid": "5608413_19",
            "document": "Sociology of terrorism . Social Learning Theory plays are part in the socialization of terroristic behaviors. Social Learning Theory states that a person becomes deviant because of an abundance of definitions that favor deviant behavior versus definitions that are unfavorable to such behaviors. This theory is broken down into four learning mechanisms: differential association, definitions, differential reinforcement, and imitation. The first learning mechanism is differential association, which refers to \"direct association and interaction with others who engage in certain kinds of behaviors or express norms, values, and attitudes supportive of such behavior, as well as indirect association and identification with more distant reference groups.\" The groups that an individual are differentially associated with provides the context in which the social learning is operated. The greater the priority, intensity, duration, and frequency of the differential association the greater the effect on behavior, so the theory in relation to terrorism is that the stronger someone's connection is towards a terrorist organization the better chance that person has of also exhibiting terroristic behaviors. The second learning mechanism is definitions. Definitions refer to an \"individual's own value and belief system about what is and is not acceptable behavior.\" These values are learned and reinforced through differential association. There are two types of definitions, general definition and specific definition. General definitions include broad beliefs about conformity that are influenced through conventional means and are often influenced by religious or moral values. Specific definitions are seen as those that align an individual with particular acts of crime. The greater the number of definitions the more likely a person will engage in criminal behavior. So the more definitions an individual has that favor terroristic behavior the greater chance that person has of committing a terroristic acts. The third learning mechanism is differential reinforcement. Differential reinforcement \"refers to the balance of anticipated or actual rewards and punishments that follow behavior.\" An individual refraining from committing a crime depends on a balance of past, present, and anticipated future rewards or punishments for their actions. In regards to terrorism the more direct or indirect social interaction a person has towards terrorism the more likely they are to commit a terroristic act. The fourth and final learning mechanism is imitation. \"Imitation is the notion that individuals engage in behaviors that they have previously witnessed others doing.\" The characters being observed, the behaviors that are being witnessed, and the consequences for those behaviors determine how much an individual imitates a behavior. All of these things need to fall into place in order for an individual to imitate a terrorist.",
            "score": 70.78832936286926
        },
        {
            "docid": "4185606_5",
            "document": "Avoidance response . Because the avoidance response is adaptive, humans have learned to use it in training animals such as dogs and horses. B.F. Skinner (1938) believed that animals learn primarily through rewards and punishments, the basis of operant conditioning. The avoidance response comes into play here when punishment is administered. An animal will presumably learn to avoid the behavior that preceded this punishment. A naturally occurring example for humans would be that after a child has been burned by a red stove, he or she learns not to touch the stove when it is red. The child avoids that behavior in the future. For a non-human animal, an example would be that of invisible fences which prompt a dog to learn not to cross a certain (invisible) boundary because its collar shocks it when it does.",
            "score": 92.14424324035645
        },
        {
            "docid": "8582684_19",
            "document": "Reward system . Rewarding stimuli can drive learning in both the form of classical conditioning (Pavlovian conditioning) and operant conditioning (instrumental conditioning). In classical conditioning, a reward can act as an unconditioned stimulus that, when associated with the conditioned stimulus, causes the conditioned stimulus to elicit both musculoskeletal (in the form of simple approach and avoidance behaviors) and vegetative responses. In operant conditioning, a reward may act as a reinforcing stimulus in that it increases or supports actions that lead to itself. Learned behaviors may or may not be sensitive to the value of the outcomes they lead to; behaviors that are sensitive to the contingency of an outcome on the performance of an action as well as the outcome value are goal-directed, while elicited actions that are insensitive to contingency or value are called habits. This distinction is thought to reflected two forms of learning, model free and model based. Model free learning involves the simple caching and updating of values. In contrast, model based learning involves the storage and construction of an internal model of events that allows inference and flexible prediction. Although pavlovian conditioning is generally assumed to be model free, the incentive salience assigned to a conditioned stimulus is flexible with regard to changes in internal motivational states.",
            "score": 75.09261107444763
        },
        {
            "docid": "42616278_10",
            "document": "Charles Perfetti . Charles Perfetti and colleagues conducted a study called \"High Proficiency in a second Language is characterized by Greater Involvement of the First Language Network: Evidence from Chinese Learners of English\" to examine the processes of learning a second language. The first thing he does is talk about the assimilation and accommodation hypothesis that involve the process of learning a second language. The assimilation hypothesis argues that second language is learned through the brains access of networks used to process the native language. Accommodation hypothesis argues that learning of a second language depends on brain structures not involve in process of the native language. Two test these hypothesis, Perfetti and colleagues examined a group of Chinese speakers who happened to be late learners with various levels of proficiency in English. The experiment was divided into 3 groups. The (ce group), (cc group) and (ee group) consisted of Chinese speaking participants who performed an English word rhyming judgment task while fMRI was performed. Assimilation was analyzed by comparing the cc group to the ce group while accommodation was analyzed by comparing the (ee group). The study involved participants deciding whether two symbol patterns presented in sequence match or mismatched. Rhyming was seen as the same rhyme for the second character of the word while orthography was defined as having the same phonetic radical for the second character of the word.",
            "score": 58.68941295146942
        },
        {
            "docid": "471571_4",
            "document": "Learned helplessness . In Part 2 of the experiment the same three groups of dogs were tested in a shuttle-box apparatus. All of the dogs could escape shocks on one side of the box by jumping over a low partition to the other side. The dogs in Groups 1 and 2 quickly learned this task and escaped the shock. Most of the Group 3 dogs \u2013 which had previously learned that nothing they did had any effect on shocks \u2013 simply lay down passively and whined when they were shocked.",
            "score": 76.51963448524475
        },
        {
            "docid": "9445847_19",
            "document": "Negativity bias . Learning and memory are direct consequences of attentional processing: the more attention is directed or devoted toward something, the more likely it is that it will be later learned and remembered. Research concerning the effects of punishment and reward on learning suggests that punishment for incorrect responses is more effective in enhancing learning than are rewards for correct responses\u2014learning occurs more quickly following bad events than good events.",
            "score": 37.102306842803955
        },
        {
            "docid": "48548_33",
            "document": "Dopamine . Within the brain, dopamine functions partly as a \"global reward signal\", where an initial phasic dopamine response to a rewarding stimulus encodes information about the salience, value, and context of a reward. In the context of reward-related learning, dopamine also functions as a \"reward prediction error\" signal, that is, the degree to which the value of a reward is unexpected. According to this hypothesis of Wolfram Schultz, rewards that are expected do not produce a second phasic dopamine response in certain dopaminergic cells, but rewards that are unexpected, or greater than expected, produce a short-lasting increase in synaptic dopamine, whereas the omission of an expected reward actually causes dopamine release to drop below its background level. The \"prediction error\" hypothesis has drawn particular interest from computational neuroscientists, because an influential computational-learning method known as temporal difference learning makes heavy use of a signal that encodes prediction error. This confluence of theory and data has led to a fertile interaction between neuroscientists and computer scientists interested in machine learning.",
            "score": 67.51537883281708
        },
        {
            "docid": "3766002_29",
            "document": "Orbitofrontal cortex . The visual discrimination test has two components. In the first component, \"reversal learning\", participants are presented with one of two pictures, A and B. They learn that they will be rewarded if they press a button when picture A is displayed, but punished if they press the button when picture B is displayed. Once this rule has been established, the rule swaps. In other words, now it is correct to press the button for picture B, not picture A. Most healthy participants pick up on this rule reversal almost immediately, but patients with OFC damage continue to respond to the original pattern of reinforcement, although they are now being punished for persevering with it. Rolls et al. noted that this pattern of behaviour is particularly unusual given that the patients reported that they understood the rule.",
            "score": 74.63924264907837
        },
        {
            "docid": "673057_3",
            "document": "Memory RNA . One experiment that was purported to show a chemical basis for memory involved training planaria (flatworms) to solve an extremely simple \"maze\", then grinding them up and feeding them to untrained planaria to see if they would be able to learn more quickly. The experiment seemed to show such an effect, but it was later suggested that only sensitization was transferred, or that no transfer occurred and the effect was due to stress hormones in the donor. Other experiments seem to support the original findings in that some memories may be stored outside the brain. Another experiment that had a purpose to show how memory can be transferred involved two groups of Alpysia Californica snails. One group of the snails was trained by shocks on their tails. The shocks were administered to the snails five times in one period of twenty-four hours. The shocks had twenty minute break periods inbetween. The training period took about two days to complete. Then the snails' reactions to a light touch on the shell was recorded. The trained snails held a defensive posture for about fifty seconds, the untrained snails held the posture for about one second. Then David Glanzman, a neurobiologist at the University of California, took the memory RNA from the trained snails and transferred it into the untrained snails. The untrained snails with the memory RNA held the defensive posture for about forty seconds. After this, the RNA from the trained snails was added to untrained snails' sensory neurons. The neurons showed increased excitability versus the untrained snails' sensory neurons without any added RNA.This experiment is evidence that memory is held within the neuron, challenging the original theory that memory is stored in the synapse.",
            "score": 69.24755871295929
        }
    ],
    "r": [
        {
            "docid": "4275189_3",
            "document": "Joseph E. LeDoux . As explained in his 1996 book, The Emotional Brain, LeDoux developed an interest in the topic of emotion through his doctoral work with Michael Gazzaniga on split-brain patients in the mid-1970s. Because techniques for studying the human brain were limited at the time, he turned to studies of rodents where the brain could be studied in detail. He chose to focus on a simple behavioral model, Pavlovian fear conditioning. This procedure allowed him to follow the flow of information about a stimulus through the brain as it comes to control behavioral responses by way of sensory pathways to the amygdala, and gave rise to the notion of two sensory roads to the amygdala, with the \u201clow road\u201d being a quick and dirty subcortical pathway for rapid activity behavioral responses to threats and the \u201chigh road\u201d providing slower but highly processed cortical information. His work has shed light on how the brain detects and responds to threats, and how memories about such experiences are formed and stored through cellular, synaptic and molecular changes in the amygdala. A long-standing collaboration with NYU colleague Elizabeth Phelps has shown the validity of the rodent work for understanding threat processing in the human brain. LeDoux\u2019s work on amygdala processing of threats has helped understand exaggerated responses to threats in anxiety disorders in humans. For example, studies with Maria Morgan in the 1990s implicated the medial prefrontal cortex in the extinction of responses to threats and paved the way for understanding how exposure therapy reduces threat reactions in people with anxiety by way of interactions between the medial prefrontal cortex and the amygdala. Work conducted with Karim Nader and Glenn Schafe triggered a wave of interest in the topic of memory reconsolidation, a process by which memories become labile and subject to change after being retrieved. This led to the idea that trauma-related cues might be weakened in humans by blocking reconsolidation. Studies with Marie Mofils, Daniela Schiller and Phelps showed that extinction conducted shortly after triggering reconsolidation is considerably more effective in reducing the threat value of stimuli than conventional extinction, a finding that has proven useful in reducing drug relapse in humans.",
            "score": 150.80447387695312
        },
        {
            "docid": "270792_5",
            "document": "Anhedonia . Studies in clinical populations, healthy populations, and animal models have implicated a number of neurobiological substrates in anhedonia. Regions implicated in anhedonia include the prefrontal cortex as a whole, particularly the orbitofrontal cortex (OFC), the striatum, amygdala, anterior cingulate cortex (ACC), hypothalamus, and ventral tegmental area (VTA). Neuroimaging studies in humans have reported that deficits in consummatory aspects of reward are associated with abnormalities in the ventral striatum and medial prefrontal cortex, while deficits in anticipatory aspects of reward are related to abnormalities in hippocampal, dorsal ACC and prefrontal regions. These abnormalities are generally consistent with animal models, except for inconsistent findings with regard to the OFC. This inconsistency may be related to the difficulty in imaging the OFC due to its anatomical location, or the small number of studies performed on anhedonia; a number of studies have reported reduced activity in the OFC in schizophrenia and major depression, as well as a direct relationship between reduced activity and anhedonia. Researchers theorize that anhedonia may result from the breakdown in the brain's reward system, involving the neurotransmitter dopamine. Anhedonia can be characterised as \"impaired ability to pursue, experience and/or learn about pleasure, which is often, but not always accessible to conscious awareness\".",
            "score": 142.9421844482422
        },
        {
            "docid": "23337_24",
            "document": "Phobia . The amygdala\u2019s role in learned fear includes interactions with other brain regions in the neural circuit of fear. While lesions in the amygdala can inhibit its ability to recognize fearful stimuli, other areas such as the ventromedial prefrontal cortex and the basolateral nuclei of the amygdala can affect the region's ability to not only become conditioned to fearful stimuli, but to eventually extinguish them. The basolateral nuclei, through receiving stimulus info, undergo synaptic changes that allow the amygdala to develop a conditioned response to fearful stimuli. Lesions in this area, therefore, have been shown to disrupt the acquisition of learned responses to fear. Likewise, lesions in the ventromedial prefrontal cortex (the area responsible for monitoring the amygdala) have been shown to not only slow down the speed of extinguishing a learned fear response, but also how effective or strong the extinction is. This suggests there is a pathway or circuit among the amygdala and nearby cortical areas that process emotional stimuli and influence emotional expression, all of which can be disrupted when an area becomes damaged.",
            "score": 133.01034545898438
        },
        {
            "docid": "10828_22",
            "document": "Fear . As with many functions of the brain, there are various regions of the brain involved in deciphering fear in humans and other nonhuman species. The amygdala communicates both directions between the prefrontal cortex, hypothalamus, the sensory cortex, the hippocampus, thalamus, septum, and the brainstem. The amygdala plays an important role in SSDR, such as the ventral amygdalofugal, which is essential for associative learning, and SSDRs are learned through interaction with the environment and others of the same species. An emotional response is created only after the signals have been relayed between the different regions of the brain, and activating the sympathetic nervous systems; which controls the flight, fight, freeze, fright, and faint response. Often a damaged amygdala can cause impairment in the recognition of fear (like the human case of patient S.M.). This impairment can cause different species to lack the sensation of fear, and often can become overly confident, confronting larger peers, or walking up to predatory creatures.",
            "score": 131.162353515625
        },
        {
            "docid": "250199_32",
            "document": "Flashbulb memory . Biological reasons for gender variances in flashbulb memory may be explained by amygdala asymmetry. The amygdala is a part of the limbic system, and is linked with memory and emotion. Memory is enhanced by emotion, and studies have shown that people are more likely to remember a negative event than a neutral or positive one. Investigations into the amygdala revealed \"people who showed strong amygdala activation in response to a set of positive or negative stimuli (relative to other study participants) also showed superior memory for those stimuli (relative to other study participants)\". This may explain why flashbulb memory typically involves traumatic events. When viewing emotional content, research has shown that men enhance their memory by activating their right amygdala while women activate the left side. The functional asymmetry of amygdala activation between genders is exemplified in experimentation with lesions and brain-damaged patients. One study found using a case-matched lesion approach that a \"man with right-sided amygdala damage developed major defects in social conduct, emotional processing and personality, and decision making, whereas the man with left-sided amygdala damage did not\". The reverse effect was found between two women. An experiment was conducted that had 12 men and 12 women view an assortment of images (emotional and nonemotional). Three weeks after the experiment a follow-up study was conducted testing the memory of those individuals, and it was \"revealed that highly emotional pictures were remembered best, and remembered better by women than by men\". One study performed an MRI scan on 40 patients after showing them aversive and non-aversive photographs proceeded by a warning stimulus. This experiment found that \"previously reported sex differences of memory associations with left amygdala for women and with right amygdala for men were confined to the ventral amygdala during picture viewing and delayed memory\". Although it is still unclear how lateralization affects memory, there may be a more effective relationship between activation of the left amygdala and memory than activation of right and memory. Generally speaking, studies testing differences between genders on episodic memory tasks revealed that \"women consistently outperform men on tasks that require remembering items that are verbal in nature or can be verbally labeled\" (Herlitz, 2008). In addition, it seems that \"women also excel on tasks requiring little or no verbal processing, such as recognition of unfamiliar odors or faces\" (Herlitz, 2008). Men only seem to excel in memory tasks that require visuospatial processing. Gender differences are also very apparent in literature pertaining to autobiographical memory research. \"Compared to men, women\u00b4s recall is more accurate and, when not specifically prompted, their narratives are longer than men\u00b4s\" (Aizpura, 2010). To sum up these gender differences, most literature on memory indicates that:",
            "score": 129.31756591796875
        },
        {
            "docid": "146000_18",
            "document": "Amygdala . The amygdalae are also involved in appetitive (positive) conditioning. It seems that distinct neurons respond to positive and negative stimuli, but there is no clustering of these distinct neurons into clear anatomical nuclei. However, lesions of the central nucleus in the amygdala have been shown to reduce appetitive learning in rats. Lesions of the basolateral regions do not exhibit the same effect. Research like this indicates that different nuclei within the amygdala have different functions in appetitive conditioning. Nevertheless, researchers found an example of appetitive emotional learning showing an important role for the basolateral amygdala: The na\u00efve female mice are innately attracted to non-volatile pheromones contained in male-soiled bedding, but not by the male-derived volatiles, become attractive if associated with non-volatile attractive pheromones, which act as unconditioned stimulus in a case of Pavlovian associative learning. In the vomeronasal, olfactory and emotional systems, Fos protein show that non-volatile pheromones stimulate the vomeronasal system, whereas air-borne volatiles activate only the olfactory system. Thus, the acquired preference for male-derived volatiles reveals an olfactory-vomeronasal associative learning. Moreover, the reward system is differentially activated by the primary pheromones and secondarily attractive odorants. Exploring the primary attractive pheromone activates the basolateral amygdala and the shell of nucleus accumbens but neither the ventral tegmental area nor the orbitofrontal cortex. In contrast, exploring the secondarily attractive male-derived odorants involves activation of a circuit that includes the basolateral amygdala, prefrontal cortex and ventral tegmental area. Therefore, the basolateral amygdala stands out as the key center for vomeronasal-olfactory associative learning.",
            "score": 126.47797393798828
        },
        {
            "docid": "7753430_46",
            "document": "Psychopathy . A 2008 review by Weber et al. suggested that psychopathy is sometimes associated with brain abnormalities in prefrontal-temporo-limbic regions that are involved in emotional and learning processes, among others. Neuroimaging studies have found structural and functional differences between those scoring high and low on the PCL-R in a 2011 review by Skeem et al. stating that they are \"most notably in the amygdala, hippocampus and parahippocampal gyri, anterior and posterior cingulate cortex, striatum, insula, and frontal and temporal cortex\". A 2010 meta-analysis found that antisocial, violent and psychopathic individuals had reduced structure function in the right orbitofrontal cortex, right anterior cingulate cortex and left dorsolateral prefrontal cortex.",
            "score": 123.88118743896484
        },
        {
            "docid": "25225295_12",
            "document": "Consumer neuroscience . Brand loyalty has been shown to be the result of changes in neural activity in the striatum, which is part of the human action reward system. In order to become brand loyal the brain must make a decision of brand A over brand B, a process which relies on the brain to make predictions based upon expected reward and then evaluate the results to learn loyalty. The brain is required to remember both positive and negative outcomes of previous brand choices in order to accurately be able to make predictions regarding the expected outcome of future brand decisions. For example, a helpful salesman or a discount in price may serve as a reward to encourage future customer loyalty. It is thought that the amygdala and striatum are the two most prominent structures for predicting the outcomes of decisions, and that the brain learns to better predict in part by establishing a larger neural network in these structures.",
            "score": 121.7334976196289
        },
        {
            "docid": "994097_21",
            "document": "Auditory cortex . Tonality is represented in more places than just the auditory cortex; one other specific area is the rostromedial prefrontal cortex (RMPFC). Janata et al., in their 2002 study, explored the areas of the brain which were active during tonality processing, by means of the fMRI technique. The results of this experiment showed preferential blood-oxygen-level dependent activation of specific voxels in RMPFC for specific tonal arrangements. Though these collections of voxels do not represent the same tonal arrangements between subjects or within subjects over multiple trials, it is interesting and informative that RMPFC, an area not usually associated with audition, seems to code for immediate tonal arrangements in this respect. RMPFC is a subsection of the medial prefrontal cortex, which projects to many diverse areas including the amygdala, and is thought to aid in the inhibition of negative emotion.",
            "score": 120.19790649414062
        },
        {
            "docid": "26685741_29",
            "document": "Sleep and memory . Cerebral activation during performance on three cognitive tasks (verbal learning, arithmetic, and divided attention) were compared after both normal sleep and 35 hours of total sleep deprivation (TSD) in a study by Drummond and Brown. Use of fMRI measured these differences in the brain. In the verbal learning task, fMRI indicated the regions involved in both verbal learning and memorization. The results found that both TSD and a normal night of sleep showed a significant response in the prefrontal cortex and following TSD displayed a response of additional areas which included other prefrontal areas, bilateral inferior parietal lobule and superior parietal lobes. Increases in sleepiness also correlated with activation of two ventral prefrontal regions and a correlation between a greater activation in bilateral parietal lobes (which include language areas) and lower levels of impairment on free recall were also found following TSD. In the arithmetic task normal sleep showed the expected activation in the bilateral prefrontal and parietal working memory regions but following TSD only showed activation in the left superior parietal lobe and the left premotor cortex in response, with no new areas to compensate (as was found in verbal learning). Increased sleepiness was also correlated with activation in a ventral prefrontal region, but only one region. The divided attention task combined both verbal learning and the arithmetic task. fMRI indicated that cerebral response after TSD is similar to that of the verbal learning task (specifically the right prefrontal cortex, bilateral parietal lobes, and cingulate gyrus showing the strongest response). The implication of this finding is that additional brain regions activated after both verbal learning and divided attention tasks following TSD represent a cerebral compensatory response to lacking sleep. For example, there is a decline in response of the left temporal lobes during both tasks which is involved in different learning tasks during a rested state but involvement of the left inferior parietal lobe in short-term verbal memory storage following TSD suggests that this region might compensate. No new areas for the arithmetic task may suggest that it relies heavily on working memory so compensation is not possible, in comparison to tasks such as verbal learning which rely less on working memory.",
            "score": 119.795654296875
        },
        {
            "docid": "12970_31",
            "document": "Gambler's fallacy . While the representativeness heuristic and other cognitive biases are the most commonly cited cause of the gambler's fallacy, research suggests that there may also be a neurological component. Functional magnetic resonance imaging has shown that after losing a bet or gamble, known as riskloss, the frontoparietal network of the brain is activated, resulting in more risk-taking behavior. In contrast, there is decreased activity in the amygdala, caudate, and ventral striatum after a riskloss. Activation in the amygdala is negatively correlated with gambler's fallacy, so that the more activity exhibited in the amygdala, the less likely an individual is to fall prey to the gambler's fallacy. These results suggest that gambler's fallacy relies more on the prefrontal cortex, which is responsible for executive, goal-directed processes, and less on the brain areas that control affective decision-making.",
            "score": 119.72198486328125
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 119.2657241821289
        },
        {
            "docid": "2640086_28",
            "document": "Affective neuroscience . Instead of investigating specific emotions, Kober, et al. 2008 reviewed 162 neuroimaging studies published between 1990-2005 to determine if groups of brain regions show consistent patterns of activation during emotional experience (that is, actively experiencing an emotion first-hand) and during emotion perception (that is, perceiving a given emotion as experienced by another). This meta-analysis used multilevel kernal density analysis (MKDA) to examine fMRI and PET studies, a technique that prevents single studies from dominating the results (particularly if they report multiple nearby peaks) and that enables studies with large sample sizes (those involving more participants) to exert more influence upon the results. MKDA was used to establish a neural reference space that includes the set of regions showing consistent increases across all studies (for further discussion of MDKA see Wager et al. 2007). Next, this neural reference space was partitioned into functional groups of brain regions showing similar activation patterns across studies by first using multivariate techniques to determine co-activation patterns and then using data-reduction techniques to define the functional groupings (resulting in six groups). Consistent with a psychological construction approach to emotion, the authors discuss each functional group in terms more basic psychological operations. The first \u201cCore Limbic\u201d group included the left amygdala, hypothalamus, periaqueductal gray/thalamus regions, and amygdala/ventral striatum/ventral globus pallidus/thalamus regions, which the authors discuss as an integrative emotional center that plays a general role in evaluating affective significance. The second \u201cLateral Paralimbic\u201d group included the ventral anterior insula/frontal operculum/right temporal pole/ posterior orbitofrontal cortex, the anterior insula/ posterior orbitofrontal cortex, the ventral anterior insula/ temporal cortex/ orbitofrontal cortex junction, the midinsula/ dorsal putamen, and the ventral striatum /mid insula/ left hippocampus, which the authors suggest plays a role in motivation, contributing to the general valuation of stimuli and particularly in reward. The third \u201cMedial Prefrontal Cortex\u201d group included the dorsal medial prefrontal cortex, pregenual anterior cingulate cortex, and rostral dorsal anterior cingulate cortex, which the authors discuss as playing a role in both the generation and regulation of emotion. The fourth \u201cCognitive/ Motor Network\u201d group included right frontal operculum, the right interior frontal gyrus, and the pre-supplementray motor area/ left interior frontal gyrus, regions that are not specific to emotion, but instead appear to play a more general role in information processing and cognitive control. The fifth \u201cOccipital/ Visual Association\u201d group included areas V8 and V4 of the primary visual cortex, the medial temporal lobe, and the lateral occipital cortex, and the sixth \u201cMedial Posterior\u201d group included posterior cingulate cortex and area V1 of the primary visual cortex. The authors suggest that these regions play a joint role in visual processing and attention to emotional stimuli.",
            "score": 118.7873764038086
        },
        {
            "docid": "302319_64",
            "document": "Empathy . Work conducted by Professor Jean Decety with large samples of incarcerated psychopaths offers additional insights. In one study, psychopaths were scanned while viewing video clips depicting people being intentionally hurt. They were also tested on their responses to seeing short videos of facial expressions of pain. The participants in the high-psychopathy group exhibited significantly less activation in the ventromedial prefrontal cortex, amygdala and periaqueductal gray parts of the brain, but more activity in the striatum and the insula when compared to control participants. In a second study, individuals with psychopathy exhibited a strong response in pain-affective brain regions when taking an imagine-self perspective, but failed to recruit the neural circuits that were activated in controls during an imagine-other perspective\u2014in particular the ventromedial prefrontal cortex and amygdala\u2014which may contribute to their lack of empathic concern.",
            "score": 118.48517608642578
        },
        {
            "docid": "7753430_32",
            "document": "Psychopathy . Dysfunctions in the prefrontal cortex and amygdala regions of the brain have been associated with specific learning impairments in psychopathy. Since the 1980s, scientists have linked traumatic brain injury, including damage to these regions, with violent and psychopathic behavior. Patients with damage in such areas resembled \"psychopathic individuals\" whose brains were incapable of acquiring social and moral knowledge; those who acquired damage as children may have trouble conceptualizing social or moral reasoning, while those with adult-acquired damage may be aware of proper social and moral conduct but be unable to behave appropriately. Dysfunctions in the amygdala and ventromedial prefrontal cortex may also impair stimulus-reinforced learning in psychopaths, whether punishment-based or reward-based. People scoring 25 or higher in the PCL-R, with an associated history of violent behavior, appear to have significantly reduced mean microstructural integrity in their uncinate fasciculus\u2014white matter connecting the amygdala and orbitofrontal cortex. There is evidence from DT-MRI, of breakdowns in the white matter connections between these two important areas.",
            "score": 118.3260726928711
        },
        {
            "docid": "35075711_45",
            "document": "Spontaneous recovery . For the learning and recall associated with spontaneous recovery to happen, there are specific gyri and neurotransmitters that play a role. Firstly, the cerebellum is needed to acquire certain motor skills and develop an automatic state with the movement patterns that are learned. Both the dorsal and ventral prefrontal cortex has been shown to play a big role in the development of memory consolidation and motor control. Reciprocal loops are formed through neural circuits between the basal ganglia and prefrontal cortex which consolidate the memory. To elicit a stronger consolidation, rewards can be involved; the case for Pavlovian conditioning. The reward-related learning causes dopamine to release from the synapses of the basal ganglia and creates a stronger bond between the stimulus and response. Furthermore, if there is a traumatic incident that is associated to a memory, and that becomes suppressed, the amygdala is responsible for this fear conditioning. The amygdala leads to the caudate nucleus in the neocortex of the basal ganglia, so the fear response can also be triggered via spontaneous recovery. Basically, the stronger the emotional arousal after a learning event, positive or negative, can greatly enhance the memory's recall in the future.",
            "score": 117.23906707763672
        },
        {
            "docid": "41420328_13",
            "document": "Interactions between the emotional and executive brain systems . The ventral stream primarily involves the vlPFC and mPFC. Signals of expected outcomes trigger the mPFC to update stimulus associations through exchanges with the amygdala and the nucleus accumbens. When a response change is needed, the mPFC interacts with the vlPFC. Then, the vlPFC modulates the emotional response to stimuli through interactions with the dorsal striatum. Preliminary findings indicate that the vlPFC may also modulate activity in the nucleus accumbens, temporal cortex, anterior insula and amygdala.",
            "score": 116.02085876464844
        },
        {
            "docid": "26685741_28",
            "document": "Sleep and memory . A blood-oxygen-level dependent (BOLD) fMRI was used in a study by Drummond et al. to measure the brain's response to verbal learning following sleep deprivation. An fMRI recorded brain activity during a verbal learning task of participants either having a normal night of sleep or those deprived of 34.7 (\u00b1 1.2) hours of sleep. The task alternated between a baseline condition of determining whether nouns were upper or lower case and an experimental condition of memorizing a list of nouns. The results of the study indicate that performance is significantly worse on free recall of the list of nouns when sleep deprived (an average of 2.8 \u00b1 2 words) compared to having a normal night of sleep (4.7 \u00b1 4 words). In terms of brain regions activated, the left prefrontal cortex, premotor cortex, and temporal lobes were found to be activated during the task in the rested state and discrete regions of the prefrontal cortex were even more activated during the task in the sleep deprived state. As well, the bilateral parietal lobe, left middle frontal gyrus, and right interior frontal gyrus were found to be activated for those sleep deprived. The implication of these findings are that the brain can initially compensate for the effects of sleep deprivation while maintaining partially intact performance, which declines with an increasing time-on-task. This initial compensation may be found in the bilateral regions of both frontal and parietal lobes and the activation of the prefrontal cortex is significantly correlated with sleepiness.",
            "score": 115.23209381103516
        },
        {
            "docid": "1165522_61",
            "document": "Mindfulness . Grey matter concentrations in brain regions that regulate emotion, self-referential processing, learning and memory processes have shown changes in density following MBSR. Additionally, MBSR practice has been associated with improvement of the immune system which could explain the correlation between stress reduction and increased quality of life. Part of these changes are a result of the thickening of the prefrontal cortex (executive functioning) and hippocampus (learning and memorisation ability), the shrinking of the amygdala (emotion and stress response) and the strengthening of the connections between brain cells. Long-term meditators have larger amounts of gyrification (\u201cfolding\u201d of the cortex, which may allow the brain to process information faster) than people who do not meditate. Further, a direct correlation was found between the amount of gyrification and the number of meditation years, possibly providing further proof of the brain\u2019s neuroplasticity, or ability to adapt to environmental changes.",
            "score": 114.09307098388672
        },
        {
            "docid": "37691351_10",
            "document": "Neuroscience and race . The amygdala, which is the most researched brain region in racism studies, shows much greater activation while viewing other-race faces than same-race faces. This region of the brain is associated with fear conditioning, and has many connections with the cortex to control the body\u2019s emotional response. Often, there is variation in amygdala activation due to motivation and goals. The amygdala\u2019s activation can be changed through not focusing on race or focusing on removing the racial bias. Scientists believe that amygdala activation differences arise due to social/cultural perceptions and individual experiences. However, it is important to note that patients with a damaged amygdala still show a racial bias, meaning that the amygdala isn\u2019t the only region involved in activating a racial bias. The link between the amygdala and racial prejudice has been comprehensively reviewed. The anterior cingulate cortex (ACC) is associated with detecting conflict and determining how to resolve that conflict. It is believed to play a part in the controversy in one\u2019s mind over personal racial biases and cultural equality norms. ACC activation increases when a person has an automatic negative response to an out-group member, as shown in amygdala activation. The ACC is used to recognize the conflict between cultural expectations and the automatic negative response, and is the first step in expressing racial attitudes.",
            "score": 113.27119445800781
        },
        {
            "docid": "547827_31",
            "document": "Loss aversion . Brain activity in a right ventral striatum cluster increases particularly when anticipating gains. This involves the ventral caudate nucleus, pallidum, putamen, bilateral orbitofrontal cortex, superior frontal and middle gyri, posterior cingulate cortex, dorsal anterior cingulate cortex, and parts of the dorsomedial thalamus connecting to temporal and prefrontal cortex. There is a significant correlation between degree of loss aversion and strength of activity in both the frontomedial cortex and the ventral striatum. This is shown by the slope of brain activity deactivation for increasing losses being significantly greater than the slope of activation for increasing gains in the appetitive system involving the ventral striatum in the network of reward-based behavioural learning. On the other hand, when anticipating loss, the central and basal nuclei of amygdala, right posterior insula extending into the supramarginal gyrus mediate the output to other structures involved in the expression of fear and anxiety, such as the right parietal operculum and supramarginal gyrus. Consistent with gain anticipation, the slope of the activation for increasing losses was significantly greater than the slope of the deactivation for increasing gains.",
            "score": 111.9217300415039
        },
        {
            "docid": "806023_22",
            "document": "Sympathy . Social and emotional stimuli, particularly those related to the well-being of another person, are being more directly studied with advent of technology that can track brain activity (such as Electroencephalograms and functional Magnetic Resonance Imaging). Amygdala and insula activation occur when a person experiences emotions, such as fear and disgust respectively. Primary motor regions are also activated during sympathy. This could be caused by humans' reaction to emotional faces, reflecting the expressions on their own faces, which seems to help people better understand the other person's emotion. In addition, researchers have also suggested that the neural mechanisms that are activated when personally experiencing emotions are also activated when viewing another person experiencing the same emotions (mirror neurons). Pain seems to specifically activate a region known as the cingulate cortex, in addition to activation that is mentioned earlier. The temporal parietal junction, orbitofrontal cortex, and ventral striatum are also thought to play a role in the production of emotion.",
            "score": 111.8558349609375
        },
        {
            "docid": "20419_26",
            "document": "Mania . Meta analysis of neuroimaging studies demonstrate increased thalamic activity, and bilaterally reduced inferior frontal gyrus activation. Activity in the amygdala and other subcortical structures such as the ventral striatum tend to be increased, although results are inconsistent and likely dependent upon task characteristics such as valence. Reduced functional connectivity between the ventral prefrontal cortex and amygdala along with variable findings supports a hypothesis of general dysregulation of subcortical structures by the prefrontal cortex. A bias towards positively valanced stimuli, and increased responsiveness in reward circuitry may predispose towards mania. Mania tends to be associated with right hemisphere lesions, while depression tends to be associated with left hemisphere lesions.",
            "score": 111.53239440917969
        },
        {
            "docid": "9916386_15",
            "document": "Synaptic gating . In studies with rodents, the prefrontal cortex, specifically the medial prefrontal cortex (mPFC) has been implicated in the processing of information lasting from milliseconds to several seconds, while the hippocampus has been implicated in the processing of information for longer time scales \u2013 such as minutes to hours. Damage to both these areas in people with ADHD seems to illustrate why they exhibit inattentiveness and impulsiveness. Nucleus accumbens neurons are bistable and thus can be selectively gated to either an \"up\" \u2013 depolarized state or a \"down\" \u2013 hyperpolarized state. Nucleus accumbens neurons are gated by hippocampal and amygdala input and this creates a depolarized accumbens neuron that is more receptive to innervation from input from the prefrontal cortex. Thus, in patients with ADHD not only is the input from the prefrontal cortex to the nucleus accumbens reduced but in addition the gating input from the hippocampus to the nucleus accumbens is also reduced leading to a reduction in activation of the nucleus accumbens neurons. Individuals that take medication such as methylphenidate (Ritalin) will increase their dopamine (DA) output along many of these synapses helping to compensate in the loss of synaptic activity generated from the pathophysiology of ADHD. Taking methylphenidate can increase DA projections to the nucleus accumbens, which can not only act to increase synaptic activity between the prefrontal cortex and hippocampus (improving memory) but also act as a reward system as the nucleus accumbens is part of the mesolimbic pathway. Moreover, it is possibly why individuals on Ritalin have a \u201cneed\u201d and \u201cdesire\u201d to learn as it acts as a positive reinforcer in the brain. In addition, this reward circuitry activation is most likely a reason why methylphenidate is highly addictive and carries great dependence. In conclusion, synaptic gating illustrates a plausible mechanism by which ADHD medication like Ritalin modulates synaptic activity and memory.",
            "score": 109.7375259399414
        },
        {
            "docid": "3619450_4",
            "document": "Sensory gating . Information from sensory receptors make their way to the brain through neurons and synapse at the thalamus. The pulvinar nuclei in the thalamus function as the gatekeeper, deciding which information should be inhibited, and which should be sent to further cortical areas. Sensory gating is mediated by a network in the brain which involves the auditory cortex (AC), prefrontal cortex and hippocampus. Other areas of the brain associated with sensory gating include the amygdala, striatum, medial prefrontal cortex, and midbrain dopamine cell region (GABAergic neurons only). Research of sensory gating primarily occurs in cortical areas where the stimulus is consciously identified because it is a less invasive means of studying sensory gating. Studies on rats show the brain stem, thalamus, and primary auditory cortex play a role in sensory gating for auditory stimuli.",
            "score": 109.04662322998047
        },
        {
            "docid": "2640086_31",
            "document": "Affective neuroscience . The results indicated that many brain regions demonstrated consistent and selective activations in the experience or perception of an emotion category (versus all the other emotion categories). Consistent with constructionist models, however, no region demonstrated functional specificity for the emotions of fear, disgust, happiness, sadness or anger. Based on the existing scientific literature, the authors proposed different roles for the brain regions that have traditionally been associated with only one emotion category. The authors propose that the amygdala, anterior insula, orbitofrontal cortex each contribute to \u201ccore affect,\u201d which are basic feelings that are pleasant or unpleasant with some level of arousal. The amygdala, for example, appears to play a more general role in indicating if external sensory information is motivationally salient, and is particularly active when a stimulus is novel or evokes uncertainty. The anterior insula may represent core affective feelings in awareness across a number of emotion categories, driven largely by sensations originating in the body. The orbitofrontal cortex appears to function as a site for integrating sensory information from the body and sensory information from the world to guide behavior. Closely related to core affect, the authors propose that anterior cingulate and dorsolateral prefrontal cortex play vital roles in attention, with anterior cingulate supporting the use of sensory information for directing attention and motor responses during response selection and with dorsolateral prefrontal cortex supporting executive attention. In many psychological construction approaches, emotions also involve the act of interpreting one\u2019s situation in the world relative to the internal state of the body, or what is referred to as \u201cconceptualization.\u201d In support of this idea, the dorsomedial prefrontal cortex and hippocampus were consistently active in this meta-analysis, regions that appear to play an important role conceptualizing during emotion, which are also involved in simulating previous experience (e.g. knowledge, memory). Language is also central to conceptualizing, and regions that support language, including ventrolateral prefrontal cortex, were also consistently active across studies of emotion experience and perception.",
            "score": 108.74668884277344
        },
        {
            "docid": "17893852_4",
            "document": "Humor research . Cognitive neuroscience has provided insight into how humor is neurologically realized. Brain imaging techniques such as fMRI and PET scans have been implemented in this subfield of humor research.  There are a few main regions of the human brain associated with humor and laughter. The production of laughter involves two primary brain pathways, one for both involuntary and voluntary laughter (cf. Duchenne and non-Duchenne). Involuntary laughter is usually emotionally driven, and includes key emotional brain areas such as the amygdala, thalamic areas, and the brainstem. Voluntary laughter instead begins in the premotor opercular area (in the temporal lobe) and moves to the motor cortex and pyramidal tract before moving to the brainstem. Wild et al. (2003) propose that the generation of laughter is mostly influenced by neural pathways that go from the premotor and motor cortex to the ventral side of the brainstem, through the cerebral peduncles. It is also suggested that real laughter is not produced from the motor cortex, but that the normal inhibition of cortical frontal areas stops during laughter. When the electrical activity of the brain is measured during and after hearing a joke, a prominent response can be seen approximately 300ms after the punchline, followed by a depolarization about 100ms later. The fact that humor response occurs in two separate waves of activity supports the idea that humor processing occurs in two stages. Functional MRI and PET studies further illuminate which parts of the brain are participating in the experience of humor. A study by Ozawa, et al., (2000) found that hearing sentences which participants rated as humorous resulted in activation in Broca's area and the middle frontal gyrus, in addition to Wernicke's area and the transverse temporal gyri, which were activated in control (non-humorous) conditions as well.",
            "score": 108.45883178710938
        },
        {
            "docid": "37689507_19",
            "document": "Neuroimaging intelligence testing . A 2012 study from Washington University, St. Louis described the global connectivity of the prefrontal cortex. Global connectivity is the mechanism by which components of the frontoparietal brain network might coordinate control of other tasks. Cole et al. wrote that: \"A lateral prefrontal cortex (LPFC) region's activity was found to predict performance in a high control demand working memory task and also to exhibit high global connectivity. Critically, global connectivity in this LPFC region, involving connections both within and outside the frontoparietal network, showed a highly selective relationship with individual differences in fluid intelligence.\" The lateral prefrontal cortex is a region of interest because those who have injuries to that part of the brain often have issues with common, every day tasks such as planning their day. The LPFC is thought to be important for \"cognitive control capacity,\" which can be used to predict future outcomes such as success in school and the workplace. It was found by van den Heuvel et al. that higher intelligence individuals employ more efficient whole-brain network organization. This had led to the thought that cognitive control capacity may be supported by these whole-brain network properties. The 2012 study used a theoretic approach to neuroimage data known as global brain connectivity (GBC) or weighted degree centrality. GBC let the researches look closely at specific regions and their range of connectivity. It was then possible to examine each region's role in human cognitive control and intelligence. The study used fMRI to acquire data and examine each region's connectivity.",
            "score": 107.32869720458984
        },
        {
            "docid": "31539062_13",
            "document": "Frustration\u2013aggression hypothesis . Some studies have shown that frustrating and equally threatening events may generate feelings of aggression. This is based on the account that one of our neural systems is responsible for executing the basic responses to threat. It so happens that one of these basic responses from this system is that of aggression. The system is made up of and follows from the amygdala to the hypothalamus and finally to the periaqueductal gray matter (PAG) In greater detail, research suggests that when one is threatened or frustrated by some stimuli, parts of our frontal cortex, that is our orbital, medial and ventrolateral frontal cortex, is activated which works in tandem with our threat response system, the amygdala-hypothalamus-PAG. More simply put, threatening events generate more action potentials in the frontal cortex regions which then relay onto the amygdala-hypothalamus-PAG. It is in this basic threat response system where the decision on which response should take hold based on the information received from the frontal cortex regions. As mentioned, there are varying degrees and responses that could take hold within an animal in the presence of a frustrating event. This has not shown to interfere with the basic circuitry at the neuronal level and simply implies that certain stimuli generate more action potentials than others, and thus stronger responses than others respectively. In the face of this, animals portray a response hierarchy at the onset of a frustrating event. For example, when low levels of danger are perceived, the threat response system induces freezing in the animal; closer subjects of threat generate the act of fleeing from their surroundings and finally, where the source of the threat is so close that escape is no longer an option, the threat circuitry system will induce reactive aggression in the animal. What this means is that the closer a frustrating stimulus is presented to us, the greater the chances our basic response systems will be activated and thus will give rise to certain behaviors accordingly. Furthermore, some research has shown that \"individuals with elevated susceptibility for frustration [showed] greater activity within these regions [amygdala-hypothalarmus-PAG] in response to frustrating events relative to those with less susceptibility\". What this research suggests is that people who get frustrated more easily than others show greater activity in the frontal cortex in connection with the amygdala-hypothalamus-PAG, the system that makes us act, given a strong enough stimulus, aggressively with reference to the studies at hand.",
            "score": 107.26470184326172
        },
        {
            "docid": "35822485_19",
            "document": "Epigenetics of cocaine addiction . Contrary to most studies focusing on the nucleus accumbens, Febo et al. suggested that the reward brain circuitry is not the only system involved in addictive behaviors. Previous knowledge has suggested that stimulants induce changes in gene expression in the main parts of mesolimbic circuitry (including the ventral tegmental area, ventral striatum/nucleus accumbens, and prefrontal cortex) and play a big role in development and maintenance of addicted state and chromatin remodeling. They applied this knowledge to investigate whether these gene expression changes are involved in cocaine related behavioral and molecular adaptations. They found unexpected patterns of brain activation in awake rats that were exposed to sodium butyrate, an HDAC inhibitor (or HDACi). An acute dose resulted in widespread BOLD (blood-oxygen-level dependent) activation in the forebrain and midbrain, but cocaine-induced activation was significantly attenuated after repeat exposure. Sodium butyrate co-treatment with cocaine restored pronounced BOLD activation after successive cocaine treatments. These suggest that the brain\u2019s initial response to repeat cocaine exposure triggers a desensitization mechanism which can be overturned by pretreatment with sodium butyrate. The neural circuitry for the epigenetic modifications contributing to cocaine sensitivity was not the limited to the mesocorticolimbic dopamine system (\u201creward system\u201d) as they expected. Instead, they saw corticolimbic circuitry (implicated in emotion and memory) had a bigger role in HDACi related alterations of reward behaviors. Evidence that HDACi-mediated enhancement of a stimulant\u2019s sensitizing effects is context specific, and involves associative learning.",
            "score": 106.47980499267578
        },
        {
            "docid": "52805859_3",
            "document": "Neuroscience of aging . Neurogenesis occurs very little in adults, only occurring in the hypothalamus and striatum to a small extent in a process called adult neurogenesis. The volume of the brain actually decrease roughly 5% per decade after forty. It is currently unclear why brain volume decreases with age, however, a few causes may include: cell death, decreased cell volume, and changes in synaptic structure. The changes in brain volume is heterogenous across regions with prefrontal cortex receiving the most significant reduction in volume followed in order by the striatum, the temporal lobe, cerebellar vermis, cerebellar hemispheres, and the hippocampus. However, one review found that the amygdala and ventromedial prefrontal cortex remained relatively free of atrophy, which is consistent with the finding of emotional stability occurring with non-pathological aging. Enlargement of the ventricles, sulci and fissures are also common in non-pathological aging.",
            "score": 106.36426544189453
        },
        {
            "docid": "1095131_20",
            "document": "Kinesthetic learning . The cerebral cortex is the brain tissue covering the top and sides of the brain in most vertebrates. It is involved in storing and processing of sensory inputs and motor outputs. In the human brain, the cerebral cortex is actually a sheet of neural tissue about 1/8th inch thick. The sheet is folded so that it can fit inside the skull. The neural circuits in this area of the brain expand with practice of an activity, just like the synaptic plasticity grows with practice. Clarification of some of the mechanisms of learning by neuro science has been advanced, in part, by the advent of non-invasive imaging technologies, such as positron emission tomography (PET) and functional magnetic resonance imaging (FMRI). These technologies have allowed researchers to observe human learning processes directly. Through these types of technologies, we are now able to see and study what happens in the process of learning. In different tests performed the brain being imaged showed a greater blood flow and activation to that area of the brain being stimulated through different activities such as finger tapping in a specific sequence. It has been revealed that the process at the beginning of learning a new skill happens quickly, and later on slows down to almost a plateau. This process can also be referred to as The Law of Learning. The slower learning showed in the FMRI that in the cerebral cortex this was when the long term learning was occurring, suggesting that the structural changes in the cortex reflect the enhancement of skill memories during later stages of training. When a person studies a skill for a longer duration of time, but in a shorter amount of time they will learn quickly, but also only retain the information into their short-term memory. Just like studying for an exam; if a student tries to learn everything the night before, it will not stick in the long run. If a person studies a skill for a shorter duration of time, but more frequently and long-term, their brain will retain this information much longer as it is stored in the long-term memory. Functional and structural studies of the brain have revealed a vast interconnectivity between diverse regions of the cerebral cortex. For example, large numbers of axons interconnect the posterior sensory areas serving vision, audition, and touch with anterior motor regions. Constant communication between sensation and movement makes sense, because to execute smooth movement through the environment, movement must be continuously integrated with knowledge about one's surroundings obtained via sensory perception. The cerebral cortex plays a role in allowing humans to do this.",
            "score": 106.33656311035156
        }
    ]
}