{
    "q": [
        {
            "docid": "3883287_8",
            "document": "Tranquillity . Within tranquillity studies, much of the emphasis has been placed on understanding the role of vision in the perception of natural environments, which is probably not surprising, considering that upon first viewing a scene its configurational coherence can be established with incredible speed. Indeed, scene information can be captured in a single glance and the gist of a scene determined in as little as 100ms. The speed of processing of complex natural images was tested by Thorpe \"et al.\" using colour photographs of a wide range of animals (mammals, birds, reptiles and fish), in their natural environments, mixed with distracters that included pictures of forests, mountains, lakes, buildings and fruit. During this experiment, subjects were shown an image for 20ms and asked to determine whether it contained an animal or not. The electrophysiological brain responses obtained in this study showed that a decision could be made within 150ms of the image being seen, indicating the speed at which cognitive visual processing occurs. However, audition, and in particular the individual components that collectively comprise the soundscape, a term coined by Schafer to describe the ever-present array of sounds that constitute the sonic environment, also significantly inform the various schemata used to characterise differing landscape types. This interpretation is supported by the auditory reaction times, which are 50 to 60ms faster than that of the visual modality. It is also known that sound can alter visual perception and that under certain conditions areas of the brain involved in processing auditory information can be activated in response to visual stimuli.  Research conducted by Pheasant \"et al.\" has shown that when individuals make tranquillity assessments based on a uni-modal auditory or visual sensory input, they characterise the environment by drawing upon a number of key landscape and soundscape characteristics. For example, when making assessments in response to visual-only stimuli the percentage of water, flora and geological features present within a scene, positively influence how tranquil a location is perceived to be. Likewise when responding to uni-modal auditory stimuli, the perceived loudness of biological sounds positively influences the perception of tranquillity, whilst the perceived loudness of mechanical sounds have a negative effect. However, when presented with bi-modal auditory-visual stimuli the individual soundscape and landscape components alone no longer influenced the perception of tranquillity. Rather configurational coherence was provided by the percentage of natural and contextual features present within the scene and the equivalent continuous sound pressure level (LAeq).",
            "score": 104.23760330677032
        },
        {
            "docid": "2999259_3",
            "document": "Choice-supportive bias . What is remembered about a decision can be as important as the decision itself, especially in determining how much regret or satisfaction one experiences. Research indicates that the process of making and remembering choices yields memories that tend to be distorted in predictable ways. In cognitive science, one predictable way that memories of choice options are distorted is that positive aspects tend to be remembered as part of the chosen option, whether or not they originally were part of that option, and negative aspects tend to be remembered as part of rejected options. Once an action has been taken, the ways in which we evaluate the effectiveness of what we did may be biased. It is believed this may influence our future decision-making. These biases may be stored as memories, which are attributions that we make about our mental experiences based on their subjective qualities, our prior knowledge and beliefs, our motives and goals, and the social context. True and false memories arise by the same mechanism because when the brain processes and stores information, it cannot tell the difference from where they came from.",
            "score": 161.4180155992508
        },
        {
            "docid": "804702_23",
            "document": "Status quo bias . Research by University College London scientists that examines the neural pathways involved in 'status quo bias' in the human brain and found that the more difficult the decision we face, the more likely we are not to act. The study, published in \"Proceedings of the National Academy of Sciences\" (PNAS), looked at the decision-making of participants taking part in a tennis 'line judgement' game while their brains were scanned using functional MRI (fMRI). The 16 study participants were asked to look at a cross between two tramlines on a screen while holding down a 'default' key. They then saw a ball land in the court and had to make a decision as to whether it was in or out. On each trial, the computer signalled which was the current default option \u2013 'in' or 'out'. The participants continued to hold down the key to accept the default and had to release it and change to another key to reject the default. The results showed a consistent bias towards the default, which led to errors. As the task became more difficult, the bias became even more pronounced. The fMRI scans showed that a region of the brain known as the sub-thalamic nucleus (STN) was more active in the cases when the default was rejected. Also, greater flow of information was seen from a separate region sensitive to difficulty (the prefrontal cortex) to the STN. This indicates that the STN plays a key role in overcoming status quo bias when the decision is difficult.",
            "score": 136.83097290992737
        },
        {
            "docid": "30525054_7",
            "document": "Anders Dale . In a 2003 interview, Dale explained that he had \u201calways been interested in using quantitative modeling methods and simulations to answer biological questions,\u201d and that as a Harvard student he had been \u201cinterested in approaching connectionist neural networks from a more biological angle.\u201d When he went to UCSD to continue his graduate work his interest \u201cshifted to learning how to test models of how the brain works. Ideally you'd like to test your models not in anesthetized animals and brain slices, but by measuring brain activity in humans non-invasively. I wanted to study normal people doing normal tasks. That was what brought me to imaging. My goal was to see what kind of things we can measure non-invasively that can be quantitatively related to the models we want to build...I wanted to know what exactly we are measuring, how can you model it, and how can you relate the signal to what is going on in the brain physiologically...at a level that say you could measure invasively and that you could relate to parameters of quantitative models.\u201d His thesis work at UCSD, he said, \u201cwas on the EEG and MEG forward and inverse problems, and how to use anatomical information to constrain the solutions. It is clear that if you only use EEG or MEG measures, the spatial precision is not good enough to make inferences at a scale that's most useful to neuroscience. That led us into trying to use information with higher spatial resolution to constrain or bias our estimations of the signal sources in the brain.\u201d",
            "score": 115.30996632575989
        },
        {
            "docid": "1903855_7",
            "document": "Sensory substitution . In a regular visual system, the data collected by the retina is converted into an electrical stimulus in the optic nerve and relayed to the brain, which re-creates the image and perceives it. Because it is the brain that is responsible for the final perception, sensory substitution is possible. During sensory substitution an intact sensory modality relays information to the visual perception areas of the brain so that the person can perceive to see. With sensory substitution, information gained from one sensory modality can reach brain structures physiologically related to other sensory modalities. Touch-to-visual sensory substitution transfers information from touch receptors to the visual cortex for interpretation and perception. For example, through fMRI, we can determine which parts of the brain are activated during sensory perception. In blind persons, we can see that while they are only receiving tactile information, their visual cortex is also activated as they perceive to \"see\" objects. We can also have touch to touch sensory substitution where information from touch receptors of one region can be used to perceive touch in another region. For example, in one experiment by Bach-y-Rita, he was able to restore the touch perception in a patient who lost peripheral sensation from leprosy.",
            "score": 65.19772183895111
        },
        {
            "docid": "26565579_50",
            "document": "Neuroscience of free will . Multivariate pattern analysis using EEG has suggested that an evidence based perceptual decision model may be applicable to free will decisions. It was found that decisions could be predicted by neural activity immediately after stimulus perception. Furthermore, when the participant was unable to determine the nature of the stimulus the recent decision history predicted the neural activity (decision). The starting point of evidence accumulation was in effect shifted towards a previous choice (suggesting a priming bias). Another study has found that subliminally priming a participant for a particular decision outcome (showing a cue for 13ms) could be used to influence free decision outcomes. Likewise, it has been found that decision history alone can be used to predict future decisions. The prediction capacities of the Soon et al. (2008) experiment were successfully replicated using a linear SVM model based on participant decision history alone (without any brain activity data). Despite this, a recent study has sought to confirm the applicability of a perceptual decision model to free will decisions. When shown a masked and therefore invisible stimulus, participants were asked to either guess between a category or make a free decision for a particular category. Multivariate pattern analysis using fMRI could be trained on \"free decision\" data to successfully predict \"guess decisions\", and trained on \"guess data\" in order to predict \"free decisions\" (in the precuneus and cuneus region).",
            "score": 156.93926811218262
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 103.62892138957977
        },
        {
            "docid": "6733469_3",
            "document": "Max Planck Institute for Biological Cybernetics . The institute is studying signal and information processing in the brain. We know that our brain is constantly processing a vast amount of sensory and intrinsic information by which our behavior is coordinated accordingly. How the brain actually achieves these tasks is less well understood, for example, how it perceives, recognizes, and learns new objects. The scientists at the Max Planck Institute for Biological Cybernetics aim to determine which signals and processes are responsible for creating a coherent percept of our environment and for eliciting the appropriate behavior. Scientists of three departments and seven research groups are working towards answering fundamental questions about processing in the brain, using different approaches and methods.",
            "score": 86.74181270599365
        },
        {
            "docid": "1156527_8",
            "document": "Detection theory . Signal detection theory (SDT) is used when psychologists want to measure the way we make decisions under conditions of uncertainty, such as how we would perceive distances in foggy conditions. SDT assumes that the decision maker is not a passive receiver of information, but an active decision-maker who makes difficult perceptual judgments under conditions of uncertainty. In foggy circumstances, we are forced to decide how far away from us an object is, based solely upon visual stimulus which is impaired by the fog. Since the brightness of the object, such as a traffic light, is used by the brain to discriminate the distance of an object, and the fog reduces the brightness of objects, we perceive the object to be much farther away than it actually is (see also decision theory).",
            "score": 110.29017531871796
        },
        {
            "docid": "5212945_3",
            "document": "Visual neuroscience . A recent study using Event-Related Potentials (ERPs) linked an increased neural activity in the occipito-temporal region of the brain to the visual categorization of facial expressions. Results focus on a negative peak in the ERP that occurs 170 milliseconds after the stimulus onset. This action potential, called the N170, was measured using electrodes in the occipito-temporal region, an area already known to be changed by face stimuli. Studying by using the EEG, and ERP methods allow for an extremely high temporal resolution of 4 milliseconds, which makes these kinds of experiments extremely well suited for accurately estimating and comparing the time it takes the brain to perform a certain function. Scientists used classification image techniques, to determine what parts of complex visual stimuli (such as a face) will be relied on when patients are asked to assign them to a category, or emotion. They computed the important features when the stimulus face exhibited one of five different emotions. Stimulus faces exhibiting fear had the distinguishing feature of widening eyes, and stimuli exhibiting happiness exhibited a change in the mouth to make a smile. Regardless of the expression of the stimuli's face, the region near the eyes affected the EEG before the regions near the mouth. This revealed a sequential, and predetermined order to the perception and processing of faces, with the eye being the first, and the mouth, and nose being processed after. This process of downward integration only occurred when the inferior facial features were crucial to the categorization of the stimuli. This is best explained by comparing what happens when participants were shown a face exhibiting fear, versus happiness. The N170 peaked slightly earlier for the fear stimuli at about 175 milliseconds, meaning that it took a participants less time to recognize the facial expression. This is expected because only the eyes need to be processed to recognize the emotion. However, when processing a happy expression, where the mouth is crucial to categorization, downward integration must take place, and thus the N170 peak occurred later at around 185 milliseconds. Eventually visual neuroscience aims to completely explain how the visual system processes all changes in faces as well as objects. This will give a complete view to how the world is constantly visually perceived, and may provide insight into a link between perception and consciousness.",
            "score": 93.99842548370361
        },
        {
            "docid": "1095131_20",
            "document": "Kinesthetic learning . The cerebral cortex is the brain tissue covering the top and sides of the brain in most vertebrates. It is involved in storing and processing of sensory inputs and motor outputs. In the human brain, the cerebral cortex is actually a sheet of neural tissue about 1/8th inch thick. The sheet is folded so that it can fit inside the skull. The neural circuits in this area of the brain expand with practice of an activity, just like the synaptic plasticity grows with practice. Clarification of some of the mechanisms of learning by neuro science has been advanced, in part, by the advent of non-invasive imaging technologies, such as positron emission tomography (PET) and functional magnetic resonance imaging (FMRI). These technologies have allowed researchers to observe human learning processes directly. Through these types of technologies, we are now able to see and study what happens in the process of learning. In different tests performed the brain being imaged showed a greater blood flow and activation to that area of the brain being stimulated through different activities such as finger tapping in a specific sequence. It has been revealed that the process at the beginning of learning a new skill happens quickly, and later on slows down to almost a plateau. This process can also be referred to as The Law of Learning. The slower learning showed in the FMRI that in the cerebral cortex this was when the long term learning was occurring, suggesting that the structural changes in the cortex reflect the enhancement of skill memories during later stages of training. When a person studies a skill for a longer duration of time, but in a shorter amount of time they will learn quickly, but also only retain the information into their short-term memory. Just like studying for an exam; if a student tries to learn everything the night before, it will not stick in the long run. If a person studies a skill for a shorter duration of time, but more frequently and long-term, their brain will retain this information much longer as it is stored in the long-term memory. Functional and structural studies of the brain have revealed a vast interconnectivity between diverse regions of the cerebral cortex. For example, large numbers of axons interconnect the posterior sensory areas serving vision, audition, and touch with anterior motor regions. Constant communication between sensation and movement makes sense, because to execute smooth movement through the environment, movement must be continuously integrated with knowledge about one's surroundings obtained via sensory perception. The cerebral cortex plays a role in allowing humans to do this.",
            "score": 83.30026733875275
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 103.95388543605804
        },
        {
            "docid": "2534964_17",
            "document": "Sensory processing . In the future, research on sensory integration will be used to better understand how different sensory modalities are incorporated within the brain to help us perform even the simplest of tasks. For example, we do not currently have the understanding needed to comprehend how neural circuits transform sensory cues into changes in motor activities. More research done on the sensorimotor system can help understand how these movements are controlled. This understanding can potentially be used to learn more about how to make better prosthetics, and eventually help patients who have lost the use of a limb. Also, by learning more about how different sensory inputs can combine can have profound effects on new engineering approaches using robotics. The robot's sensory devices may take in inputs of different modalities, but if we understand multisensory integration better, we might be able to program these robots to convey these data into a useful output to better serve our purposes.",
            "score": 112.91319954395294
        },
        {
            "docid": "2534964_14",
            "document": "Sensory processing . Perhaps one of the most studied sensory integrations is the relationship between vision and audition. These two senses perceive the same objects in the world in different ways, and by combining the two, they help us understand this information better. Vision dominates our perception of the world around us. This is because visual spatial information is one of the most reliable sensory modalities. Visual stimuli are recorded directly onto the retina, and there are few, if any, external distortions that provide incorrect information to the brain about the true location of an object. Other spatial information is not as reliable as visual spatial information. For example, consider auditory spatial input. The location of an object can sometimes be determined solely on its sound, but the sensory input can easily be modified or altered, thus giving a less reliable spatial representation of the object. Auditory information therefore is not spatially represented unlike visual stimuli. But once one has the spatial mapping from the visual information, multisensory integration helps bring the information from both the visual and auditory stimuli together to make a more robust mapping.",
            "score": 68.19395756721497
        },
        {
            "docid": "3044780_3",
            "document": "Affect heuristic . The theory of affect heuristic is that a human being's affect can influence how he or she makes decisions. Research has shown that risk and benefits are negatively correlated in people\u2019s minds. This was found after researchers found that the inverse relationship between perceived risk and perceived benefit of an activity was linked to the strength of positive or negative affect associated with the activity as measured by rating the activity on bipolar scales (e.g. good/bad). This implies that people base their judgements of an activity or a technology not only on what they think about it, but also on how they feel about it. The affect heuristic gained early attention in 1980 when Robert B. Zajonc argued that affective reactions to stimuli are often the first reaction which occur automatically and subsequently influencing the way in which we process and judge information. The affect heuristic received more recent attention when it was used to explain the unexpected negative correlation between benefit and risk perception. Finucane, Alhakami, Slovic and Johnson theorized in 2000 that a good feeling towards a situation (i.e., positive affect) would lead to a lower risk perception and a higher benefit perception, even when this is logically not warranted for that situation. This implies that a strong emotional response to a word or other stimulus might alter a person's judgment. He or she might make different decisions based on the same set of facts and might thus make an illogical decision. Overall, the affect heuristic is of influence in nearly every decision-making arena.",
            "score": 122.54958987236023
        },
        {
            "docid": "26317569_8",
            "document": "Maturity (psychological) . The pre-frontal cortex, which is responsible for higher cognitive functions such as planning, decision-making, judgment and reasoning, develops and matures most rapidly during early adolescence and into the early 20s. Accompanying the growth of the pre-frontal cortex is continued synaptic pruning (the trimming of rarely used synapses) as well as increased myelination of nerve fibers in the brain, which serves to insulate and speed up signal transmission between neurons. The incomplete development of this process contributes to the finding that adolescents use their brain less broadly than do adults when asked to inhibit a response and show less cross-talk (communication across diverse regions of the brain). The brain's \"cross-talk\" may be related to decision-making concerning risk-taking, with one study of American adolescents finding delayed reaction time and decreased spread across brain regions in a task asking them to determine whether a dangerous action is a good idea or not. Steinberg observes that there is close overlap in the activated brain regions for socioemotional and reward information, which may pose a challenge when making decisions in the most high-risk peer contexts. One study found that preference for small immediate rewards over larger long-term rewards was associated with increased activation with regions primarily responsible for socioemotional decision-making.",
            "score": 99.42511928081512
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 142.3838472366333
        },
        {
            "docid": "3975854_2",
            "document": "Sensory neuroscience . Sensory neuroscience is a subfield of neuroscience which explores the anatomy and physiology of neurons that are part of sensory systems such as vision, hearing, and olfaction. Neurons in sensory regions of the brain respond to stimuli by firing one or more nerve impulses (action potentials) following stimulus presentation. How is information about the outside world encoded by the rate, timing, and pattern of action potentials? This so-called neural code is currently poorly understood and sensory neuroscience plays an important role in the attempt to decipher it. Looking at early sensory processing is advantageous since brain regions that are \"higher up\" (e.g. those involved in memory or emotion) contain neurons which encode more abstract representations. However, the hope is that there are unifying principles which govern how the brain encodes and processes information. Studying sensory systems is an important stepping stone in our understanding of brain function in general.",
            "score": 61.35723876953125
        },
        {
            "docid": "5664_64",
            "document": "Consciousness . In neuroscience, a great deal of effort has gone into investigating how the perceived world of conscious awareness is constructed inside the brain. The process is generally thought to involve two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals arising from sensory organs are transmitted to the brain and then processed in a series of stages, which extract multiple types of information from the raw input. In the visual system, for example, sensory signals from the eyes are transmitted to the thalamus and then to the primary visual cortex; inside the cerebral cortex they are sent to areas that extract features such as three-dimensional structure, shape, color, and motion. Memory comes into play in at least two ways. First, it allows sensory information to be evaluated in the context of previous experience. Second, and even more importantly, working memory allows information to be integrated over time so that it can generate a stable representation of the world\u2014Gerald Edelman expressed this point vividly by titling one of his books about consciousness \"The Remembered Present\". In computational neuroscience, Bayesian approaches to brain function have been used to understand both the evaluation of sensory information in light of previous experience, and the integration of information over time. Bayesian models of the brain are probabilistic inference models, in which the brain takes advantage of prior knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian models have successfully predicted many perceptual phenomena in vision and the nonvisual senses.",
            "score": 66.91201984882355
        },
        {
            "docid": "4275189_3",
            "document": "Joseph E. LeDoux . As explained in his 1996 book, The Emotional Brain, LeDoux developed an interest in the topic of emotion through his doctoral work with Michael Gazzaniga on split-brain patients in the mid-1970s. Because techniques for studying the human brain were limited at the time, he turned to studies of rodents where the brain could be studied in detail. He chose to focus on a simple behavioral model, Pavlovian fear conditioning. This procedure allowed him to follow the flow of information about a stimulus through the brain as it comes to control behavioral responses by way of sensory pathways to the amygdala, and gave rise to the notion of two sensory roads to the amygdala, with the \u201clow road\u201d being a quick and dirty subcortical pathway for rapid activity behavioral responses to threats and the \u201chigh road\u201d providing slower but highly processed cortical information. His work has shed light on how the brain detects and responds to threats, and how memories about such experiences are formed and stored through cellular, synaptic and molecular changes in the amygdala. A long-standing collaboration with NYU colleague Elizabeth Phelps has shown the validity of the rodent work for understanding threat processing in the human brain. LeDoux\u2019s work on amygdala processing of threats has helped understand exaggerated responses to threats in anxiety disorders in humans. For example, studies with Maria Morgan in the 1990s implicated the medial prefrontal cortex in the extinction of responses to threats and paved the way for understanding how exposure therapy reduces threat reactions in people with anxiety by way of interactions between the medial prefrontal cortex and the amygdala. Work conducted with Karim Nader and Glenn Schafe triggered a wave of interest in the topic of memory reconsolidation, a process by which memories become labile and subject to change after being retrieved. This led to the idea that trauma-related cues might be weakened in humans by blocking reconsolidation. Studies with Marie Mofils, Daniela Schiller and Phelps showed that extinction conducted shortly after triggering reconsolidation is considerably more effective in reducing the threat value of stimuli than conventional extinction, a finding that has proven useful in reducing drug relapse in humans.",
            "score": 87.21467018127441
        },
        {
            "docid": "3704475_50",
            "document": "Executive functions . Despite the growing currency of the 'biasing' model of executive functions, direct evidence for functional connectivity between the PFC and sensory regions when executive functions are used, is to date rather sparse. Indeed, the only direct evidence comes from studies in which a portion of frontal cortex is damaged, and a corresponding effect is observed far from the lesion site, in the responses of sensory neurons. However, few studies have explored whether this effect is specific to situations where executive functions are required. Other methods for measuring connectivity between distant brain regions, such as correlation in the fMRI response, have yielded indirect evidence that the frontal cortex and sensory regions communicate during a variety of processes thought to engage executive functions, such as working memory, but more research is required to establish how information flows between the PFC and the rest of the brain when executive functions are used. As an early step in this direction, an fMRI study on the flow of information processing during visuospatial reasoning has provided evidence for causal associations (inferred from the temporal order of activity) between sensory-related activity in occipital and parietal cortices and activity in posterior and anterior PFC. Such approaches can further elucidate the distribution of processing between executive functions in PFC and the rest of the brain.",
            "score": 107.60142064094543
        },
        {
            "docid": "33937822_4",
            "document": "Information processing technology and aging . Cognitive capabilities refer our mental abilities by which we pay attention to the world, interpret the information around us, learn and remember, solve problems and make decisions. Age-related differences in cognitive functioning have been known to stem from the reduction of cognitive resources available, thus impairing older adults\u2019 ability to carry out cognitively demanding tasks. Cognitive aging causes a change in mechanism related to information processing and working memory function. According to Craik, these mechanisms are responsible for age-related speed of decline in performance for mental processing along with a reduction of online cognitive resources available at any given time to process, store, retrieve, and transform information (working memory), focusing on a target, paying attention, and sensory processing of information. This is important since the inherent relationship between cognitive abilities and technology adoption points to the importance of ensuring that system interfaces are well designed and easy to use. The use of information processing theory in cognition looks at the role of the three stages of memory related to retrieving information, transferring and recalling. Cognitive information processing focuses on different aspects of instruction and how those aspects can either facilitate or hinder learning and memory. It emphasizes using strategies that focus the learner's attention, promotes encoding and retrieval, and provide for meaningful, effective practice across learning environments and curriculum.",
            "score": 97.26323628425598
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 121.35247659683228
        },
        {
            "docid": "5119916_49",
            "document": "Character education . Other neurological research is documenting how much the unconscious mind is involved in decision making. According to cognitive neuroscientists, we are conscious of only about 5 percent of our cognitive activity, so most of our decisions, actions, emotions, and behavior depends on the 95 percent of brain activity that goes beyond our conscious awareness. These studies show that actions come from preconscious brain activity patterns and not from people consciously thinking about what they are going to do.\u0094",
            "score": 83.99538373947144
        },
        {
            "docid": "7214278_2",
            "document": "Decision field theory . Decision field theory (DFT) is a dynamic-cognitive approach to human decision making. It is a cognitive model that describes how people actually make decisions rather than a rational or normative theory that prescribes what people should or ought to do. It is also a dynamic model of decision making rather than a static model, because it describes how a person's preferences evolve across time until a decision is reached rather than assuming a fixed state of preference. The preference evolution process is mathematically represented as a stochastic process called a diffusion process. It is used to predict how humans make decisions under uncertainty, how decisions change under time pressure, and how choice context changes preferences. This model can be used to predict not only the choices that are made but also decision or response times.",
            "score": 96.76199269294739
        },
        {
            "docid": "38575751_24",
            "document": "Sniffing (behavior) . Sniffing, as an active sampling behavior, is often grouped along with other behaviors utilized to acquire sensory stimuli. For instance, sniffing has been compared to rapid eye movements, or saccades, in the ability for both methods to provide rapid \"snapshots\" of information to the brain. This analogy, though, may be imprecise since small animals (e.g., mice) make odor-based decisions (through sniffing) while also making visual decisions, yet do not saccade. Sniffing is also fundamentally similar to active touch, including swiping ones finger along a surface to scan texture.",
            "score": 49.15822672843933
        },
        {
            "docid": "2872287_26",
            "document": "Neural binding . Cognitive binding is associated with the different states of human consciousness. Two of the most studied states of consciousness are the wakefulness and REM sleep. There have been multiple studies showing, electrophysiologically, that these two states are quite similar in nature. This has led some neural binding theorists to study the modes of cognitive awareness in each state. Certain observations have even led these scientists to hypothesize that since there is little cognition going on during REM sleep, the increased thalamocortical responses show the action of processing in the waking preconscious. The thalamus and cortex are important anatomical features in cognitive and sensory awareness. The understanding of how these neurons fire and relate to one other in each of these states (REM and Waking) is paramount to understanding awareness and its relation to neural binding. In the waking state, neuronal activity in animals is subject to changes based on the current environment. Changes in environment act as a form of stress on the brain so that when sensory neurons are then fired synchronously, they acclimate to the new state. This new state can then be moved to the hippocampus where it can be stored for later use. In the words of James Newman and Anthony A. Grace in their article, \"Binding Across Time\" this idea is put forth: \"The hippocampus is the primary recipient of inferotemporal outputs and is known to be the substrate for the consolidation of working memories to long term, episodic memories.\" The logging of \"episodes\" is then used for \"streaming\", which can mediate by the selective gating of certain information reentering sensory awareness. Streaming and building of episodic memories would not be possible if neural binding did not unconsciously connect the two synchronous oscillations. The pairing of these oscillations can then help input the correct sensory material. If these paired oscillations are not new, then cognitively these firings will be easily understood. If there are new firings, the brain will have to acclimate to the new understanding. In REM sleep, the only extreme difference from the waking state is that the brain does not have the actual waking amount of sensory firings, so cognitively, there is not as much awareness here, although the activity of the \"brain\u2019s eye\" is still quite significant and very similar to the waking state. Studies have shown that during sleep there are still 40\u00a0Hz Oscillation firings. These firings are due to the perceived stimuli happening in dreams. \"",
            "score": 87.4755232334137
        },
        {
            "docid": "739262_10",
            "document": "Neural correlate . Neurophysiological studies in animals provided some insights on the neural correlates of conscious behavior. Vernon Mountcastle, in the early 1960s, set up to study this set of problems, which he termed \"the Mind/Brain problem\", by studying the neural basis of perception in the somatic sensory system. His labs at Johns Hopkins were among the first, along with Edward V.Evarts at NIH, to record neural activity from behaving monkeys. Struck with the elegance of SS Stevens approach of magnitude estimation, Mountcastle's group discovered three different modalities of somatic sensation shared one cognitive attribute: in all cases the firing rate of peripheral neurons was linearly related to the strength of the percept elicited. More recently, Ken H. Britten, William T. Newsome, and C. Daniel Salzman have shown that in area MT of monkeys, neurons respond with variability that suggests they are the basis of decision making about direction of motion. They first showed that neuronal rates are predictive of decisions using signal detection theory, and then that stimulation of these neurons could predictably bias the decision. Such studies were followed by Ranulfo Romo in the somatic sensory system, to confirm, using a different percept and brain area, that a small number of neurons in one brain area underlie perceptual decisions.",
            "score": 88.99270987510681
        },
        {
            "docid": "7175817_10",
            "document": "Emotional bias . Brain damage can cause changes in normal decision-making processes. The amygdala is an area in the brain involved in emotion. Studies have found that patients with bilateral amygdala damage, which is damage in both hemispheres of the amygdala region in the brain, are deficient in decision-making. When an initial choice is made in decision-making, the result of this choice has an emotional response, which is controlled by the amygdala.",
            "score": 98.41521549224854
        },
        {
            "docid": "5128182_13",
            "document": "Encoding (memory) . Encoding is achieved using a combination of chemicals and electricity. Neurotransmitters are released when an electrical pulse crosses the synapse which serves as a connection from nerve cells to other cells. The dendrites receive these impulses with their feathery extensions. A phenomenon called long-term potentiation allows a synapse to increase strength with increasing numbers of transmitted signals between the two neurons. For that to happen, NMDA receptor, which influences the flow of information between neurons by controlling the initiation of long-term potentiation in most hippocampal pathways, need to come to the play. For these NMDA receptors to be activated, there must be two conditions. Firstly, glutamate has to be released and bound to the NMDA receptor site on postsynaptic neurons. Secondly, excitation has to take place in postsynaptic neurons. These cells also organise themselves into groups specializing in different kinds of information processing. Thus, with new experiences the brain creates more connections and may 'rewire'. The brain organizes and reorganizes itself in response to one's experiences, creating new memories prompted by experience, education, or training. Therefore, the use of a brain reflects how it is organised. This ability to re-organize is especially important if ever a part of the brain becomes damaged. Scientists are unsure of whether the stimuli of what we do not recall are filtered out at the sensory phase or if they are filtered out after the brain examines their significance.",
            "score": 90.1449887752533
        },
        {
            "docid": "2882373_2",
            "document": "Adaptive unconscious . The adaptive unconscious, first coined by Daniel Wagner in 2002, is described as a series of mental processes that is able to affect judgement and decision making, but is out of reach of the conscious mind. Architecturally, the adaptive unconscious is said to be unreachable because it is buried in an unknown part of the brain. This type of thinking evolved earlier than the conscious mind, enabling the mind to transform information and think in ways that enhance an organism's survival. It can be described as a quick sizing up of the world which interprets information and decides how to act very quickly and outside the conscious view. The adaptive unconscious is active in everyday activities such as learning new material, detecting patterns, and filtering information. It is also characterized by being unconscious, unintentional, uncontrollable, and efficient without requiring cognitive tools. Lacking the need for cognitive tools does not make the adaptive unconscious any less useful than the conscious mind as the adaptive unconscious allows for processes like memory formation, physical balancing, language, learning, and some emotional and personalities processes that includes judgement, decision making, impression formation, evaluations, and goal pursuing. Despite being useful, the series of processes of the adaptive unconscious will not always result in accurate or correct decisions by the organism. The adaptive unconscious is affected by things like emotional reaction, estimations, and experience and is thus inclined to stereotyping and schema which can lead to inaccuracy in decision making. The adaptive conscious does however help decision making to eliminate cognitive biases such as prejudice because of its lack of cognitive tools.",
            "score": 90.26009488105774
        },
        {
            "docid": "34112061_19",
            "document": "Bioecological model . According to technology writer Nicholas Carr, technology has always determined the development of the brain and the way we think throughout History. As he illustrates with examples of reading and the rise in the use of internet. He observes that development of reading habits motivated our brains to be concentrate on the text and imagine, whereas the over exposure of internet reinforce our capability to scan and filter information productively and easily. (Taylor, 2012, #14) Attention is the key requisite which paves the way to all aspects of learning viz. perception, memory, language, creativity, reasoning, problem solving and decision making. Attention has been considered to be a highly malleable quality which can be influenced by the environment. Research shows that the invention of digital entertainment changed the attention span by presenting children with visual stimuli and very little need of imagination. In such an environment distraction becomes the norm and memory, focusing gets affected. This is in sharp contradiction to the children of the past who spent a great amount of their time reading, which requires deep and consistent attention, imagination, memory and which gave way to minimal distractions. (Taylor, 2012, #14)",
            "score": 62.25057280063629
        }
    ],
    "r": [
        {
            "docid": "21312310_11",
            "document": "Remember versus know judgements . The original high-threshold model held that recognition is a probabilistic process. It is assumed that there is some probability that previously studied items will exceed a memory threshold. If an item exceeds the threshold then it is in a discrete memory state. If an item does not exceed the threshold then it is not remembered, but it may still be endorsed as old on the basis of a random guess. According to this model, a test item is either recognized (i.e., it falls above a threshold) or it is not (i.e., it falls below a threshold), with no degrees of recognition occurring between these extremes. Only target items can generate an above-threshold recognition response because only they appeared on the list. The lures, along with any targets that are forgotten, fall below threshold, which means that they generate no memory signal whatsoever. For these items, the participant has the option of declaring them to be new (as a conservative participant might do) or guessing that some of them are old (as a more liberal participant might do). False alarms in this model reflect memory-free guesses that are made to some of the lures.  This simple and intuitively appealing model yields the once widely used correction for guessing formula, and it predicts a linear receiver operating characteristic (ROC). An ROC is simply a plot of the hit rate versus the false alarm rate for different levels of bias. A typical ROC is obtained by asking participants to supply confidence ratings for their recognition memory decisions. Several pairs of hit and false alarm rates can then be computed by accumulating ratings from different points on the confidence scale (beginning with the most confident responses). The high-threshold model of recognition memory predicts that a plot of the hit rate versus the false alarm rate (i.e., the ROC) will be linear it also predicts that the z-ROC will be curvilinear.",
            "score": 179.56234741210938
        },
        {
            "docid": "2999259_3",
            "document": "Choice-supportive bias . What is remembered about a decision can be as important as the decision itself, especially in determining how much regret or satisfaction one experiences. Research indicates that the process of making and remembering choices yields memories that tend to be distorted in predictable ways. In cognitive science, one predictable way that memories of choice options are distorted is that positive aspects tend to be remembered as part of the chosen option, whether or not they originally were part of that option, and negative aspects tend to be remembered as part of rejected options. Once an action has been taken, the ways in which we evaluate the effectiveness of what we did may be biased. It is believed this may influence our future decision-making. These biases may be stored as memories, which are attributions that we make about our mental experiences based on their subjective qualities, our prior knowledge and beliefs, our motives and goals, and the social context. True and false memories arise by the same mechanism because when the brain processes and stores information, it cannot tell the difference from where they came from.",
            "score": 161.4180145263672
        },
        {
            "docid": "37940820_23",
            "document": "Emotion perception . Researchers employ several methods designed to examine biases toward emotional stimuli to determine the salience of particular emotional stimuli, population differences in emotion perception, and also attentional biases toward or away from emotional stimuli. Tasks commonly utilized include the modified Stroop task, the dot probe task, visual search tasks, and spatial cuing tasks.  The Stroop task, or modified Stroop task, displays different types of words (e.g., threatening and neutral) in varying colors. The participant is then asked to identify the color of the word while ignoring the actual semantic content. Increased response time to indicate the color of threat words relative to neutral words suggests an attentional bias toward such threat. The Stroop task, however, has some interpretational difficulties in addition to the lack of allowance for the measurement of spatial attention allocation. To address some of the limitations of the Stroop task, the dot probe task displays two words or pictures on a computer screen (either one at the top or left and the other on the bottom or right, respectively) and after a brief stimuli presentation, often less than 1000ms, a probe appears in the location of one of the two stimuli and participants are asked to press a button indicating the location of the probe. Different response times between target (e.g., threat) and neutral stimuli infer attentional biases to the target information with shorter response times for when the probe is in the place of the target stimuli indicating an attention bias for that type of information. In another task that examines spatial attentional allocation, the visual search task asks participants to detect a target stimulus embedded in a matrix of distractors (e.g., an angry face among several neutral or other emotional faces or vice versa). Faster detection times to find emotional stimuli among neutral stimuli or slower detection times to find neutral stimuli among emotional distractors infer an attentional bias for such stimuli. The spatial cuing task asks participants to focus on a point located between two rectangles at which point a cue is presented, either in the form of one of the rectangles lighting up or some emotional stimuli appearing within one of the rectangles and this cue either directs attention toward or away from the actual location of the target stimuli. Participants then press a button indicating the location of the target stimuli with faster response times indicating an attention bias toward such stimuli.",
            "score": 160.38783264160156
        },
        {
            "docid": "17258308_14",
            "document": "Two-alternative forced choice . In the race model, evidence for each alternative is accumulated separately, and a decision made either when one of the accumulators reaches a predetermined threshold, or when a decision is forced and then the decision associated with the accumulator with the highest evidence is chosen. This can be represented formally by:",
            "score": 157.98971557617188
        },
        {
            "docid": "26565579_50",
            "document": "Neuroscience of free will . Multivariate pattern analysis using EEG has suggested that an evidence based perceptual decision model may be applicable to free will decisions. It was found that decisions could be predicted by neural activity immediately after stimulus perception. Furthermore, when the participant was unable to determine the nature of the stimulus the recent decision history predicted the neural activity (decision). The starting point of evidence accumulation was in effect shifted towards a previous choice (suggesting a priming bias). Another study has found that subliminally priming a participant for a particular decision outcome (showing a cue for 13ms) could be used to influence free decision outcomes. Likewise, it has been found that decision history alone can be used to predict future decisions. The prediction capacities of the Soon et al. (2008) experiment were successfully replicated using a linear SVM model based on participant decision history alone (without any brain activity data). Despite this, a recent study has sought to confirm the applicability of a perceptual decision model to free will decisions. When shown a masked and therefore invisible stimulus, participants were asked to either guess between a category or make a free decision for a particular category. Multivariate pattern analysis using fMRI could be trained on \"free decision\" data to successfully predict \"guess decisions\", and trained on \"guess data\" in order to predict \"free decisions\" (in the precuneus and cuneus region).",
            "score": 156.93927001953125
        },
        {
            "docid": "18956166_48",
            "document": "Stereotype . Empirical evidence suggests that stereotype activation can automatically influence social behavior. For example, Bargh, Chen, and Burrows (1996) activated the stereotype of the elderly among half of their participants by administering a scrambled-sentence test where participants saw words related to age stereotypes. Subjects primed with the stereotype walked significantly more slowly than the control group (although the test did not include any words specifically referring to slowness), thus acting in a way that the stereotype suggests that elderly people will act. In another experiment, Bargh, Chen, and Burrows also found that because the stereotype about blacks includes the notion of aggression, subliminal exposure to black faces increased the likelihood that randomly selected white college students reacted with more aggression and hostility than participants who subconsciously viewed a white face. Similarly, Correll et al. (2002) showed that activated stereotypes about blacks can influence people's behavior. In a series of experiments, black and white participants played a video game, in which a black or white person was shown holding a gun or a harmless object (e.g., a mobile phone). Participants had to decide as quickly as possible whether to shoot the target. When the target person was armed, both black and white participants were faster in deciding to shoot the target when he was black than when he was white. When the target was unarmed, the participants avoided shooting him more quickly when he was white. Time pressure made the shooter bias even more pronounced.",
            "score": 155.20257568359375
        },
        {
            "docid": "21312318_18",
            "document": "Recognition memory . Signal detection theory has been applied to recognition memory as a method of estimating the effect of the application of these internal criteria, referred to as bias.  Critical to the dual process model is the assumption that recognition memory reflects a signal detection process in which old and new items each have a distinct distribution along a dimension, such as familiarity. The application of Signal Detection Theory (SDT) to memory depends on conceiving of a memory trace as a signal that the subject must detect in order to perform in a retention task. Given this conception of memory performance, it is reasonable to assume that percentage correct scores may be biased indicators of retention\u2014just as thresholds may be biased indicators of sensory performance\u2014and, in addition, that SDT techniques should be used where possible to separate the truly retention-based aspects of memory performance from the decision aspects.  In particular, we assume that the subject compares the trace strength of the test item with a criterion, responding \"yes\" if the strength exceeds the criterion and \"no\"otherwise. There are two types of test items, \"old\" (a test item that appeared in the list for that trial) and new\" (one that did not appear in the list). Strength theory assumes that there may be noise in the value of the trace strength, the location of the criterion, or both. We assume that this noise is normally distributed.  The reporting criterion can shift along the continuum in the direction of more false hits, or more misses. The momentary memory strength of a test item is compared with the decision criteria and if the strength of the item falls within the judgment category, Jt, defined by the placement of the criteria, S makes judgment. The strength of an item is assumed to decline monotonically (with some error variance) as a continuous function of time or number of intervening items. False hits are 'new' words incorrectly recognized as old, and a greater proportion of these represents a liberal bias. Misses are 'old' words mistakenly not recognized as old, and a greater proportion of these represents a conservative bias. The relative distributions of false hits and misses can be used to interpret recognition task performance and correct for guessing. Only target items can generate an above-threshold recognition response because only they appeared on the list. The lures, along with any targets that are forgotten, fall below threshold, which means that they generate no memory signal whatsoever. False alarms in this model reflect memory-free guesses that are made to some of the lures.",
            "score": 152.29954528808594
        },
        {
            "docid": "15434333_13",
            "document": "Behavior management . Positive reinforcement, negative reinforcement, positive and negative punishment are all forms of Operant Conditioning. Reinforcements are when you try to increase behavior, either positively or negatively. If you use positive reinforcement, you add a wanted stimulus for desired behavior (e.g. awarding good behavior with a treat). Negative reinforcement is when you increase behavior by removing something unwanted. (e.g., The child\u2019s room is messy and his mom nags him to clean it up, he eventually keeps it clean to remove his mom\u2019s nagging.) Punishment is trying to decrease behavior, either by using negative or positive. Positive punishment is when you add an unwanted stimulus to decrease the target\u2019s behavior. (e.g., spanking a child when he behaves badly.) Here, spanking is being added to decrease his bad behavior. Negative punishment is when you remove something the target enjoys or likes to remove his or her bad behavior. (e.g. your child comes home past curfew every weekend, you remove watching TV when he is past curfew, therefore, your child\u2019s behavior of coming past curfew will decrease.) This is negative punishment because your child likes to watch TV, so when you take that away from him for being late, he doesn\u2019t like it, therefore, wanting to come home in time to not get that privilege taken away. (Goal: to elaborate and give more background to help reinforce the theory.)  Abraham Maslow is a very well-known humanist psychologist with his work for hierarchy needs, in this, he describes that humans have basic needs, and they are not met, that individuals will not desire anything else. Maslow also states that humans are never really satisfied, in that our needs are never fully fulfilled, therefore, this can affect how we can behave. (e.g., if our needs are never fully fulfilled, then we might not always behave well, even if we do get a treat for good behavior.) A related concept, \"Hawthorne Effect\" involves the manipulation of behavior of somebody being observed. For example, if you\u2019re being studied in an experiment, you might perform better or work harder because you are aware of the attention you are getting. It is this effect of observation that is called the \"Hawthorne Effect\". This is interesting because if we take a child who is behaving very poorly, no matter what, and they were put in an experiment, they might increase their good behavior because they are getting attention from the researcher. The point of operant conditioning in behavior modification is to regulate the behavior. It is a method to use different techniques and tie them all together to monitor how one behaves. It can cause a problem when talking about Maslow\u2019s Hierarchy of needs because in this model Maslow goes on to explain how no one\u2019s needs are fully met. The highest point on Maslow\u2019s pyramid is self-actualization which Maslow argues is the goal in which we do not reach. This can pose a problem when it comes to behavior modification because one might think if that individual can not reach that ultimate goal, why try at all. Self-actualization is the goal in which humans have this sense of belonging or accomplishment. Humans have needs, just like any other breed of animal and when one type of animal does not attain those goals or needs, there is this feeling of dissatisfaction. When a person does not meet that top goal there is a void and that person might feel depressed that he or she can not get to that ultimate step. Using these behavioral modifications or techniques one can train or teach oneself how to better attain these goals.",
            "score": 150.2883758544922
        },
        {
            "docid": "27120661_6",
            "document": "Vigilance (psychology) . Green and Swets formulated the Signal Detection Theory, or SDT, in 1966 to characterize detection task performance sensitivity while accounting for both the observer's perceptual ability and willingness to respond. SDT assumes an active observer making perceptual judgments as conditions of uncertainty vary. A decision maker can vary their sensitivity, characterized by d', to allow more or less correct detections, but at the respective cost of more or less false alarms. This is termed a criterion shift. The degree to which the observer tolerates false alarms to achieve a higher rate of detection is termed the bias. Bias represents a strategy to minimize the consequences of missed targets and false alarms. As an example, the lookout during a bank robbery must set a threshold for how \"cop-like\" an approaching individual or vehicle may be. Failing to detect the \"cop\" in a timely fashion may result in jail time, but a false alarm will result in a lost opportunity to steal money. In order to produce a bias-free measure, d' is calculated by measuring the distance between the means of the signal and non-signals (noise) and scaling by the standard deviation of the noise. Mathematically, this can be accomplished by subtracting the z-score of the hit rate from the z-score of the false alarm rate. Application of SDT to the study of vigilance indicates that in most, but not all cases, vigilance decrement is not the result of a reduction in sensitivity over time. In most cases a reduction of detections is accompanied by a commensurate reduction in false alarms, such that d' is relatively unchanged.",
            "score": 150.0908660888672
        },
        {
            "docid": "7224456_18",
            "document": "Optimism bias . Perceived risk differences occur depending on how far or close a compared target is to an individual making a risk estimate. The greater the perceived distance between the self and the comparison target, the greater the perceived difference in risk. When one brings the comparison target closer to the individual, risk estimates appear closer together than if the comparison target was someone more distant to the participant. There is support for perceived social distance in determining the optimistic bias. Through looking at comparisons of personal and target risk between the in-group level contributes to more perceived similarities than when individuals think about outer-group comparisons which lead to greater perceived differences. In one study, researchers manipulated the social context of the comparison group, where participants made judgements for two different comparison targets: the typical student at their university and a typical student at another university. Their findings showed that not only did people work with the closer comparison first, but also had closer ratings to themselves than the \"more different\" group.",
            "score": 148.6322021484375
        },
        {
            "docid": "22843418_7",
            "document": "Extinction (neurology) . Neglect and extinction often present simultaneously in patients. When looking at neglect, studies have demonstrated that there is more to the spatial nature than mere primary sensory loss. Proposals of this kind have become increasingly frequent in recent years but attentional accounts for neglect are not universally popular. We can think of one primary component of neglect as involving inattention and that extinction is by no means the whole story for neglect. Extinction encapsulates a critical general principle that applies for most aspects of neglect, namely that the patient\u2019s spatial deficit is most apparent in competitive situations, where information towards the good ipsilesional side comes to dominate information that would otherwise be acknowledged towards the contralesional side. This may relate to the attentional limitation seen in neurologically healthy people. We cannot become aware of multiple targets all at once, even if our sensory systems have transduced them. This is seen in patients with extinction, who are able to detect a single target in any location, with a deficit only for multiple concurrent targets. Therefore, extinction can be regarded as a pathological, spatially specific exaggeration of the normal difficulty in distributing attention to multiple targets so we can predict that it should be reduced if the two competing events could be grouped together. Several recent findings from right-parietal patients with left extinction confirm this prediction, suggesting that grouping mechanisms may still operate despite the pathological spatial bias of the patient to influence whether a particular stimulus will reach the patient's awareness. Thus extinction is reduced when the concurrent target events can be linked into a single subjective object, becoming allies rather than competitors in the bid to attract attention. Furthermore, the extent of residual processing extinct stimuli can vary from one patient to another, depending on the exact extent of their lesion. The examples of residual unconscious processing so far all concern the visual modality although evidence is starting to emerge concerning similar effects for extinguished tactile and auditory stimuli.",
            "score": 148.40464782714844
        },
        {
            "docid": "366943_10",
            "document": "Shooting of Amadou Diallo . The event spurred subsequent social psychology research. A number of experiments have been conducted with both undergraduate volunteers and police officers playing a computer game where they must choose whether to shoot or not to shoot a target who may be white or black, on the basis of whether or not they are armed. Such studies find that participants made slower and less accurate decisions on whether to shoot an unarmed black target than an unarmed white target, and were quicker and more likely to correctly decide to shoot an armed black target than an armed white target. The authors of one study wrote that the shooting studies \"provide powerful evidence that racial stereotypes create associations and expectations that play a role in the sort of split-second decisions that may literally be a matter of life or death.\" However, no correlations have been found between participants' indicated levels of racial bias, and their performance in the games.",
            "score": 144.67245483398438
        },
        {
            "docid": "21312310_17",
            "document": "Remember versus know judgements . The dual-process signal-detection/high-threshold theory tries to reconcile dual-process theory and signal-detection theory into one main theory. This theory states that recollection is governed by a threshold process, while familiarity is not. Recollection is a high-threshold process (i.e., recollection either occurs or does not occur), whereas familiarity is a continuous variable that is governed by an equal-variance detection model. On a recognition test, item recognition is based on recollection if the target item has exceeded threshold, producing an \"old\" response. If the target item does not reach threshold, the individual must make an item recognition decision based on familiarity. According to this theory, an individual makes a \"remember\" response when recollection has occurred. A know response is made when recollection has not occurred, and the individual must decide whether they recognize the target item solely on familiarity. Thus, in this model, the participant is thought to resort to familiarity as a backup process whenever recollection fails to occur.",
            "score": 142.78575134277344
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 142.38385009765625
        },
        {
            "docid": "26565579_9",
            "document": "Neuroscience of free will . Some thinkers like neuroscientist and philosopher Adina Roskies think these studies can still only show, unsurprisingly, that physical factors in the brain are involved before decision making. In contrast, Haggard believes that \"We feel we choose, but we don't\". Researcher John-Dylan Haynes adds \"How can I call a will 'mine' if I don't even know when it occurred and what it has decided to do?\". Philosophers Walter Glannon and Alfred Mele think some scientists are getting the science right, but misrepresenting modern philosophers. This is mainly because \"free will\" can mean many things: It is unclear what someone means when they say \"free will does not exist\". Mele and Glannon say that the available research is more evidence against any dualistic notions of free will \u2013 but that is an \"easy target for neuroscientists to knock down\". Mele says that most discussions of free will are now had in materialistic terms. In these cases, \"free will\" means something more like \"not coerced\" or that \"the person could have done otherwise at the last moment\". The existence of these types of free will is debatable. Mele agrees, however, that science will continue to reveal critical details about what goes on in the brain during decision making. This issue may be controversial for good reason: There is evidence to suggest that people normally associate a belief in free will with their ability to affect their lives. Philosopher Daniel Dennett, author of \"Elbow Room\" and a supporter of deterministic free will, believes scientists risk making a serious mistake. He says that there are types of free will that are incompatible with modern science, but he says those kinds of free will are not worth wanting. Other types of \"free will\" are pivotal to people's sense of responsibility and purpose (see also \"believing in free will\"), and many of these types are actually compatible with modern science.",
            "score": 139.59396362304688
        },
        {
            "docid": "881902_5",
            "document": "Thomas Gilovich . Gilovich condensed his academic research in judgement and decision making into a popular book, \"How We Know What Isn't So\". Writing in \"Skeptical Inquirer\", Carl Sagan called it \"a most illuminating book\" that \"shows how people systematically err in understanding numbers, in rejecting unpleasant evidence, in being influenced by the opinions of others. We're good in some things, but not in everything. Wisdom lies in understanding our limitations.\" Reviewing the book for \"The New York Times\", George Johnson wrote, \"Over time, the ability to infer rules about the way the world works from skimpy evidence confers a survival advantage, even if much of the time the lessons are wrong. From evolution's standpoint, it is better to be safe than sorry.\" In an interview, Gilovich summarized the thesis of \"How We Know What Isn't So\" as people \"thinking we really have the evidence for things, [that] the world is telling us something, but in fact the world is telling us something a little more complicated, and how is it that we can misread the evidence of our everyday experience, and be convinced that something is true when it really isn't.\" He further elaborated on some of the erroneous beliefs his book discusses, including the \"sophomore jinx\", the idea that things such as natural disasters come in threes, and the belief that the lines we are in slow down but the lines we leave speed up. In the same interview he called confirmation bias the \"mother of all biases.\"",
            "score": 139.39894104003906
        },
        {
            "docid": "35970915_11",
            "document": "Colavita visual dominance effect . Sinnett, Spence, and Faraco (2007)conducted an experiment in which they noted that, when attention was manipulated in the direction of the auditory stimulus, the Colavita effect was able to be reduced, but not reversed, to create auditory dominance. As a result, they proposed that visual dominance cannot be based entirely on attentional mechanisms, but must occur at a sensory level. This inability to reverse the Colavita effect when attention is directed to an auditory stimulus, suggests that visual dominance may involve innate biases towards visual modalities. In one of their experiments, in order to reduce the magnitude of visual dominance, Sinnett and his colleagues (2007) created a strong bias towards the auditory modality. To do this, they increased the proportion of auditory targets, which resulted in faster reaction times to unimodal auditory targets than to unimodal visual targets. Participants showed a small (nonsignificant) bias towards making more erroneous unimodal auditory responses, and no reversal of the Colavita effect was observed. These results support the claim that visual dominance occurs at a sensory level, before the engagement of attention.",
            "score": 139.347900390625
        },
        {
            "docid": "7973164_13",
            "document": "Anomalous experiences . Psychotic-like symptoms, such as hallucinations and unusual perceptual experience, involve gross alterations in the experience of reality. Normal perception is substantially constructive and what we perceive is strongly influenced by our prior experiences and expectancies. Healthy individuals prone to hallucinations, or scoring highly on psychometric measures of positive schizotypy, tend to show a bias toward reporting stimuli that did not occur under perceptually ambiguous experimental conditions. During visual detection of fast-moving words, undergraduate students scoring highly on positive schizotypy had significantly high rates of false perceptions of words (i.e. reported seeing words that were not included in the experimental trials). Positive schizotypal symptoms in healthy adults seem to predict false perceptions in laboratory tasks and certain environmental parameters such as perceptual load and frequency of visual targets are critical in the generation of false perceptions. When detection of events becomes either effortless or cognitively demanding, generation of such biases can be prevented.",
            "score": 138.56690979003906
        },
        {
            "docid": "35970915_5",
            "document": "Colavita visual dominance effect . For example, Sinnet and his colleagues conducted an experiment in which they presented participants with three response keys, one for each type of response (unimodal visual, unimodal auditory and bimodal audiovisual); instead of just two, and they instructed participants to press the bimodal key when responding to audiovisual stimuli. This new manipulation resulted in a significant reduction of the Colavita effect because errors in bimodal trials were only committed in a small number of trials. In another experiment, Sinnett and his colleagues conducted a pre-specified target detection task where auditory targets were more frequent than visual or bimodal targets. This led to the elimination of the Colavita effect. The authors suggested that this was due to the introduction of a bias toward auditory stimuli. Ngo and her colleagues conducted a similar study where the results were replicated, because their findings showed that under the appropriate conditions and task demand, the Colavita effect can be reversed. Also, Sinnett and his colleagues mention that animals and humans increase their reliance on auditory stimuli in high-arousal situations and when facing potential threats, which could imply that the Colavita effect is situation and context dependent.",
            "score": 137.90823364257812
        },
        {
            "docid": "690278_21",
            "document": "Choice . Individual personality plays a significant role in how individuals deal with large choice set sizes. Psychologists have developed a personality test that determines where an individual lies on the satisficer-maximizer spectrum. A maximizer is one who always seeks the very best option from a choice set, and may anguish after the choice is made as to whether it was indeed the best. Satisficers may set high standards but are content with a good choice, and place less priority on making the best choice. Due to this different approach to decision-making, maximizers are more likely to avoid making a choice when the choice set size is large, probably to avoid the anguish associated with not knowing whether their choice was optimal. One study looked at whether the differences in choice satisfaction between the two are partially due to a difference in willingness to commit to one\u2019s choices. It found that maximizers reported a stronger preference for retaining the ability to revise choices. Additionally, after making a choice to buy a poster, satisficers offered higher ratings of their chosen poster and lower ratings of the rejected alternatives. Maximizers, however, were less likely to change their impressions of the posters after making their choice which left them less satisfied with their decision.",
            "score": 137.8723907470703
        },
        {
            "docid": "804702_23",
            "document": "Status quo bias . Research by University College London scientists that examines the neural pathways involved in 'status quo bias' in the human brain and found that the more difficult the decision we face, the more likely we are not to act. The study, published in \"Proceedings of the National Academy of Sciences\" (PNAS), looked at the decision-making of participants taking part in a tennis 'line judgement' game while their brains were scanned using functional MRI (fMRI). The 16 study participants were asked to look at a cross between two tramlines on a screen while holding down a 'default' key. They then saw a ball land in the court and had to make a decision as to whether it was in or out. On each trial, the computer signalled which was the current default option \u2013 'in' or 'out'. The participants continued to hold down the key to accept the default and had to release it and change to another key to reject the default. The results showed a consistent bias towards the default, which led to errors. As the task became more difficult, the bias became even more pronounced. The fMRI scans showed that a region of the brain known as the sub-thalamic nucleus (STN) was more active in the cases when the default was rejected. Also, greater flow of information was seen from a separate region sensitive to difficulty (the prefrontal cortex) to the STN. This indicates that the STN plays a key role in overcoming status quo bias when the decision is difficult.",
            "score": 136.8309783935547
        },
        {
            "docid": "42618724_19",
            "document": "Sam Glucksberg . Contextual information plays a large role in discourse comprehension, but the issue that many psychologists have been trying to solve is how contextual information is used. Models have been proposed to explain how contextual information is used to decide the appropriate meaning of an ambiguous word such as \"cast\". The \"selective access model\" suggests that depending on the context of the sentence determines which meaning of the word \"cast\" comes to mind (orthopedic cast or cast of characters in a play). The \"ordered access model\" suggests that the more dominant meaning of the word is the meaning formulated first when dealing with an ambiguous word, so the orthopedic cast would be the one called to mind. Through a series of experiments, Glucksberg found that these models might have produced these outcomes in experiments because of backwards priming, which is when a visual target word influences the initial ambiguous word. For example, the ambiguous word \"cast\" is heard by a listener and then they see the word \"actress\". While processing the auditory statement, the visual target is available during the mental representation of the ambiguous word, thus bringing about the \"cast of characters\" meaning to the word rather than the more dominant one. Glucksberg's solution was to use non-words as the visual target so it would eliminate backward priming. He found that context can constrain lexical access using essentially the same paradigms used by others who did not find such evidence.",
            "score": 136.77561950683594
        },
        {
            "docid": "32017750_6",
            "document": "Languaculture . The learning of target languaculture is driven by \"rich points\". We realize that a culture is different from ours when we face some behaviours which we do not understand. Rich points are those surprises, those departures from an outsider\u2019s expectations that signal a difference between source languaculture and target languaculture. They are the moments of incomprehension, when you suddenly do not know what is happening. In this situation different reactions are possible. You can ignore the rich point and hope that the next part makes sense. You can perceive it as evidence that the person who produced it has some lacks. Or you can wonder why you do not understand and if maybe some other languaculture comes into play. Therefore, rich points belong to daily life and not only to language. Agar highlights that the term \"rich\" has the positive connotations of thickness, wealth and abundance. The largest rich point is the total incomprehension due to huge differences between source languaculture and target languaculture. In this case we are facing a \u2018culture shock\u2019 that causes a deep bewilderment. The smallest rich point can occur among different groups of the same community. The existence of rich points comes from the fact that every statement implicitly refers to various elements that are taken for granted in a certain culture and do not match the elements of another culture (cultural implicitness).",
            "score": 136.06710815429688
        },
        {
            "docid": "40786_10",
            "document": "Bias . Confirmation bias is the tendency to search for, interpret, favor, and recall information in a way that confirms one's beliefs or hypotheses while giving disproportionately less attention to information that contradicts it. The effect is stronger for emotionally charged issues and for deeply entrenched beliefs. People also tend to interpret ambiguous evidence as supporting their existing position. Biased search, interpretation and memory have been invoked to explain attitude polarization (when a disagreement becomes more extreme even though the different parties are exposed to the same evidence), belief perseverance (when beliefs persist after the evidence for them is shown to be false), the irrational primacy effect (a greater reliance on information encountered early in a series) and illusory correlation (when people falsely perceive an association between two events or situations). Confirmation biases contribute to overconfidence in personal beliefs and can maintain or strengthen beliefs in the face of contrary evidence. Poor decisions due to these biases have been found in political and organizational contexts.",
            "score": 135.11572265625
        },
        {
            "docid": "3044780_18",
            "document": "Affect heuristic . Researchers have studied how one's memory load increases one's chances of using the affect heuristic. In a study by Stiv and Fedorikhin (1999), participants were asked to either memorize a two-digit number (low cognitive demand) or a seven-digit number (high cognitive demand). Participants were then asked to enter another room where they would report their number. On the way there, they were asked for their preference for two snacks: chocolate cake (more favorable affect, less favorable cognition) or fruit salad (less favorable affect, more favorable cognition). Researchers predicted that participants given the seven-digits to remember (high cognitive load) would reduce their deliberation process due to having to remember a large amount of information. This would increase the chances of these participants choosing the cake over the fruit salad due to it being the more affectively favorable option. This hypothesis proved true with participants choosing the chocolate cake 63% of the time when given a high cognitive load and only 41% when given a low cognitive load. In the same study they also tested the impulsiveness of the participants in moderating the effects of processing-resources of choice and at the time they were asked for their preference for the two snacks high cognitive demand chose the chocolate cake 84.2%. This provides evidence that people's decisions can be influenced by affect heuristic in a relatively spontaneous manner from the stimulus, with little involvement of higher-order cognitive demand.",
            "score": 134.87684631347656
        },
        {
            "docid": "48258936_5",
            "document": "Debiasing . Changing incentives can be an effective means to debias judgment and decision making. This approach is generally derived from economic theories suggesting that people act in their self-interest by seeking to maximize their utility over their lifetime. Many decision making biases may occur simply because they are more costly to eliminate than to ignore. Making people more accountable for their decisions (increasing incentives), for example, can increase the extent to which they invest cognitive resources in making decisions, leading to less biased decision making when people generally have an idea of how a decision should be made. However, \"bias\" might not be the appropriate term for these types of decision making errors. These \"strategy-based\" errors occur simply because the necessary effort outweighs the benefit. If a person makes a suboptimal choice based on an actual bias, then incentives may exacerbate the issue. An incentive in this case may simply cause the person to perform the suboptimal behavior more enthusiastically.",
            "score": 134.38514709472656
        },
        {
            "docid": "11276152_88",
            "document": "Touchpoint . In the customer realm, when it comes down to deciding whether to use a service or purchase from a brand, it can be said that the consumer evaluates brand alternatives and ranks them from the most preferred to the least preferred and forms \u2018purchase intentions\u2019. However, there are two factors that influence the consumer\u2019s actual \"decision\" to purchase. Such factors are the \u2018attitudes of others\u2019 and the \u2018unexpected situational factors\u2019. With regard to interaction between customers, the factor that is relevant to such a situation is the \u2018attitudes of others\u2019. During the pre-purchase stage of a consumer\u2019s decision making process, the consumer searches for information about a certain product from a variety of brands. An effective touchpoint during this search for information is experiences from other consumers of a brand whether it be from family and friends, or even reviews online via internet search or social media. Internet searches, (whether the consumer is conscious of it or not), are indirect interactions between customers that ultimately define and determine a consumer\u2019s purchase decision. However, it is when a customer receives information about a product from someone important to them, that they truly take that information on board. For example, if a consumer recognizes a need for a new car, they seek advice or information from a family member or friend. In doing so, the family member or friend may advise them to buy the cheaper car out of all available options because it is just as efficient as the expensive car. This then lowers the chance of the consumer choosing the more expensive car. This emphasizes the point that a lot of the consumer\u2019s decision making can be based on experiences other consumers have had with certain brands, creating this crucial touchpoint of customer to customer interaction.",
            "score": 134.38278198242188
        },
        {
            "docid": "491696_9",
            "document": "Awareness . The ability to consciously detect an image when presented at near-threshold stimulus varies across presentations. One factor is \"baseline shifts\" due to top down attention that modulates ongoing brain activity in sensory cortex areas that affects the neural processing of subsequent perceptual judgments. Such top down biasing can occur through two distinct processes: an attention driven baseline shift in the alpha waves, and a decision bias reflected in gamma waves.",
            "score": 133.8177947998047
        },
        {
            "docid": "1803590_124",
            "document": "Job interview . For example, in the West, applicants prefer to eliminate details and focus on the larger issue, tending towards a comprehensive evaluation starting from individual elements then moving towards the whole. In Japan, a respondent would go from the general to the specific in answering, preferring to divide a problem and analyze it piece by piece. Likewise, there are differences between individualist and collectivist cultures in the types of answers they chose. When given a series of options, individualists tend to choose the task oriented option that involves direct communication with others. Yet collectivists choose the option that sees group harmony and protecting or saving face for others as more important. These differences can introduce method bias when interviewers evaluate or score how the applicant did in the interview. This is why it is important to understand how and why the best answer in one culture is not the best elsewhere. It might even be completely wrong.",
            "score": 133.8157501220703
        },
        {
            "docid": "2210835_4",
            "document": "Attentional blink . A possible explanation for lag-1 sparing is that this phenomenon is heavily interconnected with attentional blink, but does not operate on the same cognitive mechanisms and requires different stimuli to occur. Specifically, for lag-1 sparing to occur, it needs visual input as practice targets. These targets can be numbers or letters presented in rapid succession. When the first target, T1, is presented, it creates an attentional window because of its novelty, meaning that it attracts and holds more attention by the participant. The novelty that wears off between T1 and T2 creates a \u201cboost\u201d in attention and opens a metaphorical window for faster cognition. Participants now know what and how to look for targets, so they find targets more quickly. This attentional widow remains open long enough for T2 to be presented and processed at a much higher rate because of shared characteristics to T1. Targets are normally presented in less than .5 of a second from each other. Lag-1 sparing also occurred regardless of how information was visually presented. Of two RSVP streams\u2014 where T1 location was known in the first stream and unknown in the second stream, lag-1 sparing occurred whether T2 was in the same stream as T1, or in a different stream than T1.",
            "score": 133.58663940429688
        },
        {
            "docid": "59160_54",
            "document": "Confirmation bias . Explanations in terms of cost-benefit analysis assume that people do not just test hypotheses in a disinterested way, but assess the costs of different errors. Using ideas from evolutionary psychology, James Friedrich suggests that people do not primarily aim at truth in testing hypotheses, but try to avoid the most costly errors. For example, employers might ask one-sided questions in job interviews because they are focused on weeding out unsuitable candidates. Yaacov Trope and Akiva Liberman's refinement of this theory assumes that people compare the two different kinds of error: accepting a false hypothesis or rejecting a true hypothesis. For instance, someone who underestimates a friend's honesty might treat him or her suspiciously and so undermine the friendship. Overestimating the friend's honesty may also be costly, but less so. In this case, it would be rational to seek, evaluate or remember evidence of their honesty in a biased way. When someone gives an initial impression of being introverted or extroverted, questions that match that impression come across as more empathic. This suggests that when talking to someone who seems to be an introvert, it is a sign of better social skills to ask, \"Do you feel awkward in social situations?\" rather than, \"Do you like noisy parties?\" The connection between confirmation bias and social skills was corroborated by a study of how college students get to know other people. Highly self-monitoring students, who are more sensitive to their environment and to social norms, asked more matching questions when interviewing a high-status staff member than when getting to know fellow students.",
            "score": 133.0840301513672
        },
        {
            "docid": "19471895_17",
            "document": "Negative affectivity . Negative affect benefits judgment in diminishing the implicit use of stereotypes by promoting closer attention to stimuli. In one study, participants were less likely to discriminate against targets that appeared Muslim when in a negative affective state. After organizing participants into positive and negative affect groups, researchers had them play a computer game. Participants had to make rapid decisions to shoot only at targets carrying a gun. Some of the targets wore turbans making them appear Muslim. As expected, there was a significant bias against Muslim targets resulting in a tendency to shoot at them. However, this tendency decreased with subjects in negative affective states. Positive affect groups developed more aggressive tendencies toward Muslims. Researchers concluded that negative affect leads to less reliance on internal stereotypes, thus decreasing judgmental bias.",
            "score": 132.8669891357422
        }
    ]
}