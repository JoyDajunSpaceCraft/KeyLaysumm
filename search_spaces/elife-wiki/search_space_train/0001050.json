{
    "q": [
        {
            "docid": "25146378_15",
            "document": "Functional specialization (brain) . During the 1960s, Roger Sperry conducted a natural experiment on epileptic patients who had previously had their corpora callosa cut. The corpus callosum is the area of the brain dedicated to linking both the right and left hemisphere together. Sperry et al.'s experiment was based on flashing images in the right and left visual fields of his participants. Because the participant's corpus callosum was cut, the information processed by each visual field could not be transmitted to the other hemisphere. In one experiment, Sperry flashed images in the right visual field (RVF), which would subsequently be transmitted to the left hemisphere (LH) of the brain. When asked to repeat what they had previously seen, participants were fully capable of remembering the image flashed. However, when the participants were then asked to draw what they had seen, they were unable to. When Sperry et al. flashed images in the left visual field (LVF), the information processed would be sent to the right hemisphere (RH) of the brain. When asked to repeat what they had previously seen, participants were unable to recall the image flashed, but were very successful in drawing the image. Therefore, Sperry concluded that the left hemisphere of the brain was dedicated to language as the participants could clearly speak the image flashed. On the other hand, Sperry concluded that the right hemisphere of the brain was involved in more creative activities such as drawing.",
            "score": 123.80910241603851
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 144.43986117839813
        },
        {
            "docid": "1316947_4",
            "document": "Ambiguous image . When we see an image, the first thing we do is attempt to organize all the parts of the scene into different groups. To do this, one of the most basic methods used is finding the edges. Edges can include obvious perceptions such as the edge of a house, and can include other perceptions that the brain needs to process deeper, such as the edges of a person's facial features. When finding edges, the brain's visual system detects a point on the image with a sharp contrast of lighting. Being able to detect the location of the edge of an object aids in recognizing the object. In ambiguous images, detecting edges still seems natural to the person perceiving the image. However, the brain undergoes deeper processing to resolve the ambiguity. For example, consider an image that involves an opposite change in magnitude of luminance between the object and the background (e.g. From the top, the background shifts from black to white, and the object shifts from white to black). The opposing gradients will eventually come to a point where there is an equal degree of luminance of the object and the background. At this point, there is no edge to be perceived. To counter this, the visual system connects the image as a whole rather than a set of edges, allowing one to see an object rather than edges and non-edges. Although there is no complete image to be seen, the brain is able to accomplish this because of its understanding of the physical world and real incidents of ambiguous lighting. In ambiguous images, an illusion is often produced from illusory contours. An illusory contour is a perceived contour without the presence of a physical gradient. In examples where a white shape appears to occlude black objects on a white background, the white shape appears to be brighter than the background, and the edges of this shape produce the illusory contours. These illusory contours are processed by the brain in a similar way as real contours. The visual system accomplishes this by making inferences beyond the information that is presented in much the same way as the luminance gradient.",
            "score": 96.19075655937195
        },
        {
            "docid": "1038051_11",
            "document": "Stroop effect . Brain imaging techniques including magnetic resonance imaging (MRI), functional magnetic resonance imaging (fMRI), and positron emission tomography (PET) have shown that there are two main areas in the brain that are involved in the processing of the Stroop task. They are the anterior cingulate cortex, and the dorsolateral prefrontal cortex. More specifically, while both are activated when resolving conflicts and catching errors, the dorsolateral prefrontal cortex assists in memory and other executive functions, while the anterior cingulate cortex is used to select an appropriate response and allocate attentional resources.",
            "score": 86.94934320449829
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 132.86935985088348
        },
        {
            "docid": "675275_10",
            "document": "Distraction . Distraction is often used as a coping mechanism for short-term emotion regulation. When presented with an unpleasant reality, humans often choose to occupy their attention with some other reality in order to remain in a positive mental state. This is referred to as \u2018procrastination\u2019 when the unpleasant reality is in the form of work. The natural human inclination to distract oneself was put to the test when the Department of Psychology at Humboldt-Universit\u00e4t zu Berlin (Humboldt University of Berlin) held an experiment to study distraction. The goal of the experiment was to examine whether the effects of distraction on where subjects held their attention during repeated picture processing is changed by regular emotional functions. Furthermore, they hypothesized that while distraction assists in short-term emotional regulation, it is actually harmful in the long term. In order to do so, the experimenters had subjects view 15 unpleasant pictures (Set A) and \u201cattend\u201d to them (meaning the subjects were asked to pay full attention to the pictures). Next, the subjects were shown 15 unpleasant pictures (Set B) and were asked to distract themselves from the pictures (meaning they were to think about anything other than the picture on the screen; their example was to think about \u201cthe way to the supermarket\u201d). Finally, the subjects were shown 15 neutral pictures (Set C) and were asked to attend to them. After 10 minutes of rest, the subjects entered the \u201cre-exposure phase\u201d, which repeated the experiment- this time requiring the subjects to pay attention to all of the sets, including Set B. This experiment was performed on 3 separate blocks of participants. To examine the state of the subjects\u2019 brain, the subject was to wear \u201cAg/AgCl-electrodes from 61 head sites using an EasyCap electrode system with an equidistant electrode montage. Additional external electrodes were placed below the left (IO1) and right eye (IO2), below T1 (ground), on the nasion, and on the neck.\u201d The subjects were also asked to rate the unpleasantness of the picture on the screen on a scale of 1-9. To test whether distraction in the first phase resulted in increased responsiveness during the re-exposure phase, experimenters \u201ccompared mean unpleasantness ratings between unpleasant pictures that were previously presented in the attend (previous attention) versus distract (previous distraction) condition using a paired t-test\u201d. The end results of the experiment were as such: Essentially, when exposed to an unpleasant image, the subject feels initial discomfort. However, after being exposed to it once with their full attention, the subject feels much less discomfort the second time they are exposed. When the subject distracts themselves from the initial unpleasant image, the subject feels more discomfort the second time when they are required to attend to the image. The experimenters\u2019 conclusion is thus: \u201cthe obtained results suggest that distraction inhibits elaborate processing of the stimulus' meaning and adapting to it.\u201d",
            "score": 106.96599316596985
        },
        {
            "docid": "31329046_6",
            "document": "Pre-attentive processing . Information for pre-attentive processing is detected through the five senses. In the visual system, the receptive fields at the back of the eye (retina) transfer the image via axons to the thalamus, specifically the lateral geniculate nuclei. The image then travels to the primary visual cortex and continues on to be processed by the visual association cortex. At each stage, the image is processed with increasing complexity. Pre-attentive processing starts with the retinal image; this image is magnified as it moves from retina to the cortex of the brain. Shades of light and dark are processed in the lateral geniculate nuclei of the thalamus. Simple and complex cells in the brain process boundary and surface information by deciphering the image's contrast, orientation, and edges. When the image hits the fovea, it is highly magnified, facilitating object recognition. The images in the periphery are less clear but help to create a complete image used for scene perception.",
            "score": 100.01244807243347
        },
        {
            "docid": "22509570_17",
            "document": "Lateralized readiness potential . The flankers task requires blocking out irrelevant distractors from the environment, but what if the relevant and irrelevant features are embedded in one target stimulus? This is often the case in the classic Stroop task, such as when one must inhibit their natural response to read a word by responding to only the ink color that the word is printed in. This requires focusing on the task-relevant features of a given stimulus while ignoring task-irrelevant features of the same stimulus. Is information about both features processed simultaneously? The LRP has been used to investigate transmission of partial information in this context. A nice example is in a paper co-authored by one of the first to discover the LRP, Dr. Gabriele Gratton. In this study, the subject performs a spatial stroop task, where they are cued to respond to an upcoming word that is either the word \"ABOVE\" or the word \"BELOW\" presented either physically above or below a central fixation cross. Subjects were cued (in random order) to respond to either the physical position of the word or to the conceptual meaning of the word. Responses are typically slower and less accurate when word position and meaning are inconsistent. For all conditions, the left and right hand button responses corresponded to the two response options. The research question was whether during the spatial stroop task conflict on position-inconsistent (or, incongruent) trials is represented in the motor response stage as can be indexed by the LRP. If an LRP was evident for incongruent trials, this suggests information about the irrelevant stimulus feature was processed at the response stage even on correct trials and this generated response conflict, again supporting a model of continuous information processing. Indeed, the results supported this hypothesis. The study also collected event-related optical signal (EROS) data, which has a spatial resolution for imaging cortical activity in-vivo that is somewhat more coarse than functional magnetic resonance imaging, but has a temporal precision similar to event-related potentials (ERPs). Using EROS they showed that at least one source of the LRP was the motor cortex ipsilateral to the response hand, supporting response conflict in the primary motor cortex as one source of conflict in the stroop task.",
            "score": 137.82432198524475
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 131.99326252937317
        },
        {
            "docid": "7326345_7",
            "document": "Allan Paivio . The dual coding theory (DCT), according to Paivio, suggests that visual and verbal information act as two distinctive systems. It has had its roots in the practical use of imagery as a memory aid 2500 years ago For example, one can think of a car by thinking of the word \u201ccar\u201d, or by forming a mental image of a car. The verbal and image systems are correlated, as one can think of the mental image of the car and then describe it in words, or read or listen to words and then form a mental image. DCT identifies three types of processing: (1) representational, the direct activation of verbal or non-verbal representations, (2) referential, the activation of the verbal system by the nonverbal system or vice versa, and (3) associative processing, the activation of representations within the same verbal or nonverbal system. A given task may require any or all of the three kinds of processing.  Verbal system units are called logogens; these units contain information that underlies our use of the word. Non-Verbal system units are called imagens. Imagens contain information that generates mental images such as natural objects, holistic parts of objects, and natural grouping of objects. Imagens operate synchronously or in parallel; thus all parts of an image are available at once. Logogens operate sequentially; words come one at a time in a syntactically appropriate sequence in a sentence. The two codes may overlap in the processing of information but greater emphasis is on one or the other. The verbal and non-verbal systems are further divided into subsystems that process information from different modalities. Many experiments reported by Paivio and others support the importance of imagery in cognitive operations. In one experiment, participants saw pairs of items that differed in roundness (e.g., tomato, goblet) and were asked to indicate which member of the pair was rounder. The objects were presented as words, pictures, or word-picture pairs. The response times were slowest for word-word pairs, intermediate for the picture-word pairs, and fastest for the picture-picture pairs.",
            "score": 92.16081869602203
        },
        {
            "docid": "2727254_7",
            "document": "Mnemonist . The method of loci is \"the use of an orderly arrangement of locations into which one could place the images of things or people that are to be remembered\". The encoding process happens in three steps. First, an architectural area, such as the houses on a street, must be memorized. Second, each item to be remembered must be associated with a separate image. Finally, this set of images can be distributed in a \"locus,\" or place within the architectural area in a pre-determined order. Then, as one tries to recall the information, the mnemonists simply has to \"walk\" down the street, see each symbol, and recall the associated information. An example of mnemonists who used this is Solomon Shereshevsky; he would use Gorky Street, a street he lived on. When he read, each word would form a graphic image. He would then place this image in a place along the street; later, when he needed to recall the information, he would simply \"stroll\" down the street again to recall the necessary information. Neuroimaging studies have shown results that support the method of loci as the retrieval method in world-class memory performers. An fMRI recorded brain activity in memory experts and a control group as they were memorizing selected data. Previous studies have shown that teaching a control group the method of loci leads to changes in brain activation during memorization. Consistent with their use of the method of loci, memory experts had higher activity in the medial parietal cortex, retrospenial cortex, and right posterior hippocampus; these brain areas have been linked to spatial memory and navigation. These differences were observable even when the memory experts were trying to memorize stimuli, such as snowflakes, where they showed no superior ability to the control group.",
            "score": 99.9156619310379
        },
        {
            "docid": "3883287_8",
            "document": "Tranquillity . Within tranquillity studies, much of the emphasis has been placed on understanding the role of vision in the perception of natural environments, which is probably not surprising, considering that upon first viewing a scene its configurational coherence can be established with incredible speed. Indeed, scene information can be captured in a single glance and the gist of a scene determined in as little as 100ms. The speed of processing of complex natural images was tested by Thorpe \"et al.\" using colour photographs of a wide range of animals (mammals, birds, reptiles and fish), in their natural environments, mixed with distracters that included pictures of forests, mountains, lakes, buildings and fruit. During this experiment, subjects were shown an image for 20ms and asked to determine whether it contained an animal or not. The electrophysiological brain responses obtained in this study showed that a decision could be made within 150ms of the image being seen, indicating the speed at which cognitive visual processing occurs. However, audition, and in particular the individual components that collectively comprise the soundscape, a term coined by Schafer to describe the ever-present array of sounds that constitute the sonic environment, also significantly inform the various schemata used to characterise differing landscape types. This interpretation is supported by the auditory reaction times, which are 50 to 60ms faster than that of the visual modality. It is also known that sound can alter visual perception and that under certain conditions areas of the brain involved in processing auditory information can be activated in response to visual stimuli.  Research conducted by Pheasant \"et al.\" has shown that when individuals make tranquillity assessments based on a uni-modal auditory or visual sensory input, they characterise the environment by drawing upon a number of key landscape and soundscape characteristics. For example, when making assessments in response to visual-only stimuli the percentage of water, flora and geological features present within a scene, positively influence how tranquil a location is perceived to be. Likewise when responding to uni-modal auditory stimuli, the perceived loudness of biological sounds positively influences the perception of tranquillity, whilst the perceived loudness of mechanical sounds have a negative effect. However, when presented with bi-modal auditory-visual stimuli the individual soundscape and landscape components alone no longer influenced the perception of tranquillity. Rather configurational coherence was provided by the percentage of natural and contextual features present within the scene and the equivalent continuous sound pressure level (LAeq).",
            "score": 105.80749690532684
        },
        {
            "docid": "14158261_18",
            "document": "Temporoparietal junction . Theory of mind requires the collaboration of functionally related regions of the brain to form the distinction between self and other mental states and to create a comprehensive understanding of those mental states so that we may recognize, understand, and predict behavior. In general the theory of mind process is mediated by the dopaminergic-serotonergic system, which involves the TPJ as well as other associative regions necessary for mentalizing. Recent studies suggest that both the left TPJ, working in conjunction with the frontal cortex, and the right TPJ are involved in the representation of mental states; furthermore they suggest that the TPJ is particularly active in making the distinction between the mental states of self and others. A study in \"Nature Neuroscience\" from 2004 describes how the TPJ is involved in processing socially relevant cues including gaze direction and goal-directed action and also explains that results from the study show that lesions to this area of the brain result in an impaired ability to detect another persons belief. Moreover, studies have reported an increase in activity in the TPJ when patients are absorbing information through reading or images regarding other peoples' beliefs but not while observing information about physical control stimuli. Some studies, however, have shown that the TPJ, along with the cingulate cortex, is more specifically involved with attributing beliefs, but the process of mentalizing more generally is associated more with the medial prefrontal cortex. Another study in \"Current Biology\" from 2012 identifies the importance of the TPJ in both low-level, such as simple discrimination, and high-level, such as the ability to empathize, sociocognitive operations. In July 2011, a review from \"Neuropsychologia\" presented a model of the mentalizing network that established that mental states are first detected in the TPJ. The TPJ is composed of two discrete anatomical regions, the inferior parietal lobule (IPL) and the caudal parts of the superior temporal sulcus (pSTS), and both are active in the process of distinction between mental states of different individuals; thus, it is probable that this detection is the outcome of the combination and coordination of these two parts. Additionally, the right TPJ is involved in the ventral attention stream and contributes to the ability to focus attention on a particular stimuli or objective. It has also been observed that the interaction and communication between the dorsal and ventral streams involves the TPJ.",
            "score": 109.41866028308868
        },
        {
            "docid": "599917_33",
            "document": "Mental image . One of the longest-running research topics on the mental image has basis on the fact that people report large individual differences in the vividness of their images. Special questionnaires have been developed to assess such differences, including the Vividness of Visual Imagery Questionnaire (VVIQ) developed by David Marks. Laboratory studies have suggested that the subjectively reported variations in imagery vividness are associated with different neural states within the brain and also different cognitive competences such as the ability to accurately recall information presented in pictures Rodway, Gillies and Schepman used a novel long-term change detection task to determine whether participants with low and high vividness scores on the VVIQ2 showed any performance differences. Rodway et al. found that high vividness participants were significantly more accurate at detecting salient changes to pictures compared to low-vividness participants. This replicated an earlier study.",
            "score": 78.49735701084137
        },
        {
            "docid": "168191_13",
            "document": "Human intelligence . Based on A. R. Luria's (1966) seminal work on the modularization of brain function, and supported by decades of neuroimaging research, the PASS Theory of Intelligence proposes that cognition is organized in three systems and four processes. The first process is the Planning, which involves executive functions responsible for controlling and organizing behavior, selecting and constructing strategies, and monitoring performance. The second is the Attention process, which is responsible for maintaining arousal levels and alertness, and ensuring focus on relevant stimuli. The next two are called Simultaneous and Successive processing and they involve encoding, transforming, and retaining information. Simultaneous processing is engaged when the relationship between items and their integration into whole units of information is required. Examples of this include recognizing figures, such as a triangle within a circle vs. a circle within a triangle, or the difference between 'he had a shower before breakfast' and 'he had breakfast before a shower.' Successive processing is required for organizing separate items in a sequence such as remembering a sequence of words or actions exactly in the order in which they had just been presented. These four processes are functions of four areas of the brain. Planning is broadly located in the front part of our brains, the frontal lobe. Attention and arousal are combined functions of the frontal lobe and the lower parts of the cortex, although the parietal lobes are also involved in attention as well. Simultaneous processing and Successive processing occur in the posterior region or the back of the brain. Simultaneous processing is broadly associated with the occipital and the parietal lobes while Successive processing is broadly associated with the frontal-temporal lobes. The PASS (Planning/Attention/Simultaneous/Successive) theory is heavily indebted to both Luria (1966, 1973), and studies in cognitive psychology involved in promoting a better look at intelligence.",
            "score": 121.75960195064545
        },
        {
            "docid": "22509570_13",
            "document": "Lateralized readiness potential . For example, one study used the LRP component to characterize the temporal order of syntactic and phonological word processing while preparing to speak. Like described above, the experiment used a Go/No-Go paradigm, such that syntactic and phonological features of an image to be vocalized were mapped to either the \"Go\" response or the \"No-Go\" response instruction. The syntactic feature was whether the noun label for an image carried gender information, or was gender-neutral; the phonological feature was the letter that the noun label started with. Using the characteristic nature of the LRP, they showed that a response was prepared for syntactic features even when the phonological features of the word meant no response was necessary. Importantly, no LRP was evident on No-Go trials when syntax determined whether a response was necessary and phonology determined response hand, suggesting that syntax information is indeed available sometime preceding phonological information. Yet we hardly notice this when we\u2019re actually speaking because it all happens too fast for our awareness; authors showed that phonological information was available just 40 ms after syntactic information. However, more recent research using a fully counterbalanced, within-subjects design has questioned whether this serial ordering is a general property of lexical access, and shown that it may be modulated by attentional biases. Similarly, another study used the LRP in a Go/No-Go paradigm to show that conceptual information about images (e.g., is the item heavier or lighter than 500g?) is processed approximately 80 ms before syntactic information. Together these studies show how the LRP has helped map out the temporal order of information processing during speech production. When we prepare to speak our brains access conceptual information first, followed by syntactic, then phonological.",
            "score": 119.18643367290497
        },
        {
            "docid": "4778196_25",
            "document": "Mental chronometry . With the advent of the functional neuroimaging techniques of PET and fMRI, psychologists started to modify their mental chronometry paradigms for functional imaging (Posner, 2005). Although psycho(physio)logists have been using electroencephalographic measurements for decades, the images obtained with PET have attracted great interest from other branches of neuroscience, popularizing mental chronometry among a wider range of scientists in recent years. The way that mental chronometry is utilized is by performing reaction time based tasks which show through neuroimaging the parts of the brain which are involved in the cognitive process. With the invention of functional magnetic resonance imaging (fMRI), techniques were used to measure activity through electrical event-related potentials in a study when subjects were asked to identify if a digit that was presented was above or below five. According to Sternberg\u2019s additive theory, each of the stages involved in performing this task includes: encoding, comparing against the stored representation for five, selecting a response, and then checking for error in the response. The fMRI image presents the specific locations where these stages are occurring in the brain while performing this simple mental chronometry task.",
            "score": 93.02694392204285
        },
        {
            "docid": "1875075_30",
            "document": "Self-control . Functional imaging of the brain has shown that self-control is correlated with an area in the dorsolateral prefrontal cortex (dlPFC), a part of the frontal lobe. This area is distinct from those involved in generating intentional actions, attention to intentions, or select between alternatives. This control occurs through the top-down inhibition of premotor cortex. There is some debate about the mechanism of self-control and how it emerges. Traditionally, researchers believed the bottom-up approach guided self-control behavior. The more time a person spends thinking about a rewarding stimulus, the more likely he or she will experience a desire for it. Information that is most important gains control of working memory, and can then be processed through a top-down mechanism. Increasing evidence suggests that top down processing plays a strong role in self-control. Specifically, top-down processing can actually regulate bottom-up attentional mechanisms. To demonstrate this, researchers studied working memory and distraction by presenting participants with neutral or negative pictures and then a math problem or no task. They found that participants reported less negative moods after solving the math problem compared to the no task group, which was due to an influence on working memory capacity.",
            "score": 97.07050001621246
        },
        {
            "docid": "2438760_26",
            "document": "Change blindness . Other studies using fMRI (functional magnetic resonance imaging) scanners have shown that when change is not consciously detected, there was a significant decrease in the dorsolateral prefrontal and parietal lobe regions. These results further the importance of the dorsolateral prefrontal and parietal cortext in the detection of visual change. In addition to fMRI studies, recent research has used transcranial magnetic stimulation (TMS) in order to inhibit areas of the brain while participants were instructed to try to detect the change between two images. The results show that when the posterior parietal cortex (PPC) is inhibited, individuals are significantly slower at detecting change. The PPC is critical for encoding and maintaining visual images in short term working memory, which demonstrates the importance of the PPC in terms of detecting changes between images. For a change to be detected, the information of the first picture needs to be held in working memory and compared to the second picture. If the PPC is inhibited, the area of the brain responsible for encoding visual images will not function properly. The information will not be encoded and will not be held in working memory and compared to the second picture, thus inducing change blindness.",
            "score": 68.83881771564484
        },
        {
            "docid": "68753_6",
            "document": "Attention . By the 1990s, psychologists began using positron emission tomography (PET) and later functional magnetic resonance imaging (fMRI) to image the brain while monitoring tasks involving attention. Because this expensive equipment was generally only available in hospitals, psychologists sought cooperation with neurologists. Psychologist Michael Posner (then already renowned for his seminal work on visual selective attention) and neurologist Marcus Raichle pioneered brain imaging studies of selective attention. Their results soon sparked interest from the neuroscience community, which had until then focused on monkey brains. With the development of these technological innovations, neuroscientists became interested in this type of research that combines sophisticated experimental paradigms from cognitive psychology with these new brain imaging techniques. Although the older technique of electroencephalography (EEG) had long been used to study the brain activity underlying selective attention by cognitive psychophysiologists, the ability of the newer techniques to actually measure precisely localized activity inside the brain generated renewed interest by a wider community of researchers.",
            "score": 95.46426486968994
        },
        {
            "docid": "32754049_3",
            "document": "PASS theory of intelligence . Based on A. R. Luria's (1966) work on modularization of brain function, and supported by decades of neuroimaging research, the PASS Theory of Intelligence proposes that cognition is organized in three systems and four processes. The first process is Planning, which involves executive functions responsible for controlling and organizing behavior, selecting and constructing strategies, and monitoring performance. The second is the Attention process, responsible for maintaining arousal levels and alertness, and ensuring focus on relevant stimuli. The two processes, Simultaneous Processing and Successive Processing encode, transform, and retain information. Simultaneous processing is engaged for determination of the relationship between items integration into whole units of information is required. Examples of this include recognizing figures, such as a triangle within a circle vs. a circle within a triangle. Successive processing is required for organizing separate items in a sequence such as remembering a sequence of words or actions exactly in the order in which they had just been presented. These four processes are hypothesized to functions of four areas of the brain. Planning is broadly located in the front part of our brains, the frontal lobe. Attention and arousal are combined functions of the frontal lobe and the lower parts of the cortex, although the parietal lobes are also involved in attention as well. Simultaneous processing and Successive processing occur in the posterior region or the back of the brain. Simultaneous processing is broadly associated with the occipital and the parietal lobes while Successive processing is broadly associated with the frontal-temporal lobes. The PASS (Planning/Attention/Simultaneous/Successive) theory is heavily indebted to both Luria (1966, 1973), and studies in cognitive psychology involved in promoting a different look at intelligence.",
            "score": 121.45099568367004
        },
        {
            "docid": "33702464_5",
            "document": "Extrastriate body area . The experiment had subjects view images of different objects, including faces (as a control group), body parts, animals, parts of the face and intimate objects. While viewing the images, the subjects were scanned with an fMRI to see what area of the brain was activated. Through the trials a compilation of the fMRI\u2019s was made. From this compilation image a specific region was determined to have increased activity when shown visual stimuli of body parts and even more activity when viewing whole bodies. There have been no studies involving brain damage to the EBA. Thus far, only scans of brain activity, as well as transcranial magnetic stimulation, have been used to study the EBA. To find the specific functions of the EBA, Comimo Urgesi, Giovanni Berlucchi and Salvatore M. Aglioti used repetitive transcranial magnetic stimulation (rTMS) to disrupt part of the brain, making the brain less responsive in the target area. The study used event-related rTMS to disrupt the EBA, resulting in inactivation of cortical areas. This inactivation caused a slower response time in discriminating body parts. The study used facial features and motorcycle parts as non human parts for control groups. The facial features and motorcycle body parts did not display any change in response time. The neural activity data shows the EBA handles some of the visual processing of human body and parts but is not related to the processing of the face or other objects.",
            "score": 75.65093207359314
        },
        {
            "docid": "297067_7",
            "document": "Fregoli delusion . Injury to the right frontal and left temporo-parietal areas can cause Fregoli syndrome. Research by Feinberg, et al. has shown that significant deficits in executive and memory functions follow shortly after damage in the right frontal or left temporoparietal areas. Tests performed on patients that have suffered from a brain injury revealed that basic attention ability and visuomotor processing speed are typically normal. However, these patients made many errors when they were called to participate in detailed attention tasks. Selective attention tests involving auditory targets were also performed, and brain-injured patients had many errors; this meant that they were deficient in their response regulation and inhibition.",
            "score": 138.19198322296143
        },
        {
            "docid": "55780567_4",
            "document": "Snake detection theory . Many empirical studies have found evidences for the theory. Primates, including humans, are able to quickly detect snakes. Some studies have found that humans can detect snake images before subjective visual perception. However, the pre-conscious detection of snake stimuli is still under debate by the scientific community. Snakes images were proved to be detected more rapidly compared to other fear-relevant stimuli: empirical evidences have shown that snakes are more rapidly detected compared to spiders - according to the Snake Detection Theory - because the arachnids were, historically, a less relevant threat to primates. Snake stimuli are particularly distracting during perceptual tasks, suggesting that the brain preferentially processes snake stimuli, even when attentional processes are demanded by other targets. Snake enhanced detection was found also in young children.",
            "score": 102.36984610557556
        },
        {
            "docid": "30601657_12",
            "document": "Response priming . Response-priming effects have been demonstrated for a large number of stimuli and discrimination tasks, including geometric stimuli, color stimuli, various types of arrows, natural images (animals vs. objects), vowels and consonants, letters, and digits. In one study, chess configurations were presented as primes and targets, and participants had to decide whether the king was in check. Mattler (2003) could show that response priming can not only influence motor responses, but also works for cognitive operations like a spatial shift of visual attention or a shift between two different response time tasks. Different types of masking have been employed as well. Instead of measuring keypress responses (commonly with two response alternatives), some studies use more than two response alternatives or record speech responses, speeded finger pointing movements, eye movements, or so-called readiness potentials which reflect the degree of motor activation in the brain's motor cortex and can be measured by electro-encephalographic methods. Brain imaging methods like functional magnetic resonance imaging (fMRI) have been employed as well.",
            "score": 87.37563490867615
        },
        {
            "docid": "4958509_8",
            "document": "Attentional shift . Although, after reviewing Posner's research, it may seem logical to conclude that covert and overt attention shifts utilize different neural mechanisms, other more recent studies have shown more overlap than not. Multiple studies have shown activity evident in the frontal cortex, concentrating in the precentral sulcus, the parietal cortex, specifically in the intraparietal sulcus, and in the lateral occipital cortex for both overt and covert attention shifts. This is in support of the premotor theory of attention. While these studies may agree on the areas, they are not always in agreement on whether an overt or covert attentional shift causes more activation. Utilizing functional magnetic resonance imaging (fMRI) technology, Corbetta \"et al.\", found that overt and covert attention shift tasks showed activation within the same areas, namely, the frontal, parietal and temporal lobes. Additionally, this study reported that covert shifts of attention showed greater activity levels than in the overt attention condition. However, it is important to note that different tasks were used for the covert versus the overt condition. One task involved a probe being flashed to the subject's fovea, while another task showed the probe in the participant's peripheral vision, making it questionable whether these results can be directly compared. Nobre et al. also sought to determine whether covert and overt attention shifts revealed activation in the same brain areas. Once again fMRI technology was utilized, as well as, two separate tasks, one for covert attention and one for overt attention. Results showed overlap in activated areas for overt and covert attention shifts, mainly in the parietal and frontal lobes. However, one area was shown to be specific to covert attention, which was the right dorsolateral cortex; typically associated with voluntary attention shifts and working memory. One should question whether this additional activation has to do with the selected task for the covert condition, or rather if it is specific to a covert shift of attention.",
            "score": 121.41719949245453
        },
        {
            "docid": "14158261_4",
            "document": "Temporoparietal junction . The right temporoparietal junction (rTPJ) is involved in the processing of information in terms of the ability of an individual to pay attention. Evidence from neuroimaging studies as well as lesion studies revealed that the rTPJ plays a pivotal role in analyzing signals from self-produced actions as well as with signals from the external environment. For example, an individual with lesions in their rTPJ would more than likely exhibit a sense of hemi-neglect, wherein they would no longer be able to pay attention to anything they observe on the left. So, if someone were to have a lesion in their rTPJ, then over time the awareness of the left limbs may fade without treatment. Visual signals provide the sensory information necessary for the brain to process spatial recognition of the world. When vision is limited, knowledge of existence begins to fade away since as far as the brain is concerned the object does not exist. Furthermore, the rTPJ plays a role in the way individuals observe and process information, thus impacting social interaction. Empathy and sympathy require an individual to simultaneously distinguish between different possible perspectives on the same situation. Imaging studies show that this ability depends upon the coordinated interaction of the rTPJ to identify and process the social cues presented to it. This rapid process allows for an individual to quickly react to situations.",
            "score": 124.13889062404633
        },
        {
            "docid": "34042719_11",
            "document": "Visual processing abnormalities in schizophrenia . Face perception is a function of the visual system which is critical for social behavior. Patients with schizophrenia have shown abnormalities in tasks designed to probe facial processing and recognition. Specifically, performance deficits have been observed in this disorder when subjects were asked to identify degraded pictures of faces, and the deficits observed were specific to patients with predominantly disorganized symptoms. Another experiment using the same stimuli during EEG found poorer performance and slower reaction times among patients with schizophrenia, as well as abnormalities in beta band activity. The authors state that these results are related to deficits in long range coordination of neural activity, as described for contour detection. Another experiment using EEG and structural MRI to examine facial processing abnormalities in schizophrenia found decreased N170 component responses in patients, and this was correlated with decreased gray matter volumes in the fusiform gyrus. There is evidence that the fusiform face area is a visual cortical region that may be specialized for detecting faces. The authors of this study conclude that their data support a specific face processing deficit in schizophrenia. However, another study using fractured images of faces found that patients with schizophrenia were better than healthy adults at identifying images of famous people that had been distorted. These experiments state that this may be evidence of weaker \"configural\" processing in schizophrenia patients, who instead may rely more on local image features for face identification, as these were preserved in their image manipulation.",
            "score": 73.66392409801483
        },
        {
            "docid": "31098553_3",
            "document": "Right hemisphere brain damage . Individuals with right hemisphere damage exhibit deficits in visual processing. It appears as though they are only able to recognize the parts of a picture, symbol, etc. rather than seeing the image as a whole. This was shown during an experiment when patients with right hemisphere damage had to draw an M made up of small triangles. When they attempted to recreate the image, they only depicted the small triangles. This countered patients with left hemisphere damage who were able to draw the M, but left out the small triangles that made it up. In addition, those with right hemisphere damage have difficulty changing their perception of a whole pertaining to an image. They focus on one particular whole and have a hard time changing their perception and incorporating another whole when new information is presented. This phenomenon is called inference revising and individuals with right hemisphere damage therefore experience a deficit in this area.",
            "score": 75.1464227437973
        },
        {
            "docid": "35988954_6",
            "document": "Sensory enhancement theory of object-based attention . Converging evidence of sensory enhancement has been found in functional magnetic resonance imaging (\"f\"MRI) studies. A study by O'Craven, Downing and Kanwisher (1999) found that when their participants attended to one attribute (face or house) this led to an enhancement of the blood oxygenation level dependent (BOLD) signal change in the area of the brain that was responsible for processing that specific attribute as well as the brain region that is associated with processing task-irrelevant attributes that belong to the attended as opposed to the unattended object. Neural activation related to attributes that were not relevant to the task differed in relation to whether the attribute belonged to the attended or unattended object which supports sensory enhancement. It would suggest that attention is enhancing the neural representations of the objects attributes as a whole regardless of the relevance to the task.",
            "score": 120.19464540481567
        },
        {
            "docid": "32018467_7",
            "document": "Christian Keysers . After finishing his master, Christian Keysers decided to concentrate on a subfield of cognitive neuroscience called social neuroscience that uses neuroscience methods to understand how we process the social world. He therefore performed his doctoral studies at the University of St Andrews with David Ian Perrett, one of the founding father of the field, to understand how the brain processes faces and facial expressions. This thesis work led to new insights into how quickly the brain can process the faces of others. During this period, Keysers became fascinated with the question of how the brain can attach meaning to the faces of others. How is it for instance, that we understand that a certain grimace would signal that another person is happy? How do we understand that a certain bodily movement towards a glass indicates that the other person aims to grasp a glass? In 1999, Keysers was exposed to a visit of Vittorio Gallese, who presented his recent discovery of mirror neurons in the Psychology department lecture series. This deeply influenced Keysers who decided to move to the lab of Giacomo Rizzolatti to undertake further studies on how these fascinating neurons could contribute to social perception. In 2000, after finishing his doctorate, Christian Keysers moved to the University of Parma to study mirror neurons. In early work there demonstrated that mirror neurons in the premotor cortex not only respond to the sight of actions, but also when actions can only be deduced or heard, leading to a publication in the journal \"Science\". This work had tremendous impact on the field, as it suggested that the premotor cortex could play a central, modality independent role in perception and may lay the origin for the evolution of speech in humans.  Together this work indicated that brain regions involved in our own actions play a role in how we process the actions of others. Keysers wondered whether a similar principle may underlie how we process the tactile sensations and emotions of others, and became increasingly independent of the research focus on the motor system in Parma. At the time, Keysers had also met his to be wife, Valeria Gazzola, a biologist in the final phases of her studies, and together they decided to explore if the somatosensory system might be involved in perceiving the sensations of others. Via a fruitful collaboration with the French neuroimaging specialist Bruno Wicker, they used functional magnetic resonance imaging, and showed for the first time, that the secondary somatosensory cortex, previously thought only to represent a persons own experiences of touch, is also activated when seeing someone or something else be touched. They also showed that the insula, thought only to respond to the experience of first-hand emotions, was also activated when we see another individual experience similar emotions. Together this indicated a much more general principle than the original mirror neuron theory, in which people process the actions, sensations and emotions of others by vicariously activating owns own actions, sensations and emotions. Jointly, this work laid the foundation of the neuroscientific investigation of empathy.",
            "score": 91.5894103050232
        },
        {
            "docid": "5626_28",
            "document": "Cognitive science . Brain imaging involves analyzing activity within the brain while performing various tasks. This allows us to link behavior and brain function to help understand how information is processed. Different types of imaging techniques vary in their temporal (time-based) and spatial (location-based) resolution. Brain imaging is often used in cognitive neuroscience.",
            "score": 111.9500720500946
        }
    ],
    "r": [
        {
            "docid": "42382929_4",
            "document": "Now You See It (Cathy Davidson book) . In \"Now You See It: How the Brain Science of Attention Will Transform the Way We Live, Work, and Learn\" Cathy Davidson examines the phenomenon of attention blindness: humans perceive only a fraction of everything going on around us, particularly when we're focusing intently on one specific task, and that this attention blindness does not properly prepare us for the multi-task oriented digital age. According to Davidson, attention blindness is a basic neurological feature of the human brain. In the introduction of \"Now You See It,\" Davidson describes attending a lecture on attention blindness which addressed the tendency of the human brain to concentrate intensely on one task at the expense of missing almost everything else. To demonstrate this tendency, the lecturer showed a video of six people passing basketballs back and forth, and instructed viewers to count the number of tosses only between those wearing white shirts. Many people correctly counted fifteen tosses, yet nearly everyone failed to see someone in a full gorilla suit stride in among those tossing basketballs, then walk away. Davidson, who is dyslexic, didn\u2019t even try to keep count, but instead decided to relax as she watched the tape, and thus, she noticed the gorilla.",
            "score": 163.42262268066406
        },
        {
            "docid": "1781678_14",
            "document": "Cocktail party effect . Some of the earliest work in exploring mechanisms of early selective attention was performed by Donald Broadbent, who proposed a theory that came to be known as the \"filter model\". This model was established using the dichotic listening task. His research showed that most participants were accurate in recalling information that they actively attended to, but were far less accurate in recalling information that they had not attended to. This led Broadbent to the conclusion that there must be a \"filter\" mechanism in the brain that could block out information that was not selectively attended to. The filter model was hypothesized to work in the following way: as information enters the brain through sensory organs (in this case, the ears) it is stored in sensory memory, a buffer memory system that hosts an incoming stream of information long enough for us to pay attention to it. Before information is processed further, the filter mechanism allows only attended information to pass through. The selected attention is then passed into working memory, the set of mechanisms that underlies short-term memory and communicates with long-term memory. In this model, auditory information can be selectively attended to on the basis of its physical characteristics, such as location and volume. Others suggest that information can be attended to on the basis of Gestalt features, including continuity and closure. For Broadbent, this explained the mechanism by which people can choose to attend to only one source of information at a time while excluding others. However, Broadbent's model failed to account for the observation that words of semantic importance, for example the individual's own name, can be instantly attended to despite having been in an unattended channel.",
            "score": 151.5088653564453
        },
        {
            "docid": "37940820_23",
            "document": "Emotion perception . Researchers employ several methods designed to examine biases toward emotional stimuli to determine the salience of particular emotional stimuli, population differences in emotion perception, and also attentional biases toward or away from emotional stimuli. Tasks commonly utilized include the modified Stroop task, the dot probe task, visual search tasks, and spatial cuing tasks.  The Stroop task, or modified Stroop task, displays different types of words (e.g., threatening and neutral) in varying colors. The participant is then asked to identify the color of the word while ignoring the actual semantic content. Increased response time to indicate the color of threat words relative to neutral words suggests an attentional bias toward such threat. The Stroop task, however, has some interpretational difficulties in addition to the lack of allowance for the measurement of spatial attention allocation. To address some of the limitations of the Stroop task, the dot probe task displays two words or pictures on a computer screen (either one at the top or left and the other on the bottom or right, respectively) and after a brief stimuli presentation, often less than 1000ms, a probe appears in the location of one of the two stimuli and participants are asked to press a button indicating the location of the probe. Different response times between target (e.g., threat) and neutral stimuli infer attentional biases to the target information with shorter response times for when the probe is in the place of the target stimuli indicating an attention bias for that type of information. In another task that examines spatial attentional allocation, the visual search task asks participants to detect a target stimulus embedded in a matrix of distractors (e.g., an angry face among several neutral or other emotional faces or vice versa). Faster detection times to find emotional stimuli among neutral stimuli or slower detection times to find neutral stimuli among emotional distractors infer an attentional bias for such stimuli. The spatial cuing task asks participants to focus on a point located between two rectangles at which point a cue is presented, either in the form of one of the rectangles lighting up or some emotional stimuli appearing within one of the rectangles and this cue either directs attention toward or away from the actual location of the target stimuli. Participants then press a button indicating the location of the target stimuli with faster response times indicating an attention bias toward such stimuli.",
            "score": 150.36141967773438
        },
        {
            "docid": "1781678_17",
            "document": "Cocktail party effect . Diana Deutsch, best known for her work in music perception and auditory illusions, has also made important contributions to models of attention. In order to explain in more detail how words can be attended to on the basis of semantic importance, Deutsch & Deutsch and Norman proposed a model of attention which includes a second selection mechanism based on meaning. In what came to be known as the Deutsch-Norman model, information in the unattended stream is not processed all the way into working memory, as Treisman's model would imply. Instead, information on the unattended stream is passed through a secondary filter after pattern recognition. If the unattended information is recognized and deemed unimportant by the secondary filter, it is prevented from entering working memory. In this way, only immediately important information from the unattended channel can come to awareness.  Daniel Kahneman also proposed a model of attention, but it differs from previous models in that he describes attention not in terms of selection, but in terms of capacity. For Kahneman, attention is a resource to be distributed among various stimuli, a proposition which has received some support. This model describes not \"when\" attention is focused, but \"how\" it is focused. According to Kahneman, attention is generally determined by arousal; a general state of physiological activity. The Yerkes-Dodson law predicts that arousal will be optimal at moderate levels - performance will be poor when one is over- or under-aroused. Of particular relevance, Narayan et al. discovered a sharp decline in the ability to discriminate between auditory stimuli when background noises were too numerous and complex - this is evidence of the negative effect of overarousal on attention. Thus, arousal determines our available capacity for attention. Then, an \"allocation policy\" acts to distribute our available attention among a variety of possible activities. Those deemed most important by the allocation policy will have the most attention given to them. The allocation policy is affected by \"enduring dispositions\" (automatic influences on attention) and \"momentary intentions\" (a conscious decision to attend to something). \"Momentary intentions\" requiring a focused direction of attention rely on substantially more attention resources than \"enduring dispositions\". Additionally, there is an ongoing evaluation of the particular demands of certain activities on attention capacity. That is to say, activities that are particularly taxing on attention resources will lower attention capacity and will influence the allocation policy - in this case, if an activity is too draining on capacity, the allocation policy will likely cease directing resources to it and instead focus on less taxing tasks. Kahneman's model explains the cocktail party phenomenon in that \"momentary intentions\" might allow one to expressly focus on a particular auditory stimulus, but that \"enduring dispositions\" (which can include new events, and perhaps words of particular semantic importance) can capture our attention. It is important to note that Kahneman's model doesn't necessarily contradict selection models, and thus can be used to supplement them.",
            "score": 147.1855010986328
        },
        {
            "docid": "2138419_3",
            "document": "Rapid serial visual presentation . There is a delay of several hundred milliseconds. A person might be asked to identify numbers in a string of letters which are shown one by one. The first number which is an important target, would be caught by the person, however, the second number flashed seconds later might not be observed. RSVP asks the question, What would reading be like if there were no eye movements? A text is delivered at a spot on the screen, like a series of flash cards. The user can set how long each card is to be displayed. The readers are liberated from having to decide how much time to spend on each word because that is set in advance, and saccades, regressive eye movements, line sweeps, and page turning have been eliminated. A reader can fully concentrate on comprehending the text as it flashes through, however, with longer texts the reading experience is found to be monotonous and exhausting. There are a number of theories to explain how and why this works and studies have explored its limitations and parameters to learn more about visual perception. The brain deals with a quick stream of incoming information at all times. With the attentional blink, the brain has to distribute its attentional resources to comprehend, interpret, and store the information properly. The human brain is capable of processing complex tasks, but it has restrictions. The attentional blink is an illustration that has a significant insinuation for individuals who work in environments where they are usually swamped with information. An example of this is an airport baggage screener who might see a knife in one bag, but misses a second knife in another bag that is right behind the first bag. The failure to recognize the second target is because of the attentional processes that are linked with the identification of the first target.",
            "score": 144.64199829101562
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 144.4398651123047
        },
        {
            "docid": "34780199_18",
            "document": "Broadbent's filter model of attention . Deutsch and Norman were not fully convinced by Broadbent's selection criteria based solely on physical features of a stimulus. For example, the cocktail party effect influenced researchers to look further than physical selection features, to semantic selecting features. The cocktail party effect is an example of how unattended information can gain one's attention. Suppose you were at a social gathering having a conversation with some friends, when you hear someone in a different conversation mention your name and it grasps your attention. This unattended-to information somehow gained your attention and was processed beyond its physical characteristics, for its meaning. Deutsch and Deutsch proposed a late selection model and suggested that people can recognize the information from both channels, but if the information does not have any personal relevance, the information will be forgotten Therefore, the issue is not a lack of perceptual processing, but rather the information has not entered into memory. Norman stated that not only is personal relevance necessary for attention, but so is the strength of the stimuli. This fueled the development of the memory selection model, which shares the same basic principle of early selection models that stimulus features are selected via their physical properties. However, attended and unattended information pass through the filter, to a second stage of selection on the basis of semantic characteristics or message content. Items which are selected are incorporated into short-term memory. Therefore, it is the second selection mechanism, rather than the filter, decides what information is attended to.",
            "score": 143.9626922607422
        },
        {
            "docid": "102958_11",
            "document": "Roger Wolcott Sperry . Working with his graduate student Michael Gazzaniga, Sperry invited several of the \"split-brain\" patients to volunteer to take part in his study to determine if the surgery affected their functioning. These tests were designed to test the patients' language, vision, and motor skills. When a person views something in the left visual field (that is on the left side of their body), the information travels to the right hemisphere of the brain and vice versa. In the first series of tests, Sperry would present a word to either the left or right visual field for a short period of time. If the word was shown to the right visual field, meaning the left hemisphere would process it, then the patient could report seeing the word. If the word was shown to the left visual field, meaning the right hemisphere would process it, then the patient could not report seeing the word. This led Sperry to believe that only the left side of the brain could articulate speech. However, in a follow-up experiment, Sperry discovered that the right hemisphere does have some language abilities. In this experiment, he had the patients place their left hands in a tray full of objects located under a partition so the patient would not be able to see the objects. Then a word was shown to the patient's left visual field, which was processed by the right side of the brain. This word described one of the objects in the tray, so the patient's left hand picked up the object corresponding to the word. When participants were asked about the word and the object in their hand, they claimed they had not seen the word and had no idea why they were holding the object. The right side of the brain had recognized the word and told the left hand to pick it up, but because the right side of the brain cannot speak and the left side of the brain had not seen the word, the patient could not articulate what they had seen.",
            "score": 142.5631103515625
        },
        {
            "docid": "35182952_7",
            "document": "Embodied language processing . Experiential Trace Hypothesis states that each time an individual interacts with the world, traces of that particular experience are left in our brain. These traces can be accessed again when a person thinks of words or sentences that remind them of that experience. Additionally, these traces in our brain are linked to the action that they are related to. Words and sentences become those cues that retrieve these traces from our mind. Researchers have studied if the previous experience with a word, such as its location (up or down) in space, affects how people understand and then respond to that word. In one experiment, researchers hypothesized that if reading an object word also activates a location that is linked to that noun, then the following action response should be compatible with that association. They found that participants were faster to push a button higher than another button when the word was associated with being \"up\" or \"above\" than when the button was lower than the other for words associated with \"up\" and \"above\". The results of this study displayed that participants were faster to respond when the location of the word and the action they had to perform were similar. This demonstrates that language processing and action are connected. This research also found that the location information of a word is automatically activated after seeing the word. In a similar study, it was discovered that participants were equally as fast at responding to words that were associated with either an upward or downward location when the buttons to respond to these words were horizontal \u2013 meaning that the experiential trace effect was ruled out when the responding action did not link to either of the locations that were activated.",
            "score": 141.680419921875
        },
        {
            "docid": "195552_35",
            "document": "Artificial consciousness . In 2011, Michael Graziano and Sabine Kastler published a paper named \"Human consciousness and its relationship to social neuroscience: A novel hypothesis\" proposing a theory of consciousness as an attention schema. Graziano went on to publish an expanded discussion of this theory in his book \"Consciousness and the Social Brain\". This Attention Schema Theory of Consciousness, as he named it, proposes that the brain tracks attention to various sensory inputs by way of an attention schema, analogous to the well study body schema that tracks the spatial place of a person's body. This relates to artificial consciousness by proposing a specific mechanism of information handling, that produces what we allegedly experience and describe as consciousness, and which should be able to be duplicated by a machine using current technology. When the brain finds that person X is aware of thing Y, it is in effect modeling the state in which person X is applying an attentional enhancement to Y. In the attention schema theory, the same process can be applied to oneself. The brain tracks attention to various sensory inputs, and one's own awareness is a schematized model of one's attention. Graziano proposes specific locations in the brain for this process, and suggests that such awareness is a computed feature constructed by an expert system in the brain.",
            "score": 140.4454345703125
        },
        {
            "docid": "297067_7",
            "document": "Fregoli delusion . Injury to the right frontal and left temporo-parietal areas can cause Fregoli syndrome. Research by Feinberg, et al. has shown that significant deficits in executive and memory functions follow shortly after damage in the right frontal or left temporoparietal areas. Tests performed on patients that have suffered from a brain injury revealed that basic attention ability and visuomotor processing speed are typically normal. However, these patients made many errors when they were called to participate in detailed attention tasks. Selective attention tests involving auditory targets were also performed, and brain-injured patients had many errors; this meant that they were deficient in their response regulation and inhibition.",
            "score": 138.19198608398438
        },
        {
            "docid": "22509570_17",
            "document": "Lateralized readiness potential . The flankers task requires blocking out irrelevant distractors from the environment, but what if the relevant and irrelevant features are embedded in one target stimulus? This is often the case in the classic Stroop task, such as when one must inhibit their natural response to read a word by responding to only the ink color that the word is printed in. This requires focusing on the task-relevant features of a given stimulus while ignoring task-irrelevant features of the same stimulus. Is information about both features processed simultaneously? The LRP has been used to investigate transmission of partial information in this context. A nice example is in a paper co-authored by one of the first to discover the LRP, Dr. Gabriele Gratton. In this study, the subject performs a spatial stroop task, where they are cued to respond to an upcoming word that is either the word \"ABOVE\" or the word \"BELOW\" presented either physically above or below a central fixation cross. Subjects were cued (in random order) to respond to either the physical position of the word or to the conceptual meaning of the word. Responses are typically slower and less accurate when word position and meaning are inconsistent. For all conditions, the left and right hand button responses corresponded to the two response options. The research question was whether during the spatial stroop task conflict on position-inconsistent (or, incongruent) trials is represented in the motor response stage as can be indexed by the LRP. If an LRP was evident for incongruent trials, this suggests information about the irrelevant stimulus feature was processed at the response stage even on correct trials and this generated response conflict, again supporting a model of continuous information processing. Indeed, the results supported this hypothesis. The study also collected event-related optical signal (EROS) data, which has a spatial resolution for imaging cortical activity in-vivo that is somewhat more coarse than functional magnetic resonance imaging, but has a temporal precision similar to event-related potentials (ERPs). Using EROS they showed that at least one source of the LRP was the motor cortex ipsilateral to the response hand, supporting response conflict in the primary motor cortex as one source of conflict in the stroop task.",
            "score": 137.82432556152344
        },
        {
            "docid": "26685741_28",
            "document": "Sleep and memory . A blood-oxygen-level dependent (BOLD) fMRI was used in a study by Drummond et al. to measure the brain's response to verbal learning following sleep deprivation. An fMRI recorded brain activity during a verbal learning task of participants either having a normal night of sleep or those deprived of 34.7 (\u00b1 1.2) hours of sleep. The task alternated between a baseline condition of determining whether nouns were upper or lower case and an experimental condition of memorizing a list of nouns. The results of the study indicate that performance is significantly worse on free recall of the list of nouns when sleep deprived (an average of 2.8 \u00b1 2 words) compared to having a normal night of sleep (4.7 \u00b1 4 words). In terms of brain regions activated, the left prefrontal cortex, premotor cortex, and temporal lobes were found to be activated during the task in the rested state and discrete regions of the prefrontal cortex were even more activated during the task in the sleep deprived state. As well, the bilateral parietal lobe, left middle frontal gyrus, and right interior frontal gyrus were found to be activated for those sleep deprived. The implication of these findings are that the brain can initially compensate for the effects of sleep deprivation while maintaining partially intact performance, which declines with an increasing time-on-task. This initial compensation may be found in the bilateral regions of both frontal and parietal lobes and the activation of the prefrontal cortex is significantly correlated with sleepiness.",
            "score": 136.20838928222656
        },
        {
            "docid": "1038051_12",
            "document": "Stroop effect . The posterior dorsolateral prefrontal cortex creates the appropriate rules for the brain to accomplish the current goal. For the Stroop effect, this involves activating the areas of the brain involved in color perception, but not those involved in word encoding. It counteracts biases and irrelevant information, for instance, the fact that the semantic perception of the word is more striking than the color in which it is printed. Next, the mid-dorsolateral prefrontal cortex selects the representation that will fulfil the goal. The relevant information must be separated from irrelevant information in the task; thus, the focus is placed on the ink color and not the word.  Furthermore, research has suggested that left dorsolateral prefrontal cortex activation during a Stroop task is related to an individual's\u2019 expectation regarding the conflicting nature of the upcoming trial, and not so much on the conflict itself. Conversely, the right dorsolateral prefrontal cortex aims to reduce the attentional conflict and is activated after the conflict is over.",
            "score": 133.90087890625
        },
        {
            "docid": "6331719_8",
            "document": "Mind-wandering . Jonathan Smallwood and colleagues popularized mind-wandering using thought sampling and questionnaires. Mind-wandering is studied by finding lapses of external attention in participants. One method to study mind-wandering is the SART (sustained attention to response) task. In a SART task there are two categories of words. One of the categories are the target words. In each block of the task a word appears for about 300 ms, there will be a pause and then another word. When a target word appears the participant hits a designated key. About 60% of the time after a target word a thought probe will appear to gauge whether thoughts were on task. If participants were not engaged in the task they were experiencing task-unrelated thoughts (TUTs), signifying mind-wandering. Another task to judge TUTs is the experience sampling method (ESM). Participants carry around a personal digital assistant (PDA) that signals several times a day. At the signal a questionnaire is provided. The questionnaire questions vary but can include: (a) whether or not their minds had wandered at the time of the (b) what state of control they had over their thoughts and (c) about the content of their thoughts. Questions about context are also asked to measure the level of attention necessary for the task. One process used was to give participants something to focus on and then at different times ask them what they were thinking about. Those who were not thinking about what was given to them were considered \"wandering\". Another process was to have participants keep a diary of their mind-wandering. Participants are asked to write a brief description of their mind-wandering and the time in which it happened. These methodologies are improvements on past methods that were inconclusive.",
            "score": 133.44334411621094
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 132.86935424804688
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 131.99325561523438
        },
        {
            "docid": "31329046_5",
            "document": "Pre-attentive processing . The \"contingent-capture\" model emphasizes the idea that a person\u2019s current intentions and/or goals affect the speed and efficiency of pre-attentive processing. The brain directs an individual\u2019s attention towards stimuli with features that fit in with their goals. Consequently, these stimuli will be processed faster at the pre-attentive stage and will be more likely to be selected for attentive processing. Since this model focuses on the importance of conscious processes (rather than properties of the stimulus itself) in selecting information for attentive processing, it is sometimes called \"top-down\" selection. In support of this model, it has been shown that a target stimulus can be located faster if it is preceded by the presentation of a similar, priming stimulus. For example, if an individual is shown the color green and then required to find a green circle among distractors, the initial exposure to the color will make it easier to find the green circle. This is because they are already thinking about and envisioning the color green, so when it shows up again as the green circle, their brain readily directs its attention towards it. This suggests that processing an initial stimulus speeds up a person\u2019s ability to select a similar target from pre-attentive processing. However, it could be that the speed of pre-attentive processing itself is not affected by the first stimulus, but rather that people are simply able to quickly abandon dissimilar stimuli, enabling them to re-engage to the correct target more quickly. This would mean that the difference in reaction time occurs at the attentive level, after pre-attentive processing and stimulus selection has already taken place.",
            "score": 130.98175048828125
        },
        {
            "docid": "35988494_2",
            "document": "Selective auditory attention . Selective auditory attention or selective hearing is a type of selective attention and involves the auditory system of the nervous system. Selective hearing is characterized as the action in which people focus their attention on a specific source of a sound or spoken words. The sounds and noise in the surrounding environment is heard by the auditory system but only certain parts of the auditory information are processed in the brain. Most often, auditory attention is directed at things people are most interested in hearing. In an article by Krans, Isbell, Giuliano, and Neville (2013), selective auditory attention is defined as the ability to acknowledge some stimuli while ignoring other stimuli that is occurring at the same time. An example of this is a student focusing on a teacher giving a lesson and ignoring the sounds of classmates in a rowdy classroom (p.\u00a053). This is an example of bottlenecking which means that information cannot be processed simultaneously so only some sensory information gets through the \"bottleneck\" and is processed. A brain simply cannot process all sensory information that is occurring in an environment so only that which is most important is thoroughly processed. Selective hearing is not a physiological disorder but rather it is the capability of humans to block out sounds and noise. It is the notion of ignoring certain things in the surrounding environment. Over the years, there has been increased research in the selectivity of auditory attention, namely selective hearing.",
            "score": 130.75762939453125
        },
        {
            "docid": "11707911_10",
            "document": "Human multitasking . Some research suggests that the human brain can be trained to multitask. A study published in Child Development by Monica Luciana, associate professor of psychology at the University of Minnesota, discovered that the brain\u2019s capability of categorizing competing information continues to develop until ages sixteen and seventeen. A study by Vanderbilt University found that multitasking is largely limited by \u201cthe speed with which our prefrontal cortex processes information.\u201d Paul E. Dux, the co-author of the study, believes that this process can become faster through proper training. The study trained seven people to perform two simple tasks, either separately or together and conducted brain scans of the participants. The individuals multitasked poorly at first but, with training, were able to adeptly perform the tasks simultaneously. Brain scans of the participants indicate that the prefrontal cortex quickened its ability to process the information, enabling the individuals to multitask more efficiently. However, the study also suggests that the brain is incapable of performing multiple tasks at one time, even after extensive training. This study further indicates that, while the brain can become adept at processing and responding to certain information, it cannot truly multitask.",
            "score": 130.61373901367188
        },
        {
            "docid": "32036278_10",
            "document": "Dichotic listening . In selective attention experiments, the participants may be asked to repeat aloud the content of the message they are listening to. This task is known as shadowing. As Colin Cherry (1953) found, people do not recall the shadowed message well, suggesting that most of the processing necessary to shadow the attended to message occurs in working memory and is not preserved in the long-term store. Performance on the unattended message is worse. Participants are generally able to report almost nothing about the content of the unattended message. In fact, a change from English to German in the unattended channel frequently goes unnoticed. However, participants are able to report that the unattended message is speech rather than non-verbal content. In addition to this, if the content of the unattended message contains certain information, such as the listener's name, then the unattended message is more likely to be noticed and remembered. A demonstration of this was done by Conway, Cowen, and Bunting (2001) in which they had subjects shadow words in one ear while ignoring words in the other ear. At some point, the subject's name was spoken in the ignored ear, and the question was whether the subject would report hearing their name. Subjects with a high working memory (WM) span were more capable of blocking out the distracting information. Also if the message contains sexual words then people usually notice them immediately. This suggests that the unattended information is also undergoing analysis and keywords can divert attention to it.",
            "score": 130.51893615722656
        },
        {
            "docid": "1781678_2",
            "document": "Cocktail party effect . The cocktail party effect is the phenomenon of the brain's ability to focus one's auditory attention (an effect of selective attention in the brain) on a particular stimulus while filtering out a range of other stimuli, as when a partygoer can focus on a single conversation in a noisy room. Listeners have the ability to both segregate different stimuli into different streams, and subsequently decide which streams are most pertinent to them. Thus, it has been proposed that one's sensory memory subconsciously parses all stimuli, identifying discrete pieces of information and classifying them by salience. This effect is what allows most people to \"tune into\" a single voice and \"tune out\" all others. It may also describe a similar phenomenon that occurs when one may immediately detect words of importance originating from unattended stimuli, for instance hearing one's name among a wide range of auditory input.",
            "score": 128.9976806640625
        },
        {
            "docid": "39068271_7",
            "document": "Automatic and controlled processes . One definition of a controlled process is an intentionally-initiated sequence of cognitive activities. In other words, when attention is required for a task, we are consciously aware and in control. Controlled processes require us to think about situations, evaluate and make decisions. An example would be reading this article. We are required to read and understand the concepts of these processes and it takes effort to think conceptually. Controlled processes are thought to be slower, since by definition they require effortful control; therefore, they generally cannot be conducted simultaneously with other controlled processes without task-switching or impaired performance. So the drawback of controlled processes is that humans are thought to have a limited capacity for overtly controlling behavior. Being tightly capacity-limited, controlled processing imposes considerable limitations on speed and the ability to multitask. In a study, participants were randomly assigned into two conditions, one requiring one task (small cognitive load) and one requiring two tasks (heavy cognitive load). In the one-task condition, participants were told that they would hear an anti- or pro-abortion speech and would have to diagnose the speaker's attitude toward abortion. The two-task condition had the same first assignment, but they were required to switch spots with the speaker and take their place after that. Even after being specifically told that they would be given further instructions at the next step, their cognitive load was affected in this study. Participants in the two-task condition performed more poorly than the one-task condition simply because they had the next task on their mind (they had extra cognitive load). Basically, the more tasks someone tries to manage at the same time, the more their performance will suffer.",
            "score": 128.41409301757812
        },
        {
            "docid": "33912_20",
            "document": "Working memory . None of these hypotheses can explain the experimental data entirely. The resource hypothesis, for example, was meant to explain the trade-off between maintenance and processing: The more information must be maintained in working memory, the slower and more error prone concurrent processes become, and with a higher demand on concurrent processing memory suffers. This trade-off has been investigated by tasks like the reading-span task described above. It has been found that the amount of trade-off depends on the similarity of the information to be remembered and the information to be processed. For example, remembering numbers while processing spatial information, or remembering spatial information while processing numbers, impair each other much less than when material of the same kind must be remembered and processed. Also, remembering words and processing digits, or remembering digits and processing words, is easier than remembering and processing materials of the same category. These findings are also difficult to explain for the decay hypothesis, because decay of memory representations should depend only on how long the processing task delays rehearsal or recall, not on the content of the processing task. A further problem for the decay hypothesis comes from experiments in which the recall of a list of letters was delayed, either by instructing participants to recall at a slower pace, or by instructing them to say an irrelevant word once or three times in between recall of each letter. Delaying recall had virtually no effect on recall accuracy. The interference theory seems to fare best with explaining why the similarity between memory contents and the contents of concurrent processing tasks affects how much they impair each other. More similar materials are more likely to be confused, leading to retrieval competition.",
            "score": 128.33538818359375
        },
        {
            "docid": "10269587_6",
            "document": "Echoic memory . Following Sperling's (1960) procedures on iconic memory tasks, future researchers were interested in testing the same phenomenon for the auditory sensory store. Echoic memory is measured by behavioural tasks where participants are asked to repeat a sequence of tones, words, or syllables that were presented to them, usually requiring attention and motivation. The most famous partial report task was conducted by presenting participants with an auditory stimulus in the left, right, and both ears simultaneously. Then they were asked to report spatial location and category name of each stimulus. Results showed that spatial location was far easier to recall than semantic information when inhibiting information from one ear over the other. Consistent with results on iconic memory tasks, performance on the partial report conditions were far superior to the whole report condition. In addition, a decrease in performance was observed as the interstimulus interval(ISI) (length of time between presentation of the stimulus and recall) increased.",
            "score": 127.94050598144531
        },
        {
            "docid": "45446039_6",
            "document": "Measurement of memory . The information received by the system remains in it for very short period (i.e. 20 sec or slightly more. The most common use of this is reminders or remembering numbers. After that this information either vanishes or is moved to next system of memory. Short-term memory has limited capacity and is often referred to as \"working-memory\", however these are not the same. Working memory involves a different part of the brain and allows you to manipulate it after initial storage. The information that travels from sensory memory to short-term memory must pass through the \"Attention\" gateway. The filter of attention keeps a check between sensory memory and short-term memory. You cannot skip systems of memory, such as jumping directly from sensory input to long-term memory. Sensory input must be actively relayed and filtered by the thalamus to the cortex for short term memory storage. Interestingly enough, olfactory sensory input is the most prevalent in our memory, contrary to the popular belief, as it mostly bypasses the thalamus, and all such information gets encoded directly. If there were no such filter, as with olfaction, all 11 million bits per second of sensory input would flood the brain and make it impossible to think about anything. This \"attention gateway\" created by the thalamus limits what is recorded to the small portion that you more or less tell it to. This is how focusing works.  This system is more permanent and has a virtually unlimited capacity of storage. In this system basic meaning and essence can be stored for hours, days, weeks, and even for years. Much of the information retained here covers the whole life. When required, with appropriate cues, the material is typically retrieved. For studying, in order to maximize information retention, psychologists developed another version (one of many) of the learning cycle:",
            "score": 127.80167388916016
        },
        {
            "docid": "389579_2",
            "document": "Cognitive neuropsychology . Cognitive neuropsychology is a branch of cognitive psychology that aims to understand how the structure and function of the brain relates to specific psychological processes. Cognitive psychology is the science that looks at how mental processes are responsible for our cognitive abilities to store and produce new memories, produce language, recognize people and objects, as well as our ability to reason and problem solve. Cognitive neuropsychology places a particular emphasis on studying the cognitive effects of brain injury or neurological illness with a view to inferring models of normal cognitive functioning. Evidence is based on case studies of individual brain damaged patients who show deficits in brain areas and from patients who exhibit double dissociations. Double dissociations involve two patients and two tasks. One patient is impaired at one task but normal on the other, while the other patient is normal on the first task and impaired on the other. For example, patient A would be poor at reading printed words while still being normal at understanding spoken words, while the patient B would be normal at understanding written words and be poor at understanding spoken words. Scientists can interpret this information to explain how there is a single cognitive module for word comprehension. From studies like these, researchers infer that different areas of the brain are highly specialised. Cognitive neuropsychology can be distinguished from cognitive neuroscience, which is also interested in brain damaged patients, but is particularly focused on uncovering the neural mechanisms underlying cognitive processes.",
            "score": 127.77349853515625
        },
        {
            "docid": "31329046_4",
            "document": "Pre-attentive processing . The \"pure-capture\" model focuses on stimulus salience. If certain properties of a stimulus stand out from its background, the stimulus has a higher chance of being selected for attentive processing. This is sometimes referred to as \"bottom-up\" processing, as it is the properties of the stimuli which affect selection. Since things that affect pre-attentive processing do not necessarily correlate with things that affect attention, stimulus salience may be more important than conscious goals. For example, pre-attentive processing is slowed by sleep deprivation while attention, although less focused, is not slowed. Furthermore, when searching for a particular visual stimulus among a variety of visual distractions, people often have more trouble finding what they are looking for if one or more of the distractions is particularly salient. For example, it is easier to locate a bright, green circle (which is salient) among distractor circles if they are all grey (a bland color) than it is to locate a green circle among distractor circles if some are red (also salient colour). This is thought to occur because the salient red circles attract our attention away from the target green circle. However, this is difficult to prove because when given a target (like the green circle) to search for in a laboratory experiment, participants may generalize the task to searching for anything that stands out, rather than solely searching for the target. If this happens, the conscious goal becomes finding anything that stands out, which would direct the person\u2019s attention towards red distractor circles as well as the green target. This means that a person\u2019s goal, rather than the salience of the stimuli, could be causing the delayed ability to find the target.",
            "score": 127.70502471923828
        },
        {
            "docid": "19146397_16",
            "document": "Adroitness . Because many of the behaviors associated with adroitness are similar to some of the behaviors associated with psychopathy, experiments that delve into the mind of the psychopath can shed light onto some of the brain function involved with the adroitness trait. In 2008, fMRI testing showed that psychopaths are impaired in basic emotional and cognitive functions. Because these functions are controlled by the prefrontal cortex and the temporal lobes of the brain, there must be some problem in these areas. Due to the aforementioned similarities, it follows that people expressing the adroitness trait may also have some kind of problem or damage in these parts of the brain.  The cognitive functions of psychopaths and controls in this study were tested through the use of the Simon paradigm. This test measures reaction time based on stimulus and response locations. In the M\u00fcller et al. study, the stimuli were an X and an O, both of which appeared at different locations on a screen. The participant was required to respond by tapping the right side of a separate screen with their middle finger for X and on the left side with their index finger for O. In the control group, as the task became more difficult, negative emotion interfered with cognition. Essentially, as people became angrier, it became more difficult to accurately complete the task. However, as the psychopaths became angrier, their performance did not change, suggesting that there is a disconnect between the emotional process and cognitive abilities in the psychopathic brain. If psychopaths have trouble connecting emotion to the thinking process, the perhaps those with the adroitness trait do as well. Certainly the ability to manipulate others requires a substantial amount of effort, regardless of emotion. The resource allocation model suggests that negative emotions worsen cognitive performance on difficult tasks because they drain resources that are required for cognitive processes. Manipulation and persuasion are cognitive processes that require a lot of effort due to the number of things that require focus. The art of manipulation requires some element of dishonesty as well as a significant knowledge of both the target as well as the purpose of manipulation, or the ability to fabricate important details. These elements are also required for persuasion. It follows that these processes must require a significant amount of effort, and therefore emotions, especially negative ones, would take resources away from those processes.  Manipulation and persuasion can also be very stressful tasks. Stress is known to cause negative emotions, which are shown to interfere in complex cognitive processes. Therefore, people who express the adroitness trait may suffer from similar damage to the prefrontal cortex and/or temporal lobe as psychopaths.",
            "score": 127.23701477050781
        },
        {
            "docid": "35988494_3",
            "document": "Selective auditory attention . The cocktail party problem was first brought up in 1953 by Colin Cherry. This common problem is how our minds solves the issue of knowing what in the auditory scene is important and combining those in a coherent whole, such as the problem of how we can perceive our friend talking in the midst of a crowded cocktail party. He suggested that the auditory system can filter sounds being heard. Physical characteristics of the auditory information such as speaker's voice or location can improve a person's ability to focus on certain stimuli even if there is other auditory stimuli present. Cherry also did work with shadowing which involves different information being played into both ears and only one ear's information can be processed and remembered (Eysneck, 2012, p.\u00a084). Another psychologist, Albert Bregman, came up with the auditory scene analysis model. The model has three main characteristics: segmentation, integration, and segregation. Segmentation involves the division of auditory messages into segments of importance. The process of combining parts of an auditory message to form a whole is associated with integration. Segregation is the separation of important auditory messages and the unwanted information in the brain. It is important to note that Bregman also makes a link back to the idea of perception. He states that it is essential for one to make a useful representation of the world from sensory inputs around us. Without perception, an individual will not recognize or have the knowledge of what is going on around them. While Begman's seminal work is critical to understanding selective auditory attention, his studies did not focus on the way in which an auditory message is selected, if and when it was correctly segregated from other sounds in a mixture, which is a critical stage of selective auditory attention. Inspired in part by Bregman's work, a number of researchers then set out to link directly work on auditory scene analysis to the processes governing attention, including Maria Chait, Mounya Elhilali, Shihab Shamma, and Barbara Shinn-Cunningham.",
            "score": 127.10491180419922
        },
        {
            "docid": "49045837_6",
            "document": "Spatial ability . Spatial perception is also very relevant in sports. For example, a study found that cricket players who were faster at picking up information from briefly presented visual displays were significantly better batsmen in an actual game. A 2015 study published in the \"Journal of Vision\" found that soccer players had higher perceptual ability for body kinematics such as processing multitasking crowd scenes which involve pedestrians crossing a street or complex dynamic visual scenes. Another study published in the \"Journal of Human Kinetics\" on fencing athletes found that achievement level was highly correlated with spatial perceptual skills such as visual discrimination, visual-spatial relationships, visual sequential memory, narrow attentional focus and visual information processing. A review published in the journal of \"Neuropsychologia\" found that spatial perception involves attributing meaning to an object or space, so that their sensory processing is actually part of semantic processing of the incoming visual information. The review also found that spatial perception involves the human visual system in the brain and the parietal lobule which is responsible for visuomotor processing and visually goal-directed action. Studies have also found that individuals who played first person shooting games had better spatial perceptual skills like faster and more accurate performance in a peripheral and identification task while simultaneously performing a central search. Researchers suggested that, in addition to enhancing the ability to divide attention, playing action games significantly enhances perceptual skills like top-down guidance of attention to possible target locations.",
            "score": 126.4278793334961
        },
        {
            "docid": "3233755_7",
            "document": "Directed attention fatigue . Directed attention, or voluntary attention, requires a great deal of concentration and focus, and is employed in tasks such as problem solving. This type of attention employs the inhibitory mechanisms of the brain, which help block incoming stimuli that are unrelated to the task at hand. Several parts of the brain are involved in maintaining directed attention, primarily those located in the frontal lobe and the parietal lobe of the brain. Specifically, the mechanism of directed attention employs the prefrontal cortex (PFC), the anterior cingulate cortex (ACC) and the brain stem\u2019s basal ganglia. Some fMRI studies have shown that directed attention involves changes in the anterior cingulate cortex and the lateral prefrontal cortex, perhaps as a consequence of increased connectivity between these two areas. Evidence also suggests that the right inferior frontal cortex (IFC) plays a specialized role in response inhibition. It seems that this region plays a key role in the integration of bottom-up response-related information and facilitates goal-directed behavior. While these areas of the brain are known to be involved in DAF, their specific molecular mechanisms in the perpetuation of DAF symptoms are not yet known.",
            "score": 126.27233123779297
        }
    ]
}