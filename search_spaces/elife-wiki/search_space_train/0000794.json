{
    "q": [
        {
            "docid": "25225295_12",
            "document": "Consumer neuroscience . Brand loyalty has been shown to be the result of changes in neural activity in the striatum, which is part of the human action reward system. In order to become brand loyal the brain must make a decision of brand A over brand B, a process which relies on the brain to make predictions based upon expected reward and then evaluate the results to learn loyalty. The brain is required to remember both positive and negative outcomes of previous brand choices in order to accurately be able to make predictions regarding the expected outcome of future brand decisions. For example, a helpful salesman or a discount in price may serve as a reward to encourage future customer loyalty. It is thought that the amygdala and striatum are the two most prominent structures for predicting the outcomes of decisions, and that the brain learns to better predict in part by establishing a larger neural network in these structures.",
            "score": 184.56917119026184
        },
        {
            "docid": "3766002_17",
            "document": "Orbitofrontal cortex . The human OFC is among the least-understood regions of the human brain; but it has been proposed that the OFC is involved in sensory integration, in representing the affective value of reinforcers, and in decision-making and expectation. In particular, the OFC seems to be important in signaling the expected rewards/punishments of an action given the particular details of a situation. In doing this, the brain is capable of comparing the expected reward/punishment with the actual delivery of reward/punishment, thus, making the OFC critical for adaptive learning. This is supported by research in humans, non-human primates, and rodents.",
            "score": 162.11203837394714
        },
        {
            "docid": "448244_11",
            "document": "Caudate nucleus . Meanwhile, behavioral studies provide another layer to the argument: recent studies suggest that the caudate is fundamental to goal direction action, that is, \"the selection of behavior based on the changing values of goals and a knowledge of which actions lead to what outcomes.\" One such study presented rats with levers that triggered the release of a cinnamon flavored solution. After the rats learned to press the lever, the researchers changed the value of the outcome (the rats were taught to dislike the flavor either by being given too much of the flavor, or by making the rats ill after drinking the solution) and the effects were observed. Normal rats pressed the lever less frequently, while rats with lesions in the caudate did not suppress the behavior as effectively. In this way, the study demonstrates the link between the caudate and goal-directed behavior; rats with damaged caudate nuclei had difficulty assessing the changing value of the outcome. In a 2003 human behavioral study, a similar process was repeated, but the decision this time was whether or not to trust another person when money was at stake. While here the choice was far more complex\u2013\u2013the subjects were not simply asked to press a lever, but had to weigh a host of different factors\u2013\u2013at the crux of the study was still behavioral selection based on changing values of outcomes.",
            "score": 147.9393184185028
        },
        {
            "docid": "48548_33",
            "document": "Dopamine . Within the brain, dopamine functions partly as a \"global reward signal\", where an initial phasic dopamine response to a rewarding stimulus encodes information about the salience, value, and context of a reward. In the context of reward-related learning, dopamine also functions as a \"reward prediction error\" signal, that is, the degree to which the value of a reward is unexpected. According to this hypothesis of Wolfram Schultz, rewards that are expected do not produce a second phasic dopamine response in certain dopaminergic cells, but rewards that are unexpected, or greater than expected, produce a short-lasting increase in synaptic dopamine, whereas the omission of an expected reward actually causes dopamine release to drop below its background level. The \"prediction error\" hypothesis has drawn particular interest from computational neuroscientists, because an influential computational-learning method known as temporal difference learning makes heavy use of a signal that encodes prediction error. This confluence of theory and data has led to a fertile interaction between neuroscientists and computer scientists interested in machine learning.",
            "score": 121.8690402507782
        },
        {
            "docid": "52324876_8",
            "document": "Distress tolerance . There are several candidate biological neural network mechanisms for distress tolerance. These proposed brain areas are based on the conceptualization of distress tolerance as a function of reward learning. Within this framework, individuals learn to attune to and pursue reward; reduction of tension in escaping from a stressor is similarly framed as a reward and thus can be learned. Individuals differ in how quickly and for how long they display preferences for pursuing reward or in the case of distress tolerance, escaping from a distressful stimulus. Therefore, brain regions that are activated during reward processing and learning are hypothesized to also serve as neurobiological substrates for distress tolerance. For instance, activation intensity of dopamine neurons projecting to the nucleus accumbens, ventral striatum, and prefrontal cortex is associated with an individual's predicted value of an immediate reward during a learning task. As the firing rate for these neurons increases, individuals predict high values of an immediate reward. During instances in which the predicted value is correct, the basal rate of neuronal firing remains the same. When the predicted reward value is below the actual value, neuronal firing rates increase when the reward is received, resulting in a learned response. When the expected reward value is below the actual value, the firing rate of these neurons decreases below baseline levels, resulting in a learned shift that reduces expectancies about reward value. It is posited that these same dopaminergic firing rates are associated with distress tolerance, in that learning the value of escaping a distressing stimulus is analogous to an estimation of an immediate reward There are several potential clinical implications if these posited distress tolerance substrates are corroborated. It may suggest that distress tolerance is malleable among individuals; interventions that change neuronal firing rates may shift predicted values of behaviors intended to escape a distressor and provide relief, thereby increasing distress tolerance.",
            "score": 168.04351997375488
        },
        {
            "docid": "19337310_46",
            "document": "Rodent . Laboratory (brown) rats may have the capacity for metacognition\u2014to consider their own learning and then make decisions based on what they know, or do not know, as indicated by choices they make apparently trading off difficulty of tasks and expected rewards, making them the first animals other than primates known to have this capacity, but these findings are disputed, since the rats may have been following simple operant conditioning principles, or a behavioral economic model. Brown rats use social learning in a wide range of situations, but perhaps especially so in acquiring food preferences.",
            "score": 139.8751974105835
        },
        {
            "docid": "15895551_8",
            "document": "Disappointment . Disappointed individuals focus on \"upward counterfactuals\"\u2014alternative outcomes that would have been better than the one actually experienced\u2014to the point that even positive outcomes may result in disappointment. One example, supplied by Bell, concerns a lottery win of $10,000.00, an event which will theoretically be perceived more positively if that amount represents the highest possible win in the lottery than if it represents the lowest. Decision analysts operate on the assumption that individuals will anticipate the potential for disappointment and make decisions that are less likely to lead to the experience of this feeling. Disappointment aversion has been posited as one explanation for the Allais paradox, a problematic response in expected utility theory wherein people prove more likely to choose a certain reward than to risk a greater reward while at the same time being willing to attempt a greater reward with lower probability when both options include some risk.",
            "score": 115.4324746131897
        },
        {
            "docid": "15497991_20",
            "document": "BELBIC . O, the orbitofrontal cortex, operates based on the difference between the \"perceived\" (i.e. expected) reward/punishment and the actual \"received\" reward/punishment. This perceived reward/punishment is the one that has been developed in the brain over time using learning mechanisms and it reaches the orbitofrontal cortex via the sensory cortex and the amygdala. The received reward/punishment on the other hand, comes courtesy of the outside world and is the \"actual\" reward/punishment that the specie has just obtained. If these two are identical, the output is the same as always through E. If not, the orbitofronal cortex inhibits and restrains emotional response to make way for further learning. So the path W is only activated in such conditions.",
            "score": 211.43970251083374
        },
        {
            "docid": "8582684_19",
            "document": "Reward system . Rewarding stimuli can drive learning in both the form of classical conditioning (Pavlovian conditioning) and operant conditioning (instrumental conditioning). In classical conditioning, a reward can act as an unconditioned stimulus that, when associated with the conditioned stimulus, causes the conditioned stimulus to elicit both musculoskeletal (in the form of simple approach and avoidance behaviors) and vegetative responses. In operant conditioning, a reward may act as a reinforcing stimulus in that it increases or supports actions that lead to itself. Learned behaviors may or may not be sensitive to the value of the outcomes they lead to; behaviors that are sensitive to the contingency of an outcome on the performance of an action as well as the outcome value are goal-directed, while elicited actions that are insensitive to contingency or value are called habits. This distinction is thought to reflected two forms of learning, model free and model based. Model free learning involves the simple caching and updating of values. In contrast, model based learning involves the storage and construction of an internal model of events that allows inference and flexible prediction. Although pavlovian conditioning is generally assumed to be model free, the incentive salience assigned to a conditioned stimulus is flexible with regard to changes in internal motivational states.",
            "score": 111.58160138130188
        },
        {
            "docid": "45222866_7",
            "document": "Behavioral game theory . Beliefs about other people in a decision-making game are expected to influence ones ability to make rational choices. However, beliefs of others can also cause experimental results to deviate from equilibrium, utility-maximizing decisions. In an experiment by Costa-Gomez (2008) participants were questioned about their first order beliefs about their opponent's actions prior to completing a series of normal-form games with other participants. Participants complied with Nash Equilibrium only 35% of the time. Further, participants only stated beliefs that their opponents would comply with traditional game theory equilibrium 15% of the time. This means participants believed their opponents would be less rational than they really were. The results of this study show that participants do not choose the utility-maximizing action and they expect their opponents to do the same. Also, the results show that participants did not choose the utility-maximizing action that corresponded to their beliefs about their opponent's action. While participants may have believed their opponent was more likely to make a certain decision, they still made decisions as if their opponent was choosing randomly. Another study that examined participants from the TV show Deal or No Deal found divergence from rational choice. Participants were more likely to base their decisions on previous outcomes when progressing through the game. Risk aversion decreased when participants' expectations were not met within the game. For example a subject that experienced a string of positive outcomes was less likely to accept the deal and end the game. The same was true for a subject that experienced primarily negative outcomes early in the game.",
            "score": 89.44232738018036
        },
        {
            "docid": "425938_29",
            "document": "Animal cognition . The use of rules has sometimes been considered an ability restricted to humans, but a number of experiments have shown evidence of simple rule learning in primates and also in other animals. Much of the evidence has come from studies of sequence learning in which the \"rule\" consists of the order in which a series of events occurs. Rule use is shown if the animal learns to discriminate different orders of events and transfers this discrimination to new events arranged in the same order. For example, Murphy \"et al.\" (2008) trained rats to discriminate between visual sequences. For one group ABA and BAB were rewarded, where A=\"bright light\" and B=\"dim light\". Other stimulus triplets were not rewarded. The rats learned the visual sequence, although both bright and dim lights were equally associated with reward. More importantly, in a second experiment with auditory stimuli, rats responded correctly to sequences of novel stimuli that were arranged in the same order as those previously learned. Similar sequence learning has been demonstrated in birds and other animals as well.",
            "score": 137.49828469753265
        },
        {
            "docid": "2215386_19",
            "document": "Deilephila elpenor . \"D. elpenor\", like many other insects, can learn to adapt its behavior to changing environmental conditions. Experiments with \"D. elpenor\" has shown that it can discriminate between various visual stimuli (i.e. color) and associate it with a food reward. This behavior is especially important because the wrong decision when choosing a food source can prove to be a costly mistake in terms of time and energy resources. The experiment was conducted through the use of differently colored artificial flowers. When no reward in the form of nectar was given by the flower, the moth did not further participate in foraging behavior with that particular flower. This demonstrated the moth's need to keep energy expenses as low as possible while foraging.",
            "score": 120.24503254890442
        },
        {
            "docid": "7118482_23",
            "document": "Dog behavior . Two dogs that are contesting possession of a highly valued resource for the first time, if one is in a state of emotional arousal, in pain; if reactivity is influenced by recent endocrine changes, or motivational states such as hunger, then the outcome of the interaction may be different than if none of these factors were present. Equally, the threshold at which aggression is shown may be influenced by a range of medical factors, or, in some cases, precipitated entirely by pathological disorders. Hence, the contextual and physiological factors present when two dogs first encounter each other may profoundly influence the long-term nature of the relationship between those dogs. The complexity of the factors involved in this type of learning means that dogs may develop different \u2018\u2018expectations\u2019\u2019 about the likely response of another individual for each resource in a range of different situations. Puppies learn early not to challenge an older dog and this respect stays with them into adulthood. When adult animals meet for the first time, they have no expectations of the behavior of the other: they will both, therefore, be initially anxious and vigilant in this encounter (characterized by the tense body posture and sudden movements typically seen when two dogs first meet), until they start to be able to predict the responses of the other individual. The outcome of these early adult\u2013adult interactions will be influenced by the specific factors present at the time of the initial encounters. As well as contextual and physiological factors, the previous experiences of each member of the dyad of other dogs will also influence their behavior.",
            "score": 104.32719564437866
        },
        {
            "docid": "99026_25",
            "document": "Basal ganglia . Two models have been proposed for the basal ganglia, one being that actions are generated by a \"critic\" in the ventral striatum and estimates value, and the actions are carried out by an \"actor\" in the dorsal striatum. Another model proposes the basal ganglia acts as a selection mechanism, where actions are generated in the cortex and are selected based on context by the basal ganglia. The CBGTC loop is also involved in reward discounting, with firing increasing with an unexpected or greater than expected reward. One review supported the idea that the cortex was involved in learning actions regardless of their outcome, while the basal ganglia was involved in selecting appropriate actions based on associative reward based trial and error learning.",
            "score": 103.41198086738586
        },
        {
            "docid": "569334_4",
            "document": "Association (psychology) . Edward Thorndike did research in this area and developed the law of effect, where associations between a stimulus and response are affected by the consequence of the response. For example, behaviors increase in strength and/or frequency when they have been followed by reward.\u00a0This occurs because of an association between the behavior and a\u00a0mental representation\u00a0of the reward (such as food). Conversely, receiving a negative consequence lowers the frequency of the behavior due to the negative association. An example of this would be a rat in a cage with a bar lever. If pressing the lever results in a food pellet, the rat will learn to press the lever to receive food. If pressing the lever resulted in an electric shock on the floor of the cage, the rat would learn to avoid pressing the lever.",
            "score": 130.54186749458313
        },
        {
            "docid": "3844076_12",
            "document": "Harold Kelley . The theory is set up with a rewards and costs model similar to those used in game theory. The balance of rewards and costs between partners within a relationship as well as how well rewards and costs compare to what would be expected in another relationship predict relationship quality. Kelley used the economic terminology to defend the idea that people are maximizers of good outcomes (high rewards, low costs) in relationships just as they are with finances or other decision-making. These reward and cost outcomes are often presented in matrices closely resembling the payoff matrices used in game theory, which had also been adapted in psychological research previously but not as comprehensively utilized. In the matrix, person A\u2019s possible actions in the interaction would be listed on the horizontal, and person B\u2019s on the vertical. Each cell within the matrix then represents the reward and cost outcomes for both individuals given the particular combination of A\u2019s and B\u2019s actions. Kelley\u2019s use of the matrices provided an objective visual representation of all possible outcomes in a given interaction.",
            "score": 99.62280631065369
        },
        {
            "docid": "29109801_4",
            "document": "Methastyridone . \"Merck\u2019s behavioral psychopharmacology screening program finally identified one highly promising new antidepressant. Code named MK-202, the chemical increased lever-pressing work output under a range of conditions, in seemingly more adaptive ways than amphetamine. For instance, in the \u201cstrained fixed-ratio\u201d test, designed to measure \u201can animal\u2019s ability to handle an overly large workload with inadequate motivation,\u201d MK-202 performed better than dextroamphetamine. Here, hungry rats were given a drop of condensed milk only after pressing a lever two hundred times in response to a light signal. However, in the middle of their heavy and under-rewarded task a second light would turn on intermittently, and if they immediately responded by pressing a second lever they would get a milk drop instantly. Thus, this experiment measured both willingness to do \u201ca particularly long and tedious job\u201d as well as \u201calertness\u201d to a second stimulus, according to Merck researchers. The rats on amphetamine performed well on the repetitive task but tended to miss the second stimulus; not so the rats on MK-202. Given the similarity between the rat\u2019s situation and the repetitive work that most people must endure to make a living, a drug that increased lever pressing without producing unresponsiveness would seem a likely antidepressant\u2014provided we accept that inefficiency in unrewarding jobs indicates psychiatric depression.\" \"This implicit identification of impaired work efficiency with depressive illness, inscribed in the use of amphetamine-boosted lever pressing as the benchmark that subsequent antidepressants had to meet, applied to the highest level executive type of work also. (The business world is called a \u201crat race\u201d with reason!) This is evident from another test, designed to measure a rat\u2019s capacity to perform complex tasks. Here, to get a reward, rats had to press a lever rapidly when a white light was on, slowly when a red light was on, and not at all when both lights were on. The rats on amphetamine pressed their levers fast no matter what lights were on, but the rats on MK-202 only pressed fast when high speed was rewarded. In these and a half a dozen other experiments with trained rats subject to diabolically ingenious \u201creinforcement schedules\u201d (that is, particular programs of reward and punishment), MK-202 outperformed amphetamine for boosting work output, maximizing reward, and minimizing punishment, particularly when tasks were both difficult and unrewarding. A more promising antidepressant drug candidate could hardly be imagined, and in January 1960 the behavioral psychopharmacology unit passed it on for human testing as an antidepressant, with its highest recommendation.\"",
            "score": 138.61499774456024
        },
        {
            "docid": "35822485_19",
            "document": "Epigenetics of cocaine addiction . Contrary to most studies focusing on the nucleus accumbens, Febo et al. suggested that the reward brain circuitry is not the only system involved in addictive behaviors. Previous knowledge has suggested that stimulants induce changes in gene expression in the main parts of mesolimbic circuitry (including the ventral tegmental area, ventral striatum/nucleus accumbens, and prefrontal cortex) and play a big role in development and maintenance of addicted state and chromatin remodeling. They applied this knowledge to investigate whether these gene expression changes are involved in cocaine related behavioral and molecular adaptations. They found unexpected patterns of brain activation in awake rats that were exposed to sodium butyrate, an HDAC inhibitor (or HDACi). An acute dose resulted in widespread BOLD (blood-oxygen-level dependent) activation in the forebrain and midbrain, but cocaine-induced activation was significantly attenuated after repeat exposure. Sodium butyrate co-treatment with cocaine restored pronounced BOLD activation after successive cocaine treatments. These suggest that the brain\u2019s initial response to repeat cocaine exposure triggers a desensitization mechanism which can be overturned by pretreatment with sodium butyrate. The neural circuitry for the epigenetic modifications contributing to cocaine sensitivity was not the limited to the mesocorticolimbic dopamine system (\u201creward system\u201d) as they expected. Instead, they saw corticolimbic circuitry (implicated in emotion and memory) had a bigger role in HDACi related alterations of reward behaviors. Evidence that HDACi-mediated enhancement of a stimulant\u2019s sensitizing effects is context specific, and involves associative learning.",
            "score": 144.79061675071716
        },
        {
            "docid": "3766002_20",
            "document": "Orbitofrontal cortex . Animal models, and cell specific manipulations in relation to drug seeking behavior implicate dsyfunction of the OFC in addiction. Substance abuse disorders are associated with a variety of deficits related to flexible goal directed behavior and decision making. These deficits overlap with symptoms related to OFC lesions, and are also associated with reduced orbitofrontal grey matter, resting state hypometabolism, and blunted OFC activity during tasks involving decision making or goal directed behavior. In contrast to resting state and decision related activity, cues associated with drugs evoke robust OFC activity that correlates with craving. Rodent studies also demonstrate that lOFC to BLA projections are necessary for cue induced reinstatement of self administration. These findings are all congruent with the role that the OFC plays in encoding the outcomes associated with certain stimuli. The progression towards compulsive substance abuse may reflect a shift between model based decision making, where an internal model of future outcomes guides decisions, to model free learning, where decisions are based on reinforcement history. Model based learning involves the OFC and is flexible and goal directed, while model free learning is more rigid; as shift to more model free behavior due to dysfunction in the OFC, like that produced by drugs of abuse, could underlie drug seeking habits.",
            "score": 136.97993111610413
        },
        {
            "docid": "372045_3",
            "document": "Bee learning and communication . Honey bees are adept at associative learning, and many of the phenomena of operant and classical conditioning take the same form in honey bees as they do in the vertebrates. Efficient foraging requires such learning. For example, honey bees make few repeat visits to a plant if it provides little in the way of reward. A single forager will visit different flowers in the morning and, if there is sufficient reward in a particular kind of flower, she will make visits to that type of flower for most of the day, unless the plants stop producing nectar or weather conditions change.  A relatively recent experiment demonstrates several aspects of bee learning. Foragers were trained to enter a simple Y-shaped maze that had been marked at the entrance with a particular color. Inside the maze was a branching point where the bee was required to choose between two paths. One path, which led to the food reward, was marked with the same color that had been used at the entrance to the maze, while the other was marked with a different color. Foragers learned to choose the correct path, and continued to do so when a different kind of marker (black and white stripes oriented in various directions) was substituted for the colored markers. When the experimental conditions were reversed, rewarding bees for choosing the inner passage marked with a symbol that was different from the entrance symbol, the bees again learned to choose the correct path. Variations in the length of the tunnel between the stimulus markers showed that bees retain information in working memory for about 5 seconds, equivalent to the short-term memory of birds. Altogether, the experiments demonstrated that bees can to choose between alternatives, determine if a stimulus is the same or different than one seen earlier, remember the earlier one for a short period, and generalize this performance to new pairs of stimuli.",
            "score": 132.15266489982605
        },
        {
            "docid": "5212259_6",
            "document": "Pars compacta . \"Dopamine neurons are activated by novel, unexpected stimuli, by primary rewards in the absence of predictive stimuli and during learning\". Dopamine neurons are thought to be involved in learning to predict which behaviours will lead to a reward (for example food or sex). In particular, it is suggested that dopamine neurons fire when a reward is greater than that previously expected; a key component of many reinforcement learning models. This signal can then be used to update the expected value of that action. Many recreational drugs, such as cocaine, mimic this reward response\u2014providing an explanation for their addictive nature.",
            "score": 110.3053023815155
        },
        {
            "docid": "13149599_14",
            "document": "Habit . The following is a description of a classic goal devaluation experiment (from a Scientific American MIND guest blog post called Should Habits or Goals Direct Your Life? It Depends) which demonstrates the difference between goal-directed and habitual behavior: A series of elegant experiments conducted by Anthony Dickinson and colleagues in the early 1980s at the University of Cambridge in England clearly exposes the behavioral differences between goal-directed and habitual processes. Basically, in the training phase, a rat was trained to press a lever in order to receive some food. Then, in a second phase, the rat was placed in a different cage without a lever and was given the food, but it was made ill whenever it ate the food. This caused the rat to \"devalue\" the food, because it associated the food with being ill, without directly associating the action of pressing the lever with being ill. Finally, in the test phase, the rat was placed in the original cage with the lever. (To prevent additional learning, no food was delivered in the test phase.) Rats that had undergone an extensive training phase continued to press the lever in the test phase even though the food was devalued; their behavior was called habitual. Rats that had undergone a moderate training phase did not, and their behavior was called goal-directed. \u2026 [G]oal-directed behavior is explained by the rat using an explicit prediction of the consequence, or outcome, of an action to select that action. If the rat wants the food, it presses the lever, because it predicts that pressing the lever will deliver the food. If the food has been devalued, the rat will not press the lever. Habitual behavior is explained by a strong association between an action and the situation from which the action was executed. The rat presses the lever when it sees the lever, not because of the predicted outcome.",
            "score": 119.10848009586334
        },
        {
            "docid": "596726_5",
            "document": "Expectancy theory . The expectancy theory of motivation explains the behavioral process of why individuals choose one behavioral option over the other. This theory explains that individuals can be motivated towards goals if they believe that there is a positive correlation between efforts and performance, the outcome of a favorable performance will result in a desirable reward, a reward from a performance will satisfy an important need, and/or the outcome satisfies their need enough to make the effort worthwhile. Vroom introduced three variables within the expectancy theory which are valence (V), expectancy (E) and instrumentality (I). The three elements are important behind choosing one element over another because they are clearly defined: effort-performance expectancy (E>P expectancy), performance-outcome expectancy (P>O expectancy).",
            "score": 100.20344519615173
        },
        {
            "docid": "228053_18",
            "document": "Organizational communication . Physical and cognitive, including semantic filters (which decide the meaning of words) combine to form a part of our memory system that helps us respond to reality. In this sense, March and Simon compare a person to a data processing system. Behavior results from an interaction between a person's internal state and environmental stimuli. What we have learned through past experience becomes an inventory, or data bank, consisting of values or goals, sets of expectations and preconceptions about the consequences of acting one way or another, and a variety of possible ways of responding to the situation. This memory system determines what things we will notice and respond to in the environment. At the same time, stimuli in the environment help to determine what parts of the memory system will be activated. Hence, the memory and the environment form an interactive system that causes our behavior. As this interactive system responds to new experiences, new learnings occur which feed back into memory and gradually change its content. This process is how people adapt to a changing world.",
            "score": 111.0427360534668
        },
        {
            "docid": "18345642_14",
            "document": "Behavioral addiction . One of the most important discoveries of addictions has been the drug based reinforcement and, even more important, reward based learning processes. Several structures of the brain are important in the conditioning process of behavioral addiction; these subcortical structures form the brain regions known as the reward system. One of the major areas of study is the amygdala, a brain structure which involves emotional significance and associated learning. Research shows that dopaminergic projections from the ventral tegmental area facilitate a motivational or learned association to a specific behavior.  Dopamine neurons take a role in the learning and sustaining of many acquired behaviors. Research specific to Parkinson\u2019s disease has led to identifying the intracellular signaling pathways that underlie the immediate actions of dopamine. The most common mechanism of dopamine is to create addictive properties along with certain behaviors. There are three stages to the dopamine reward system: bursts of dopamine, triggering of behavior, and further impact to the behavior. Once electronically signaled, possibly through the behavior, dopamine neurons let out a \u2018burst-fire\u2019 of elements to stimulate areas along fast transmitting pathways. The behavior response then perpetuates the striated neurons to further send stimuli. The fast firing of dopamine neurons can be monitored over time by evaluating the amount of extracellular concentrations of dopamine through micro dialysis and brain imaging. This monitoring can lead to a model in which one can see the multiplicity of triggering over a period of time. Once the behavior is triggered, it is hard to work away from the dopamine reward system.",
            "score": 155.60855889320374
        },
        {
            "docid": "36476254_3",
            "document": "T-maze . The T-maze is one of a group of various mazes of differing sizes and many shapes. It is one of the most simple, consisting of just two turns - right or left. The maze is only able to be altered by blocking one of the two paths. The basis behind the T-maze is to place the rat at the base of the maze. By placing a reward at one arm or both arms of the maze, the rat must make the choice of which path to take. The decision made by the rat can be a cause of a natural preference within the rat. A study of alternation can be performed by repeating the experiment multiple times with no reward in either arm of the maze. Another experiment that can be performed is the alternation of rewards each time the experiment is performed, proving the rat will choose the arm that was not visited each time the experiment starts.",
            "score": 152.03250527381897
        },
        {
            "docid": "27797792_26",
            "document": "Construal level theory . Distance or high-level construals can make alternative choices that are hard to accomplish more desirable. Near-future or low-level construals can oppositely make alternative choices that are hard to accomplish less desirable. Risky behavior therefore, can be explained by CLT. High level construals can make more difficult or impossible outcomes more attractive and therefore cause people to take greater risks for less likely outcomes. High-level construals can have an effect of valuing rewards that are more risky, and further in the future. For example, people will take riskier bets when the bet is in the distant than the near future. The ideas of time and probability are often thought of in very similar ways; therefore, they tend to correspond, as one increases the other one does as well. The connections between these two are often made automatically, without the conscious knowledge of the individual. When thinking of investments in a high-level construal, people tend to engage in more risk taking behavior. When thinking about the same investment in a low-level construal, there is more focus on the present and what the risk would mean in terms of the here and now. Thus, focusing on the low level aspects of a decision can deter some risk taking behavior by causing one to focus on the actual details, and lesson an overall possible feeling for the future. Across the overall idea of decision making, CLT has been supported for aiding in the help or harm of organizational decision making processes and outcomes. Research has also examined more common decisions, such as the choice to procrastinate. More concrete activities, or near future events tend to create a more low-level construal, and therefore people are less likely to procrastinate for these functions, than for more abstract activities set further into the future.",
            "score": 107.85163807868958
        },
        {
            "docid": "515094_13",
            "document": "Neuroeconomics . In addition to the importance of specific brain areas to the decision process, there is also evidence that the neurotransmitter dopamine may transmit information about uncertainty throughout the cortex. Dopaminergic neurons are strongly involved in the reward process and become highly active after an unexpected reward occurs. In monkeys, the level of dopaminergic activity is highly correlated with the level of uncertainty such that the activity increases with uncertainty. Furthermore, rats with lesions to the nucleus accumbens, which is an important part of the dopamine reward pathway through the brain, are far more risk averse than normal rats. This suggests that dopamine may be an important mediator of risky behavior.",
            "score": 156.26292204856873
        },
        {
            "docid": "21312313_32",
            "document": "Procedural memory . Dopamine is one of the more known neuromodulators involved in procedural memory. Evidence suggests that it may influence neural plasticity in memory systems by adapting brain processing when the environment is changing and an individual is then forced to make a behavioural choice or series of rapid decisions. It is very important in the process of \"adaptive navigation\", which serves to help different brain areas respond together during a new situation that has many unknown stimuli and features. Dopamine pathways are dispersed all over the brain and this allows for parallel processing in many structures all at the same time. Currently most research points to the mesocorticolimbic dopamine pathway as the system most related to reward learning and psychological conditioning.",
            "score": 136.1092836856842
        },
        {
            "docid": "45222866_9",
            "document": "Behavioral game theory . The role of incentives and consequences in decision-making is interesting to behavioral game theorists because it affects rational behavior. Post (2008) analyzed Deal or no Deal contestant behavior in order to reach conclusions about decision-making when stakes are high. Studying the contestant's choices formed the conclusion that in a sequential game with high stakes decisions were based on previous outcomes rather than rationality. Players who face a succession of good outcomes, in this case they eliminate the low-value cases from play, or players who face a succession of poor outcomes become less risk averse. This means that players who are having exceptionally good or exceptionally bad outcomes are more likely to gamble and continue playing than average players. The lucky or unlucky players were willing to reject offers of over one hundred percent of the expected value of their case in order to continue playing. This shows a shift from risk avoiding behavior to risk seeking behavior. This study highlights behavioral biases that are not accounted for by traditional game theory. Riskier behavior in unlucky contestants can be attributed to the break-even effect, which states that gamblers will continue to make risky decisions in order to win back money. On the other hand, riskier behavior in lucky contestants can be explained by the house-money effect, which states that winning gamblers are more likely to make risky decisions because they perceive that they are not gambling with their own money. This analysis shows that incentives influence rational choice, especially when players make a series of decisions.",
            "score": 71.59970998764038
        },
        {
            "docid": "27797792_12",
            "document": "Construal level theory . Time discounting or temporal discounting is a wide range of ideas involving the connection between time and the extent to which an object, situation, or course of action is seen as valuable. The overall theory is that people put more value and worth into immediate events and outcomes, and apply less value to future outcomes or events. According to Trope and Liberman, CLT can provide a framework with which to understand the broad array of phenomena described by temporal discounting research. Different construals may differ in the extent to which they are associated with positive or negative evaluations. An abstract, high-level construal of an activity (e.g., \"learning to speak French\") may lead to a more positive evaluation of that activity than a concrete, low-level construal (e.g., \"learning to conjugate the irregular French verb 'avoir). Thus, CLT predicts that we will think about the value of the low-level construals when evaluating an event in the near future, but think about the value of the high-level construals when evaluating an event in the distant future. Thus CLT predicts that when low-level construals are more valuable, time delay will discount the attractiveness of an option, but when high-level construals are more valuable, time delay will increase its attractiveness. Thus, the discounting rate is affected and measured by the amount of value placed on the event or outcome. If there is a small reward, it is discounted faster than if the reward were larger.",
            "score": 136.12486517429352
        },
        {
            "docid": "3766002_26",
            "document": "Orbitofrontal cortex . When OFC connections are disrupted, a number of cognitive, behavioral, and emotional consequences may arise. Research supports that the main disorders associated with dysregulated OFC connectivity/circuitry center around decision-making, emotion regulation, and reward expectation. A recent multi-modal human neuroimaging study shows disrupted structural and functional connectivity of the OFC with the subcortical limbic structures (e.g., amygdala or hippocampus) and other frontal regions (e.g., dorsal prefrontal cortex or anterior cingulate cortex) correlates with abnormal OFC affect (e.g., fear) processing in clinically anxious adults. One clear extension of problems with decision-making is drug addiction/substance dependence, which can result from disruption of the striato-thalamo-orbitofrontal circuit. Attention deficit hyperactivity disorder (ADHD) has also been implicated in dysfunction of neural reward circuitry controlling motivation, reward, and impulsivity, including OFC systems. Other disorders of executive functioning and impulse control may be affected by OFC circuitry dysregulation, such as obsessive\u2013compulsive disorder and trichotillomania",
            "score": 158.4175649881363
        }
    ],
    "r": [
        {
            "docid": "15497991_20",
            "document": "BELBIC . O, the orbitofrontal cortex, operates based on the difference between the \"perceived\" (i.e. expected) reward/punishment and the actual \"received\" reward/punishment. This perceived reward/punishment is the one that has been developed in the brain over time using learning mechanisms and it reaches the orbitofrontal cortex via the sensory cortex and the amygdala. The received reward/punishment on the other hand, comes courtesy of the outside world and is the \"actual\" reward/punishment that the specie has just obtained. If these two are identical, the output is the same as always through E. If not, the orbitofronal cortex inhibits and restrains emotional response to make way for further learning. So the path W is only activated in such conditions.",
            "score": 211.439697265625
        },
        {
            "docid": "14511650_49",
            "document": "Impulsivity . Intertemporal choice is commonly measured in the laboratory using a \"delayed discounting\" paradigm, which measures the process of devaluing rewards and punishments that happen in the future. In this paradigm, subjects must choose between a smaller reward delivered soon and a larger reward delivered at a delay in the future. Choosing the smaller-sooner reward is considered impulsive. By repeatedly making these choices, indifference points can be estimated. For example, if someone chose $70 now over $100 in a week, but chose the $100 in a week over $60 now, it can be inferred that they are indifferent between $100 in a week and an intermediate value between $60 and $70. A delay discounting curve can be obtained for each participant by plotting their indifference points with different reward amounts and time delays. Individual differences in discounting curves are affected by personality characteristics such as self-reports of impulsivity and locus of control; personal characteristics such as age, gender, IQ, race, and culture; socioeconomic characteristics such as income and education; and many other variables. Lesions of the nucleus accumbens core subregion or basolateral amygdala produce shifts towards choosing the smaller-sooner reward, suggesting the involvement of these brain regions in the preference for delayed reinforcers. There is also evidence that the orbitofrontal cortex is involved in delay discounting, although there is currently debate on whether lesions in this region result in more or less impulsivity.",
            "score": 195.48228454589844
        },
        {
            "docid": "7753430_32",
            "document": "Psychopathy . Dysfunctions in the prefrontal cortex and amygdala regions of the brain have been associated with specific learning impairments in psychopathy. Since the 1980s, scientists have linked traumatic brain injury, including damage to these regions, with violent and psychopathic behavior. Patients with damage in such areas resembled \"psychopathic individuals\" whose brains were incapable of acquiring social and moral knowledge; those who acquired damage as children may have trouble conceptualizing social or moral reasoning, while those with adult-acquired damage may be aware of proper social and moral conduct but be unable to behave appropriately. Dysfunctions in the amygdala and ventromedial prefrontal cortex may also impair stimulus-reinforced learning in psychopaths, whether punishment-based or reward-based. People scoring 25 or higher in the PCL-R, with an associated history of violent behavior, appear to have significantly reduced mean microstructural integrity in their uncinate fasciculus\u2014white matter connecting the amygdala and orbitofrontal cortex. There is evidence from DT-MRI, of breakdowns in the white matter connections between these two important areas.",
            "score": 195.4325408935547
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 187.0042724609375
        },
        {
            "docid": "1095131_20",
            "document": "Kinesthetic learning . The cerebral cortex is the brain tissue covering the top and sides of the brain in most vertebrates. It is involved in storing and processing of sensory inputs and motor outputs. In the human brain, the cerebral cortex is actually a sheet of neural tissue about 1/8th inch thick. The sheet is folded so that it can fit inside the skull. The neural circuits in this area of the brain expand with practice of an activity, just like the synaptic plasticity grows with practice. Clarification of some of the mechanisms of learning by neuro science has been advanced, in part, by the advent of non-invasive imaging technologies, such as positron emission tomography (PET) and functional magnetic resonance imaging (FMRI). These technologies have allowed researchers to observe human learning processes directly. Through these types of technologies, we are now able to see and study what happens in the process of learning. In different tests performed the brain being imaged showed a greater blood flow and activation to that area of the brain being stimulated through different activities such as finger tapping in a specific sequence. It has been revealed that the process at the beginning of learning a new skill happens quickly, and later on slows down to almost a plateau. This process can also be referred to as The Law of Learning. The slower learning showed in the FMRI that in the cerebral cortex this was when the long term learning was occurring, suggesting that the structural changes in the cortex reflect the enhancement of skill memories during later stages of training. When a person studies a skill for a longer duration of time, but in a shorter amount of time they will learn quickly, but also only retain the information into their short-term memory. Just like studying for an exam; if a student tries to learn everything the night before, it will not stick in the long run. If a person studies a skill for a shorter duration of time, but more frequently and long-term, their brain will retain this information much longer as it is stored in the long-term memory. Functional and structural studies of the brain have revealed a vast interconnectivity between diverse regions of the cerebral cortex. For example, large numbers of axons interconnect the posterior sensory areas serving vision, audition, and touch with anterior motor regions. Constant communication between sensation and movement makes sense, because to execute smooth movement through the environment, movement must be continuously integrated with knowledge about one's surroundings obtained via sensory perception. The cerebral cortex plays a role in allowing humans to do this.",
            "score": 186.89622497558594
        },
        {
            "docid": "1875075_34",
            "document": "Self-control . The prefrontal cortex is located in the most anterior portion of the frontal lobe in the brain. It forms a larger portion of the cortex in humans. The dendrites in the prefrontal cortex contain up to 16 times as many dendritic spines as neurons in other cortical areas. Due to this, the prefrontal cortex integrates a large amount of information. The orbitofrontal cortex cells are important factors for self-control. If an individual has the choice between an immediate reward or a more valuable reward which they can receive later, an individual would most likely try to control the impulse to take that immediate reward. If an individual has a damaged orbitofrontal cortex, this impulse control will most likely not be as strong, and they may be more likely to take the immediate reinforcement. Additionally, we see lack of impulse control in children because the prefrontal cortex develops slowly.",
            "score": 186.3160858154297
        },
        {
            "docid": "538267_11",
            "document": "Karl Lashley . Although Lashley studied many things, his most influential research centered around the cortical basis of learning and discrimination. He researched this by looking at the measurement of behavior before and after specific, carefully quantified, induced brain damage in rats. He trained rats to perform specific tasks (seeking a food reward), then lesioned specific areas of the rats' cortex, either before or after the animals received the training. The cortical lesions had specific effects on acquisition and retention of knowledge, but the location of the removed cortex had no effect on the rats' performance in the maze. This led Lashley to conclude that memories are not localized, but that they are widely distributed across the cortex. Today we know that distribution of engrams does in fact exist, but that the distribution is not equal across all cortical areas, as Lashley assumed. His study of V1 (primary visual cortex) led him to believe that it was a site of learning and memory storage (i.e. an engram) in the brain. He reached this erroneous conclusion due to imperfect lesioning methods.",
            "score": 185.75946044921875
        },
        {
            "docid": "25225295_12",
            "document": "Consumer neuroscience . Brand loyalty has been shown to be the result of changes in neural activity in the striatum, which is part of the human action reward system. In order to become brand loyal the brain must make a decision of brand A over brand B, a process which relies on the brain to make predictions based upon expected reward and then evaluate the results to learn loyalty. The brain is required to remember both positive and negative outcomes of previous brand choices in order to accurately be able to make predictions regarding the expected outcome of future brand decisions. For example, a helpful salesman or a discount in price may serve as a reward to encourage future customer loyalty. It is thought that the amygdala and striatum are the two most prominent structures for predicting the outcomes of decisions, and that the brain learns to better predict in part by establishing a larger neural network in these structures.",
            "score": 184.5691680908203
        },
        {
            "docid": "42744692_10",
            "document": "Marian Diamond . Neuroplasticity: Diamond was a pioneer in anatomical neuroscience whose major scientific contributions have changed forever how we view the human brain. Diamond produced the first scientific evidence of anatomical neuroplasticity in the early 1960s. At that time, the scientific consensus was that the nature of your brain was due to genetics and was unchangeable and fixed. Diamond showed that the structural components of the cerebral cortex can be altered by either enriched or impoverished environments at any age, from prenatal to extremely old age. Her initial anatomical experiment, and replication experiments, with young rats showed that the cerebral cortex of the enriched rats was 6% thicker than the cortex of the impoverished rats based on different kinds of early life experiences. An enriched cortex shows greater learning capacity while an impoverished one shows lesser learning capacity. These paradigm-changing results, published in 1964, helped to launch modern neuroscience.",
            "score": 183.45188903808594
        },
        {
            "docid": "41275963_52",
            "document": "Risk aversion (psychology) . Damasio posited that emotional information in the form of physiological arousal, is needed to inform decision making. When confronted with a decision, we may react emotionally to the situation, a reaction that manifests as changes in physiological arousal in the body, or somatic markers. Given data collected from the Iowa Gambling Task, Damasio postulated that the orbitofrontal cortex assists individuals in forming an association between somatic markers and the situations that trigger them. Once an association is made, the orbitofrontal cortex and other brain areas evaluate an individual\u2019s previous experiences eliciting similar somatic markers. Once recognized, the orbitofrontal cortex can determine an adequate and swift behavioural response, and its likeliness for reward.",
            "score": 182.36244201660156
        },
        {
            "docid": "14511650_50",
            "document": "Impulsivity . Economic theory suggests that optimal discounting involves the exponential discounting of value over time. This model assumes that people and institutions should discount the value of rewards and punishments at a constant rate according to how delayed they are in time. While economically rational, recent evidence suggests that people and animals do not discount exponentially. Many studies suggest that humans and animals discount future values according to a hyperbolic discounting curve where the discount factor decreases with the length of the delay (for example, waiting from today to tomorrow involves more loss of value than waiting from twenty days to twenty-one days). Further evidence for non-constant delay discounting is suggested by the differential involvement of various brain regions in evaluating immediate versus delayed consequences. Specifically, the prefrontal cortex is activated when choosing between rewards at a short delay or a long delay, but regions associated with the dopamine system are additionally activated when the option of an immediate reinforcer is added. Additionally, intertemporal choices differ from economic models because they involve anticipation (which may involve a neurological \"reward\" even if the reinforcer is delayed), self-control (and the breakdown of it when faced with temptations), and representation (how the choice is framed may influence desirability of the reinforcer), none of which are accounted for by a model that assumes economic rationality.",
            "score": 181.90126037597656
        },
        {
            "docid": "33826069_3",
            "document": "Viral neuronal tracing . Most neuroanatomists would agree that understanding how the brain is connected to itself and the body is of paramount importance. As such, it is of equal importance to have a way to visualize and study the connections among neurons. Neuronal tracing methods offer an unprecedented view into the morphology and connectivity of neural networks. Depending on the tracer used, this can be limited to a single neuron or can progress trans-synaptically to adjacent neurons. After the tracer has spread sufficiently, the extent may be measured either by fluorescence (for dyes) or by immunohistochemistry (for biological tracers). An important innovation in this field is the use of neurotropic viruses as tracers. These not only spread throughout the initial site of infection, but can jump across synapses. The use of a virus provides a self-replicating tracer. This can allow for the elucidation of neural microcircuitry to an extent that was previously unobtainable.  This has significant implications for the real world. If we can better understand what parts of the brain are intimately connected, we can predict the effect of localized brain injury. For example, if a patient has a stroke in the amygdala, primarily responsible for emotion, the patient might also have trouble learning to perform certain tasks because the amygdala is highly interconnected with the orbitofrontal cortex, responsible for reward learning. As always, the first step to solving a problem is fully understanding it, so if we are to have any hope of fixing brain injury, we must first understand its extent and complexity.",
            "score": 181.28199768066406
        },
        {
            "docid": "270792_5",
            "document": "Anhedonia . Studies in clinical populations, healthy populations, and animal models have implicated a number of neurobiological substrates in anhedonia. Regions implicated in anhedonia include the prefrontal cortex as a whole, particularly the orbitofrontal cortex (OFC), the striatum, amygdala, anterior cingulate cortex (ACC), hypothalamus, and ventral tegmental area (VTA). Neuroimaging studies in humans have reported that deficits in consummatory aspects of reward are associated with abnormalities in the ventral striatum and medial prefrontal cortex, while deficits in anticipatory aspects of reward are related to abnormalities in hippocampal, dorsal ACC and prefrontal regions. These abnormalities are generally consistent with animal models, except for inconsistent findings with regard to the OFC. This inconsistency may be related to the difficulty in imaging the OFC due to its anatomical location, or the small number of studies performed on anhedonia; a number of studies have reported reduced activity in the OFC in schizophrenia and major depression, as well as a direct relationship between reduced activity and anhedonia. Researchers theorize that anhedonia may result from the breakdown in the brain's reward system, involving the neurotransmitter dopamine. Anhedonia can be characterised as \"impaired ability to pursue, experience and/or learn about pleasure, which is often, but not always accessible to conscious awareness\".",
            "score": 178.73106384277344
        },
        {
            "docid": "83859_25",
            "document": "Adolescence . The first areas of the brain to be pruned are those involving primary functions, such as motor and sensory areas. The areas of the brain involved in more complex processes lose matter later in development. These include the lateral and prefrontal cortices, among other regions. Some of the most developmentally significant changes in the brain occur in the prefrontal cortex, which is involved in decision making and cognitive control, as well as other higher cognitive functions. During adolescence, myelination and synaptic pruning in the prefrontal cortex increases, improving the efficiency of information processing, and neural connections between the prefrontal cortex and other regions of the brain are strengthened. This leads to better evaluation of risks and rewards, as well as improved control over impulses. Specifically, developments in the dorsolateral prefrontal cortex are important for controlling impulses and planning ahead, while development in the ventromedial prefrontal cortex is important for decision making. Changes in the orbitofrontal cortex are important for evaluating rewards and risks.",
            "score": 176.41062927246094
        },
        {
            "docid": "26317569_8",
            "document": "Maturity (psychological) . The pre-frontal cortex, which is responsible for higher cognitive functions such as planning, decision-making, judgment and reasoning, develops and matures most rapidly during early adolescence and into the early 20s. Accompanying the growth of the pre-frontal cortex is continued synaptic pruning (the trimming of rarely used synapses) as well as increased myelination of nerve fibers in the brain, which serves to insulate and speed up signal transmission between neurons. The incomplete development of this process contributes to the finding that adolescents use their brain less broadly than do adults when asked to inhibit a response and show less cross-talk (communication across diverse regions of the brain). The brain's \"cross-talk\" may be related to decision-making concerning risk-taking, with one study of American adolescents finding delayed reaction time and decreased spread across brain regions in a task asking them to determine whether a dangerous action is a good idea or not. Steinberg observes that there is close overlap in the activated brain regions for socioemotional and reward information, which may pose a challenge when making decisions in the most high-risk peer contexts. One study found that preference for small immediate rewards over larger long-term rewards was associated with increased activation with regions primarily responsible for socioemotional decision-making.",
            "score": 176.0342254638672
        },
        {
            "docid": "25049383_38",
            "document": "Cognitive neuroscience of music . Music is able to create an incredibly pleasurable experience that can be described as \"chills\". Blood and Zatorre (2001) used PET to measure changes in cerebral blood flow while participants listened to music that they knew to give them the \"chills\" or any sort of intensely pleasant emotional response. They found that as these chills increase, many changes in cerebral blood flow are seen in brain regions such as the amygdala, orbitofrontal cortex, ventral striatum, midbrain, and the ventral medial prefrontal cortex. Many of these areas appear to be linked to reward, motivation, emotion, and arousal, and are also activated in other pleasurable situations. Nucleus accumbens (a part of striatum) is involved in both music related emotions, as well as rhythmic timing.",
            "score": 173.64979553222656
        },
        {
            "docid": "393535_12",
            "document": "Coolidge effect . Though there is no single reason for why males will choose a novel partner, there have been experiments that show that the major determining factor for detecting a novel partner is through olfactory preference. An experiment using Long-Evans rats, showed that odour played a major role in distinguishing the difference between a novel partner and familiar partner. In their experiment, Carr et al. paired each male rat with a female rat and allowed them to mate. Male rats were then tested for preference through the use of an apparatus which had two cylinders that were attached to their home cage, and contained the familiar female and the novel female in each cylinder. Caps at the end of these cylinders prevented access to the females, but had a hole in them to allow their odours to pass through to the male's cage. Before the testing phase, the females were removed, and then the caps were removed to allow the male to explore both cylinders. From this experiment, they found that males preferred the scent of the novel female. While these males did not have access to these females to demonstrate mating preferences, this odour preference is believed to reflect promiscuous behaviour, and therefore be important to the male mating strategy. In an earlier experiment, also conducted by Carr et al., they found that unlike male rats, female rats preferred the odour of a familiar partner rather than the odour of a novel partner. Another study also examined not only olfactory preference, but what part of the brain targeted the olfactory preference. In this study, male hamsters were given lesions to either the hippocampus or the perirhinal-entorhinal cortex, or received a sham treatment. Then the hamsters were allowed to mate with a female hamster until they became satiated. All subjects were then presented with two anesthetized females, one was the female they had previously copulated with, and the other was a novel female. Hamsters with sham and hippocampal lesions investigated the anogenital region of the novel females for a significantly longer period of time in comparison to the familiar female. Males with lesions to the perirhinal-entorhinal cortex did not show a preference for either a familiar or novel female, and spent a similar amount of time investigating the anogenital region of both females. The results from this study revealed that the perirhinal-entorhinal cortex region of the brain in golden hamsters is crucial for the recognition of familiar conspecifics and certain social behaviors. The conclusion from this experiment was also consistent in rats and monkeys, since damage to this region of the brain impaired standard recognition memory, which would suggest that the hippocampal region of the brain is not crucial in social behavior memory, but rather, the perirhinal-entorhinal cortex.",
            "score": 171.3812255859375
        },
        {
            "docid": "515094_21",
            "document": "Neuroeconomics . Neuroeconomic research in intertemporal choice is largely aimed at understanding what mediates observed behaviors such as future discounting and impulsively choosing smaller sooner rather than larger later rewards. The process of choosing between immediate and delayed rewards seems to be mediated by an interaction between two brain areas. In choices involving both primary (fruit juice) and secondary rewards (money), the limbic system is highly active when choosing the immediate reward while the lateral prefrontal cortex was equally active when making either choice. Furthermore, the ratio of limbic to cortex activity decreased as a function of the amount of time until reward. This suggests that the limbic system, which forms part of the dopamine reward pathway, is most involved in making impulsive decisions while the cortex is responsible for the more general aspects of the intertemporal decision process.",
            "score": 171.00631713867188
        },
        {
            "docid": "159209_17",
            "document": "Conduct disorder . Beyond difficulties in executive function, neurological research on youth with conduct disorder also demonstrate differences in brain anatomy and function that reflect the behaviors and mental anomalies associated in conduct disorder. Compared to normal controls, youths with early and adolescent onset of conduct disorder displayed reduced responses in brain regions associated with social behavior (i.e., amygdala, ventromedial prefrontal cortex, insula, and orbitofrontal cortex). In addition, youths with conduct disorder also demonstrated less responsiveness in the orbitofrontal regions of the brain during a stimulus-reinforcement and reward task. This provides a neural explanation for why youths with conduct disorder may be more likely to repeat poor decision making patterns. Lastly, youths with conduct disorder display a reduction in grey matter volume in the amygdala, which may account for the fear conditioning deficits. This reduction has been linked to difficulty processing social emotional stimuli, regardless of the age of onset.  Aside from the differences in neuroanatomy and activation patterns between youth with conduct disorder and controls, neurochemical profiles also vary between groups. Individuals with conduct disorder are characterized as having reduced serotonin and cortisol levels (e.g., reduced hypothalamic-pituitary-adrenal (HPA) axis), as well as reduced autonomic nervous system (ANS) functioning. These reductions are associated with the inability to regulate mood and impulsive behaviors, weakened signals of anxiety and fear, and decreased self-esteem. Taken together, these findings may account for some of the variance in the psychological and behavioral patterns of youth with conduct disorder.",
            "score": 169.51632690429688
        },
        {
            "docid": "10828_22",
            "document": "Fear . As with many functions of the brain, there are various regions of the brain involved in deciphering fear in humans and other nonhuman species. The amygdala communicates both directions between the prefrontal cortex, hypothalamus, the sensory cortex, the hippocampus, thalamus, septum, and the brainstem. The amygdala plays an important role in SSDR, such as the ventral amygdalofugal, which is essential for associative learning, and SSDRs are learned through interaction with the environment and others of the same species. An emotional response is created only after the signals have been relayed between the different regions of the brain, and activating the sympathetic nervous systems; which controls the flight, fight, freeze, fright, and faint response. Often a damaged amygdala can cause impairment in the recognition of fear (like the human case of patient S.M.). This impairment can cause different species to lack the sensation of fear, and often can become overly confident, confronting larger peers, or walking up to predatory creatures.",
            "score": 168.5048370361328
        },
        {
            "docid": "52324876_8",
            "document": "Distress tolerance . There are several candidate biological neural network mechanisms for distress tolerance. These proposed brain areas are based on the conceptualization of distress tolerance as a function of reward learning. Within this framework, individuals learn to attune to and pursue reward; reduction of tension in escaping from a stressor is similarly framed as a reward and thus can be learned. Individuals differ in how quickly and for how long they display preferences for pursuing reward or in the case of distress tolerance, escaping from a distressful stimulus. Therefore, brain regions that are activated during reward processing and learning are hypothesized to also serve as neurobiological substrates for distress tolerance. For instance, activation intensity of dopamine neurons projecting to the nucleus accumbens, ventral striatum, and prefrontal cortex is associated with an individual's predicted value of an immediate reward during a learning task. As the firing rate for these neurons increases, individuals predict high values of an immediate reward. During instances in which the predicted value is correct, the basal rate of neuronal firing remains the same. When the predicted reward value is below the actual value, neuronal firing rates increase when the reward is received, resulting in a learned response. When the expected reward value is below the actual value, the firing rate of these neurons decreases below baseline levels, resulting in a learned shift that reduces expectancies about reward value. It is posited that these same dopaminergic firing rates are associated with distress tolerance, in that learning the value of escaping a distressing stimulus is analogous to an estimation of an immediate reward There are several potential clinical implications if these posited distress tolerance substrates are corroborated. It may suggest that distress tolerance is malleable among individuals; interventions that change neuronal firing rates may shift predicted values of behaviors intended to escape a distressor and provide relief, thereby increasing distress tolerance.",
            "score": 168.04351806640625
        },
        {
            "docid": "1684561_17",
            "document": "Method of loci . Brain scans of \"superior memorizers\", 90% of whom use the method of loci technique, have shown that it involves activation of regions of the brain involved in spatial awareness, such as the medial parietal cortex, retrosplenial cortex, and the right posterior hippocampus. The medial parietal cortex is most associated with encoding and retrieving of information. Patients who have medial parietal cortex damage have trouble linking landmarks with certain locations; many of these patients are unable to give or follow directions and often get lost. The retrosplenial cortex is also linked to memory and navigation. In one study on the effects of selective granular retrosplenial cortex lesions in rats, the researcher found that damage to the retrosplenial cortex led to impaired spatial learning abilities. Rats with damage to this area failed to recall which areas of the maze they had already visited, rarely explored different arms of the maze, almost never recalled the maze in future trials, and took longer to reach the end of the maze, as compared to rats with a fully working retrosplenial cortex.",
            "score": 167.8660888671875
        },
        {
            "docid": "2640086_31",
            "document": "Affective neuroscience . The results indicated that many brain regions demonstrated consistent and selective activations in the experience or perception of an emotion category (versus all the other emotion categories). Consistent with constructionist models, however, no region demonstrated functional specificity for the emotions of fear, disgust, happiness, sadness or anger. Based on the existing scientific literature, the authors proposed different roles for the brain regions that have traditionally been associated with only one emotion category. The authors propose that the amygdala, anterior insula, orbitofrontal cortex each contribute to \u201ccore affect,\u201d which are basic feelings that are pleasant or unpleasant with some level of arousal. The amygdala, for example, appears to play a more general role in indicating if external sensory information is motivationally salient, and is particularly active when a stimulus is novel or evokes uncertainty. The anterior insula may represent core affective feelings in awareness across a number of emotion categories, driven largely by sensations originating in the body. The orbitofrontal cortex appears to function as a site for integrating sensory information from the body and sensory information from the world to guide behavior. Closely related to core affect, the authors propose that anterior cingulate and dorsolateral prefrontal cortex play vital roles in attention, with anterior cingulate supporting the use of sensory information for directing attention and motor responses during response selection and with dorsolateral prefrontal cortex supporting executive attention. In many psychological construction approaches, emotions also involve the act of interpreting one\u2019s situation in the world relative to the internal state of the body, or what is referred to as \u201cconceptualization.\u201d In support of this idea, the dorsomedial prefrontal cortex and hippocampus were consistently active in this meta-analysis, regions that appear to play an important role conceptualizing during emotion, which are also involved in simulating previous experience (e.g. knowledge, memory). Language is also central to conceptualizing, and regions that support language, including ventrolateral prefrontal cortex, were also consistently active across studies of emotion experience and perception.",
            "score": 165.58766174316406
        },
        {
            "docid": "146000_18",
            "document": "Amygdala . The amygdalae are also involved in appetitive (positive) conditioning. It seems that distinct neurons respond to positive and negative stimuli, but there is no clustering of these distinct neurons into clear anatomical nuclei. However, lesions of the central nucleus in the amygdala have been shown to reduce appetitive learning in rats. Lesions of the basolateral regions do not exhibit the same effect. Research like this indicates that different nuclei within the amygdala have different functions in appetitive conditioning. Nevertheless, researchers found an example of appetitive emotional learning showing an important role for the basolateral amygdala: The na\u00efve female mice are innately attracted to non-volatile pheromones contained in male-soiled bedding, but not by the male-derived volatiles, become attractive if associated with non-volatile attractive pheromones, which act as unconditioned stimulus in a case of Pavlovian associative learning. In the vomeronasal, olfactory and emotional systems, Fos protein show that non-volatile pheromones stimulate the vomeronasal system, whereas air-borne volatiles activate only the olfactory system. Thus, the acquired preference for male-derived volatiles reveals an olfactory-vomeronasal associative learning. Moreover, the reward system is differentially activated by the primary pheromones and secondarily attractive odorants. Exploring the primary attractive pheromone activates the basolateral amygdala and the shell of nucleus accumbens but neither the ventral tegmental area nor the orbitofrontal cortex. In contrast, exploring the secondarily attractive male-derived odorants involves activation of a circuit that includes the basolateral amygdala, prefrontal cortex and ventral tegmental area. Therefore, the basolateral amygdala stands out as the key center for vomeronasal-olfactory associative learning.",
            "score": 165.27906799316406
        },
        {
            "docid": "17363313_6",
            "document": "Mass Action Principle (neuroscience) . Karl Lashley's most famous research was an attempt to find the parts of the brain that were responsible for learning and memory traces, a hypothetical structure he called the engram. He trained rats to perform specific tasks (seeking a food reward), then lesioned varying portions of the rats' cortexes, either before or after the animals received the training depending upon the experiment. The amount of cortical tissue removed had specific effects on acquisition and retention of knowledge, but the location of the removed cortex had no effect on the rats' performance in the maze. This led Lashley to conclude that memories are not localized but widely distributed across the cortex.",
            "score": 164.76998901367188
        },
        {
            "docid": "33932515_27",
            "document": "Social cue . In order to monitor changing facial expressions of individuals, the hippocampus and orbitofrontal cortex may be a crucial part in guiding critical real-world social behavior in social gatherings. The hippocampus may well be a part of using social cues to understand numerous appearances of the same person over short delay periods. The orbitofrontal cortex being important in the processing of social cues leads researchers to believe that it works with the hippocampus to create, maintain, and retrieve corresponding representations of the same individual seen with multiple facial expressions in working memory. After coming across the same person multiple times with different social cues, the right lateral orbitofrontal cortex and hippocampus are more strongly employed and display a stronger functional connection when disambiguating each encounter with that individual. During an fMRI scan the lateral orbitofrontal cortex, hippocampus, fusiform gyrus bilaterally showed activation after meeting the same person again and having previously seen two different social cues. This would suggest that both of these brain areas help retrieve correct information about a person's last encounter with the person. The ability to separate the different encounters with different people seen with different social cues leads researchers to believe that it permits for suitable social interactions. Ross, LoPresti and Schon offer that the orbitofrontal cortex and hippocampus are a part of both working memory and long-term memory, which permits flexibility in encoding separate representations of an individual in the varying social contexts in which we encounter them.",
            "score": 163.90536499023438
        },
        {
            "docid": "3766002_17",
            "document": "Orbitofrontal cortex . The human OFC is among the least-understood regions of the human brain; but it has been proposed that the OFC is involved in sensory integration, in representing the affective value of reinforcers, and in decision-making and expectation. In particular, the OFC seems to be important in signaling the expected rewards/punishments of an action given the particular details of a situation. In doing this, the brain is capable of comparing the expected reward/punishment with the actual delivery of reward/punishment, thus, making the OFC critical for adaptive learning. This is supported by research in humans, non-human primates, and rodents.",
            "score": 162.11204528808594
        },
        {
            "docid": "27942343_6",
            "document": "Psychological effects of Internet use . Specialised MRI brain scans showed changes in the white matter of the brain\u2014the part that contains nerve fibres\u2014in those classed as being web addicts, compared with non-addicts. Furthermore, the study says, \"We provided evidences demonstrating the multiple structural changes of the brain in IAD subjects. VBM results indicated the decreased gray matter volume in the bilateral dorsolateral prefrontal cortex (DLPFC), the supplementary motor area (SMA), the orbitofrontal cortex (OFC), the cerebellum and the left rostral ACC (rACC).\" UCLA professor of psychiatry Gary Small studied brain activity in experienced web surfers versus casual web surfers. He used MRI scans on both groups to evaluate brain activity. The study showed that when Internet surfing, the brain activity of the experienced Internet users was far more extensive than that of the novices, particularly in areas of the prefrontal cortex associated with problem-solving and decision making. However, the two groups had no significant differences in brain activity when reading blocks of text. This evidence suggested that the distinctive neural pathways of experienced Web users had developed because of their Web use. Dr. Small concluded that \u201cThe current explosion of digital technology not only is changing the way we live and communicate, but is rapidly and profoundly altering our brains.\u201d",
            "score": 161.64268493652344
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 161.0659942626953
        },
        {
            "docid": "37691351_10",
            "document": "Neuroscience and race . The amygdala, which is the most researched brain region in racism studies, shows much greater activation while viewing other-race faces than same-race faces. This region of the brain is associated with fear conditioning, and has many connections with the cortex to control the body\u2019s emotional response. Often, there is variation in amygdala activation due to motivation and goals. The amygdala\u2019s activation can be changed through not focusing on race or focusing on removing the racial bias. Scientists believe that amygdala activation differences arise due to social/cultural perceptions and individual experiences. However, it is important to note that patients with a damaged amygdala still show a racial bias, meaning that the amygdala isn\u2019t the only region involved in activating a racial bias. The link between the amygdala and racial prejudice has been comprehensively reviewed. The anterior cingulate cortex (ACC) is associated with detecting conflict and determining how to resolve that conflict. It is believed to play a part in the controversy in one\u2019s mind over personal racial biases and cultural equality norms. ACC activation increases when a person has an automatic negative response to an out-group member, as shown in amygdala activation. The ACC is used to recognize the conflict between cultural expectations and the automatic negative response, and is the first step in expressing racial attitudes.",
            "score": 161.03823852539062
        },
        {
            "docid": "1639997_25",
            "document": "Environmental psychology . Environmental cognition (involved in human cognition) plays a crucial role in environmental perception. All different areas of the brain engage with environmentally relevant information. Some believe that the orbitofrontal cortex integrates environmentally relevant information from many distributed areas of the brain. Due to its anterior location within the frontal cortex, the orbitofrontal cortex may make judgments about the environment, and refine the organism's \"understanding\" through error analysis, and other processes specific to prefrontal cortex. But to be certain, there is no single brain area dedicated to the organism's interactions with its environment. Rather, all brain areas are dedicated to this task. One area (probably the orbitofrontal cortex) may collate the various pieces of the informational puzzle in order to develop a long term strategy of engagement with the ever-changing \"environment.\" Moreover, the orbitofrontal cortex may show the greatest change in blood oxygenation (BOLD level) when an organism thinks of the broad, and amorphous category referred to as \"the environment.\" Because of the recent concern with the environment, environmental consciousness or awareness has come to be related to the growth and development of understanding and consciousness toward the biophysical environment and its problems.",
            "score": 161.01388549804688
        },
        {
            "docid": "23337_24",
            "document": "Phobia . The amygdala\u2019s role in learned fear includes interactions with other brain regions in the neural circuit of fear. While lesions in the amygdala can inhibit its ability to recognize fearful stimuli, other areas such as the ventromedial prefrontal cortex and the basolateral nuclei of the amygdala can affect the region's ability to not only become conditioned to fearful stimuli, but to eventually extinguish them. The basolateral nuclei, through receiving stimulus info, undergo synaptic changes that allow the amygdala to develop a conditioned response to fearful stimuli. Lesions in this area, therefore, have been shown to disrupt the acquisition of learned responses to fear. Likewise, lesions in the ventromedial prefrontal cortex (the area responsible for monitoring the amygdala) have been shown to not only slow down the speed of extinguishing a learned fear response, but also how effective or strong the extinction is. This suggests there is a pathway or circuit among the amygdala and nearby cortical areas that process emotional stimuli and influence emotional expression, all of which can be disrupted when an area becomes damaged.",
            "score": 160.87034606933594
        }
    ]
}