{
    "q": [
        {
            "docid": "15559385_11",
            "document": "Tactile discrimination . When a person has become blind, in order to \u201csee\u201d the world, their other senses become heightened. An important sense for the blind is their sense of touch, which becomes more frequently used to help them perceive the world. People that are blind have displayed that their visual cortices become more responsive to auditory and tactile stimulation. Braille allows the blind to be able to use their sense of touch to feel the roughness, and distance of various patterns to be used as a form of language. Within the brain, the activation of the occipital cortex is functionally relevant for tactile braille reading, as well as the somatosensory cortex. These various parts of the brain function in their own way, in which they each contribute to the effectiveness of how braille is read by the blind. People that are blind also rely heavily on Tactile Gnosis, Spatial discrimination, Graphesthesia, and Two-point discrimination. Essentially, the occipital cortex allows one to effectively make judgements on the distance of braille patterns, which is related to spatial discrimination. Meanwhile, the somatosensory cortex allows one to effectively make judgements on the roughness of braille patterns, which is related to two-point discrimination. The various visual areas in the brain are very essential for a blind person to read braille, just as much as it is for a person that has sight. Essentially, whether one is blind or not, the perception of objects that involves tactile discrimination is not impaired if one cannot see. When comparing people that are blind to people that have sight, the amount of activity within the their somatosensory and visual areas of the brain do differ. The activity in the somatosensory and visual areas are not as high in tactile gnosis for people that are not blind, and are more-so active for more visual related stimuli that does not involve touch. Nonetheless, there is a difference in these various areas within the brain when comparing the blind to the sighted, which is that shape discrimination causes a difference in brain activity, as well as tactile gnosis. The visual cortices of blind individuals are active during various vision related tasks including tactile discrimination, and the function of the cortices resemble the activity of adults with sight.",
            "score": 287.42121863365173
        },
        {
            "docid": "26945761_5",
            "document": "Cross modal plasticity . The somatosensory cortex is also able to recruit the visual cortex to assist with tactile sensation. Cross modal plasticity reworks the network structure of the brain, leading to increased connections between the somatosensory and visual cortices. Furthermore, the somatosensory cortex acts as a hub region of nerve connections in the brain for the early blind but not for the sighted. With this cross-modal networking the early blind are able to react to tactile stimuli with greater speed and accuracy, as they have more neural pathways to work with. One element of the visual system that the somatosensory cortex is able to recruit is the dorsal-visual stream. The dorsal stream is used by the sighted to identify spatial information visually, but the early blind use it during tactile sensation of 3D objects. However, both sighted and blind participants used the dorsal stream to process spatial information, suggesting that cross modal plasticity in the blind re-routed the dorsal visual stream to work with the sense of touch rather than changing the overall function of the stream.",
            "score": 193.20625138282776
        },
        {
            "docid": "49596807_6",
            "document": "Ludwig Boltzmann Institute for Functional Brain Topography . With 14 early blind subjects the study group Uhl was able to show that specific changes occurred in occipital and basal temporo-occipital brain areas only, whereby the primary visual cortex plays an important role. Subcomponents of Braille reading were correlated in different ways: a) Passive tactile stimulation, b) Active tactile pattern recognition and c) mental imagery of Braille. Although Braille reading is tactile, it does not activate the somatosensory cortex, but the primary visual cortex (striate area) or area 17. Thus the visual cortex remains a cortex for the orientation in space as well as for reading in general including reading Braille with fingers when reading with the eyes fails.",
            "score": 257.26636934280396
        },
        {
            "docid": "26945761_6",
            "document": "Cross modal plasticity . There is evidence that the degree of cross modal plasticity between the somatosensory and visual cortices is experience-dependent. In a study using tactile tongue devices to transmit spatial information, early blind individuals were able to show visual cortex activations after 1 week of training with the device. Although there were no cross modal connections at the start, the early blind were able to develop connections between the somatosensory and visual cortices while sighted controls were unable to. Early or congenitally blind individuals have stronger cross modal connections the earlier they began learning Braille. An earlier start allows for stronger connections to form as early blind children have to grow up using their sense of touch to read instead of using their sight. Perhaps due to these cross modal connections, sensory testing studies have shown that people who are born blind and read braille proficiently perceive through touch more rapidly than others. Furthermore, tactile spatial acuity is enhanced in blindness and this enhancement is experience-dependent.",
            "score": 196.98893761634827
        },
        {
            "docid": "7913402_16",
            "document": "Paul Baltes . Neuronal plasticity, or the capability of the brain to adapt to new requirements, is a prime example of plasticity stressing that the individual\u2019s ability to change is a lifelong process. Recently, researchers have been analyzing how the spared senses compensate for the loss of vision. Without visual input, blind humans have demonstrated that tactile and auditory functions still fully develop. A superiority of the blind has even been observed when they are presented with tactile and auditory tasks. This superiority may suggest that the specific sensory experiences of the blind may influence the development of certain sensory functions, namely tactile and auditory. One experiment was designed by R\u00f6der and colleagues to clarify the auditory localization skills of the blind in comparison to the sighted. They examined both blind human adults\u2019 and sighted human adults\u2019 abilities to locate sounds presented either central or peripheral (lateral) to them. Both congenitally blind adults and sighted adults could locate a sound presented in front of them with precision but the blind were clearly superior in locating sounds presented laterally. Currently, brain-imaging studies have revealed that the sensory cortices in the brain are reorganized after visual deprivation. These findings suggest that when vision is absent in development, the auditory cortices in the brain recruit areas that are normally devoted to vision, thus becoming further refined.",
            "score": 160.92338812351227
        },
        {
            "docid": "39151518_17",
            "document": "Neuronal recycling hypothesis . Using imaging studies, scientists found that the visual word form area played a clear role in reading. However, they also found the same area to be active during several other forms of object recognition and naming tasks. Additionally, activation of this area was also observed when subjects were asked to think about the meaning of spoken words, hear definitions of objects and make meaningful decisions about them, or when they imagine an object. Furthermore, the same area is activated when blind subjects read via tactile stimulation, implying that the visual word form area processes more than just visual stimuli.",
            "score": 114.89227819442749
        },
        {
            "docid": "6265123_13",
            "document": "Stanislas Dehaene . In addition, Dehaene has used brain imaging to study language processing in monolingual and bilingual subjects, and in collaboration with Laurent Cohen, the neural basis of reading. Dehaene and Cohen initially focused on the role of ventral stream regions in visual word recognition, and in particular the role of the left inferior temporal cortex for reading written words. They identified a region they called the \"visual word form area\" (VWFA) that was consistently activated during reading, and also found that when this region was surgically removed to treat patients with intractable epilepsy, reading abilities were severely impaired.",
            "score": 133.3749852180481
        },
        {
            "docid": "41119526_10",
            "document": "Tactile hallucination . Tactile Hallucinations are the result of a dysfunctional somatosensory and a dysfunctional awareness regions of the brain. Tactile sensory input is produced and conducted through the spinal cord and thalamus and it is received at the primary somatosensory cortex. Once it has reached the primary somatosensory cortex, it is distributed across the brain and it will not be processed unless it is important and one pays close attention to the information based on a specific context. Consciousness to these specific tactile sensations is generated only through multiple feedback loops passing through higher cortical areas such as secondary somatosensory area, parietal, insular cortex and premotor areas. The intensity of the tactile stimulus is directly proportional to the area of the primary somatosensory region activated. A feedback mechanism from different cortical areas results in the awareness of touch. Even with complete sensory deprivation, discrete tactile memories can trigger spontaneous firing of impaired neurons. Therefore, individuals with various psychiatric disorders are more prone to tactile hallucinations than normal individuals. Tactile hallucinations are especially possible due to faulty sensory integration of neuronal signals in the primary and secondary somatosensory system with neuronal signals in the parietal cortex, insular cortex and premotor cortex. Moreover, the posterior insula is responsible for mental body schema representation and can produce tactile hallucination if defected. Additionally, it is interesting to note that the regions of the brain involved in tactile hallucinations are similar to the regions of the brain involved in pain.",
            "score": 174.18455839157104
        },
        {
            "docid": "525667_10",
            "document": "Human echolocation . In a 2014 study by Thaler and colleagues, the researchers first made recordings of the clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, not only did they perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. The brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any auditory area, becomes involved in the computation of echolocation tasks.",
            "score": 170.22246479988098
        },
        {
            "docid": "31122898_3",
            "document": "Haptic memory . Perhaps the first experiment conducted to study the phenomenon of haptic memory was that of Bliss, Crane, Mansfield, and Townsend who investigated the characteristics of immediate recall for brief tactile stimuli applied to the hand. The results obtained showed a haptic memory store remarkably similar to the visual memory store suggested by Sperling in 1960, with a capacity of approximately four to five items. Similar to tests of visual sensory memory, it was also found that haptic memory performance was significantly improved with the use of partial report procedures. This particular finding is consistent with more recent research by Gallace in 2008. Bliss et al. interpreted this difference in partial report versus whole report as a sensory form of memory for passively presented tactile stimuli with a high capacity and short duration. Additional support for the short duration of haptic memory comes from studies by Gilson and Baddeley in 1969. According to these studies, memory for stimuli applied to the skin is resilient for approximately ten seconds after removal of the stimulus, even when the individual is engaged in tasks that inhibit verbal rehearsal. After this delay, the memory trace becomes vulnerable to forgetting as it decays from the haptic memory store and begins to rely on a more central memory store. Similar findings were later reported by Miles and Borthwick in 1996, who emphasized the role of tactile interference on discriminability of the target location and the role of central processing resources in consolidation of haptic memory. More recent experimental procedures and technologies such as minielectrode recording devices and transcranial magnetic stimulation have allowed for mapping of brain areas involved in the storage of tactile memories. Implicated in most of these studies is the primary somatosensory cortex. More recent studies have also investigated a broader selection of participants, allowing for the discovery of an intact haptic memory in infants.",
            "score": 131.58817553520203
        },
        {
            "docid": "1903855_9",
            "document": "Sensory substitution . \"Brain plasticity\" refers to the brain's ability to adapt to a changing environment, for instance to the absence or deterioration of a sense. It is conceivable that cortical remapping or reorganization in response to the loss of one sense may be an evolutionary mechanism that allows people to adapt and compensate by using other senses better. Functional imaging of congenitally blind patients showed a cross-modal recruitment of the occipital cortex during perceptual tasks such as Braille reading, tactile perception, tactual object recognition, sound localization, and sound discrimination. This may suggest that blind people can use their occipital lobe, generally used for vision, to perceive objects through the use of other sensory modalities. This cross modal plasticity may explain the often described tendency of blind people to show enhanced ability in the other senses.",
            "score": 175.27224826812744
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 153.87719893455505
        },
        {
            "docid": "1903855_23",
            "document": "Sensory substitution . While there are no tactile\u2013auditory substitution systems currently available, recent experiments by Schurmann et al. show that tactile senses can activate the human auditory cortex. Currently vibrotactile stimuli can be used to facilitate hearing in normal and hearing-impaired people. To test for the auditory areas activated by touch, Schurmann et al. tested subjects while stimulating their fingers and palms with vibration bursts and their fingertips with tactile pressure. They found that tactile stimulation of the fingers lead to activation of the auditory belt area, which suggests that there is a relationship between audition and tactition. Therefore, future research can be done to investigate the likelihood of a tactile\u2013auditory sensory substitution system. One promising invention is the 'Sense organs synthesizer' which aims at delivering a normal hearing range of nine octaves via 216 electrodes to sequential touch nerve zones, next to the spine.",
            "score": 164.77954196929932
        },
        {
            "docid": "1903855_7",
            "document": "Sensory substitution . In a regular visual system, the data collected by the retina is converted into an electrical stimulus in the optic nerve and relayed to the brain, which re-creates the image and perceives it. Because it is the brain that is responsible for the final perception, sensory substitution is possible. During sensory substitution an intact sensory modality relays information to the visual perception areas of the brain so that the person can perceive to see. With sensory substitution, information gained from one sensory modality can reach brain structures physiologically related to other sensory modalities. Touch-to-visual sensory substitution transfers information from touch receptors to the visual cortex for interpretation and perception. For example, through fMRI, we can determine which parts of the brain are activated during sensory perception. In blind persons, we can see that while they are only receiving tactile information, their visual cortex is also activated as they perceive to \"see\" objects. We can also have touch to touch sensory substitution where information from touch receptors of one region can be used to perceive touch in another region. For example, in one experiment by Bach-y-Rita, he was able to restore the touch perception in a patient who lost peripheral sensation from leprosy.",
            "score": 194.13516891002655
        },
        {
            "docid": "22843418_26",
            "document": "Extinction (neurology) . Neglect and extinction can overlap for a single sensory modality, and even for multiple sensory modalities. Extinction affecting a unimodal sensory system can be influenced by the concurrent activation of another modality. Tactile extinction, as an example, can be modulated by visual events simultaneously presented in the region near the tactile stimulation, increasing or reducing tactile perception, depending upon the spatial arrangement of the stimuli. In one example of visual and tactile relationship, the visual stimulation in the ipsilesional side exacerbates contralesional tactile extinction, whereby the presentation of visual and tactile stimuli on the same contralesional side can reduce the deficit. Tactile and visual informations can also be integrated in other peripersonal space regions, such as around the face.",
            "score": 113.31752920150757
        },
        {
            "docid": "8305_23",
            "document": "Dyslexia . Pure, or phonologically-based, dyslexia, also known as agnosic dyslexia, dyslexia without agraphia, and pure word blindness, is dyslexia due to difficulty in recognizing written sequences of letters (such as words), or sometimes even letters. It is considered '\"pure\" because it is not accompanied by other significant language-related impairments. Pure dyslexia does not affect speech, handwriting style, language or comprehension impairments. Pure dyslexia is caused by lesions on the visual word form area (VWFA). The VWFA is composed of the left lateral occipital sulcus and is activated during reading. A lesion in the VWFA stops transmission between the visual cortex and the left angular gyrus. It can also be caused by a lesion involving the left occipital lobe or the splenium. It is usually accompanied by a homonymous hemianopsia in the right side of the visual field. Multiple oral re-reading (MOR) is a treatment for pure dyslexia. It is considered a top-down processing technique in which affected individuals read and reread texts a predetermined number of times or until reading speed or accuracy improves a predetermined amount.",
            "score": 106.86087942123413
        },
        {
            "docid": "7151320_18",
            "document": "Recovery from blindness . At 3 years of age, Michael's vision had still not reached the acuity of an adult person, so his brain was still not completely exposed to all possible clarity of images and light of the environment. This made it difficult for Michael to lead a normal daily life. Cohen et al. (1997) suggested that early blindness causes a poor development of the visual cortex with the result of a decrease in somatosensory development. This study proposed that Michael's long-term blindness affects his ability to distinguish in between faces of males and females, and to recognize pictures and images. In spite of the surgery on his right eye, his newly regained vision, after blindness of forty years, is not fully recovered. Thinus-Blanc and Gaunet (1997) suggest that early blinded people show limited ability in spatial representation. Michael still struggles to identify pictures or illustrations. The impairment of his visual cortex, due to the loss of his vision at a very early age, resulted in visual cortex cells that are not used to the stimuli in his surroundings. Cohen et al. (1997) proposed that in their early age, blinded subjects developed strong motivations to tactile discrimination tasks. Michael's early blindness benefited him so far; he developed very precise senses of hearing and touch.",
            "score": 171.30779361724854
        },
        {
            "docid": "20510214_5",
            "document": "Activity-dependent plasticity . The history of activity-dependent plasticity begins with Paul Bach y Rita. With conventional ideology being that the brain development is finalized upon adulthood, Bach y Rita designed several experiments in the late 1960s and 1970s that proved that the brain is capable of changing. These included a pivotal visual substitution method for blind people provided by tactile image projection in 1969. The basis behind this experiment was to take one sense and use it to detect another: in this case use the sense of touch on the tongue to visualize the surrounding. This experiment was years ahead of its time and lead to many questions and applications. A similar experiment was reported again by Bach y Rita in 1986 where vibrotactile stimulation was delivered to the index fingertips of naive blindfolded subjects. Even though the experiment did not yield great results, it supported the study and proposed further investigations. In 1998, his design was even further developed and tested again with a 49-point electrotactile stimulus array on the tongue. He found that five sighted adult subjects recognized shapes across all sizes 79.8% of the time, a remarkable finding that has led to the incorporation of the tongue electrotactile stimulus into cosmetically acceptable and practical designs for blind people. In later years, he has published a number of other articles including \"Seeing with the brain\" in 2003 where Bach y Rita addresses the plasticity of the brain relative to visual learning. Here, images are enhanced and perceived by other plastic mechanisms within the realm of information passing to the brain.",
            "score": 138.26575374603271
        },
        {
            "docid": "25335695_4",
            "document": "Perceptual learning . Laboratory studies reported many examples of dramatic improvements in sensitivities from appropriately structured perceptual learning tasks. In visual Vernier acuity tasks, observers judge whether one line is displaced above or below a second line. Untrained observers are often already very good with this task, but after training, observers' threshold has been shown to improve as much as 6 fold. Similar improvements have been found for visual motion discrimination and orientation sensitivity. In visual search tasks, observers are asked to find a target object hidden among distractors or in noise. Studies of perceptual learning with visual search show that experience leads to great gains in sensitivity and speed. In one study by Karni and Sagi, the time it took for subjects to search for an oblique line among a field of horizontal lines was found to improve dramatically, from about 200ms in one session to about 50ms in a later session. With appropriate practice, visual search can become automatic and very efficient, such that observers do not need more time to search when there are more items present on the search field. Tactile perceptual learning has been demonstrated on spatial acuity tasks such as tactile grating orientation discrimination, and on vibrotactile perceptual tasks such as frequency discrimination; tactile learning on these tasks has been found to transfer from trained to untrained fingers. Practice with Braille reading and daily reliance on the sense of touch may underlie the enhancement in tactile spatial acuity of blind compared to sighted individuals.",
            "score": 144.75477135181427
        },
        {
            "docid": "33702464_5",
            "document": "Extrastriate body area . The experiment had subjects view images of different objects, including faces (as a control group), body parts, animals, parts of the face and intimate objects. While viewing the images, the subjects were scanned with an fMRI to see what area of the brain was activated. Through the trials a compilation of the fMRI\u2019s was made. From this compilation image a specific region was determined to have increased activity when shown visual stimuli of body parts and even more activity when viewing whole bodies. There have been no studies involving brain damage to the EBA. Thus far, only scans of brain activity, as well as transcranial magnetic stimulation, have been used to study the EBA. To find the specific functions of the EBA, Comimo Urgesi, Giovanni Berlucchi and Salvatore M. Aglioti used repetitive transcranial magnetic stimulation (rTMS) to disrupt part of the brain, making the brain less responsive in the target area. The study used event-related rTMS to disrupt the EBA, resulting in inactivation of cortical areas. This inactivation caused a slower response time in discriminating body parts. The study used facial features and motorcycle parts as non human parts for control groups. The facial features and motorcycle body parts did not display any change in response time. The neural activity data shows the EBA handles some of the visual processing of human body and parts but is not related to the processing of the face or other objects.",
            "score": 118.74526691436768
        },
        {
            "docid": "1061157_11",
            "document": "Dual-coding theory . Two different methods have been used to identify the regions involved in visual perception and visual imagery. First, functional magnetic resonance imaging (fMRI) is used to measure cerebral blood flow, which allows researchers to identify the amount of glucose and oxygen being consumed by a specific part of the brain, with an increase in blood flow providing a measure of brain activity. Second, an event related potential (ERP) can be used to show the amount of electrical brain activity that is occurring due to a particular stimulus. Researchers have used both methods to determine which areas of the brain are active with different stimuli, and results have supported the dual-coding theory. Other research has been done with positron emission tomography (PET) scans and fMRI to show that participants had improved memory for spoken words and sentences when paired with an image, imagined or real, and showed increased brain activation to process abstract words not easily paired with an image.",
            "score": 109.53852725028992
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 153.20688557624817
        },
        {
            "docid": "25259743_17",
            "document": "Cortical cooling . In cats, the ability to disengage visual attention and redirect it to a new location is normally localizable to posterior middle suprasylvian (pMS) cortex, and investigators wanted to determine if, when primary visual cortical areas 17 and 18 are removed at birth, the neural functions of these areas are redistributed across other sections of the visual cortex, such as the pMS. This neural compensation would spare the function of areas 17 and 18 but at a possible cost of reducing the functional capabilities of the compensating cortex. After birth, areas 17 and 18 were lesioned in four cats, and they were then trained on behavioral tasks requiring detection and orienting to a visual or sound (as a negative control) stimulus. Then bilaterial cryoloops were implanted over the pMS and ventral posterior suprasylvian (vPS) cortices. The vPS lies adjacent to the pMS, and these areas were previously surmised to receive networks from other visual areas. Investigators found that, for moving visual stimuli, unilateral deactivation of pMS cortex partially impaired task performance when visual stimuli were moved into the hemifield opposite the side of the brain being cooled. Additionally deactivating the ipsilateral vPS cortex produced more complete task impairment. Bilateral deactivation of the pMS cortex, either alone or in combination with bilateral vPS deactivation, largely reversed the unilaterally cooling-induced impairments. For static visual stimuli, unilateral deactivation of pMS fully impaired task performance in the contralateral hemifield, while bilateral deactivation created full neglect of stimuli across the entire field of vision. For the vPS, unilateral deactivation had no effect on task performance, while bilateral deactivation generated inconsistencies in performance. All impairments were completely reversed when cooling was terminated. This study showed that the plasticity of neural tissue enabled functions from removed brain sections to redistribute to functionally distinct sections of cortex.  Reversible cooling was performed on slices of rat visual cortex, and spike characteristics were observed. Cooling depolarized the neural tissue, bringing the cells closer to the threshold necessary for an action potential (spike). Cooling increased spike width, and between 12 and 20\u00b0C, spike amplitudes were greatest. Cooling decreased passive potassium conductance while increasing the activation threshold and lowering the amplitude of voltage-gated potassium channels (thus essentially reducing the cells\u2019 capability to repolarize after an action potential). No sodium channel characteristics were altered. Hence, basic membrane properties were changed due to the modified conductance ratio of potassium and sodium, and this change was temperature dependent. Part of the somatosensory cortex of rats is arranged in distinct sections called barrels that account for stimuli sensed by each whisker. Cooling the somatosensory cortex surface helps to dissociate the activity generated in different barrels, thus bringing to light some of the dynamics involved in cortical processing of sensory inputs.",
            "score": 141.5830944776535
        },
        {
            "docid": "32018467_7",
            "document": "Christian Keysers . After finishing his master, Christian Keysers decided to concentrate on a subfield of cognitive neuroscience called social neuroscience that uses neuroscience methods to understand how we process the social world. He therefore performed his doctoral studies at the University of St Andrews with David Ian Perrett, one of the founding father of the field, to understand how the brain processes faces and facial expressions. This thesis work led to new insights into how quickly the brain can process the faces of others. During this period, Keysers became fascinated with the question of how the brain can attach meaning to the faces of others. How is it for instance, that we understand that a certain grimace would signal that another person is happy? How do we understand that a certain bodily movement towards a glass indicates that the other person aims to grasp a glass? In 1999, Keysers was exposed to a visit of Vittorio Gallese, who presented his recent discovery of mirror neurons in the Psychology department lecture series. This deeply influenced Keysers who decided to move to the lab of Giacomo Rizzolatti to undertake further studies on how these fascinating neurons could contribute to social perception. In 2000, after finishing his doctorate, Christian Keysers moved to the University of Parma to study mirror neurons. In early work there demonstrated that mirror neurons in the premotor cortex not only respond to the sight of actions, but also when actions can only be deduced or heard, leading to a publication in the journal \"Science\". This work had tremendous impact on the field, as it suggested that the premotor cortex could play a central, modality independent role in perception and may lay the origin for the evolution of speech in humans.  Together this work indicated that brain regions involved in our own actions play a role in how we process the actions of others. Keysers wondered whether a similar principle may underlie how we process the tactile sensations and emotions of others, and became increasingly independent of the research focus on the motor system in Parma. At the time, Keysers had also met his to be wife, Valeria Gazzola, a biologist in the final phases of her studies, and together they decided to explore if the somatosensory system might be involved in perceiving the sensations of others. Via a fruitful collaboration with the French neuroimaging specialist Bruno Wicker, they used functional magnetic resonance imaging, and showed for the first time, that the secondary somatosensory cortex, previously thought only to represent a persons own experiences of touch, is also activated when seeing someone or something else be touched. They also showed that the insula, thought only to respond to the experience of first-hand emotions, was also activated when we see another individual experience similar emotions. Together this indicated a much more general principle than the original mirror neuron theory, in which people process the actions, sensations and emotions of others by vicariously activating owns own actions, sensations and emotions. Jointly, this work laid the foundation of the neuroscientific investigation of empathy.",
            "score": 154.0759333372116
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 176.2205446958542
        },
        {
            "docid": "11630765_5",
            "document": "Pure alexia . Pure alexia almost always involves an infarct to the left posterior cerebral artery (which perfuses the splenium of the corpus callosum and left visual cortex, among other things). The resulting deficit will be pure alexia \u2013 i.e., the patient can write but cannot read (even what they have just written). However, because pure alexia affects visual input, not auditory input, patients with pure alexia can recognize words that are spelled out loud to them. This is because the left visual cortex has been damaged, leaving only the right visual cortex (occipital lobe) able to process visual information, but it is unable to send this information to the language areas (Broca's area, Wernicke's area, etc.) in the left brain because of the damage to the splenium of the corpus callosum. Patients with this deficit mostly do have a stroke to the posterior cerebral artery. But they may be susceptible to pure alexia as a consequence of other traumatic brain injuries (TBIs) as well. Anything that stops proper blood flow to the area necessary for normal reading abilities will cause a form of alexia. The posterior cerebral artery is a main local for the cause of this deficit because this artery is not just responsible for itself. It also supplies the anterior temporal branches, the posterior temporal branches, the calcarrine branch, and the parieto-occipital branch. What is important about these arteries is their location. All of them supply blood to the back outer parts of the brain. This part of the brain is also referred to as the posterior lateral part of the brain. In cases of pure alexia, locations are found in the section of the brain, specifically the temporo-occipital area. This is the area that is activated when people without any sort of alexia receive activation when undergoing orthographic processing. This area is known as the visual word form area due to this pattern of activation.",
            "score": 150.66222095489502
        },
        {
            "docid": "20395179_7",
            "document": "Vittorio Gallese . Observing the world is more complex than the mere activation of the visual brain. Vision is multimodal: it encompasses the activation of motor, somatosensory and emotion-related brain networks. Any intentional relation entertained with the external world has an intrinsic pragmatic nature, hence it always bears a motor content. The same motor circuits that control our motor behavior also map the space around us, the objects at hand in that very same space, thus defining and shaping in motor terms their representational content. The space around us is defined by the motor potentialities of our body. Motor neurons also respond to visual, tactile and auditory stimuli. Indeed, premotor neurons controlling the movements of the upper arm also respond to tactile stimuli applied to it, to visual stimuli moved within the arm's peripersonal space, or to auditory stimuli also coming from the same peri-personal space. The same applies to artifacts, like three-dimensional objects. The manipulable objects we look at are classified by the motor brain as potential targets of the interactions we might entertain with them. Premotor and parietal 'canonical neurons' control the grasping and manipulation of objects and also respond to their mere observation. The functional architecture of embodied simulation seems to constitute a basic characteristic of our brain, making possible our rich and diversified experiences of space, objects and other individuals, being at the basis of our capacity to empathize with them.\"",
            "score": 133.58716583251953
        },
        {
            "docid": "23029636_19",
            "document": "History of dyslexia research . In 2003, Turkeltaub et al., reported: \"The complexities of pediatric brain imaging have precluded studies that trace the neural development of cognitive skills acquired during childhood. Using a task that isolates reading-related brain activity and minimizes confounding performance effects, we carried out a cross-sectional functional magnetic resonance imaging (fMRI) study using subjects whose ages ranged from 6 to 22 years. We found that learning to read is associated with two patterns of change in brain activity: increased activity in left-hemisphere middle temporal and Inferior frontal gyrus and decreased activity in right inferotemporal cortica areas. Activity in the left-posterior superior temporal sulcus of the youngest readers was associated with the maturation of their phonological processing abilities. These findings inform current reading models and provide strong support for Orton's 1925 theory of reading development.\"",
            "score": 128.93294608592987
        },
        {
            "docid": "21312318_27",
            "document": "Recognition memory . Recognition memory is critically dependent on a hierarchically organized network of brain areas including the visual ventral stream, medial temporal lobe structures, frontal lobe and parietal cortices along with the hippocampus. As mentioned previously, the processes of recollection and familiarity are represented differently in the brain. As such, each of the regions listed above can be further subdivided according to which part is primarily involved in recollection or in familiarity. In the temporal cortex, for instance, the medial region is related to recollection whereas the anterior region is related to familiarity. Similarly, in the parietal cortex, the lateral region is related to recollection whereas the superior region is related to familiarity. An even more specific account divides the medial parietal region, relating the posterior cingulate to recollection and the precuneus to familiarity. The hippocampus plays a prominent role in recollection whereas familiarity depends heavily on the surrounding medial-temporal regions, especially the perirhinal cortex. Finally, it is not yet clear what specific regions of the prefrontal lobes are associated with recollection versus familiarity, although there is evidence that the left prefrontal cortex is correlated more strongly with recollection whereas the right prefrontal cortex is involved more in familiarity. Though left-side activation involved in recollection was originally hypothesized to result from semantic processing of words (many of these earlier studies used written words for stimuli) subsequent studies using nonverbal stimuli produced the same finding\u2014suggesting that prefrontal activation in the left hemisphere results from any kind of detailed remembering.  As previously mentioned, recognition memory is not a stand-alone concept; rather it is a highly interconnected and integrated sub-system of memory. Perhaps misleadingly, the regions of the brain listed above correspond to an abstract and highly generalized understanding of recognition memory, in which the stimuli or items-to-be-recognized are not specified. In reality, however, the location of brain activation involved in recognition is highly dependent on the nature of the stimulus itself. Consider the conceptual differences in recognizing written words compared to recognizing human faces. These are two qualitatively different tasks and as such it is not surprising that they involve additional, distinct regions of the brain. Recognizing words, for example, involves the visual word form area, a region in the left fusiform gyrus, which is believed to specialized in recognizing written words. Similarly, the fusiform face area, located in the right hemisphere, is linked specifically to the recognition of faces.",
            "score": 129.95518612861633
        },
        {
            "docid": "1095131_20",
            "document": "Kinesthetic learning . The cerebral cortex is the brain tissue covering the top and sides of the brain in most vertebrates. It is involved in storing and processing of sensory inputs and motor outputs. In the human brain, the cerebral cortex is actually a sheet of neural tissue about 1/8th inch thick. The sheet is folded so that it can fit inside the skull. The neural circuits in this area of the brain expand with practice of an activity, just like the synaptic plasticity grows with practice. Clarification of some of the mechanisms of learning by neuro science has been advanced, in part, by the advent of non-invasive imaging technologies, such as positron emission tomography (PET) and functional magnetic resonance imaging (FMRI). These technologies have allowed researchers to observe human learning processes directly. Through these types of technologies, we are now able to see and study what happens in the process of learning. In different tests performed the brain being imaged showed a greater blood flow and activation to that area of the brain being stimulated through different activities such as finger tapping in a specific sequence. It has been revealed that the process at the beginning of learning a new skill happens quickly, and later on slows down to almost a plateau. This process can also be referred to as The Law of Learning. The slower learning showed in the FMRI that in the cerebral cortex this was when the long term learning was occurring, suggesting that the structural changes in the cortex reflect the enhancement of skill memories during later stages of training. When a person studies a skill for a longer duration of time, but in a shorter amount of time they will learn quickly, but also only retain the information into their short-term memory. Just like studying for an exam; if a student tries to learn everything the night before, it will not stick in the long run. If a person studies a skill for a shorter duration of time, but more frequently and long-term, their brain will retain this information much longer as it is stored in the long-term memory. Functional and structural studies of the brain have revealed a vast interconnectivity between diverse regions of the cerebral cortex. For example, large numbers of axons interconnect the posterior sensory areas serving vision, audition, and touch with anterior motor regions. Constant communication between sensation and movement makes sense, because to execute smooth movement through the environment, movement must be continuously integrated with knowledge about one's surroundings obtained via sensory perception. The cerebral cortex plays a role in allowing humans to do this.",
            "score": 163.4913479089737
        },
        {
            "docid": "31122898_4",
            "document": "Haptic memory . Tactile memories are organized somatotopically, following the organization of the somatosensory cortex. This means that areas close on the body surface receive nervous signals from areas that are close together on the brain surface. Several distinct areas of the parietal lobe are responsible for contributing to different aspects of haptic memory. Memory for the properties of stimuli such as roughness, spatial density, and texture involves activation of the parietal operculum. Properties of stimuli such as size and shape, as detected by touch receptors in the skin, are stored in the anterior part of the parietal lobe. Memory for spatial information such as the location of stimuli involves the right superior parietal lobule and temporoparietal junction. Additional neuroimaging data has been provided by studies using microelectrodes implanted in the somatosensory cortex of monkeys. When performing a delayed match to sample task with objects of identical dimensions but different surface features, activity is observed in somatosensory neurons during perception and in the short-term memory for tactile stimuli.",
            "score": 121.90667736530304
        },
        {
            "docid": "599917_19",
            "document": "Mental image . Research has occurred to designate a specific neural correlate of imagery; however, studies show a multitude of results. Most studies published before 2001 suggest neural correlates of visual imagery occur in brodmann area 17. Auditory performance imagery have been observed in the premotor areas, precunes, and medial brodmann area 40. Auditory imagery in general occurs across participants in the temporal voice area (TVA), which allows top-down imaging manipulations, processing, and storage of audition functions. Olfactory imagery research shows activation in the anterior piriform cortex and the posterior piriform cortex; experts in olfactory imagery have larger gray matter associated to olfactory areas. Tactile imagery is found to occur in the dorsolateral prefrontal area, inferior frontal gyrus, frontal gyrus, insula, precentral gyrus, and the medial frontal gyrus with basil ganglia activation in the ventral posteriomedial nucleus and putamen (hemisphere activation corresponds to the location of the imagined tactile stimulus). Research in gustatory imagery reveals activation in the anterior insular cortex, frontal operculum, and prefrontal cortex. Novices of a specific form of mental imagery show less gray matter than experts of mental imagery congruent to that form. A meta-analysis of neuroimagery studies revealed significant activation of the bilateral dorsal parietal, interior insula, and left inferior frontal regions of the brain.",
            "score": 146.0531141757965
        }
    ],
    "r": [
        {
            "docid": "15559385_11",
            "document": "Tactile discrimination . When a person has become blind, in order to \u201csee\u201d the world, their other senses become heightened. An important sense for the blind is their sense of touch, which becomes more frequently used to help them perceive the world. People that are blind have displayed that their visual cortices become more responsive to auditory and tactile stimulation. Braille allows the blind to be able to use their sense of touch to feel the roughness, and distance of various patterns to be used as a form of language. Within the brain, the activation of the occipital cortex is functionally relevant for tactile braille reading, as well as the somatosensory cortex. These various parts of the brain function in their own way, in which they each contribute to the effectiveness of how braille is read by the blind. People that are blind also rely heavily on Tactile Gnosis, Spatial discrimination, Graphesthesia, and Two-point discrimination. Essentially, the occipital cortex allows one to effectively make judgements on the distance of braille patterns, which is related to spatial discrimination. Meanwhile, the somatosensory cortex allows one to effectively make judgements on the roughness of braille patterns, which is related to two-point discrimination. The various visual areas in the brain are very essential for a blind person to read braille, just as much as it is for a person that has sight. Essentially, whether one is blind or not, the perception of objects that involves tactile discrimination is not impaired if one cannot see. When comparing people that are blind to people that have sight, the amount of activity within the their somatosensory and visual areas of the brain do differ. The activity in the somatosensory and visual areas are not as high in tactile gnosis for people that are not blind, and are more-so active for more visual related stimuli that does not involve touch. Nonetheless, there is a difference in these various areas within the brain when comparing the blind to the sighted, which is that shape discrimination causes a difference in brain activity, as well as tactile gnosis. The visual cortices of blind individuals are active during various vision related tasks including tactile discrimination, and the function of the cortices resemble the activity of adults with sight.",
            "score": 287.42120361328125
        },
        {
            "docid": "49596807_6",
            "document": "Ludwig Boltzmann Institute for Functional Brain Topography . With 14 early blind subjects the study group Uhl was able to show that specific changes occurred in occipital and basal temporo-occipital brain areas only, whereby the primary visual cortex plays an important role. Subcomponents of Braille reading were correlated in different ways: a) Passive tactile stimulation, b) Active tactile pattern recognition and c) mental imagery of Braille. Although Braille reading is tactile, it does not activate the somatosensory cortex, but the primary visual cortex (striate area) or area 17. Thus the visual cortex remains a cortex for the orientation in space as well as for reading in general including reading Braille with fingers when reading with the eyes fails.",
            "score": 257.266357421875
        },
        {
            "docid": "26945761_6",
            "document": "Cross modal plasticity . There is evidence that the degree of cross modal plasticity between the somatosensory and visual cortices is experience-dependent. In a study using tactile tongue devices to transmit spatial information, early blind individuals were able to show visual cortex activations after 1 week of training with the device. Although there were no cross modal connections at the start, the early blind were able to develop connections between the somatosensory and visual cortices while sighted controls were unable to. Early or congenitally blind individuals have stronger cross modal connections the earlier they began learning Braille. An earlier start allows for stronger connections to form as early blind children have to grow up using their sense of touch to read instead of using their sight. Perhaps due to these cross modal connections, sensory testing studies have shown that people who are born blind and read braille proficiently perceive through touch more rapidly than others. Furthermore, tactile spatial acuity is enhanced in blindness and this enhancement is experience-dependent.",
            "score": 196.9889373779297
        },
        {
            "docid": "1903855_7",
            "document": "Sensory substitution . In a regular visual system, the data collected by the retina is converted into an electrical stimulus in the optic nerve and relayed to the brain, which re-creates the image and perceives it. Because it is the brain that is responsible for the final perception, sensory substitution is possible. During sensory substitution an intact sensory modality relays information to the visual perception areas of the brain so that the person can perceive to see. With sensory substitution, information gained from one sensory modality can reach brain structures physiologically related to other sensory modalities. Touch-to-visual sensory substitution transfers information from touch receptors to the visual cortex for interpretation and perception. For example, through fMRI, we can determine which parts of the brain are activated during sensory perception. In blind persons, we can see that while they are only receiving tactile information, their visual cortex is also activated as they perceive to \"see\" objects. We can also have touch to touch sensory substitution where information from touch receptors of one region can be used to perceive touch in another region. For example, in one experiment by Bach-y-Rita, he was able to restore the touch perception in a patient who lost peripheral sensation from leprosy.",
            "score": 194.1351776123047
        },
        {
            "docid": "26945761_5",
            "document": "Cross modal plasticity . The somatosensory cortex is also able to recruit the visual cortex to assist with tactile sensation. Cross modal plasticity reworks the network structure of the brain, leading to increased connections between the somatosensory and visual cortices. Furthermore, the somatosensory cortex acts as a hub region of nerve connections in the brain for the early blind but not for the sighted. With this cross-modal networking the early blind are able to react to tactile stimuli with greater speed and accuracy, as they have more neural pathways to work with. One element of the visual system that the somatosensory cortex is able to recruit is the dorsal-visual stream. The dorsal stream is used by the sighted to identify spatial information visually, but the early blind use it during tactile sensation of 3D objects. However, both sighted and blind participants used the dorsal stream to process spatial information, suggesting that cross modal plasticity in the blind re-routed the dorsal visual stream to work with the sense of touch rather than changing the overall function of the stream.",
            "score": 193.2062530517578
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 176.22055053710938
        },
        {
            "docid": "1903855_9",
            "document": "Sensory substitution . \"Brain plasticity\" refers to the brain's ability to adapt to a changing environment, for instance to the absence or deterioration of a sense. It is conceivable that cortical remapping or reorganization in response to the loss of one sense may be an evolutionary mechanism that allows people to adapt and compensate by using other senses better. Functional imaging of congenitally blind patients showed a cross-modal recruitment of the occipital cortex during perceptual tasks such as Braille reading, tactile perception, tactual object recognition, sound localization, and sound discrimination. This may suggest that blind people can use their occipital lobe, generally used for vision, to perceive objects through the use of other sensory modalities. This cross modal plasticity may explain the often described tendency of blind people to show enhanced ability in the other senses.",
            "score": 175.27224731445312
        },
        {
            "docid": "41119526_10",
            "document": "Tactile hallucination . Tactile Hallucinations are the result of a dysfunctional somatosensory and a dysfunctional awareness regions of the brain. Tactile sensory input is produced and conducted through the spinal cord and thalamus and it is received at the primary somatosensory cortex. Once it has reached the primary somatosensory cortex, it is distributed across the brain and it will not be processed unless it is important and one pays close attention to the information based on a specific context. Consciousness to these specific tactile sensations is generated only through multiple feedback loops passing through higher cortical areas such as secondary somatosensory area, parietal, insular cortex and premotor areas. The intensity of the tactile stimulus is directly proportional to the area of the primary somatosensory region activated. A feedback mechanism from different cortical areas results in the awareness of touch. Even with complete sensory deprivation, discrete tactile memories can trigger spontaneous firing of impaired neurons. Therefore, individuals with various psychiatric disorders are more prone to tactile hallucinations than normal individuals. Tactile hallucinations are especially possible due to faulty sensory integration of neuronal signals in the primary and secondary somatosensory system with neuronal signals in the parietal cortex, insular cortex and premotor cortex. Moreover, the posterior insula is responsible for mental body schema representation and can produce tactile hallucination if defected. Additionally, it is interesting to note that the regions of the brain involved in tactile hallucinations are similar to the regions of the brain involved in pain.",
            "score": 174.1845703125
        },
        {
            "docid": "7151320_18",
            "document": "Recovery from blindness . At 3 years of age, Michael's vision had still not reached the acuity of an adult person, so his brain was still not completely exposed to all possible clarity of images and light of the environment. This made it difficult for Michael to lead a normal daily life. Cohen et al. (1997) suggested that early blindness causes a poor development of the visual cortex with the result of a decrease in somatosensory development. This study proposed that Michael's long-term blindness affects his ability to distinguish in between faces of males and females, and to recognize pictures and images. In spite of the surgery on his right eye, his newly regained vision, after blindness of forty years, is not fully recovered. Thinus-Blanc and Gaunet (1997) suggest that early blinded people show limited ability in spatial representation. Michael still struggles to identify pictures or illustrations. The impairment of his visual cortex, due to the loss of his vision at a very early age, resulted in visual cortex cells that are not used to the stimuli in his surroundings. Cohen et al. (1997) proposed that in their early age, blinded subjects developed strong motivations to tactile discrimination tasks. Michael's early blindness benefited him so far; he developed very precise senses of hearing and touch.",
            "score": 171.30780029296875
        },
        {
            "docid": "525667_10",
            "document": "Human echolocation . In a 2014 study by Thaler and colleagues, the researchers first made recordings of the clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, not only did they perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. The brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any auditory area, becomes involved in the computation of echolocation tasks.",
            "score": 170.22247314453125
        },
        {
            "docid": "1903855_23",
            "document": "Sensory substitution . While there are no tactile\u2013auditory substitution systems currently available, recent experiments by Schurmann et al. show that tactile senses can activate the human auditory cortex. Currently vibrotactile stimuli can be used to facilitate hearing in normal and hearing-impaired people. To test for the auditory areas activated by touch, Schurmann et al. tested subjects while stimulating their fingers and palms with vibration bursts and their fingertips with tactile pressure. They found that tactile stimulation of the fingers lead to activation of the auditory belt area, which suggests that there is a relationship between audition and tactition. Therefore, future research can be done to investigate the likelihood of a tactile\u2013auditory sensory substitution system. One promising invention is the 'Sense organs synthesizer' which aims at delivering a normal hearing range of nine octaves via 216 electrodes to sequential touch nerve zones, next to the spine.",
            "score": 164.779541015625
        },
        {
            "docid": "1095131_20",
            "document": "Kinesthetic learning . The cerebral cortex is the brain tissue covering the top and sides of the brain in most vertebrates. It is involved in storing and processing of sensory inputs and motor outputs. In the human brain, the cerebral cortex is actually a sheet of neural tissue about 1/8th inch thick. The sheet is folded so that it can fit inside the skull. The neural circuits in this area of the brain expand with practice of an activity, just like the synaptic plasticity grows with practice. Clarification of some of the mechanisms of learning by neuro science has been advanced, in part, by the advent of non-invasive imaging technologies, such as positron emission tomography (PET) and functional magnetic resonance imaging (FMRI). These technologies have allowed researchers to observe human learning processes directly. Through these types of technologies, we are now able to see and study what happens in the process of learning. In different tests performed the brain being imaged showed a greater blood flow and activation to that area of the brain being stimulated through different activities such as finger tapping in a specific sequence. It has been revealed that the process at the beginning of learning a new skill happens quickly, and later on slows down to almost a plateau. This process can also be referred to as The Law of Learning. The slower learning showed in the FMRI that in the cerebral cortex this was when the long term learning was occurring, suggesting that the structural changes in the cortex reflect the enhancement of skill memories during later stages of training. When a person studies a skill for a longer duration of time, but in a shorter amount of time they will learn quickly, but also only retain the information into their short-term memory. Just like studying for an exam; if a student tries to learn everything the night before, it will not stick in the long run. If a person studies a skill for a shorter duration of time, but more frequently and long-term, their brain will retain this information much longer as it is stored in the long-term memory. Functional and structural studies of the brain have revealed a vast interconnectivity between diverse regions of the cerebral cortex. For example, large numbers of axons interconnect the posterior sensory areas serving vision, audition, and touch with anterior motor regions. Constant communication between sensation and movement makes sense, because to execute smooth movement through the environment, movement must be continuously integrated with knowledge about one's surroundings obtained via sensory perception. The cerebral cortex plays a role in allowing humans to do this.",
            "score": 163.49134826660156
        },
        {
            "docid": "2467112_4",
            "document": "E\u015fref Arma\u011fan . In 2008 two researchers from Harvard, Amir Amedi and Alvaro Pascual-Leone, tried to find more about neural plasticity using Armagan as a study case. Both scientists had evidence that in cases of blindness, the \"visual\" cortex acts differently from how it acts with the non-blind. Pascual-Leone has found that Braille readers use this very same area for touch. Amedi, together (with Ehud Zohary) at the Hebrew University in Jerusalem, found that the area is also activated in verbal memory tasks. When Amedi analyzed the results, however, he found that Armagan's visual cortex lit up during the drawing task, but hardly at all for verbal recall, meaning that some unused visual areas might be used in collaboration with ones needs from the brain. Moreover, in scans that were held while Armagan drew, his visual cortex signals seemed as he was seeing to the extent that a naive viewer of his scan might assume Armagan really could see.",
            "score": 163.38107299804688
        },
        {
            "docid": "7913402_16",
            "document": "Paul Baltes . Neuronal plasticity, or the capability of the brain to adapt to new requirements, is a prime example of plasticity stressing that the individual\u2019s ability to change is a lifelong process. Recently, researchers have been analyzing how the spared senses compensate for the loss of vision. Without visual input, blind humans have demonstrated that tactile and auditory functions still fully develop. A superiority of the blind has even been observed when they are presented with tactile and auditory tasks. This superiority may suggest that the specific sensory experiences of the blind may influence the development of certain sensory functions, namely tactile and auditory. One experiment was designed by R\u00f6der and colleagues to clarify the auditory localization skills of the blind in comparison to the sighted. They examined both blind human adults\u2019 and sighted human adults\u2019 abilities to locate sounds presented either central or peripheral (lateral) to them. Both congenitally blind adults and sighted adults could locate a sound presented in front of them with precision but the blind were clearly superior in locating sounds presented laterally. Currently, brain-imaging studies have revealed that the sensory cortices in the brain are reorganized after visual deprivation. These findings suggest that when vision is absent in development, the auditory cortices in the brain recruit areas that are normally devoted to vision, thus becoming further refined.",
            "score": 160.9233856201172
        },
        {
            "docid": "39151518_10",
            "document": "Neuronal recycling hypothesis . As was stated in the neuronal recycling hypothesis, brain circuits bias what we are able to learn. One bias identified involves the preference of central versus peripheral images at different points along the cerebral cortex. It was observed that in all individuals, the visual word form area fell on the region of the cortex with a massive preference for fine-grained, central images. This area is most suitable to accommodate reading ability, due to the high degree of visual precision necessary to perform this function effectively. Another cortical bias relevant to reading comes from the lateralization of cerebral hemispheres. Reading consistently activates the left hemisphere, which is associated with language abilities and discriminating between small shapes, showing a clear bias towards reading functions. There is a preadaptation of the inferior temporal cortex that we use when learning to read. It is the area activated during invariant object recognition, and it's sufficient plasticity allows it to accommodate the new shapes and symbols necessary for reading.",
            "score": 157.5974884033203
        },
        {
            "docid": "305136_57",
            "document": "Visual system . The notion that the cerebral cortex is divided into functionally distinct cortices now known to be responsible for capacities such as touch (somatosensory cortex), movement (motor cortex), and vision (visual cortex), was first proposed by Franz Joseph Gall in 1810. Evidence for functionally distinct areas of the brain (and, specifically, of the cerebral cortex) mounted throughout the 19th century with discoveries by Paul Broca of the language center (1861), and Gustav Fritsch and Edouard Hitzig of the motor cortex (1871). Based on selective damage to parts of the brain and the functional effects of the resulting lesions, David Ferrier proposed that visual function was localized to the parietal lobe of the brain in 1876. In 1881, Hermann Munk more accurately located vision in the occipital lobe, where the primary visual cortex is now known to be.",
            "score": 156.33546447753906
        },
        {
            "docid": "599917_9",
            "document": "Mental image . The biological foundation of the mind's eye is not fully understood. Studies using fMRI have shown that the lateral geniculate nucleus and the V1 area of the visual cortex are activated during mental imagery tasks. Ratey writes: The visual pathway is not a one-way street. Higher areas of the brain can also send visual input back to neurons in lower areas of the visual cortex. [...] As humans, we have the ability to see with the mind's eye \u2013 to have a perceptual experience in the absence of visual input. For example, PET scans have shown that when subjects, seated in a room, imagine they are at their front door starting to walk either to the left or right, activation begins in the visual association cortex, the parietal cortex, and the prefrontal cortex - all higher cognitive processing centers of the brain.",
            "score": 155.2239990234375
        },
        {
            "docid": "4231622_5",
            "document": "Inferior temporal gyrus . The temporal lobe is unique to primates. In humans, the IT cortex is more complex than their relative primate counterparts. The human inferior temporal cortex consists of the inferior temporal gyrus, the middle temporal gyrus, and the fusiform gyrus. When looking at the brain laterally \u2013 that is from the side and looking at the surface of the temporal lobe \u2013 the inferior temporal gyrus is along the bottom portion of the temporal lobe, and is separated from the middle temporal gyrus located directly above by the inferior temporal sulcus. Additionally, some processing of the visual field that corresponds to the ventral stream of visual processing occurs in the lower portion of the superior temporal gyrus closest to the superior temporal sulcus. The medial and ventral view of the brain \u2013 meaning looking at the medial surface from below the brain, facing upwards \u2013 reveals that the inferior temporal gyrus is separated from the fusiform gyrus by the occipital-temporal sulcus. This human inferior temporal cortex is much more complex than that of other primates: non-human primates have an inferior temporal cortex that is not divided into unique regions such as humans' inferior temporal gyrus, fusiform gyrus, or middle temporal gyrus.  This region of the brain corresponds to the inferior temporal cortex and is responsible for visual object recognition and receives processed visual information. The inferior temporal cortex in primates has specific regions dedicated to processing different visual stimuli processed and organized by the different layers of the striate cortex and extra-striate cortex. The information from the V1 \u2013V5 regions of the geniculate and tectopulvinar pathways are radiated to the IT cortex via the ventral stream: visual information specifically related to the color and form of the visual stimuli. Through comparative research between primates \u2013 humans and non-human primates \u2013 results indicate that the IT cortex plays a significant role in visual shape processing. This is supported by functional magnetic resonance imaging (fMRI) data collected by researchers comparing this neurological process between humans and macaques.",
            "score": 154.68722534179688
        },
        {
            "docid": "32018467_7",
            "document": "Christian Keysers . After finishing his master, Christian Keysers decided to concentrate on a subfield of cognitive neuroscience called social neuroscience that uses neuroscience methods to understand how we process the social world. He therefore performed his doctoral studies at the University of St Andrews with David Ian Perrett, one of the founding father of the field, to understand how the brain processes faces and facial expressions. This thesis work led to new insights into how quickly the brain can process the faces of others. During this period, Keysers became fascinated with the question of how the brain can attach meaning to the faces of others. How is it for instance, that we understand that a certain grimace would signal that another person is happy? How do we understand that a certain bodily movement towards a glass indicates that the other person aims to grasp a glass? In 1999, Keysers was exposed to a visit of Vittorio Gallese, who presented his recent discovery of mirror neurons in the Psychology department lecture series. This deeply influenced Keysers who decided to move to the lab of Giacomo Rizzolatti to undertake further studies on how these fascinating neurons could contribute to social perception. In 2000, after finishing his doctorate, Christian Keysers moved to the University of Parma to study mirror neurons. In early work there demonstrated that mirror neurons in the premotor cortex not only respond to the sight of actions, but also when actions can only be deduced or heard, leading to a publication in the journal \"Science\". This work had tremendous impact on the field, as it suggested that the premotor cortex could play a central, modality independent role in perception and may lay the origin for the evolution of speech in humans.  Together this work indicated that brain regions involved in our own actions play a role in how we process the actions of others. Keysers wondered whether a similar principle may underlie how we process the tactile sensations and emotions of others, and became increasingly independent of the research focus on the motor system in Parma. At the time, Keysers had also met his to be wife, Valeria Gazzola, a biologist in the final phases of her studies, and together they decided to explore if the somatosensory system might be involved in perceiving the sensations of others. Via a fruitful collaboration with the French neuroimaging specialist Bruno Wicker, they used functional magnetic resonance imaging, and showed for the first time, that the secondary somatosensory cortex, previously thought only to represent a persons own experiences of touch, is also activated when seeing someone or something else be touched. They also showed that the insula, thought only to respond to the experience of first-hand emotions, was also activated when we see another individual experience similar emotions. Together this indicated a much more general principle than the original mirror neuron theory, in which people process the actions, sensations and emotions of others by vicariously activating owns own actions, sensations and emotions. Jointly, this work laid the foundation of the neuroscientific investigation of empathy.",
            "score": 154.07594299316406
        },
        {
            "docid": "599917_34",
            "document": "Mental image . Recent studies have found that individual differences in VVIQ scores can be used to predict changes in a person's brain while visualizing different activities. Functional magnetic resonance imaging (fMRI) was used to study the association between early visual cortex activity relative to the whole brain while participants visualized themselves or another person bench pressing or stair climbing. Reported image vividness correlates significantly with the relative fMRI signal in the visual cortex. Thus, individual differences in the vividness of visual imagery can be measured objectively.",
            "score": 153.98936462402344
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 153.877197265625
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 153.20687866210938
        },
        {
            "docid": "8305_11",
            "document": "Dyslexia . Modern neuroimaging techniques such as functional magnetic resonance imaging (fMRI) and positron emission tomography (PET) have shown a correlation between both functional and structural differences in the brains of children with reading difficulties. Some dyslexics show less electrical activation in parts of the left hemisphere of the brain involved with reading, such as the inferior frontal gyrus, inferior parietal lobule, and the middle and ventral temporal cortex. Over the past decade, brain activation studies using PET to study language have produced a breakthrough in the understanding of the neural basis of language. Neural bases for the visual lexicon and for auditory verbal short-term memory components have been proposed, with some implication that the observed neural manifestation of developmental dyslexia is task-specific (i.e. functional rather than structural). fMRIs in dyslexics have provided important data which point to the interactive role of the cerebellum and cerebral cortex as well as other brain structures.",
            "score": 152.9866180419922
        },
        {
            "docid": "226722_25",
            "document": "Functional magnetic resonance imaging . Researchers have checked the BOLD signal against both signals from implanted electrodes (mostly in monkeys) and signals of field potentials (that is the electric or magnetic field from the brain's activity, measured outside the skull) from EEG and MEG. The local field potential, which includes both post-neuron-synaptic activity and internal neuron processing, better predicts the BOLD signal. So the BOLD contrast reflects mainly the inputs to a neuron and the neuron's integrative processing within its body, and less the output firing of neurons. In humans, electrodes can be implanted only in patients who need surgery as treatment, but evidence suggests a similar relationship at least for the auditory cortex and the primary visual cortex. Activation locations detected by BOLD fMRI in cortical areas (brain surface regions) are known to tally with CBF-based functional maps from PET scans. Some regions just a few millimeters in size, such as the lateral geniculate nucleus (LGN) of the thalamus, which relays visual inputs from the retina to the visual cortex, have been shown to generate the BOLD signal correctly when presented with visual input. Nearby regions such as the pulvinar nucleus were not stimulated for this task, indicating millimeter resolution for the spatial extent of the BOLD response, at least in thalamic nuclei. In the rat brain, single-whisker touch has been shown to elicit BOLD signals from the somatosensory cortex.",
            "score": 152.94564819335938
        },
        {
            "docid": "533281_40",
            "document": "Interference theory . The performance of Stroop and Simon tasks were monitored on 10 healthy young adults using magnetic resonance image (MRI) scanning. Functional images were acquired at specific time intervals during each subject's scan. Brain activation during the Stroop and Simon task was remarkably similar including anterior cingulate, supplementary motor cortex, visual association cortex, inferior temporal cortex, inferior parietal cortex, inferior frontal cortex, dorsolateral prefrontal cortex, and caudate nuclei. Interference effects in the Stroop and Simon tasks activate similar brain regions at similar time distributions.",
            "score": 151.73843383789062
        },
        {
            "docid": "490258_4",
            "document": "Split-brain . When split-brain patients are shown an image only in the left half of each eye's visual field, they cannot vocally name what they have seen. This is because the image seen in the left visual field is sent only to the right side of the brain (see optic tract), and most people's speech-control center is on the left side of the brain. Communication between the two sides is inhibited, so the patient cannot say out loud the name of that which the right side of the brain is seeing. A similar effect occurs if a split-brain patient touches an object with only the left hand while receiving no visual cues in the right visual field; the patient will be unable to name the object, as each cerebral hemisphere of the primary somatosensory cortex only contains a tactile representation of the opposite side of the body. If the speech-control center is on the right side of the brain, the same effect can be achieved by presenting the image or object to only the right visual field or hand.",
            "score": 151.5994873046875
        },
        {
            "docid": "7151320_17",
            "document": "Recovery from blindness . The effect of visual loss has an impact in the development of the visual cortex of the brain. The visual impairment causes the occipital lobe to lose its sensitivity in perceiving spatial processing. Sui and Morley (2008) proposed that after 7 days of visual deprivation, a potential decrease in vision may occur. They also found an increasing visual impairment with deprivation after 30 days and 120 days. This study suggests that the function of the brain depends on visual input. Michael lost his eyesight at age 3, when his vision was still not fully developed to distinguish shapes, drawings or images clearly. It would be difficult for him to be able to describe the world compared to a normal sighted person. For instance, Michael would have trouble differentiating complex shapes, dimension and orientations of objects. Hannan (2006) hypothesized that the temporal visual cortex uses prior memory and experiences to make sense of shapes, colours and forms. She proposed that the long-term effect of blindness in the visual cortex is the lack of recognition of spatial cues.",
            "score": 150.93678283691406
        },
        {
            "docid": "11630765_5",
            "document": "Pure alexia . Pure alexia almost always involves an infarct to the left posterior cerebral artery (which perfuses the splenium of the corpus callosum and left visual cortex, among other things). The resulting deficit will be pure alexia \u2013 i.e., the patient can write but cannot read (even what they have just written). However, because pure alexia affects visual input, not auditory input, patients with pure alexia can recognize words that are spelled out loud to them. This is because the left visual cortex has been damaged, leaving only the right visual cortex (occipital lobe) able to process visual information, but it is unable to send this information to the language areas (Broca's area, Wernicke's area, etc.) in the left brain because of the damage to the splenium of the corpus callosum. Patients with this deficit mostly do have a stroke to the posterior cerebral artery. But they may be susceptible to pure alexia as a consequence of other traumatic brain injuries (TBIs) as well. Anything that stops proper blood flow to the area necessary for normal reading abilities will cause a form of alexia. The posterior cerebral artery is a main local for the cause of this deficit because this artery is not just responsible for itself. It also supplies the anterior temporal branches, the posterior temporal branches, the calcarrine branch, and the parieto-occipital branch. What is important about these arteries is their location. All of them supply blood to the back outer parts of the brain. This part of the brain is also referred to as the posterior lateral part of the brain. In cases of pure alexia, locations are found in the section of the brain, specifically the temporo-occipital area. This is the area that is activated when people without any sort of alexia receive activation when undergoing orthographic processing. This area is known as the visual word form area due to this pattern of activation.",
            "score": 150.66221618652344
        },
        {
            "docid": "6840372_14",
            "document": "Jeffrey Alan Gray . In discussing this question further, Gray looked at synaesthesia, where he described modalities as becoming mixed, as when numbers or sounds are experienced with colour. Experimentation in recent years has demonstrated that synaesthesia is most likely the consequence of abnormal projections into the V4 colour region of the visual cortex from other parts of the brain. Brain scanning studies have shown that when words are spoken, in addition to the normal activity in the auditory cortex, the V4 colour vision area in the visual cortex became active, in a way which does not occur in normal subjects. There was no related activation in V1 or V2, the earlier stages of the visual pathway. The conclusion drawn from a whole series of experiments was that the 'word-type' of synaesthete has an abnormal projection from the auditory cortex into the visual cortex causing the V4 colour area to produce consciousness of colour. However, there is no evidence that this colour sensation has any function.",
            "score": 150.11766052246094
        },
        {
            "docid": "29806557_6",
            "document": "Vision restoration therapy . The cerebrum is involved with higher brain function, and one component of the cerebrum is the primary visual cortex. The primary visual cortex is a region in the occipital lobe that can be altered by neuroplasticity to create new neuronal pathways around damaged areas to help regain lost visual functions. Sensory visual information is sent from the retina of the eye to the Lateral geniculate nucleus (LGN) in the Thalamus, which relays the visual information to the primary visual cortex by the fibers of the optic radiation. Lesions or damage to parts of the brain that cause visual field defects usually occur posterior to the optic chiasm. Although the exact mechanisms that underlie regaining visual field functions through visual neuroplasticity and VRT are not yet fully known, the reorganization of the primary visual cortex is thought to make new connections and pathways in the optic radiation to the LGN to help regain visual field functions. The stimulation of existing neurons near a damaged site in the brain can form new synapses with other functional neurons to help take on and compensate for the function lost due to the damaged neurons. This is what is theorized to occur during VRT treatment.",
            "score": 148.65841674804688
        },
        {
            "docid": "26166115_3",
            "document": "Audio-visual entrainment . All of our senses (except smell) access the brain's cerebral cortex via the thalamus, and because the thalamus is highly innervated with the cortex, sensory stimulation can easily influence cortical activity. In order to affect brain (neuronal) activity, sensory stimulation must be within the frequency range of roughly 0.5 to 25 hertz (Hz) . Touch, photic and auditory stimulation are capable of affecting brain wave activity. A large area of skin must be stimulated to affect brainwaves, which leaves both auditory and photic stimulation as the most effective and easiest means of affecting brain activity. Therefore, mind machines are typically in the form of light and sound devices.",
            "score": 148.1947784423828
        },
        {
            "docid": "49706798_6",
            "document": "Cortical implant . However, there are some issues that come with direct stimulation of the visual cortex. As with all implants, the impact of their presence over extended periods of time must be monitored. If an implant needs to be removed or re-positioned after a few years, complications can occur. The visual cortex is much more complex and difficult to deal with than the other areas where artificial vision are possible, such as the retina or optic nerve. The visual field is much easier to process in different locations other than the visual cortex. In addition, each areas of the cortex is specialized to deal with different aspects of vision, so simple direct stimulation will not provide complete images to patients. Lastly, surgical operations dealing with brain implants are extremely high-risk for patients, so the research needs to be further improved. However, cortical visual prostheses are important to people who have a completed damaged retina, optic nerve or lateral geniculate body, as they are one of the only ways they would be able to have their vision restored, so further developments will need to be sought out.",
            "score": 146.32009887695312
        }
    ]
}