{
    "q": [
        {
            "docid": "45222866_7",
            "document": "Behavioral game theory . Beliefs about other people in a decision-making game are expected to influence ones ability to make rational choices. However, beliefs of others can also cause experimental results to deviate from equilibrium, utility-maximizing decisions. In an experiment by Costa-Gomez (2008) participants were questioned about their first order beliefs about their opponent's actions prior to completing a series of normal-form games with other participants. Participants complied with Nash Equilibrium only 35% of the time. Further, participants only stated beliefs that their opponents would comply with traditional game theory equilibrium 15% of the time. This means participants believed their opponents would be less rational than they really were. The results of this study show that participants do not choose the utility-maximizing action and they expect their opponents to do the same. Also, the results show that participants did not choose the utility-maximizing action that corresponded to their beliefs about their opponent's action. While participants may have believed their opponent was more likely to make a certain decision, they still made decisions as if their opponent was choosing randomly. Another study that examined participants from the TV show Deal or No Deal found divergence from rational choice. Participants were more likely to base their decisions on previous outcomes when progressing through the game. Risk aversion decreased when participants' expectations were not met within the game. For example a subject that experienced a string of positive outcomes was less likely to accept the deal and end the game. The same was true for a subject that experienced primarily negative outcomes early in the game.",
            "score": 171.3986736536026
        },
        {
            "docid": "1805135_12",
            "document": "Inequity aversion . In 2011, Ert Erev and Roth ran a model prediction competition on two datasets, each of which included 120 two-player games. In each game player 1 decides whether to \"opt out\" and determine the payoffs for both players, or to \"opt in\" and let player 2 decide about the payoff allocation by choosing between actions \"left\" or \"right\". The payoffs were randomly selected, so the dataset included games like the Ultimatum, Dictator, and Trust, as well as other games. The results suggested that inequity aversion could be described as one of many strategies that people might use in such games.",
            "score": 128.4735951423645
        },
        {
            "docid": "2352847_2",
            "document": "Strategic dominance . In game theory, strategic dominance (commonly called simply dominance) occurs when one strategy is better than another strategy for one player, no matter how that player's opponents may play. Many simple games can be solved using dominance. The opposite, intransitivity, occurs in games where one strategy may be better or worse than another strategy for one player, depending on how the player's opponents may play. When a player tries to choose the \"best\" strategy among a multitude of options, that player may compare two strategies A and B to see which one is better. The result of the comparison is one of: This notion can be generalized beyond the comparison of two strategies.",
            "score": 137.39579796791077
        },
        {
            "docid": "4698768_6",
            "document": "Naturalistic decision-making . The recognition-primed decision (RPD) model is the main protocol derived from the NDM framework. RPD describes how people use their experience in the form of patterns. These patterns highlight the relevant cues, provide expected outcomes, identify plausible goals, and suggest typical types of reactions in that type of situation. When people need to make a decision, they can quickly match the situation to the patterns they have learned and experienced in the past. Doing this, people can successfully make rapid decisions. The RPD model explains how people can make good decisions without comparing options. However, there is more to the RPD model than pattern matching. How can a person evaluate an option without comparing it with others? It has been found that fireground commanders evaluate a course of action by using mental simulation to imagine how a situation would play out within the context of the current situation. If it would work, then the commanders could initiate the action. If it almost worked, they could try to adapt it or else consider other actions that were somewhat less typical, continuing until they found an option that felt comfortable. This process exemplifies Herbert Simon's (1957) notion of satisficing \u2013 looking for the first workable option rather than trying to find the best possible option. Because fires grow exponentially, the faster the commanders could react, the easier their job. Therefore, the RPD model is a blend of intuition and analysis. The pattern matching is the intuitive part, and the mental simulation is the conscious, deliberate, and analytical part. Intuitive strategy relying only on pattern matching would be too risky because sometimes the pattern matching generates flawed options. Also, a completely deliberative and analytical strategy would be too slow; the fires would be out of control by the time the commanders finished deliberating. In-depth interviews with fireground commanders who recently experienced challenging incidents show that the percentage of RPD strategies used in those situations generally ranged from 80% to 90% (Klein, 1989). Other researchers have replicated these findings (see Klein, 1998). The first moves that occurred to them were much better than would be expected by chance. These findings support the RPD hypothesis that the first option considered is usually satisfactory. These results were later replicated by Johnson and Raab (2003).",
            "score": 140.01891899108887
        },
        {
            "docid": "9292690_9",
            "document": "Risk dominance . A number of evolutionary approaches have established that when played in a large population, players might fail to play the payoff dominant equilibrium strategy and instead end up in the payoff dominated, risk dominant equilibrium. Two separate evolutionary models both support the idea that the risk dominant equilibrium is more likely to occur. The first model, based on replicator dynamics, predicts that a population is more likely to adopt the risk dominant equilibrium than the payoff dominant equilibrium. The second model, based on best response strategy revision and mutation, predicts that the risk dominant state is the only stochastically stable equilibrium. Both models assume that multiple two-player games are played in a population of N players. The players are matched randomly with opponents, with each player having equal likelihoods of drawing any of the N\u22121 other players. The players start with a pure strategy, G or H, and play this strategy against their opponent. In replicator dynamics, the population game is repeated in sequential generations where subpopulations change based on the success of their chosen strategies. In best response, players update their strategies to improve expected payoffs in the subsequent generations. The recognition of Kandori, Mailath & Rob (1993) and Young (1993) was that if the rule to update one's strategy allows for mutation, and the probability of mutation vanishes, i.e. asymptotically reaches zero over time, the likelihood that the risk dominant equilibrium is reached goes to one, even if it is payoff dominated.",
            "score": 164.23559749126434
        },
        {
            "docid": "26990501_4",
            "document": "Marvel vs. Capcom 3: Fate of Two Worlds . \"Marvel vs. Capcom 3: Fate of Two Worlds\" is a fighting game in which players compete in battle using characters with different fighting styles and special attacks. The game features tag team-based gameplay similar to previous installments of the series. Players select teams of three characters to engage in one-on-one combat, and can choose to switch between them at any point during the match. During combat, players can call in one of their off-screen characters to perform a single special move, known as an \"assist\". As characters deal or receive damage, their team's \"Hyper Combo Gauge\" will gradually fill with energy, which can be expended by players to execute certain techniques, such as hyper combos, which are stronger versions of special moves; \"snapbacks\", which force the current opponent off the screen and replaces them with one of their other teammates; and \"crossover combinations\", which summon the player's entire team to use their hyper combos all at once. Players must use the various attacks in their arsenal to exhaust their opponent's life gauge and defeat the entire enemy team, or have the most cumulative health when time runs out. \"Marvel vs. Capcom 3\" is the first entry in the franchise to feature three-dimensional character models as opposed to two-dimensional sprites. However, gameplay remains restricted to two dimensions, resulting in a 2.5D graphical design.",
            "score": 111.43887114524841
        },
        {
            "docid": "5970591_20",
            "document": "Ideal free distribution . However, this prediction assumes that each individual will act on its own. It does not hold for situations involving group choice, which is an example of social behavior. In 2001, Kraft et al. performed an experiment that tested the IFD\u2019s predictions of group choice using humans. This experiment involved groups of participants choosing between blue and red cards in order to earn points towards prizes. When the groups\u2019 choice of cards was graphed in relation to the ratios between the points, the slopes demonstrated some undermatching, which is a deviation from the Matching Law. Undermatching is the situation when the ratio of foragers between two patches (in this case, how many people picked each card) is less than the ratio of resources between the two patches (the points each card is worth). The results show that the IFD could not predict the outcome. However, they also show that it is possible to apply the Ideal Free Distribution to group choice, if that group choice is motivated by the individuals\u2019 tendencies to maximize positive reinforcement.",
            "score": 98.24714934825897
        },
        {
            "docid": "2539764_66",
            "document": "Two envelopes problem . Some authors prefer to think of probability in a frequentist sense. If the player knows the probability distribution used by the organizer to determine the smaller of the two values, then the analysis would proceed just as in the case when \"p\" or \"f\" represents subjective prior beliefs. However, what if we take a frequentist point of view, but the player does not know what probability distribution is used by the organiser to fix the amounts of money in any one instance? Thinking of the arranger of the game and the player as two parties in a two-person game, puts the problem into the range of game theory. The arranger's strategy consists of a choice of a probability distribution of \"x\", the smaller of the two amounts. Allowing the player also to use randomness in making his decision, his strategy is determined by his choosing a probability of switching formula_53 for each possible amount of money \"a\" he might see in Envelope A. In this section we so far only discussed \"fixed strategies\", that is strategies for which \"q\" only takes the values 0 and 1, and we saw that the player is fine with a fixed strategy, if he knows the strategy of the organizer. In the next section we will see that randomized strategies can be useful when the organizer's strategy is not known.",
            "score": 145.1671426296234
        },
        {
            "docid": "8421833_3",
            "document": "4th &amp; Inches . Like other sports games by Bob Whitehead, \"4th & Inches\" was hailed upon release, combining the action of previous titles with the new feature of strategic play calling. For the first time in a computer football game, players could choose from a number of plays. The player initially designated a formation, and then selected one of five plays based on the formation. These plays included a great number of offensive strategies, including draws, curls, sweeps and long bombs, among others. Defensive tactics equally were varied, with the player being able to choose a defensive formation based on what they thought the opponent would attempt.",
            "score": 122.96191763877869
        },
        {
            "docid": "4068088_8",
            "document": "The King of Fighters '94 . Notably, \"KOF 94\" innovated the genre by replacing a traditional round-based format used in preceding fighting games with a format consisting of 3-on-3 team based matches dubbed the Team Battle System. Instead of choosing a single character, the player selects from one of eight available teams, each consisting of three members. Before each match, the players choose the order in which each of their team member enters the battle. When the match begins, the members chosen to go first on their respective teams will fight. When one character is defeated, the following member of the same team will take his or her place, while the character on the other team will have a small portion of their life restored (if energy was lost during the previous round). If a character is losing a match against the opponent, then the player can call one of the remaining teammates standing on the sidelines to jump in and perform a support attack. The match ends when all three members of either team lose.",
            "score": 98.86593449115753
        },
        {
            "docid": "1602490_4",
            "document": "Extensive-form game . A play is thus a path through the tree from the root to a terminal node. At any given non-terminal node belonging to Chance, an outgoing branch is chosen according to the probability distribution. At any rational player's node, the player must choose one of the equivalence classes for the edges, which determines precisely one outgoing edge except (in general) the player doesn't know which one is being followed. (An outside observer knowing every other player's choices up to that point, and the realization of Nature's moves, can determine the edge precisely.) A pure strategy for a player thus consists of a selection\u2014choosing precisely one class of outgoing edges for every information set (of his). In a game of perfect information, the information sets are singletons. It's less evident how payoffs should be interpreted in games with Chance nodes. It is assumed that each player has a von Neumann\u2013Morgenstern utility function defined for every game outcome; this assumption entails that every rational player will evaluate an a priori random outcome by its expected utility. The above presentation, while precisely defining the mathematical structure over which the game is played, elides however the more technical discussion of formalizing statements about how the game is played like \"a player cannot distinguish between nodes in the same information set when making a decision\". These can be made precise using epistemic modal logic; see for details.",
            "score": 119.8601576089859
        },
        {
            "docid": "39258533_14",
            "document": "My Kitchen Rules (series 5) . Rapid Cook-off: One on One: \u2014 The six teams were to compete head to head with another team in a 30-minute rapid cook-off. The money ranking from the previous challenge determined how the game process will be played out. As Bree and Jessica received the most money out of the six, they were able to choose their opponent, however their opponent determined which protein both teams will use to cook. In this case, Thalia and Bianca were the selected opponent and chose game meats as the protein. Next in line was Cathy and Anna, choosing Helena and Vikki as their opponent. They then chose lamb as the protein. Out of the two remaining teams, Josh and Danielle had made more money than Chloe and Kelly, but since they were left with no choice of opponent, they were able to choose the protein and decided on fish. The three winning teams from each head to head became safe from elimination, while the three losing teams headed into the next Showdown.<br> Showdown: Entree, Main, Dessert: \u2014 As the losing teams from the previous head to head battles, they must now cook one course out of Entree, Main and Dessert in an hour. Only one team can cook one course and this was decided in a verbal first-say-first-go basis between the three teams. The losing team from this Showdown, headed into Sudden Death with Carly and Tresne.",
            "score": 120.79875075817108
        },
        {
            "docid": "759831_6",
            "document": "Best response . Games such as the game of chicken and hawk-dove game in which players score highest when they choose opposite strategies, i.e., discoordinate, are called anti-coordination games. They have reaction correspondences (Figure 4) that cross in the opposite direction to coordination games, with three Nash equilibria, one in each of the top left and bottom right corners, where one player chooses one strategy, the other player chooses the opposite strategy. The third Nash equilibrium is a mixed strategy which lies along the diagonal from the bottom left to top right corners. If the players do not know which one of them is which, then the mixed Nash is an evolutionarily stable strategy (ESS), as play is confined to the bottom left to top right diagonal line. Otherwise an uncorrelated asymmetry is said to exist, and the corner Nash equilibria are ESSes. Games with dominated strategies have reaction correspondences which only cross at one point, which will be in either the bottom left, or top right corner in payoff symmetric 2x2 games. For instance, in the single-play prisoner's dilemma, the \"Cooperate\" move is not optimal for any probability of opponent Cooperation. Figure 5 shows the reaction correspondence for such a game, where the dimensions are \"Probability play Cooperate\", the Nash equilibrium is in the lower left corner where neither player plays Cooperate. If the dimensions were defined as \"Probability play Defect\", then both players best response curves would be 1 for all opponent strategy probabilities and the reaction correspondences would cross (and form a Nash equilibrium) at the top right corner.",
            "score": 150.87266337871552
        },
        {
            "docid": "28714082_13",
            "document": "Wald's maximin model . Inspired by maximin models of game theory, Abraham Wald developed this model in the early 1940s as an approach to situations in which there is only one player (the decision maker). The second player represents a pessimistic (worst case) approach to uncertainty. In Wald's maximin model, player 1 (the formula_8 player) plays first and player 2 (the formula_20 player) knows player 1's decision when he selects his decision. This is a major simplification of the classic 2-person zero-sum game in which the two players choose their strategies without knowing the other player's choice. The game of Wald's maximin model is also a 2-person zero-sum game, but the players choose sequentially.",
            "score": 96.36699891090393
        },
        {
            "docid": "45222866_8",
            "document": "Behavioral game theory . Social behavior and cooperation with other participants are two factors that are not modeled in traditional game theory, but are often seen in an experimental setting. The evolution of social norms has been neglected in decision-making models, but these norms influence the ways in which real people interact with one another and make choices. One tendency is for a person to be a strong reciprocator. This type of person enters a game with the predisposition to cooperate with other players. They will increase their cooperation levels in response to cooperation from other players and decrease their cooperation levels, even at their own expense, to punish players who do not cooperate. This is not utility-maximizing behavior, as a strong reciprocator is willing to reduce their payoff in order to encourage cooperation from others. Dufwenberg and Kirchsteiger (2004) developed a model based on reciprocity called the sequential reciprocity equilibrium. This model adapts traditional game theory logic to the idea that players reciprocate actions in order to cooperate. The model had been used to more accurately predict experimental outcomes of classic games such as the prisoner's dilemma and the centipede game. Rabin (1993) also created a fairness equilibrium that measures altruism's effect on choices. He found that when a player is altruistic to another player the second player is more likely to reciprocate that altruism. This is due to the idea of fairness. Fairness equilibriums take the form of mutual maximum, where both players choose an outcome that benefits both of them the most, or mutual minimum, where both players choose an outcome that hurts both of them the most. These equilibriums are also Nash equilibriums, but they incorporate the willingness of participants to cooperate and play fair.",
            "score": 130.1968195438385
        },
        {
            "docid": "26254667_3",
            "document": "Porter's four corners model . This helps in determining competitor's action by understanding their goals (both strategic and tactical) and their current position vis-\u00e0-vis their goals. A wide gap between the two could mean the competitor is highly likely to react to any external threat that comes in its way, whereas a narrower gap is likely to produce a defensive strategy.  The question to be answered here is: What is it that drives the competitor? These drivers can be at various levels and dimensions and can provide insights into future goals. The perceptions and assumptions the competitor has about itself and its industry would shape strategy. This corner includes determining the competitor's perception of its strengths and weaknesses, organization culture and their beliefs about competitor's goals. If the competitor thinks highly of its competition and has a fair sense of industry forces, it is likely to be ready with plans to counter any threats to its position. On the other hand, a competitor who has a misplaced understanding of industry forces is not very likely to respond to a potential attack. The question to be answered here is: What are competitor's assumption about the industry, the competition and its own capabilities? A competitor's strategy determines how it competes in the market. However, there could be a difference between the company's intended strategy (as stated in the annual report and interviews) and its realized strategy (as is evident in its acquisitions, new product development, etc.).  It is therefore important here to determine the competitor's realized strategy and how they are actually performing. If current strategy is yielding satisfactory results, it is safe to assume that the competitor is likely to continue to operate in the same way. The questions to be answered here are: What is the competitor actually doing and how successful is it in implementing its current strategy?",
            "score": 104.8539342880249
        },
        {
            "docid": "11336559_10",
            "document": "Traveler's dilemma . Furthermore, the travelers are rewarded by deviating strongly from the Nash equilibrium in the game and obtain much higher rewards than would be realized with the purely rational strategy. These experiments (and others, such as focal points) show that the majority of people do not use purely rational strategies, but the strategies they do use are demonstrably optimal. This paradox could reduce the value of pure game theory analysis, but could also point to the benefit of an expanded reasoning that understands how it can be quite rational to make non-rational choices, at least in the context of games that have players that can be counted on to not play \"rationally.\" For instance, Capraro has proposed a model where humans do not act a priori as single agents but they forecast how the game would be played if they formed coalitions and then they act so as to maximize the forecast. His model fits the experimental data on the Traveler's dilemma and similar games quite well. Recently, the traveler's dilemma was tested with decision undertaken in groups rather than individually, in order to test the assumption that groups decisions are more rational, delivering the message that, usually, two heads are better than one. Experimental findings show that groups are always more rational \u2013 i.e. their claims are closer to the Nash equilibrium - and more sensitive to the size of the bonus/malus.",
            "score": 113.89232897758484
        },
        {
            "docid": "7502798_3",
            "document": "Peace war game . The peace war game is a variation of the iterated prisoner's dilemma in which the decisions (Cooperate, Defect) are replaced by (Peace, War). Strategies remain the same with reciprocal altruism, \"Tit for Tat\", or \"provokable nice guy\" as the best deterministic one. This strategy is simply to make peace on the first iteration of the game; after that, the player does what his opponent did on the previous move. A slightly better strategy is \"Tit for Tat with forgiveness\". When the opponent makes war, on the next move, the player sometimes makes peace anyway, with a small probability. This allows an escape from wasting cycles of retribution, a motivation similar to the Rule of Ko in the game of Go. \"Tit for Tat with forgiveness\" is best when miscommunication is introduced, when one's move is incorrectly reported to the opponent. A typical payoff matrix for two players (A, B) of one iteration of this game is: Here a player's resources have a value of 2, half of which must be spent to wage war. In this case, there exists a Nash equilibrium, a mutually best response for a single iteration, here (War, War), by definition heedless of consequences in later iterations. \"Provokable nice guy's\" optimality depends on iterations. How many are necessary is likely tied to the payoff matrix and probabilities of choosing. A subgame perfect version of this strategy is \"Contrite Tit-for-Tat\" which is to make peace unless one is in \"good standing\" and one's opponent is not. Good (\"standing\" assumed) means to make peace with good opponents, make peace when bad, or make war when good and opponent is not.",
            "score": 169.15171039104462
        },
        {
            "docid": "15842171_9",
            "document": "Magic: The Gathering \u2013 Duels of the Planeswalkers . The game's artificial intelligence (AI) is based on creating a multistep \"lookahead\" decision tree from the current state of the board, evaluating possible known moves by its opponents, scoring the current and resulting situations both positively and negatively, and then selecting the option with the highest score. The artificial intelligence utilizes threading to run the main intelligence algorithm alongside three \"sub-contractors\" that evaluate the possible future states and report back to the main algorithm. Each of these instances of the AI uses a special engine that both implements the rules of \"Magic\", while also providing \"undo\" actions so that they may explore up and down the decision tree. The game's intelligence algorithm runs on a separate CPU core than the main game to avoid creating framerate issues with its display while the player is considering their actions. When the player makes an action, the AI threads are interrupted and brought to the same state as the game, then continue processing, in some cases, reusing existing branches on the decision tree that match with the player's selection. The AI itself does not employ any strategy in terms of strong card combinations, but instead, when such combinations improve the computer's situation, the chances of playing these combinations will \"ripple\" back through the decision tree. In this manner, the computer AI will play one card of such a combination should it be the best choice at that time, and follow up with the second card of the combination should that option still remain the best after any other player actions.",
            "score": 146.22782611846924
        },
        {
            "docid": "47349294_12",
            "document": "Subjective expected relative similarity (SERS) . Developing the SERS theory into an evolutionary strategy yields the \"Mimicry and Relative Similarity (MaRS)\" algorithm. Fusing enacted and expected mimicry generates a powerful and cooperative mechanism that enhances fitness and reduces the risks associated with trust and cooperation. When conflicts take the form of repeated PD games, individuals get the opportunity to learn and monitor the extent of similarity with their opponents. They can then react by choosing whether to enact, expect, or exclude mimicry. This rather simple behavior has the capacity to protect individuals from exploitation and drive the evolution of cooperation within entire populations. MaRS paves the way for the induction of cooperation and supports the survival of other cooperative strategies. The existence of MaRS in heterogeneous populations helps those cooperative strategies that do not have the capacity of MaRS to combat hostile and random opponents. Despite the fact that MaRS cannot prevail in a duel with an unconditional defector, interacting within heterogeneous populations allows MaRS to fight unpredictable and hostile strategies and cooperate with cooperative ones, including itself. The operation of MaRS promotes cooperation, minimizes the extent of exploitation, and accounts for high fitness levels. Testing the model in computer simulations of behavioral niches, populated with agents that enact various strategies and learning algorithms, shows how mimicry and relative similarity outperforms all the opponent strategies it was tested against, pushes noncooperative opponents toward extinction, and promotes the development of cooperative populations.",
            "score": 140.43744552135468
        },
        {
            "docid": "39254605_27",
            "document": "Puzzle &amp; Dragons . The arcade game was released in collaboration with Square Enix on April 24, 2014. Gameplay in \"Battle Tournament\" is similar to the mobile game. The player uses a team of monsters and solves a tile-matching puzzle to determine how powerful their monsters' attacks are, and can activate their monsters' active skills during play for various effects and choose one monster to serve as team leader to use the passive leader skill. However, several changes were made to suit the arcade version, which uses the NESiCA smart card to save playing data for individual players. The puzzle is now on an 8-by-5 grid, allowing for greater movement and combos. The player's team of monsters consists only of their leader monster, three sub members, and a friend monster, however the player can also choose three reserve monsters that they can switch into play. Players choose avatars to play through the game's story mode as well as its online mode to play against other players in real time, and these avatars have their own active skills that can be used during play. Monsters' HP is not pooled, and individual monsters can be temporarily knocked out of play if they lose all HP. If more damage is dealt by the player's monsters when any have run out of HP, then the opponent receives direct damage. When either player's HP runs out, they lose the match. Throughout play, players can obtain special items used to either evolve their collected monsters or to use the game's Rare Egg Machine to obtain new monsters.",
            "score": 99.6379200220108
        },
        {
            "docid": "12711100_12",
            "document": "Duel2 . The individual strategy consists of selecting weapons, selecting Offensive Efforts(OE), Activity Levels (AL), Kill Desires (KD), Attack Locations, Protect Locations, Offensive Tactics, Defensive Tactics, Armor, Head Protection, Desired Training, Challenges, Avoids, and whether you wish an alternate strategy for Challenges, whether the player's or another player's. The player gets twenty-two weapons that can be selected, regardless of whether the warrior is capable of wielding them effectively or not. The OE, AL, and KD are a number between 1-10 which the player selects. Attack and Protect Locations are the places where the warrior will try to concentrate their attacks. In the tactics section, warriors can choose to use a tactic for offense or defense or both which will make them concentrate on a particular portion of their overall abilities. The game offers seven types of armor and four choices of head protection, not including the option of fighting with no armor or helmet. Training is either to increase an attribute (except size) or to learn skills. Challenges allow the player to request a fight against up to two specific warriors. Avoids allow the player to request that their warrior not face warriors from up to two specific teams. And in the event that a Challenge goes through, the player may wish to use an alternate strategy and this is what goes on the back of the turn sheet.",
            "score": 102.90842425823212
        },
        {
            "docid": "2852685_7",
            "document": "Apollo Justice: Ace Attorney . The trial portions consist of listening to and cross-examining witness testimonies. The player is given the option to either Press or Present evidence in response to statements made by witnesses. The player can either select their choice or yell into the microphone. By choosing Press, the player questions the witness's statement, which sometimes causes the witness to change their testimony. When finding inconsistencies in the testimony, the player may choose Present in order to show a piece of evidence that they think contradicts the testimony. The player has a health bar, representing the judge's patience. If the player presents incorrect pieces of evidence or choose incorrect answers to questions in court, health is lost. If the health bar reaches zero, the player loses the game and their client is declared guilty. A new system, known as the \"Perceive System,\" can be used to look for motions or actions made by witnesses that show nervousness, similar to a tell in poker. The game also includes a \"Crime Recreation Mode\" that models evidence or the crime scene in a 3-D rendition and allow the player to explore the recreation to look for clues. Additionally, the game often recreates the crime in cutscene sequences, allowing the player to observe the action and find contradictions.",
            "score": 73.09957504272461
        },
        {
            "docid": "18933251_10",
            "document": "Battle.net . \"\" was released in 2002 and its expansion pack, \"\", was released in 2003. The release of these two games brought with them a number of new features to the online service. The most significant feature to be added was probably the concept of Anonymous Matchmaking. This feature allowed a user who wanted to play a game to simply press a button and automatically be matched up with one or more other players who were similar in skill (based on ranking) and also wanted to play a game. This allowed for people to get into games quickly and easily. It also reduced win-trading, where two people would purposely win and lose games to artificially raise their rank on the ladder. The matchmaking concept was also expanded to team games in a feature called \"Arranged Teams\". In an arranged team game, you could make a team with one or more friends, which was then anonymously matched up with another team of the same size and rank. However, a strategy was introduced on how to cheat the automated 'fair' matchups, called 'Abusing', simply by someone losing the Arranged Team Games intentionally with one ally so that with another ally (who wants to gain wins easily) won't find it difficult because the automatic matchups would put the two players up against relatively unskilled players. Automated tournaments were added in the expansion, where players would compete to be crowned tournament champion in a series of games played throughout the day. In addition to the new game styles, a slew of other features were added including selectable chatroom icons unlocked based on the player's number of wins, a friends list, and clan support.",
            "score": 113.34106075763702
        },
        {
            "docid": "24406823_4",
            "document": "The Kung-Fu Master Jackie Chan . The player's character fights against his or her opponent in standard one-on-one best two-of-three format like most fighting games, but a match can last up to five rounds if there is no clear-cut winner in previous rounds (the game will end if both fighters lose the fifth round and no bonus points will be awarded if one wins the fifth round). Players has a character roster of six fighters to choose from at the start, each with their own fighting style and special techniques. In one player mode, after selecting a character, the arcade randomly selects an opponent. After two opponents are knocked out, one out of three versions of Jackie Chan becomes the next opponent. Unlike the \"Mortal Kombat\" series, some powerful finishing moves lack blood and gore, some don't destroy the opponents. The fast-paced action and zooming view are similar to that of numerous Neo-Geo fighting games.",
            "score": 139.20477557182312
        },
        {
            "docid": "45337_27",
            "document": "Nash equilibrium . This situation can be modeled as a \"game\" where every traveler has a choice of 3 strategies, where each strategy is a route from A to D (either , , or ). The \"payoff\" of each strategy is the travel time of each route. In the graph on the right, a car travelling via experiences travel time of , where is the number of cars traveling on edge . Thus, payoffs for any given strategy depend on the choices of the other players, as is usual. However, the goal, in this case, is to minimize travel time, not maximize it. Equilibrium will occur when the time on all paths is exactly the same. When that happens, no single driver has any incentive to switch routes, since it can only add to their travel time. For the graph on the right, if, for example, 100 cars are travelling from A to D, then equilibrium will occur when 25 drivers travel via , 50 via , and 25 via . Every driver now has a total travel time of 3.75 (to see this, note that a total of 75 cars take the edge, and likewise, 75 cars take the edge).",
            "score": 81.16247570514679
        },
        {
            "docid": "5363_76",
            "document": "Video game . Short for electronic sports, are video game competitions played most by professional players individually or in teams that gained popularity from the late 2000s, the most common genres are fighting, first-person shooter (FPS), multiplayer online battle arena (MOBA) and real-time strategy. There are certain games that are made for just competitive multiplayer purposes. With those type of games, players focus entirely one choosing the right character or obtaining the right equipment in the game to help them when facing other players. Tournaments are held so that people in the area or from different regions can play against other players of the same game and see who is the best. Major League Gaming (MLG) is a company that reports tournaments that are held across the country. The players that compete in these tournaments are given a rank depending on their skill level in the game that they choose to play in and face other players that play that game. The players that also compete are mostly called professional players for the fact that they have played the game they are competing in for many, long hours. Those players have been able to come up with different strategies for facing different characters. The professional players are able to pick a character to their liking and be able to master how to use that character very effectively. With strategy games, players tend to know how to get resources quick and are able to make quick decisions about where their troops are to be deployed and what kind of troops to create.",
            "score": 131.0323302745819
        },
        {
            "docid": "1195168_35",
            "document": "Paul Milgrom . Milgrom and Roberts build on their work in supermodular games to understand the processes by which strategic agents reach equilibrium in a normal-form game. In Milgrom and Roberts (1991), they proposed two learning processes each with a degree of generality so as to not model learning but learning processes. They considered a sequence of plays over time which, for a player \"n\", is denoted {\"x\"(\"t\")} where for each possible time, \"t\", \"x\"(\"t\") is a pure strategy. Given this, an observed sequence, {\"x\"(\"t\")}, is \"consistent with adaptive learning\" if a player \"n\" eventually chooses only strategies that are nearly best-replies to some probability distribution over the joint strategies of other players (with near zero probability being assigned to strategies that have not been played for a sufficiently long time). By contrast, {\"x\"(\"t\")}, is \"consistent with sophisticated learning\" if the player eventually chooses only nearly best-replies to their probabilistic forecast of the choices of other players, where the support of that probability distribution may include not only past plays but also strategies that the players might choose if they themselves were adaptive or sophisticated learners. Thus, a sequence consistent with adaptive learning is also consistent with sophisticated learning. Sophisticated learning allows players to make use of payoff information that is used in equilibrium analysis but does not impose the fulfilled expectations requirement of equilibrium analysis.",
            "score": 115.07972776889801
        },
        {
            "docid": "31919748_13",
            "document": "FIFA 12 . EA claims to have \"revolutionized\" the online side of \"FIFA 12\". Among the changes is a new mode called \"Head to Head Seasons\", a variation on regular ranked matches where league points are awarded for winning or drawing matches. The aim is to progress up through ten divisions, with each \"season\" consisting of ten games. All players will start in the tenth and lowest division, with promotion and relegation based on a target number of points won in each season. Multiplayer matchmaking has been expanded with the addition of the \"flow\" mode. This involves choosing various options such as team and line-up before being matched with an opponent. This change is intended to counter the problem of being paired with opponents who choose one of a small number of five-star teams, a situation that often results in repetitive matches between the same few clubs. By selecting a team beforehand, an opponent with similar team preferences will automatically be chosen. There is also the option for players who use the \"manual\" control method, with reduced AI assistance on shots and passes, to choose to be paired against other \"manual\" users only. The percentage of games an opponent has finished can be specified too, making it easier to avoid \"rage quitters\".",
            "score": 128.8694715499878
        },
        {
            "docid": "11336559_9",
            "document": "Traveler's dilemma . The ($2, $2) outcome in this instance is the Nash equilibrium of the game. By definition this means that if your opponent chooses this Nash equilibrium value then your best choice is that Nash equilibrium value of $2. This will not be the optimum choice if there is a chance of your opponent choosing a higher value than $2. When the game is played experimentally, most participants select a value higher than the Nash equilibrium and closer to $100 (corresponding to the Pareto optimal solution). More precisely, the Nash equilibrium strategy solution proved to be a bad predictor of people\u2019s behavior in a traveler's dilemma with small bonus/malus and a rather good predictor if the bonus/malus parameter was big.",
            "score": 144.52355122566223
        },
        {
            "docid": "45222866_10",
            "document": "Behavioral game theory . Incentives and consequences also play a large role in deception in games. Gneezy (2005) studied deception using a cheap talk sender-receiver game. In this type of game player one receives information about the payouts of option A and option B. Then, player one gives a recommendation to player two about which option to take. Player one can choose to deceive player two, and player two can choose to reject player one's advice. Gneezy found that participants were more sensitive to their gain from lying than to their opponent's loss. He also found that participants were not wholly selfish and cared about how much their opponents lost from their deception, but this effect diminished as their own payout increased. These findings show that decision makers examine both incentives to lie and consequences of lying in order to decide whether or not to lie. In general people are averse to lying, but given the right incentives they tend to ignore consequences. Wang (2009) also used a cheap talk game to study deception in participants with an incentive to deceive. Using eye tracking he found that participants who received information about payoffs focused on their own payoff twice as often as their opponents. This suggests minimal strategic thinking. Further, participants' pupils dilated when they sent a deceiving, and they dilated more when telling a bigger lie. Through these physical cues Wang concluded that deception is cognitively difficult. These findings show that factors such as incentives, consequences, and deception can create irrational decisions and affect the way games unfold.",
            "score": 145.87426781654358
        },
        {
            "docid": "27128547_3",
            "document": "Hysteria Project . The game is played from a first-person perspective and composed entirely of full motion video scenes as the unnamed protagonist attempts to flee a man wielding an axe. Gameplay involves the player either making choices as regards what action to take at a given moment, or tapping on the touchscreen during context sensitive moments. When the player is presented with a choice, the game cuts to a decision tree, where the player selects their choice. The game then moves on to the next segment, and the player can see if they selected the correct choice. Choices involve, for example, choosing to take the left or right path, or choosing to remain hidden or run away. However, the game script is fixed, different choices do not lead to a branching narrative - if the player makes the wrong choice (choosing to remain hidden instead of fleeing, for example), the player will die and the game will end, with a text description of how the player has died. At this point, the game can jump back anywhere between one and three choices.",
            "score": 111.44333529472351
        }
    ],
    "r": [
        {
            "docid": "1010274_11",
            "document": "Build order . In professional and competitive tournaments it is implicit that before a match each player will have studied his opponent's recent public games in order to prepare an appropriate build order to defeat his style. Since both players understand that each side will be doing this it can create interesting situations \u2013 for example: a defense-oriented player could pretend to be using his traditional strategy to fool his opponent, while instead creating an offensive force in a hard-to-spot position. This makes competitive strategy gaming as much a guessing of what your opponent is trying to do as it is on focusing on your own strategy in order to win. This sort of play is often called mind games by narrators and commentators and it often happens that a bad \"read\" on an opponent's intentions is enough to lose a match.",
            "score": 190.17259216308594
        },
        {
            "docid": "21266327_18",
            "document": "Android (board game) . Unlike many games of this genre, there are no dice involved in the game. The game is determined by card play, and your ability to accumulate Victory Points in various ways. Some of the characters in the game are \"better\" at uncovering the Conspiracy, and gain more points and better game benefits by doing so. Some are better at solving the murder, and some are better at solving their particular Plot lines. This leaves a lot of different strategies to win the game, and solving the murder is not a guarantee you will win the game. Players attempting to balance both solving the murder, and solving the Conspiracy while trying to find out their opponents' hunches, throwing them off, and forcing them into bad Plot Endings generally win. Because of this the game is very replayable, and very open to future expansions. No character has an optimal way to win a game, because of the element of plots, which can change how to play a character, and the element of players playing Dark Cards against you. Players can also place hits on suspects to kill them, place Alibis on suspects, and some Twilight cards allow players to move around the leads on suspects, messing up an opponent's strategy. In addition, leads are constantly being moved around the board, forcing players to travel between Earth and the Moon and adjusting priorities and strategies.",
            "score": 173.23635864257812
        },
        {
            "docid": "45222866_7",
            "document": "Behavioral game theory . Beliefs about other people in a decision-making game are expected to influence ones ability to make rational choices. However, beliefs of others can also cause experimental results to deviate from equilibrium, utility-maximizing decisions. In an experiment by Costa-Gomez (2008) participants were questioned about their first order beliefs about their opponent's actions prior to completing a series of normal-form games with other participants. Participants complied with Nash Equilibrium only 35% of the time. Further, participants only stated beliefs that their opponents would comply with traditional game theory equilibrium 15% of the time. This means participants believed their opponents would be less rational than they really were. The results of this study show that participants do not choose the utility-maximizing action and they expect their opponents to do the same. Also, the results show that participants did not choose the utility-maximizing action that corresponded to their beliefs about their opponent's action. While participants may have believed their opponent was more likely to make a certain decision, they still made decisions as if their opponent was choosing randomly. Another study that examined participants from the TV show Deal or No Deal found divergence from rational choice. Participants were more likely to base their decisions on previous outcomes when progressing through the game. Risk aversion decreased when participants' expectations were not met within the game. For example a subject that experienced a string of positive outcomes was less likely to accept the deal and end the game. The same was true for a subject that experienced primarily negative outcomes early in the game.",
            "score": 171.398681640625
        },
        {
            "docid": "27032_16",
            "document": "Rock\u2013paper\u2013scissors . As a consequence of rock\u2013paper\u2013scissors programming contests, many strong algorithms have emerged. For example, Iocaine Powder, which won the First International RoShamBo Programming Competition in 1999, uses a heuristically designed compilation of strategies. For each strategy it employs, it also has six metastrategies which defeat second-guessing, triple-guessing, as well as second-guessing the opponent, and so on. The optimal strategy or metastrategy is chosen based on past performance. The main strategies it employs are history matching, frequency analysis, and random guessing. Its strongest strategy, history matching, searches for a sequence in the past that matches the last few moves in order to predict the next move of the algorithm. In frequency analysis, the program simply identifies the most frequently played move. The random guess is a fallback method that is used to prevent a devastating loss in the event that the other strategies fail. More than ten years later, the top performing strategies on an ongoing rock\u2013paper\u2013scissors programming competition similarly use metastrategies. However, there have been some innovations, such as using multiple history matching schemes that each match a different aspect of the history\u00a0\u2013 for example, the opponent's moves, the program's own moves, or a combination of both. There have also been other algorithms based on Markov chains.",
            "score": 169.8352508544922
        },
        {
            "docid": "7502798_3",
            "document": "Peace war game . The peace war game is a variation of the iterated prisoner's dilemma in which the decisions (Cooperate, Defect) are replaced by (Peace, War). Strategies remain the same with reciprocal altruism, \"Tit for Tat\", or \"provokable nice guy\" as the best deterministic one. This strategy is simply to make peace on the first iteration of the game; after that, the player does what his opponent did on the previous move. A slightly better strategy is \"Tit for Tat with forgiveness\". When the opponent makes war, on the next move, the player sometimes makes peace anyway, with a small probability. This allows an escape from wasting cycles of retribution, a motivation similar to the Rule of Ko in the game of Go. \"Tit for Tat with forgiveness\" is best when miscommunication is introduced, when one's move is incorrectly reported to the opponent. A typical payoff matrix for two players (A, B) of one iteration of this game is: Here a player's resources have a value of 2, half of which must be spent to wage war. In this case, there exists a Nash equilibrium, a mutually best response for a single iteration, here (War, War), by definition heedless of consequences in later iterations. \"Provokable nice guy's\" optimality depends on iterations. How many are necessary is likely tied to the payoff matrix and probabilities of choosing. A subgame perfect version of this strategy is \"Contrite Tit-for-Tat\" which is to make peace unless one is in \"good standing\" and one's opponent is not. Good (\"standing\" assumed) means to make peace with good opponents, make peace when bad, or make war when good and opponent is not.",
            "score": 169.15170288085938
        },
        {
            "docid": "9292690_9",
            "document": "Risk dominance . A number of evolutionary approaches have established that when played in a large population, players might fail to play the payoff dominant equilibrium strategy and instead end up in the payoff dominated, risk dominant equilibrium. Two separate evolutionary models both support the idea that the risk dominant equilibrium is more likely to occur. The first model, based on replicator dynamics, predicts that a population is more likely to adopt the risk dominant equilibrium than the payoff dominant equilibrium. The second model, based on best response strategy revision and mutation, predicts that the risk dominant state is the only stochastically stable equilibrium. Both models assume that multiple two-player games are played in a population of N players. The players are matched randomly with opponents, with each player having equal likelihoods of drawing any of the N\u22121 other players. The players start with a pure strategy, G or H, and play this strategy against their opponent. In replicator dynamics, the population game is repeated in sequential generations where subpopulations change based on the success of their chosen strategies. In best response, players update their strategies to improve expected payoffs in the subsequent generations. The recognition of Kandori, Mailath & Rob (1993) and Young (1993) was that if the rule to update one's strategy allows for mutation, and the probability of mutation vanishes, i.e. asymptotically reaches zero over time, the likelihood that the risk dominant equilibrium is reached goes to one, even if it is payoff dominated.",
            "score": 164.235595703125
        },
        {
            "docid": "5729639_4",
            "document": "Chopsticks (hand game) . For the specific variation described above, the first player has a winning strategy (can always force a win). One winning strategy is to always reach one of the following configurations after each of your moves, preferentially choosing the first one in the list if there is more than one choice. Each configuration will be given as [a,b],[c,d] where [a,b] represents your two hands (ignoring order) and [c,d] represents your opponent's.",
            "score": 162.38282775878906
        },
        {
            "docid": "1369392_6",
            "document": "Matching pennies . This game has no pure strategy Nash equilibrium since there is no pure strategy (heads or tails) that is a best response to a best response. In other words, there is no pair of pure strategies such that neither player would want to switch if told what the other would do. Instead, the unique Nash equilibrium of this game is in mixed strategies: each player chooses heads or tails with equal probability. In this way, each player makes the other indifferent between choosing heads or tails, so neither player has an incentive to try another strategy. The best response functions for mixed strategies are depicted on the figure 1 below:",
            "score": 161.03900146484375
        },
        {
            "docid": "12658857_16",
            "document": "Liar Game . 17 Poker: A deck of 17 cards. Four Aces, four Jacks, four Queens, four Kings, and a Joker (Wild Card). The deck is shuffled and four cards are dealt to players. Winning hands are one-of-kind, two-of-a-kind, three-of-a-kind, and four-of-a-kind. Joker is a wild card. \"How to win 17 Poker:\" Each hand must start with a newly opened deck. Thus the deck will begin ordered by suit. Rifle shuffle the deck (perfectly) twice. This will mathematically order the deck by picture (A\u2019s, J\u2019s, Q\u2019s, K\u2019s, Joker). An opponent can cut the deck wherever they wish. The starting card will change, but the order remains the same. If your opponent has cleverly figured a way to get the Joker, then the following cards will always be four-of-card. \"Problem with the winning strategy of 17 Poker:\" It requires the dealer perfectly rifle shuffle the deck twice. Your opponent must figure out how to get the Joker, then get the Joker and no further cards, and that no other subsequent opponent get any cards before you. That is to say, you must get the very next four cards after the Joker is received by your opponent. \"Reality of 17 Poker:\" Whomever gets the Joker by whatever means has the highest probability of winning any given hand; unless sleight of hand is involved. The winning strategy as presented in Liar Game is unlikely to work.",
            "score": 157.26800537109375
        },
        {
            "docid": "63763_11",
            "document": "Solved game . In game theory, perfect play is the behavior or strategy of a player that leads to the best possible outcome for that player regardless of the response by the opponent. Perfect play for a game is known when the game is solved. Based on the rules of a game, every possible final position can be evaluated (as a win, loss or draw). By backward reasoning, one can recursively evaluate a non-final position as identical to that of the position that is one move away and best valued for the player whose move it is. Thus a transition between positions can never result in a better evaluation for the moving player, and a perfect move in a position would be a transition between positions that are equally evaluated. As an example, a perfect player in a drawn position would always get a draw or win, never a loss. If there are multiple options with the same outcome, perfect play is sometimes considered the fastest method leading to a good result, or the slowest method leading to a bad result.",
            "score": 156.02964782714844
        },
        {
            "docid": "43717_25",
            "document": "Prisoner's dilemma . The winning deterministic strategy was tit for tat, which Anatol Rapoport developed and entered into the tournament. It was the simplest of any program entered, containing only four lines of BASIC, and won the contest. The strategy is simply to cooperate on the first iteration of the game; after that, the player does what his or her opponent did on the previous move. Depending on the situation, a slightly better strategy can be \"tit for tat with forgiveness\". When the opponent defects, on the next move, the player sometimes cooperates anyway, with a small probability (around 1\u20135%). This allows for occasional recovery from getting trapped in a cycle of defections. The exact probability depends on the line-up of opponents.",
            "score": 155.21249389648438
        },
        {
            "docid": "34417_13",
            "document": "Zero-sum game . \u00c9mile Borel and John von Neumann had the fundamental insight that probability provides a way out of this conundrum. Instead of deciding on a definite action to take, the two players assign probabilities to their respective actions, and then use a random device which, according to these probabilities, chooses an action for them. Each player computes the probabilities so as to minimize the maximum expected point-loss independent of the opponent's strategy. This leads to a linear programming problem with the optimal strategies for each player. This minimax method can compute provably optimal strategies for all two-player zero-sum games.",
            "score": 155.18411254882812
        },
        {
            "docid": "24418908_6",
            "document": "Violence Fight . Each match consists of up to three rounds. The timer will initially be set at 100 seconds, or 1 minute, 40 seconds. Your objective is to get your opponent's life meter to zero to win a round. Winning two out of three rounds will win the match. Each brawler begins the round with 100 health points. Direct hits to your opponent will reduce his health gradually, based on certain factors. For each round won, you gain one point towards winning the match. If time runs out in a round, the round will end in a draw. If two of three rounds end in a draw, the brawler with only one point will be the winner. If the point totals are tied at the end of all three rounds, the match ends in a draw. If you get more points than your opponent, you'll continue on to the next gameplay round, or \"stage\" of the game. If your opponent has more points than you, your game is over and you'll have the option of continuing the game, at the cost of one additional coin. If the match ends in a draw against the CPU, it will be the same as a loss. If the match ends in a draw of a 2-player match, either player will have to insert another coin to continue the single-player campaign.",
            "score": 153.31124877929688
        },
        {
            "docid": "43997138_4",
            "document": "WWE SuperCard . In a wild match, the player has to set up a group of four superstars, two female superstars, and two support cards. You get to pick from any card that you unlocked between seasons 1, 2, 3, and 4. The player gets to choose from three opponents, which are similar to your tier. It also provides the number of matches won and lost by your opponent. After selecting the opponent, the player heads towards a match with his or her opponent's deck. All games of wild are set inside the NXT arena in season 4. In season 3, they would be held in a gym or a bar with WWE logos throughout the venue. Each wild match features a variety of matches in which the player selects one or two cards with or without a support card suiting to the one or two stats to be compared in the match and that the match is for the male superstars, female superstars, or tag teams. In such a game, there are usually three matches, each carrying one point, which goes to the winning player. Although, a match might end up as a tie and both players earn one point each, which might further lead to a tie among the players. In such a case, there is an extra match and the winner of the latter wins the whole match. Each win awards the player two picks whereas a loss provides only one pick and a perfect 3-0 victory provides an extra pick which makes a total of three picks. You are also able to watch an ad for an extra 4 bonus picks.",
            "score": 152.12088012695312
        },
        {
            "docid": "1282637_16",
            "document": "Bracket racing . Professional(and some amateur) Bracket Racing has evolved over the years into a drivers sport. It used to consist of trying to get a good reaction time then hoping the car ran near the number. Drivers would avoid breaking out like the plague, dialing their car's .01 faster than it had ever gone before.  Now it has turned into a chess match between two drivers, guessing each other's next move. The race starts in the staging lane where you get ready to race, where you decide what dial in to put on your car. This is arguably the most important part of a bracket race : making sure you can \"run the number\". In other words, make sure you can go as fast as your dial in says you can. Everyone has a different strategy, but any strategy has its flaws and can be beaten; that why the best strategy is one that includes many different strategies and cannot be predicted.",
            "score": 151.35813903808594
        },
        {
            "docid": "642879_7",
            "document": "Shuffleboard . In \"deck\" or \"floor\" shuffleboard, players use a \"cue\" (\"cue-stick\"), to push their colored \"disks\", down a \"court\" (a flat floor of concrete, wood or other hard material, marked with lines denoting scoring zones), attempting to place their disks within a marked scoring area at the far end of the court. The disks themselves are of two contrasting colors (usually yellow and black), each color belonging to a player or team. The scoring diagram is divided by lines, into six scoring zones, with the following values: 10, 8, 8, 7, 7, 10-off. (See \"Court Description\" below for details.) After 8 disks (four per team, taking alternating shots) have been played from one end of the court (a \"frame\"), the final score values of disks for each player (or team) in the scoring zones is assessed: If a disk is completely within a scoring zone without touching (overlapping) any part of the border-line of the zone, it is \"good\" and that zone value is added to the correct player's score for the frame, and then to the player's total points. Both players good disks are added to their respective scores (As opposed to being subtracted to give only one player a net score for a frame.) Players (or teams of two players, one at each end) take turns going first during a game, so that the advantageous last shot of a frame (the \"hammer\") also alternates between players. The winner of the game may be the first to reach any total decided upon, or may be the higher score after playing a certain number of frames (e.g. 8, 12 or 16). There is also the 'first to 75-points' game. Ties are broken by playing extra frames (two for singles, four for doubles). In shuffleboard, one tries to score, prevent the opponent from scoring, or both.  The basic strategy involves both offense and defense. If it is your turn to shoot first, you are automatically on the defensive, because your opponent has the last shot of the frame. If you simply put your first shot into the scoring area, your opponent will knock it off, and if you then score with your second shot, the same will happen, and so on until you have used your last shot, and your opponent will knock that off and probably score. To combat this you can use the strategy of blocking and hiding \u2013 That is your first shot will be a guard disk shot to a location so that it blocks your opponent from that part of the scoring area that you can still place a good disk. Your second shot will be the one to play into that hiding place you created with your first shot, so your opponent cannot hit you out directly.",
            "score": 151.12799072265625
        },
        {
            "docid": "759831_6",
            "document": "Best response . Games such as the game of chicken and hawk-dove game in which players score highest when they choose opposite strategies, i.e., discoordinate, are called anti-coordination games. They have reaction correspondences (Figure 4) that cross in the opposite direction to coordination games, with three Nash equilibria, one in each of the top left and bottom right corners, where one player chooses one strategy, the other player chooses the opposite strategy. The third Nash equilibrium is a mixed strategy which lies along the diagonal from the bottom left to top right corners. If the players do not know which one of them is which, then the mixed Nash is an evolutionarily stable strategy (ESS), as play is confined to the bottom left to top right diagonal line. Otherwise an uncorrelated asymmetry is said to exist, and the corner Nash equilibria are ESSes. Games with dominated strategies have reaction correspondences which only cross at one point, which will be in either the bottom left, or top right corner in payoff symmetric 2x2 games. For instance, in the single-play prisoner's dilemma, the \"Cooperate\" move is not optimal for any probability of opponent Cooperation. Figure 5 shows the reaction correspondence for such a game, where the dimensions are \"Probability play Cooperate\", the Nash equilibrium is in the lower left corner where neither player plays Cooperate. If the dimensions were defined as \"Probability play Defect\", then both players best response curves would be 1 for all opponent strategy probabilities and the reaction correspondences would cross (and form a Nash equilibrium) at the top right corner.",
            "score": 150.87266540527344
        },
        {
            "docid": "44153_6",
            "document": "Kill Doctor Lucky . At this point, the player making the murder attempt succeeds, and thereby wins the game, unless the opponents play Failure cards of combined value equal to the value of the weapon used. The situation is complicated by the requirement that players play Failure cards in clockwise order, with each player having only one opportunity to play cards. Since it is to any player's advantage to eliminate failure cards from his opponents' hands, a large part of the strategy of the game consists in bluffing: when one player attacks Doctor Lucky, it is in your interest to persuade your other opponents that you have no failure cards in your hand, to attempt to force them to save the game by spending the required cards.",
            "score": 148.74044799804688
        },
        {
            "docid": "5864467_21",
            "document": "The Ravages of Time . The \"Best Strategy Ever\" has been often repeated by L\u00fc Bu, Cao Cao and Pang Tong, among others, and it goes as \"The best strategy is to let your opponent know your next move. Even better is to let your opponent know your next two moves\".",
            "score": 147.63055419921875
        },
        {
            "docid": "896746_8",
            "document": "Sylver coinage . When the greatest common divisor of the moves that have been made so far is 1, the remaining set of numbers that can be played will be a finite set, and can be described mathematically as the set of gaps of a numerical semigroup. Some of these finite positions, including all of the positions after the second player has responded to one of Hutchings' winning moves, allow a special move that Sicherman calls an \"ender\". An ender is a number that may only be played immediately: playing any other number would rule it out. If an ender exists, it is always the largest number that can still be played. For instance, after the moves (4,5), the largest number that can still be played is 11. Playing 11 cannot rule out any smaller numbers, but playing any of the smaller available numbers (1, 2, 3, 6, or 7) would rule out playing 11, so 11 is an ender. When an ender exists, the next player can win by following a strategy-stealing argument. If one of the non-ender moves can win, the next player takes that winning move. And if none of the non-ender moves wins, then the next player can win by playing the ender and forcing the other player to make one of the other non-winning moves. However, although this argument proves that the next player can win, it does not identify a winning strategy for the player. After playing a prime number that is 5 or larger as a first move, the first player in a game of sylver coinage can always win by following this (non-constructive) ender strategy on their next turn. If there are any other winning openings, they must be 3-smooth numbers (numbers of the form for non-negative integers and ). For, if any number that is not of this form and is not prime is played, then the second player can win by choosing a large prime factor of . The first few 3-smooth numbers, 1, 2, 3, 4, 6, 8, 9, and 12, are all losing openings, for which complete strategies are known by which the second player can win. By Dickson's lemma (applied to the pairs of exponents of these numbers), only finitely many 3-smooth numbers can be winning openings, but it is not known whether any of them are.",
            "score": 147.53359985351562
        },
        {
            "docid": "15842171_9",
            "document": "Magic: The Gathering \u2013 Duels of the Planeswalkers . The game's artificial intelligence (AI) is based on creating a multistep \"lookahead\" decision tree from the current state of the board, evaluating possible known moves by its opponents, scoring the current and resulting situations both positively and negatively, and then selecting the option with the highest score. The artificial intelligence utilizes threading to run the main intelligence algorithm alongside three \"sub-contractors\" that evaluate the possible future states and report back to the main algorithm. Each of these instances of the AI uses a special engine that both implements the rules of \"Magic\", while also providing \"undo\" actions so that they may explore up and down the decision tree. The game's intelligence algorithm runs on a separate CPU core than the main game to avoid creating framerate issues with its display while the player is considering their actions. When the player makes an action, the AI threads are interrupted and brought to the same state as the game, then continue processing, in some cases, reusing existing branches on the decision tree that match with the player's selection. The AI itself does not employ any strategy in terms of strong card combinations, but instead, when such combinations improve the computer's situation, the chances of playing these combinations will \"ripple\" back through the decision tree. In this manner, the computer AI will play one card of such a combination should it be the best choice at that time, and follow up with the second card of the combination should that option still remain the best after any other player actions.",
            "score": 146.2278289794922
        },
        {
            "docid": "92729_14",
            "document": "Match play . Golfers can employ a slightly different strategy during a match play event since the scoring is different. The situation in the match and the outcome of each shot already played on a hole will both be taken into account. On the whole, match play encourages more aggressive play, especially at the professional level, where a par is not usually good enough to win a hole. Since a very poor result for a hole is no worse than a slightly-below-average result when playing against an opponent with an average score, it often makes sense to accept the higher risk connected with aggressive tactics. However, in some circumstances players will be especially cautious in match play. For instance, a player may choose to play more conservatively if the opponent has hit a poor tee shot or is otherwise under pressure to compensate a poor start on a particular hole, reasoning that there is a good chance to win the hole with an average result.",
            "score": 146.08837890625
        },
        {
            "docid": "759831_3",
            "document": "Best response . Reaction correspondences, also known as best response correspondences, are used in the proof of the existence of mixed strategy Nash equilibria (, Section 1.3.B; , Section 2.2). Reaction correspondences are not \"reaction functions\" since functions must only have one value per argument, and many reaction correspondences will be undefined, i.e. a vertical line, for some opponent strategy choice. One constructs a correspondence formula_1, for each player from the set of opponent strategy profiles into the set of the player's strategies. So, for any given set of opponent's strategies formula_2, formula_3 represents player \"i\" 's best responses to formula_2. Response correspondences for all 2x2 normal form games can be drawn with a line for each player in a unit square strategy space. Figures 1 to 3 graphs the best response correspondences for the stag hunt game. The dotted line in Figure 1 shows the optimal probability that player Y plays 'Stag' (in the y-axis), as a function of the probability that player X plays Stag (shown in the x-axis). In Figure 2 the dotted line shows the optimal probability that player X plays 'Stag' (shown in the x-axis), as a function of the probability that player Y plays Stag (shown in the y-axis). Note that Figure 2 plots the independent and response variables in the opposite axes to those normally used, so that it may be superimposed onto the previous graph, to show the Nash equilibria at the points where the two player's best responses agree in Figure 3.",
            "score": 146.01075744628906
        },
        {
            "docid": "1654769_28",
            "document": "Artificial intelligence in video games . Creatures is an artificial life program where the user \"hatches\" small furry animals and teaches them how to behave. These \"Norns\" can talk, feed themselves, and protect themselves against vicious creatures. It's the first popular application of machine learning into an interactive simulation. Neural networks are used by the creatures to learn what to do. The game is regarded as a breakthrough in artificial life research, which aims to model the behavior of creatures interacting with their environment. A first-person shooter where the player assumes the role of the Master Chief, battling various aliens on foot or in vehicles. Enemies use cover very wisely, and employ suppression fire and grenades. The squad situation affects the individuals, so certain enemies flee when their leader dies. A lot of attention is paid to the little details, with enemies notably throwing back grenades or team-members responding to you bothering them. The underlying \"behavior tree\" technology has become very popular in the games industry (especially since Halo 2). A first-person shooter where the player helps contain supernatural phenomenon and armies of cloned soldiers. The AI uses a planner to generate context-sensitive behaviors, the first time in a mainstream game. This technology used as a reference for many studios still today. The enemies are capable of using the environment very cleverly, finding cover behind tables, tipping bookshelves, opening doors, crashing through windows, and so on. Squad tactics are used to great effect. The enemies perform flanking maneuvers, use suppression fire, etc. A first-person shooter survival horror game where the player must face man-made experiments, military soldiers, and mercenaries known as Stalkers. The various encountered enemies (if the difficulty level is set to its highest) use combat tactics and behaviours such as healing wounded allies, giving orders, out-flanking the player or using weapons with pinpoint accuracy. A first-person shooter where the player fights off numerous mercenaries and assassinates faction leaders. The AI is behavior based and uses action selection, essential if an AI is to multitask or react to a situation. The AI can react in an unpredictable fashion in many situations. The enemies respond to sounds and visual distractions such as fire or nearby explosions and can be subject to investigate the hazard, the player can utilize these distractions to his own advantage. There are also social interfaces with an AI but however not in the form of direct conversation but more reactionary, if the player gets too close or even nudges an AI, the player is subject to getting shoved off or sworn at and by extent getting aimed at. Other social interfaces between AI exist when in combat, or neutral situations, if an enemy AI is injured on the ground, he will shout out for help, release emotional distress, etc. A real-time strategy game where a player takes control of one of three factions in a 1v1, 2v2, or 3v3 battle arena. The player must defeat his opponents by extinguishing all their opponents units and bases. This is accomplished by creating units that are effective at countering your opponents units. Players can play against multiple different levels of AI difficulty ranging from very easy to cheater 3 (insane). The AI is able to cheat at the difficulty, cheater 1 (vision), where it begins to have vision assistance on your location and units. Cheater 2 gives the AI extra resources, while Cheater 3 give an extensive advantage over its opponent.",
            "score": 145.98204040527344
        },
        {
            "docid": "45222866_10",
            "document": "Behavioral game theory . Incentives and consequences also play a large role in deception in games. Gneezy (2005) studied deception using a cheap talk sender-receiver game. In this type of game player one receives information about the payouts of option A and option B. Then, player one gives a recommendation to player two about which option to take. Player one can choose to deceive player two, and player two can choose to reject player one's advice. Gneezy found that participants were more sensitive to their gain from lying than to their opponent's loss. He also found that participants were not wholly selfish and cared about how much their opponents lost from their deception, but this effect diminished as their own payout increased. These findings show that decision makers examine both incentives to lie and consequences of lying in order to decide whether or not to lie. In general people are averse to lying, but given the right incentives they tend to ignore consequences. Wang (2009) also used a cheap talk game to study deception in participants with an incentive to deceive. Using eye tracking he found that participants who received information about payoffs focused on their own payoff twice as often as their opponents. This suggests minimal strategic thinking. Further, participants' pupils dilated when they sent a deceiving, and they dilated more when telling a bigger lie. Through these physical cues Wang concluded that deception is cognitively difficult. These findings show that factors such as incentives, consequences, and deception can create irrational decisions and affect the way games unfold.",
            "score": 145.874267578125
        },
        {
            "docid": "3026543_10",
            "document": "Situation awareness . Before being widely adopted by human factors scientists in the 1990s, the term is said to have been used by United States Air Force (USAF) fighter aircrew returning from war in Korea and Vietnam. They identified having good SA as the decisive factor in air combat engagements\u2014the \"ace factor\". Survival in a dogfight was typically a matter of observing the opponent's current move and anticipating his next move a fraction of a second before he could observe and anticipate it himself. USAF pilots also came to equate SA with the \"observe\" and \"orient\" phases of the famous observe-orient-decide-act loop (OODA loop), or Boyd cycle, as described by the USAF war theorist Col. John Boyd. In combat, the winning strategy is to \"get inside\" your opponent's OODA loop, not just by making one's own decisions quicker, but also by having better SA than one's opponent, and even changing the situation in ways that the opponent cannot monitor or even comprehend. Losing one's own SA, in contrast, equates to being \"out of the loop\".",
            "score": 145.5667266845703
        },
        {
            "docid": "52114770_7",
            "document": "MLB The Show 17 . \"MLB The Show 17\" also added a lot of features to other pre-existing game modes like Franchise and Diamond Dynasty. In Franchise you make your moves and plan your perfect strategy as you take control of an entire MLB franchise. Choose what tactics to employ and where. Take over Coaching, Player Development, and GM duties. Whats new to this mode are ways to still keep the same level of control of your team as previous years but do it in less time if the player wants. Additions like critical situations in which you only play important at bats in late innings of games and quick manage where you are in complete control of all managerial decisions during a game are new game components that are letting the player do more in a shorter amount of time.",
            "score": 145.54595947265625
        },
        {
            "docid": "1607942_9",
            "document": "Metagaming . Recently the term metagame has come to be used by PC Gaming shoutcasters to describe an emergent methodology that is a subset of the basic strategy necessary to play the game at a high level. The definitions of this term are varied but can include \"pre-game\" theory, behavior prediction, or \"\"ad hoc\" strategy\" depending on the game being played. An example of this would be in StarCraft where a player's previous matches with the same opponent have given them insight into that player's playstyle and may cause them to make certain decisions which would otherwise seem inferior.",
            "score": 145.27696228027344
        },
        {
            "docid": "1619050_5",
            "document": "Game of the Amazons . The strategy of the game is based on using arrows (as well as one's four amazons) to block the movement of the opponent's amazons and gradually wall off territory, trying to trap the opponents in smaller regions and gain larger areas for oneself. Each move reduces the available playing area, and eventually each amazon finds itself in a territory blocked off from all other amazons. The amazon can then move about its territory firing arrows until it no longer has any room to move. Since it would be tedious to actually play out all these moves, in practice the game usually ends when all of the amazons are in separate territories. The player with the largest amount of territory will be able to win, as the opponent will have to fill in her own territory more quickly.",
            "score": 145.27679443359375
        },
        {
            "docid": "2539764_66",
            "document": "Two envelopes problem . Some authors prefer to think of probability in a frequentist sense. If the player knows the probability distribution used by the organizer to determine the smaller of the two values, then the analysis would proceed just as in the case when \"p\" or \"f\" represents subjective prior beliefs. However, what if we take a frequentist point of view, but the player does not know what probability distribution is used by the organiser to fix the amounts of money in any one instance? Thinking of the arranger of the game and the player as two parties in a two-person game, puts the problem into the range of game theory. The arranger's strategy consists of a choice of a probability distribution of \"x\", the smaller of the two amounts. Allowing the player also to use randomness in making his decision, his strategy is determined by his choosing a probability of switching formula_53 for each possible amount of money \"a\" he might see in Envelope A. In this section we so far only discussed \"fixed strategies\", that is strategies for which \"q\" only takes the values 0 and 1, and we saw that the player is fine with a fixed strategy, if he knows the strategy of the organizer. In the next section we will see that randomized strategies can be useful when the organizer's strategy is not known.",
            "score": 145.16714477539062
        },
        {
            "docid": "8900_56",
            "document": "Discrimination . Economist Yanis Varoufakis (2013) argues that \"discrimination based on utterly arbitrary characteristics evolves quickly and systematically in the experimental laboratory\", and that neither classical game theory nor neoclassical economics can explain this. Varoufakis and Shaun Hargreaves-Heap (2002) ran an experiment where volunteers played a computer-mediated, multiround hawk-dove game (HD game). At the start of each session, each participant was assigned a color at random, either red or blue. At each round, each player learned the color assigned to his or her opponent, but nothing else about the opponent. Hargreaves-Heap and Varoufakis found that the players' behavior within a session frequently developed a discriminatory convention, giving a Nash equilibrium where players of one color (the \"advantaged\" color) consistently played the aggressive \"hawk\" strategy against players of the other, \"disadvantaged\" color, who played the acquiescent \"dove\" strategy against the advantaged color. Players of both colors used a mixed strategy when playing against players assigned the same color as their own.",
            "score": 144.83364868164062
        },
        {
            "docid": "11336559_9",
            "document": "Traveler's dilemma . The ($2, $2) outcome in this instance is the Nash equilibrium of the game. By definition this means that if your opponent chooses this Nash equilibrium value then your best choice is that Nash equilibrium value of $2. This will not be the optimum choice if there is a chance of your opponent choosing a higher value than $2. When the game is played experimentally, most participants select a value higher than the Nash equilibrium and closer to $100 (corresponding to the Pareto optimal solution). More precisely, the Nash equilibrium strategy solution proved to be a bad predictor of people\u2019s behavior in a traveler's dilemma with small bonus/malus and a rather good predictor if the bonus/malus parameter was big.",
            "score": 144.52354431152344
        }
    ]
}