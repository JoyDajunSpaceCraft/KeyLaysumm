{
    "q": [
        {
            "docid": "35629150_2",
            "document": "Bacterial genome . Bacterial genomes are generally smaller and less variant in size among species when compared with genomes of animals and single cell eukaryotes. Bacterial genomes can range in size anywhere from about 130 kbp to over 14 Mbp. A study that included, but was not limited to, 478 bacterial genomes, concluded that as genome size increases, the number of genes increases at a disproportionately slower rate in eukaryotes than in non-eukaryotes. Thus, the proportion of non-coding DNA goes up with genome size more quickly in non-bacteria than in bacteria. This is consistent with the fact that most eukaryotic nuclear DNA is non-gene coding, while the majority of prokaryotic, viral, and organellar genes are coding. Right now, we have genome sequences from 50 different bacterial phyla and 11 different archaeal phyla. Second-generation sequencing has yielded many draft genomes (close to 90% of bacterial genomes in GenBank are currently not complete); third-generation sequencing might eventually yield a complete genome in a few hours. The genome sequences reveal much diversity in bacteria. Analysis of over 2000 \"Escherichia coli\" genomes reveals an \"E. coli\" core genome of about 3100 gene families and a total of about 89,000 different gene families. Genome sequences show that parasitic bacteria have 500\u20131200 genes, free-living bacteria have 1500\u20137500 genes, and archaea have 1500\u20132700 genes. A striking discovery by Cole et al. described massive amounts of gene decay when comparing Leprosy bacillus to ancestral bacteria. Studies have since shown that several bacteria have smaller genome sizes than their ancestors did. Over the years, researchers have proposed several theories to explain the general trend of bacterial genome decay and the relatively small size of bacterial genomes. Compelling evidence indicates that the apparent degradation of bacterial genomes is owed to a deletional bias.",
            "score": 75.64790773391724
        },
        {
            "docid": "35629150_27",
            "document": "Bacterial genome . Molecular phylogenetics has revealed that every clade of bacteria with genome sizes under 2 Mb was derived from ancestors with much larger genomes, thus refuting the hypothesis that bacteria evolved by the successive doubling of small-genomed ancestors. Recent studies performed by Nilsson et al. examined the rates of bacterial genome reduction of obligate bacteria. Bacteria were cultured introducing frequent bottlenecks and growing cells in serial passage to reduce gene transfer so as to mimic conditions of endosymbiotic bacteria. The data predicted that bacteria exhibiting a one-day generation time lose as many as 1,000 kbp in as few as 50,000 years (a relatively short evolutionary time period). Furthermore, after deleting genes essential to the methyl-directed DNA mismatch repair (MMR) system, it was shown that bacterial genome size reduction increased in rate by as much as 50 times. These results indicate that genome size reduction can occur relatively rapidly, and loss of certain genes can speed up the process of bacterial genome compaction.",
            "score": 77.18850815296173
        },
        {
            "docid": "20377_24",
            "document": "Microorganism . Their genome is usually a circular bacterial chromosome \u2013 a single loop of DNA, although they can also harbor small pieces of DNA called plasmids. These plasmids can be transferred between cells through bacterial conjugation. Bacteria have an enclosing cell wall, which provides strength and rigidity to their cells. They reproduce by binary fission or sometimes by budding, but do not undergo meiotic sexual reproduction. However, many bacterial species can transfer DNA between individual cells by a horizontal gene transfer process referred to as natural transformation. Some species form extraordinarily resilient spores, but for bacteria this is a mechanism for survival, not reproduction. Under optimal conditions bacteria can grow extremely rapidly and their numbers can double as quickly as every 20 minutes.",
            "score": 72.80145740509033
        },
        {
            "docid": "318669_21",
            "document": "Schizosaccharomyces pombe . Fission yeast has become a notable model system to study basic principles of a cell that can be used to understand more complex organisms like mammals and in particular humans. This single cell eukaryote is nonpathogenic and easily grown and manipulated in the lab. Fission yeast contains one of the smallest numbers of genes of a known genome sequence for a eukaryote, and has only three chromosomes in its genome. Many of the genes responsible for cell division and cellular organization in fission yeast cell are also found in the human\u2019s genome. Cell cycle regulation and division are crucial for growth and development of any cell. Fission yeast\u2019s conserved genes has been heavily studied and the reason for many recent biomedical developments. Fission yeast is also a practical model system to observe cell division because fission yeast\u2019s are cylindrically shaped single celled eukaryotes that divide and reproduce by medial fission. This can easily be seen using microscopy. Fission yeast also have an extremely short generation time, 2 to 4 hours, which also makes it an easy model system to observe and grow in the laboratory Fission yeast\u2019s simplicity in genomic structure yet similarities with mammalian genome, ease of ability to manipulate, and ability to be used for drug analysis is why fission yeast is making many contributions to biomedicine and cellular biology research, and a model system for genetic analysis.",
            "score": 138.40041553974152
        },
        {
            "docid": "37388686_11",
            "document": "Minimal genome . J. Craig Venter Institute (JCVI) conducted a study to find all the essential genes of \"M. genitalium\" through global transposon mutagenesis. As a result they found that 382 out of 482 protein coding genes were essential. Genes encoding proteins of unknown function constitute 28% of the essential protein coding genes set. Before conducting this study the JCVI had performed another study on the non-essential genes, genes not required for growth, of \"M.genitalium\", where they reported the use of transposon mutagenesis. Despite figuring out the non-essential genes, it is not confirmed that the products that these genes make have any important biological functions. It was only through gene essentiality studies of bacteria that JCVI have been able to compose a hypothetical minimal gene sets.",
            "score": 50.04239463806152
        },
        {
            "docid": "9028799_36",
            "document": "Bacteria . Some bacteria also transfer genetic material between cells. This can occur in three main ways. First, bacteria can take up exogenous DNA from their environment, in a process called transformation. Many bacteria can naturally take up DNA from the environment, while others must be chemically altered in order to induce them to take up DNA. The development of competence in nature is usually associated with stressful environmental conditions, and seems to be an adaptation for facilitating repair of DNA damage in recipient cells. The second way bacteria transfer genetic material is by transduction, when the integration of a bacteriophage introduces foreign DNA into the chromosome. Many types of bacteriophage exist, some simply infect and lyse their host bacteria, while others insert into the bacterial chromosome. Bacteria resist phage infection through restriction modification systems that degrade foreign DNA, and a system that uses CRISPR sequences to retain fragments of the genomes of phage that the bacteria have come into contact with in the past, which allows them to block virus replication through a form of RNA interference. The third method of gene transfer is conjugation, whereby DNA is transferred through direct cell contact. In ordinary circumstances, transduction, conjugation, and transformation involve transfer of DNA between individual bacteria of the same species, but occasionally transfer may occur between individuals of different bacterial species and this may have significant consequences, such as the transfer of antibiotic resistance. In such cases, gene acquisition from other bacteria or the environment is called horizontal gene transfer and may be common under natural conditions.",
            "score": 76.45681071281433
        },
        {
            "docid": "37388686_10",
            "document": "Minimal genome . Reconstruction of a minimal genome is possible by using the knowledge of existing genomes via which the sets of genes, essential for living can also be determined. Once the set of essential genetic elements are known, one can proceed to define the key pathways and core-players by modeling simulations and wet lab genome engineering. The two organisms upon which the \u2018minimal gene set for cellular life' was applied were: \"Haemophilus influenzae\", and \"M. genitalium\". A list of orthologous proteins were compiled in hope that it would contain protein necessary for cell survival, as orthologous analysis determines how two organisms evolved and shed away any non-essential genes. Since, \"H. influenza\" and \"M. genitalium\" are Gram negative and Gram positive bacteria and due to their vast evolution it was expected that these organisms would be enriched genes that were of universal importance. However, 244 detected orthologs discovered contained no parasitism-specific proteins. The conclusion of this analysis was that similar biochemical functions might be performed by non-orthologous proteins. Even when biochemical pathways of these two organisms were mapped, several pathways were present but many were incomplete. Proteins determined to be common between the two organisms were non-orthologous to each other. Much of the research mainly focuses on the ancestral genome and less on the minimal genome. Studies of these existing genomes have helped determine that orthologous genes found in these two species are not necessarily essential for survival, in fact non-orthologous genes were found to be more important. Also, it was determined that in order for proteins to share same functions they do not need to have same sequence or common three dimensional folds. Distinguishing between orthologs and paralogs and detecting displacements of orthologs have been quiet beneficial in reconstructing evolution and determining the minimal gene set required for a cellular life. Instead, of conducting a strict orthology study, comparing groups of orthologs and occurrence in most clades instead of every species helped encounter genes lost or displaced. Only genomes that have been completely sequenced have enabled in studying orthologs among group of organisms. Without a fully sequenced genome it would not be possible to determine the essential minimal gene set required for survival.",
            "score": 114.74944055080414
        },
        {
            "docid": "779824_3",
            "document": "Transfer DNA . The bacterial T-DNA is about 24,000 base pairs long and contains [[gene]]s that code for [[enzyme]]s synthesizing [[opines]] and [[phytohormone]]s. By transferring the T-DNA into the plant genome, the bacterium essentially reprograms the plant cells to grow into a tumor and produce a unique food source for the bacteria. The synthesis of the plant hormones [[auxin]] and [[cytokinin]] by enzymes encoded in the T-DNA enables the plant cell to grow uncontrollably, thus forming the [[crown gall tumor]]s typically induced by \"Agrobacterium tumefaciens\" infection. Whereas \"Agrobacterium rhizogenes\" causes hairy root disease. The [[opines]] are [[amino acid]] derivatives used by the bacterium as a source of carbon and energy. This natural process of [[horizontal gene transfer]] in plants is being utilized as a tool for fundamental and applied research in plant biology through \"Agrobacterium tumefaciens\" mediated foreign gene transformation and insertional mutagenesis.",
            "score": 59.52267789840698
        },
        {
            "docid": "9028799_46",
            "document": "Bacteria . Classification seeks to describe the diversity of bacterial species by naming and grouping organisms based on similarities. Bacteria can be classified on the basis of cell structure, cellular metabolism or on differences in cell components, such as DNA, fatty acids, pigments, antigens and quinones. While these schemes allowed the identification and classification of bacterial strains, it was unclear whether these differences represented variation between distinct species or between strains of the same species. This uncertainty was due to the lack of distinctive structures in most bacteria, as well as lateral gene transfer between unrelated species. Due to lateral gene transfer, some closely related bacteria can have very different morphologies and metabolisms. To overcome this uncertainty, modern bacterial classification emphasises molecular systematics, using genetic techniques such as guanine cytosine ratio determination, genome-genome hybridisation, as well as sequencing genes that have not undergone extensive lateral gene transfer, such as the rRNA gene. Classification of bacteria is determined by publication in the International Journal of Systematic Bacteriology, and Bergey's Manual of Systematic Bacteriology. The International Committee on Systematic Bacteriology (ICSB) maintains international rules for the naming of bacteria and taxonomic categories and for the ranking of them in the International Code of Nomenclature of Bacteria.",
            "score": 62.570927143096924
        },
        {
            "docid": "619137_9",
            "document": "Origin of replication . Many bacteria, including \"E. coli\", contain plasmids that each contain an origin of replication. These are separate from the origins of replication that are used by the bacteria to copy their genome and often function very differently. For example, the \"E. coli\" plasmid pBR322 uses a protein called Rop/Rom to regulate the number of plasmids that are within each bacterial cell . The most common origin of replication that is used in plasmids for genetic engineering is called pUC. This origin is derived from pBR322 but it contains two mutations. One single point mutation in the origin itself and another that deletes the Rop/Rom gene. This removes all the regulatory constraints on the plasmids replication and the bacteria then go from producing 30\u201340 plasmids per cell with pBR322 up to producing over 500 with pUC. This allows genetic engineers to produce large quantities of DNA for research purposes. Other origins of replication include pSC101 (derived from Salmonella, around 5 copies per cell), 15A origin (derived from p15A, 10\u201320 copies per cell) and Bacterial artificial chromosomes (1 copy per cell).",
            "score": 61.017468214035034
        },
        {
            "docid": "40160407_33",
            "document": "Essential gene . Comparative genomics. Shortly after the first genomes (of \"Haemophilus influenzae\" and \"Mycoplasma genitalium\") became available, Mushegian et al. tried to predict the number of essential genes based on common genes in these two species. It was surmised that only essential genes should be conserved over the long evolutionary distance that separated the two bacteria. This study identified approximately 250 candidate essential genes. As more genomes became available the number of predicted essential genes kept shrinking because more genomes shared fewer and fewer genes. As a consequence, it was concluded that the universal conserved core consists of less than 40 genes. However, this set of conserved genes is not identical to the set of essential genes as different species rely on different essential genes.",
            "score": 57.178319454193115
        },
        {
            "docid": "1728034_7",
            "document": "Complementation (genetics) . Complementation tests can also be carried out with haploid eukaryotes such as fungi, with bacteria and with viruses such as bacteriophage. Research on the fungus Neurospora crassa led to the development of the one-gene-one enzyme concept that provided the foundation for the subsequent development of molecular genetics. The complementation test was one of the main tools used in the early Neurospora work, because it was easy to do, and allowed the investigator to determine whether any two nutritional mutants were defective in the same, or different genes. The complementation test was also used in the early development of molecular genetics when bacteriophage T4 was one of the main objects of study. In this case the test depends on mixed infections of host bacterial cells with two different bacteriophage mutant types. Its use was key to defining most of the genes of the virus, and provided the foundation for the study of such fundamental processes as DNA replication and repair, and how molecular machines are constructed.",
            "score": 80.34508609771729
        },
        {
            "docid": "48626085_6",
            "document": "Streptomyces lavendulae . While most bacteria have circular chromosomes, all actinomycetes chromosomes are linear and fairly large, 8-9Mb. In addition, actinomycete genomes contain extrachromosomal genetic elements such as rolling circle replication plasmids. These extrachromosomal genetic elements have been shown to transport their own genes as well as chromosomal genes to other actinomycete hosts. This provides a pathway for genetic information to be exchanged between cells, and could provide a mechanism for the transfer of antibiotic resistance between organisms. One study found genes for streptothricin resistance, an antibiotic produced by Actinomycete bacteria, on plasmids within gram-negative bacteria.",
            "score": 57.16456699371338
        },
        {
            "docid": "48997033_5",
            "document": "Oscar Kuipers . An important topic of research is the study of the genetics and fysiology of bacteria. Among others the cellular differentiation of bacteria is investigated. Bacteria growing in a culture can develop different characteristics, while their genome remains unchanged. Kuipers: \u2018Our research has many applications, for example the improvement of protein production in industrial fermentation'. An other important subject is the production and modification of peptides peptides. These modified peptides (lantibiotics), are made by bacteria, and can serve as antibiotic. Modified peptides are chemically more stable and retain their function longer than unmodified peptides. This is beneficial for medical applications as a novel class of antibiotics. Further areas of focus are the molecular biology of: competence, sporulation and bistability in Bacteria subtilis, the reconstruction of gene networks, antimicrobial peptides, especially antibiotics, pathogenesis mechanisms, cell wall anchoring, controlled gene expressionsystems, the subcellular localization of protein, stress response, quorum sensing, regulation of the C- and N-metabolism, natural gene transfer methodologies, plant-biocontrol by Bacilli and Biotechnology applications.",
            "score": 75.8995566368103
        },
        {
            "docid": "40160407_4",
            "document": "Essential gene . Table 1. Essential genes in bacteria. Mutagenesis: \"targeted\" mutants are gene deletions; \"random\" mutants are transposon insertions. Methods: \"Clones\" indicate single gene deletions, \"population\" indicates whole population mutagenesis, e.g. using transposons. Essential genes from population screens include genes essential for fitness (see text). ORFs: number of all open reading frames in that genome. Notes: (a) mutant collection available; (b) direct essentiality screening method (e.g. via antisense RNA) that does not provide information about nonessential genes. (c) Only partial dataset available. (d) Includes predicted gene essentiality and data compilation from published single-gene essentiality studies. (e) Project in progress. (f) Deduced by comparison of the two gene essentiality datasets obtained independently in the \"P. aeruginosa \"strains PA14 and PAO1. (g) The original result of 271 essential genes has been corrected to 261, with 31 genes that were thought to be essential being in fact non-essential whereas 20 novel essential genes have been described since then. (h) Counting genes with essential domains and those that lead to growth-defects when disrupted as essential, and those who lead to growth-advantage when disrupted as non-essential. (i) Involved a fully saturated mutant library of 14 replicates, with 84.3% of possible insertion sites with at least one transposon insertion.",
            "score": 43.475600361824036
        },
        {
            "docid": "240850_21",
            "document": "Gene silencing . Unlike viruses, bacteria are not as susceptible to silencing by siRNA. This is largely due to how bacteria replicate. Bacteria replicate outside of the host cell and do not contain the necessary machinery for RNAi to function. However, bacterial infections can still be suppressed by siRNA by targeting the host genes that are involved in the immune response caused by the infection or by targeting the host genes involved in mediating the entry of bacteria into cells. For instance, siRNA was used to reduce the amount of pro-inflammatory cytokines expressed in the cells of mice treated with lipopolysaccharide (LPS). The reduced expression of the inflammatory cytokine, tumor necrosis factor \u03b1 (TNF\u03b1), in turn, caused a reduction in the septic shock felt by the LPS-treated mice. In addition, siRNA was used to prevent the bacteria, \"Psueomonas aeruginosa\", from invading murine lung epithelial cells by knocking down the caveolin-2 (CAV2) gene. Thus, though bacteria cannot be directly targeted by siRNA mechanisms, they can still be affected by siRNA when the components involved in the bacterial infection are targeted.",
            "score": 54.036686182022095
        },
        {
            "docid": "12383_18",
            "document": "Genetic engineering . The next step is to isolate the candidate gene. The cell containing the gene is opened and the DNA is purified. The gene is separated by using restriction enzymes to cut the DNA into fragments or polymerase chain reaction (PCR) to amplify up the gene segment. These segments can then be extracted through gel electrophoresis. If the chosen gene or the donor organism's genome has been well studied it may already be accessible from a genetic library. If the DNA sequence is known, but no copies of the gene are available, it can also be artificially synthesised. Once isolated the gene is ligated into a plasmid that is then inserted into a bacterium. The plasmid is replicated when the bacteria divide, ensuring unlimited copies of the gene are available.",
            "score": 50.45629835128784
        },
        {
            "docid": "46471055_7",
            "document": "Mycoplasma orale . While the genome of \"M. orale\" itself has not been fully sequenced, information can be surmised from the sequence data of its close relatives. Members of the \"Mycoplasma\" genus are known for their incredibly small genomes, with an average size of 0.6 Mb. This is the smallest discovered self-replicating genome of all known prokaryotes. This significantly reduced genome size is thought to be the result of the taxon's evolution into obligate parasites. \"Mycoplasma\" species typically invade and adhere to host cells from which they obtain their nutrients, usually at the expense of the host. All members of this genus, including \"M. orale,\" inhabit a wide range of mammalian hosts. Though \"M. orale\" usually exists as a commensal in human oral cavities, it is an opputunistic pathogen and will cause illness in human hosts when conditions are right. Due to their small genome size and parasitic lifecycle, they lack many non-essential biosynthetic pathways in their metabolism. These include those for cell wall synthesis as well as purine synthesis. These genomic characteristics make them a good model for the Minimal Genome Concept. \"Mycoplasma\" members, including \"M. orale\", also generally have a low G-C content compared to other bacteria. Research has revealed that the 16S rRNA gene of \"M. orale\" is about 1,510 bp.",
            "score": 80.62474822998047
        },
        {
            "docid": "9028799_62",
            "document": "Bacteria . Because of their ability to quickly grow and the relative ease with which they can be manipulated, bacteria are the workhorses for the fields of molecular biology, genetics and biochemistry. By making mutations in bacterial DNA and examining the resulting phenotypes, scientists can determine the function of genes, enzymes and metabolic pathways in bacteria, then apply this knowledge to more complex organisms. This aim of understanding the biochemistry of a cell reaches its most complex expression in the synthesis of huge amounts of enzyme kinetic and gene expression data into mathematical models of entire organisms. This is achievable in some well-studied bacteria, with models of \"Escherichia coli\" metabolism now being produced and tested. This understanding of bacterial metabolism and genetics allows the use of biotechnology to bioengineer bacteria for the production of therapeutic proteins, such as insulin, growth factors, or antibodies.",
            "score": 127.05906534194946
        },
        {
            "docid": "2571276_8",
            "document": "Computational genomics . Researchers at Stanford University created the first software simulation of an entire organism.  They mapped the 525 genes of the bacteria \"Mycoplasma genitalium\", the smallest free-living organism. With data from more than 900 scientific papers reported on the bacterium, researchers developed the software model using the object-oriented programming approach. A series of modules mimic the various functions of the cell, and then integrated it into a whole simulated organism. The simulation runs on a single CPU, recreating the complete life span of the cell at the molecular level, reproducing the interactions of molecules in cell processes including metabolism and cell division.",
            "score": 137.64043283462524
        },
        {
            "docid": "446223_8",
            "document": "Gene knockdown . A different means of silencing exogenous DNA that has been discovered in prokaryotes is a mechanism involving loci called 'Clustered Regularly Interspaced Short Palindromic Repeats', or CRISPRs. Proteins called 'CRISPR-associated genes' (cas genes) encode cellular machinery that cuts exogenous DNA into small fragments and inserts them into a CRISPR repeat locus. When this CRISPR region of DNA is expressed by the cell, the small RNAs produced from the exogenous DNA inserts serve as a template sequence that other Cas proteins use to silence this same exogenous sequence. The transcripts of the short exogenous sequences are used as a guide to silence these foreign DNA when they are present in the cell. This serves as a kind of acquired immunity, and this process is like a prokaryotic RNA interference mechanism. The CRISPR repeats are conserved amongst many species and have been demonstrated to be usable in human cells, bacteria, \"C. elegans\", zebrafish, and other organisms for effective genome manipulation. The use of CRISPRs as a versatile research tool can be illustrated by many studies making use of it to generate organisms with genome alterations.",
            "score": 60.77732729911804
        },
        {
            "docid": "5824073_12",
            "document": "High-content screening . This technology allows a (very) large number of experiments to be performed, allowing explorative screening. Cell-based systems are mainly used in chemical genetics where large, diverse small molecule collections are systematically tested for their effect on cellular model systems. Novel drugs can be found using screens of tens of thousands of molecules, and these have promise for the future of drug development.  Beyond drug discovery, chemical genetics is aimed at functionalizing the genome by identifying small molecules that acts on most of the 21,000 gene products in a cell. High-content technology will be part of this effort which could provide useful tools for learning where and when proteins act by knocking them out chemically. This would be most useful for gene where knock out mice (missing one or several genes) can not be made because the protein is required for development, growth or otherwise lethal when it is not there. Chemical knock out could address how and where these genes work. Further the technology is used in combination with RNAi to identify sets of genes involved in specific mechanisms, for example cell division. Here, libraries of RNAis, covering a whole set of predicted genes inside the target organism's genome can be used to identify relevant subsets, facilitating the annotation of genes for which no clear role has been established beforehand. The large datasets produced by automated cell biology contain spatially resolved, quantitative data which can be used for building for systems level models and simulations of how cells and organisms function. Systems biology models of cell function would permit prediction of why, where and how the cell responds to external changes, growth and disease.",
            "score": 155.94351375102997
        },
        {
            "docid": "205624_19",
            "document": "Horizontal gene transfer . The virus called \"Mimivirus\" infects amoebae. Another virus, called \"Sputnik\", also infects amoebae, but it cannot reproduce unless mimivirus has already infected the same cell. \"Sputnik's genome reveals further insight into its biology. Although 13 of its genes show little similarity to any other known genes, three are closely related to mimivirus and mamavirus genes, perhaps cannibalized by the tiny virus as it packaged up particles sometime in its history. This suggests that the satellite virus could perform horizontal gene transfer between viruses, paralleling the way that bacteriophages ferry genes between bacteria.\" Horizontal transfer is also seen between geminiviruses and tobacco plants.",
            "score": 56.84403109550476
        },
        {
            "docid": "35629150_23",
            "document": "Bacterial genome . Selection is but one process involved in evolution. Two other major processes (mutation and genetic drift) can be used to explain the genome sizes of various types of bacteria. A study done by Mira et al. examined the size of insertions and deletions in bacterial pseudogenes. Results indicated that mutational deletions tend to be larger than insertions in bacteria in the absence of gene transfer or gene duplication. Insertions caused by horizontal or lateral gene transfer and gene duplication tend to involve transfer of large amounts of genetic material. Assuming a lack of these processes, genomes will tend to reduce in size in the absence of selective constraint. Evidence of a deletional bias is present in the respective genome sizes of free-living bacteria, facultative and recently derived parasites and obligate parasites and symbionts.",
            "score": 61.04260873794556
        },
        {
            "docid": "37388686_12",
            "document": "Minimal genome . In JCVI's 1999 study among the two organisms, \"M. genitalium\" and \"Mycoplasma pneumoniae\" they mapped around 2,200 transposon insertion sites and identified 130 putative non-essentials genes in \"M. genitalium\" protein coding genes or \"M. pneumoniae\" orthologs of \"M. genitalium\" genes. In their experiment they grew a set of Tn4001 transformed cells for many weeks and isolated the genomic DNA from these mixture of mutants. Amplicons were sequenced to detect the transposon insertion sites in mycoplasma genomes. Genes that contained the transposon insertions were hypothetical proteins or proteins considered non-essential.",
            "score": 50.50115203857422
        },
        {
            "docid": "43567293_8",
            "document": "Ruth Hall (scientist) . Bacteria can adapt rapidly to environmental pressures, including antibiotic use, through acquisition of further genes, and Hall has investigated the role of mobile genetic elements in the development of multiple antibiotic resistance and in bacterial evolution using different Gram negative pathogens including Escherichia coli, Salmonella enterica, Klebsiella pneumoniae and Acinetobacter baumanni . Hall's work has characterized a variety of mobile elements, including plasmids, genomic islands, transposons, gene cassettes and integrons. Gene cassettes are mobile genetic units each carrying only one gene which can be readily transferred into and between larger, stable genetic backbones called integrons that are responsible for moving the cassettes. The integron is also responsible for expression of the genes in cassettes. This exchange of genes between different bacteria enables rapid emergence of resistance under selection pressure of antibiotics.",
            "score": 39.964303851127625
        },
        {
            "docid": "285948_10",
            "document": "Unicellular organism . Bacteria are one of the world\u2019s oldest forms of life, and are found virtually everywhere in nature. Many common bacteria have plasmids, which are short, circular, self-replicating DNA molecules that are separate from the bacteria chromosome. Plasmids can carry genes responsible for novel abilities, of current critical importance being antibiotic resistance. Bacteria predominantly reproduce asexually through a process called binary fission. However, about 80 different species can undergo a sexual process referred to as natural genetic transformation. Transformation is a bacterial process for transferring DNA from one cell to another, and is apparently an adaptation for repairing DNA damage in the recipient cell. In addition, plasmids can be exchanged through the use of a pilus in a process known as conjugation.",
            "score": 74.51410698890686
        },
        {
            "docid": "35629150_6",
            "document": "Bacterial genome . Bacteria possess a compact genome architecture distinct from eukaryotes in two important ways: bacteria show a strong correlation between genome size and number of functional genes in a genome, and those genes are structured into operons. The main reason for the relative density of bacterial genomes compared to eukaryotic genomes (especially multicellular eukaryotes) is the presence of noncoding DNA in the form of intergenic regions and introns. Some notable exceptions include recently formed pathogenic bacteria. This was initially described in a study by Cole \"et al\". in which \"Mycobacterium leprae\" was discovered to have a significantly higher percentage of pseudogenes to functional genes (~40%) than its free-living ancestors.",
            "score": 55.17178201675415
        },
        {
            "docid": "37388686_25",
            "document": "Minimal genome . May 20, 2010 \u2013 Researchers at the JCVI have successfully created a synthetic bacterial cell that is capable of replicating itself. The team has synthesized a 1.08 million base pair chromosome of a modified \"Mycoplasma mycoides\". The synthetic cell is called: \"Mycoplasma mycoides\" JCVI-syn1.0. One of the remarkable thing about this cell is that its DNA was built in the computer and transplanted into cell from which is own (origin) genome was removed. The original molecules and on-going reaction networks of the recipient cell then used the artificial DNA to generate daughter cells. These daughter cells are of synthetic origin and capable of further replication. This proves that genomes can be designed on computers. The steps they applied to build this was first they simulated a model of this genome computationally, they identified DNA via watermarks; next, they chemically produced this genome in the laboratory and finally, transplanted this genome into a recipient cell to produce a synthetic cell solely controlled by this synthetic genome.",
            "score": 130.18310928344727
        },
        {
            "docid": "7011824_9",
            "document": "Biotechnology in pharmaceutical manufacturing . Plasmids containing the Factor IX gene, along with plasmids with a gene that codes for resistance to methotrexate, were inserted into Chinese hamster ovary cells via transfection. Transfection involves the insertion of DNA into a eukaryotic cell. Unlike the analogous process of transformation in bacteria, transfected DNA is not ordinarily integrated into the cell's genome, and is therefore not usually passed on to subsequent generations via cell division. Thus, in order to obtain a \"stable\" transfection, a gene which confers a significant survival advantage must also be transfected, causing the few cells that did integrate the transfected DNA into their genomes to increase their population as cells that did not integrate the DNA are eliminated. In the case of this study, \"grow[th] in increasing concentrations of methotrexate\" promoted the survival of stably transfected cells, and diminished the survival of other cells.",
            "score": 52.461756467819214
        },
        {
            "docid": "11913227_18",
            "document": "Artificial gene synthesis . On Oct 6, 2007, Craig Venter announced in an interview with UK's \"The Guardian\" newspaper that the same team had synthesized a modified version of the single chromosome of \"Mycoplasma genitalium\" using chemicals. The chromosome was modified to eliminate all genes which tests in live bacteria had shown to be unnecessary. The next planned step in this \"minimal genome project\" is to transplant the synthesized minimal genome into a bacterial cell with its old DNA removed; the resulting bacterium will be called \"Mycoplasma laboratorium\". The next day the Canadian bioethics group, ETC Group issued a statement through their representative, Pat Mooney, saying Venter's \"creation\" was \"a chassis on which you could build almost anything\". The synthesized genome had not yet been transplanted into a working cell.",
            "score": 83.9935896396637
        },
        {
            "docid": "2954908_6",
            "document": "Lysogenic cycle . Bacteriophages are viruses that infect and replicate within a bacterium. Temperate phages (such as lambda phage) can reproduce using both the lytic and the lysogenic cycle. Via the lysogenic cycle, the bacteriophage's genome is not expressed and is instead integrated into the bacteria's genome to form the prophage. Since the bacteriophage's genetic information is incorporated into the bacteria's genetic information as a prophage, the bacteriophage replicates passively as the bacterium divides to form daughter bacteria cells. In this scenario, the daughter bacteria cells contain prophage and are known as lysogens. Lysogens can remain in the lysogenic cycle for many generations but can switch to the lytic cycle at any time via a process known as induction. During induction, prophage DNA is excised from the bacterial genome and is transcribed and translated to make coat proteins for the virus and regulate lytic growth.",
            "score": 50.157317876815796
        }
    ],
    "r": [
        {
            "docid": "24044102_6",
            "document": "Cellular model . The eukaryotic cell cycle is very complex and is one of the most studied topics, since its misregulation leads to cancers. It is possibly a good example of a mathematical model as it deals with simple calculus but gives valid results. Two research groups have produced several models of the cell cycle simulating several organisms. They have recently produced a generic eukaryotic cell cycle model which can represent a particular eukaryote depending on the values of the parameters, demonstrating that the idiosyncrasies of the individual cell cycles are due to different protein concentrations and affinities, while the underlying mechanisms are conserved (Csikasz-Nagy et al., 2006). By means of a system of ordinary differential equations these models show the change in time (dynamical system) of the protein inside a single typical cell; this type of model is called a deterministic process (whereas a model describing a statistical distribution of protein concentrations in a population of cells is called a stochastic process). To obtain these equations an iterative series of steps must be done: first the several models and observations are combined to form a consensus diagram and the appropriate kinetic laws are chosen to write the differential equations, such as rate kinetics for stoichiometric reactions, Michaelis-Menten kinetics for enzyme substrate reactions and Goldbeter\u2013Koshland kinetics for ultrasensitive transcription factors, afterwards the parameters of the equations (rate constants, enzyme efficiency coefficients and Michaelis constants) must be fitted to match observations; when they cannot be fitted the kinetic equation is revised and when that is not possible the wiring diagram is modified. The parameters are fitted and validated using observations of both wild type and mutants, such as protein half-life and cell size. In order to fit the parameters the differential equations need to be studied. This can be done either by simulation or by analysis.  In a simulation, given a starting vector (list of the values of the variables), the progression of the system is calculated by solving the equations at each time-frame in small increments. In analysis, the properties of the equations are used to investigate the behavior of the system depending of the values of the parameters and variables. A system of differential equations can be represented as a vector field, where each vector described the change (in concentration of two or more protein) determining where and how fast the trajectory (simulation) is heading. Vector fields can have several special points: a stable point, called a sink, that attracts in all directions (forcing the concentrations to be at a certain value), an unstable point, either a source or a saddle point which repels (forcing the concentrations to change away from a certain value), and a limit cycle, a closed trajectory towards which several trajectories spiral towards (making the concentrations oscillate). A better representation which can handle the large number of variables and parameters is called a bifurcation diagram (bifurcation theory): the presence of these special steady-state points at certain values of a parameter (e.g. mass) is represented by a point and once the parameter passes a certain value, a qualitative change occurs, called a bifurcation, in which the nature of the space changes, with profound consequences for the protein concentrations: the cell cycle has phases (partially corresponding to G1 and G2) in which mass, via a stable point, controls cyclin levels, and phases (S and M phases) in which the concentrations change independently, but once the phase has changed at a bifurcation event (cell cycle checkpoint), the system cannot go back to the previous levels since at the current mass the vector field is profoundly different and the mass cannot be reversed back through the bifurcation event, making a checkpoint irreversible. In particular the S and M checkpoints are regulated by means of special bifurcations called a Hopf bifurcation and an infinite period bifurcation. Cell Collective is a modeling software that enables one to house dynamical biological data, build computational models, stimulate, break and recreate models. The development is led by Tomas Helikar, a researcher within the field of computational biology. It is designed for biologists, students learning about computational biology, teachers focused on teaching life sciences, and researchers within the field of life science. The complexities of math and computer science are built into the backend and one can learn about the methods used for modeling biological species, but complex math equations, algorithms, programming are not required and hence won't impede model building.",
            "score": 159.11239624023438
        },
        {
            "docid": "5824073_12",
            "document": "High-content screening . This technology allows a (very) large number of experiments to be performed, allowing explorative screening. Cell-based systems are mainly used in chemical genetics where large, diverse small molecule collections are systematically tested for their effect on cellular model systems. Novel drugs can be found using screens of tens of thousands of molecules, and these have promise for the future of drug development.  Beyond drug discovery, chemical genetics is aimed at functionalizing the genome by identifying small molecules that acts on most of the 21,000 gene products in a cell. High-content technology will be part of this effort which could provide useful tools for learning where and when proteins act by knocking them out chemically. This would be most useful for gene where knock out mice (missing one or several genes) can not be made because the protein is required for development, growth or otherwise lethal when it is not there. Chemical knock out could address how and where these genes work. Further the technology is used in combination with RNAi to identify sets of genes involved in specific mechanisms, for example cell division. Here, libraries of RNAis, covering a whole set of predicted genes inside the target organism's genome can be used to identify relevant subsets, facilitating the annotation of genes for which no clear role has been established beforehand. The large datasets produced by automated cell biology contain spatially resolved, quantitative data which can be used for building for systems level models and simulations of how cells and organisms function. Systems biology models of cell function would permit prediction of why, where and how the cell responds to external changes, growth and disease.",
            "score": 155.94351196289062
        },
        {
            "docid": "2567511_12",
            "document": "Neural engineering . Neuromechanics is the coupling of neurobiology, biomechanics, sensation and perception, and robotics (Edwards 2010). Researchers are using advanced techniques and models to study the mechanical properties of neural tissues and their effects on the tissues' ability to withstand and generate force and movements as well as their vulnerability to traumatic loading (Laplaca & Prado 2010). This area of research focuses on translating the transformations of information among the neuromuscular and skeletal systems to develop functions and governing rules relating to operation and organization of these systems (Nishikawa et al. 2007). Neuromechanics can be simulated by connecting computational models of neural circuits to models of animal bodies situated in virtual physical worlds (Edwards 2010). Experimental analysis of biomechanics including the kinematics and dynamics of movements, the process and patterns of motor and sensory feedback during movement processes, and the circuit and synaptic organization of the brain responsible for motor control are all currently being researched to understand the complexity of animal movement. Dr. Michelle LaPlaca's lab at Georgia Institute of Technology is involved in the study of mechanical stretch of cell cultures, shear deformation of planar cell cultures, and shear deformation of 3D cell containing matrices. Understanding of these processes is followed by development of functioning models capable of characterizing these systems under closed loop conditions with specially defined parameters. The study of neuromechanics is aimed at improving treatments for physiological health problems which includes optimization of prostheses design, restoration of movement post injury, and design and control of mobile robots. By studying structures in 3D hydrogels, researchers can identify new models of nerve cell mechanoproperties. For example, LaPlaca et al. developed a new model showing that strain may play a role in cell culture (LaPlaca et al. 2005).",
            "score": 151.99862670898438
        },
        {
            "docid": "841429_24",
            "document": "Synthetic biology . Models inform the design of engineered biological systems by better predicting system behavior prior to fabrication. Synthetic biology benefits from better models of how biological molecules bind substrates and catalyze reactions, how DNA encodes the information needed to specify the cell and how multi-component integrated systems behave. Multiscale models of gene regulatory networks focus on synthetic biology applications. Simulations can model all biomolecular interactions in transcription, translation, regulation and induction of gene regulatory networks. In a living cell, molecular motifs are embedded in a bigger network with upstream and downstream components. These components may alter the signalling capability of the modeling module. In the case of ultrasensitive modules, the sensitivity contribution of a module can differ from the sensitivity that the module sustains in isolation.",
            "score": 151.32728576660156
        },
        {
            "docid": "38374635_2",
            "document": "Eric Schadt . Eric Emil Schadt (born January 31, 1965) is an American mathematician and computational biologist. He is Dean for Precision Medicine at the Icahn School of Medicine at Mount Sinai and Chief Executive Officer of Sema4, a spinout next generation health information company of the Mount Sinai Health System that provides advanced genomic testing and merges big data analytics with clinical diagnostics. He was previously founding director of the Icahn Institute for Genomics and Multiscale Biology and chair of the Department of Genetics and Genomics Sciences at the Icahn School of Medicine at Mount Sinai. Schadt\u2019s work combines supercomputing and advanced computational modeling with diverse biological data to understand the relationship between genes, gene products, other molecular features such as cells, organs, organisms, and communities and their impact on complex human traits such as disease. He is known for calling for a shift in molecular biology toward a network-oriented view of living systems to complement the reductionist, single-gene approaches that currently dominate biology to more accurately model the complexity of biological systems. Schadt has also worked to engage the public, encouraging people to participate in scientific research and helping them understand privacy concerns around DNA-based information.",
            "score": 146.1090545654297
        },
        {
            "docid": "22549833_2",
            "document": "Modeling and simulation . Modeling and simulation (M&S) in simple terms is a substitute for physical experimentation, in which computers are used to compute the results of some physical phenomenon. As it is apparent from its name \"Modeling and simulation\" firstly computer is used to build a mathematical model which contains all the parameters of physical model and represent physical model in virtual form then conditions are applied which we want to experiment on physical model, then simulation starts i.e, we leave on computer to compute/calculate the results of those conditions on mathematical model. In this way actual experimentation can be avoided which is costly and time consuming instead of using mathematical knowledge and computer's computation power to solve real world problems cheaply and in time efficient manner. As such, M&S can facilitate understanding a system's behavior without actually testing the system in the real world. For instance, to determine which type of spoiler would improve traction the most while designing a race car, a computer simulation of the car could be used to estimate the effect of different spoiler shapes on the coefficient of friction in a turn. Useful insights about different decisions in the design could be gleaned without actually building the car. In addition, simulation can support experimentation that occurs totally in software, or in human-in-the-loop environments where simulation represents systems or generates data needed to meet experiment objectives. Furthermore, simulation can be used to train persons using a virtual environment that would otherwise be difficult or expensive to produce.",
            "score": 145.03131103515625
        },
        {
            "docid": "48397458_4",
            "document": "John J. Tyson . Since receiving his PhD in chemical physics at the University of Chicago in 1973, John Tyson has been studying temporal and spatial organization in chemical, biochemical and biological systems. Recently he has focused on the macro-molecular reaction networks that process information in living cells and initiate appropriate responses in terms of cell growth, division and death. He represents the dynamics of these reaction networks in terms of mathematical equations, using computer simulations to work out the precise behavior to be expected of the network. By comparing simulations with experimental data, the computer models can be tested, refined and developed, eventually, into tools for accurate predictions of the physiological responses of healthy and diseased cells.",
            "score": 143.54283142089844
        },
        {
            "docid": "3408308_23",
            "document": "Metabolic network modelling . Metabolic network reconstructions and models are used to understand how an organism or parasite functions inside of the host cell. For example, if the parasite serves to compromise the immune system by lysing macrophages, then the goal of metabolic reconstruction/simulation would be to determine the metabolites that are essential to the organism's proliferation inside of macrophages. If the proliferation cycle is inhibited, then the parasite would not continue to evade the host's immune system. A reconstruction model serves as a first step to deciphering the complicated mechanisms surrounding disease. These models can also look at the minimal genes necessary for a cell to maintain virulence. The next step would be to use the predictions and postulates generated from a reconstruction model and apply it to discover novel biological functions such as drug-engineering and drug delivery techniques.",
            "score": 141.31846618652344
        },
        {
            "docid": "318669_21",
            "document": "Schizosaccharomyces pombe . Fission yeast has become a notable model system to study basic principles of a cell that can be used to understand more complex organisms like mammals and in particular humans. This single cell eukaryote is nonpathogenic and easily grown and manipulated in the lab. Fission yeast contains one of the smallest numbers of genes of a known genome sequence for a eukaryote, and has only three chromosomes in its genome. Many of the genes responsible for cell division and cellular organization in fission yeast cell are also found in the human\u2019s genome. Cell cycle regulation and division are crucial for growth and development of any cell. Fission yeast\u2019s conserved genes has been heavily studied and the reason for many recent biomedical developments. Fission yeast is also a practical model system to observe cell division because fission yeast\u2019s are cylindrically shaped single celled eukaryotes that divide and reproduce by medial fission. This can easily be seen using microscopy. Fission yeast also have an extremely short generation time, 2 to 4 hours, which also makes it an easy model system to observe and grow in the laboratory Fission yeast\u2019s simplicity in genomic structure yet similarities with mammalian genome, ease of ability to manipulate, and ability to be used for drug analysis is why fission yeast is making many contributions to biomedicine and cellular biology research, and a model system for genetic analysis.",
            "score": 138.40042114257812
        },
        {
            "docid": "2571276_8",
            "document": "Computational genomics . Researchers at Stanford University created the first software simulation of an entire organism.  They mapped the 525 genes of the bacteria \"Mycoplasma genitalium\", the smallest free-living organism. With data from more than 900 scientific papers reported on the bacterium, researchers developed the software model using the object-oriented programming approach. A series of modules mimic the various functions of the cell, and then integrated it into a whole simulated organism. The simulation runs on a single CPU, recreating the complete life span of the cell at the molecular level, reproducing the interactions of molecules in cell processes including metabolism and cell division.",
            "score": 137.64044189453125
        },
        {
            "docid": "55680252_6",
            "document": "Amyotrophic lateral sclerosis research . Many animals have been used over the years to study ALS and to search for a potential therapy. The animal models can be C. elegans which has only 959 cells with simple structure, and known gene code.. Also, some studied have introduced the transgenic strain of C. elegans, which has a mutation in a gene related to ALS for example, and crossed them with the transgenic nlp-29 GFP reporter strain, resulting in fluorescent markers to the cells that are expressing these mutated genes, which can be used to monitor the disease development and effects . Similar, but more complex nervous system from the C. elegans is the Drosophila. Fruit fly ALS models can be used to study the locomotion and eye changes that can be related to human symptoms. Thus, drugs can be tested on these transgenic fruit flies to discovery new target molecules . On the other hand, zebrafish models have been used widely due to their similarity in the development and anatomy characteristics as a vertebrate to the human body . A study introduced the SOD1/GFP transgenic zebra-fish to study that specific gene on the development and occurrence of ALS in the fish, and how can that be used in testing potential therapeutic molecules . All the previous models are considered simple, and saves time and money due to their short lifespan and small and simple body structure .",
            "score": 137.0897979736328
        },
        {
            "docid": "149353_8",
            "document": "Computational biology . Computational biomodeling is a field concerned with building computer models of biological systems. Computational biomodeling aims to develop and use visual simulations in order to assess the complexity of biological systems. This is accomplished through the use of specialized algorithms, and visualization software. These models allow for prediction of how systems will react under different environments. This is useful for determining if a system is robust. A robust biological system is one that \u201cmaintain their state and functions against external and internal perturbations\u201d, which is essential for a biological system to survive. Computational biomodeling generates a large archive of such data, allowing for analysis from multiple users. While current techniques focus on small biological systems, researchers are working on approaches that will allow for larger networks to be analyzed and modeled. A majority of researchers believe that this will be essential in developing modern medical approaches to creating new drugs and gene therapy. A useful modelling approach is to use Petri nets via tools such as esyN",
            "score": 136.24551391601562
        },
        {
            "docid": "39178155_3",
            "document": "Bilingual lexical access . Early research of bilingual lexical access was generated from the theories of unilingual lexical access.  Theories derived from early unilingual research relied mainly upon generalizations without precise specification of how these specific systems of lexical access works. Due to the advancement of medical science within the last decade, the field of Psycholinguistics has evolved immensely, resulting in more detailed research and therefore, a deeper understanding of the mechanisms behind language production. \"Many early studies of second language acquisition focused on the morphosyntactic development of learners, and the general findings was that bound morphemes appear in the same order in the first and second language\"(Bardovi-Harlig 1999. In addition, \"second language learners are also able to produce and process simple sentences before complex sentences\" (Pienemann et al.2005), just like first language learners. For example, the theory of serial search models and parallel access models. \"Serial Search Models\" propose that when monolinguals encounter a word, they will look through all the lexical entries to distinguish whether the input item is a word not, and then they will only retrieve the necessary information about that word (i.e., its semantics or orthography). They also propose that the lexical access would process sequentially by activating only one lexical entry at a time. In contrast, the \"Parallel Access Models\" believe that multiple entries can be activated at once, which means that the perceptual input from a word would activate all lexical items directly, even though some of them might not be necessary. In this way, numbers of potential candidates would be activated simultaneously and then the lexical candidates which are most consistent with the input stimulus would be chosen. Later, the researchers addressed that both the serial and parallel process are accounted for the lexical organization and lexical access. Knowledge of unilingual access has inevitably led to the curiosity of bilingual lexical access. Early models of bilingual lexical access shared similar characteristics with these unilingual lexical access models. For example, the bilingual models began with focusing on whether the lexical access for bilinguals would be different from monolinguals. In addition to study the activation process in separate language, they also investigated whether the lexical activation would be processed in a parallel fashion for both languages or selectively processed for the target language. In this case, the bilingual models also studied whether the bilingual system has a single lexicon combining words from both languages or separate lexicons for words in each language. With the occurrence of widespread computational modeling, researchers extended the theoretical approaches for the studies of bilingual lexical access.The computational models are now essential component for mainstream theories, for example, the models of Bilingual Interactive Activation [BIA] model,  the Semantic, Orthographic and Phonological Interactive Activation [SOPIA] model, and the Bilingual interactive Model of Lexical Access [BLMOLA]. Since most computational models need to specify all the vague descriptive notions used in the earlier models, they force researchers to be more clarified with their theories. Those revised models can also serve as to test the viability of the original theories by comparing the empirical results with data generated from the model. In addition, the computational models can also help to generate new testable hypothesis and allow researchers to manipulate conditions which might not be possible in normal experimentation. For example, researchers can investigate and simulate the lexical access systems under various states of damage without using aphasic people.",
            "score": 136.18905639648438
        },
        {
            "docid": "662088_31",
            "document": "Mathematical and theoretical biology . The eukaryotic cell cycle is very complex and is one of the most studied topics, since its misregulation leads to cancers. It is possibly a good example of a mathematical model as it deals with simple calculus but gives valid results. Two research groups have produced several models of the cell cycle simulating several organisms. They have recently produced a generic eukaryotic cell cycle model that can represent a particular eukaryote depending on the values of the parameters, demonstrating that the idiosyncrasies of the individual cell cycles are due to different protein concentrations and affinities, while the underlying mechanisms are conserved (Csikasz-Nagy et al., 2006).",
            "score": 135.6638641357422
        },
        {
            "docid": "3190431_32",
            "document": "Spatial analysis . Complex adaptive systems theory as applied to spatial analysis suggests that simple interactions among proximal entities can lead to intricate, persistent and functional spatial entities at aggregate levels. Two fundamentally spatial simulation methods are cellular automata and agent-based modeling. Cellular automata modeling imposes a fixed spatial framework such as grid cells and specifies rules that dictate the state of a cell based on the states of its neighboring cells. As time progresses, spatial patterns emerge as cells change states based on their neighbors; this alters the conditions for future time periods. For example, cells can represent locations in an urban area and their states can be different types of land use. Patterns that can emerge from the simple interactions of local land uses include office districts and urban sprawl. Agent-based modeling uses software entities (agents) that have purposeful behavior (goals) and can react, interact and modify their environment while seeking their objectives. Unlike the cells in cellular automata, simulysts can allow agents to be mobile with respect to space. For example, one could model traffic flow and dynamics using agents representing individual vehicles that try to minimize travel time between specified origins and destinations. While pursuing minimal travel times, the agents must avoid collisions with other vehicles also seeking to minimize their travel times. Cellular automata and agent-based modeling are complementary modeling strategies. They can be integrated into a common geographic automata system where some agents are fixed while others are mobile.",
            "score": 135.49681091308594
        },
        {
            "docid": "1434685_10",
            "document": "Prognostics . The motivation for pre-estimate aggregation may be that no ground truth data are available. This may occur in situations where diagnostics does a good job in detecting faults that are resolved (through maintenance) before system failure occurs. Therefore, there are hardly any run-to-failure data. However, there is incentive to know better when a system would fail to better leverage the remaining useful life while at the same time avoiding unscheduled maintenance (unscheduled maintenance is typically more costly than scheduled maintenance and results in system downtime). Garga et al. describe conceptually a pre-estimate aggregation hybrid approach where domain knowledge is used to change the structure of a neural network, thus resulting in a more parsimonious representation of the network. Another way to accomplish the pre-estimate aggregation is by a combined off-line process and on-line process: In the off-line mode, one can use a physics-based simulation model to understand the relationships of sensor response to fault state; In the on-line mode, one can use data to identify current damage state, then track the data to characterize damage propagation, and finally apply an individualized data-driven propagation model for remaining life prediction. For example, Khorasgani et al modeled the physics of failure in electrolytic capacitors. Then, they used a particle filter approach to derive the dynamic form of the degradation model and estimate the current state of capacitor health. This model is then used to get more accurate estimation of the Remaining Useful Life (RUL) of the capacitors as they are subjected to the thermal stress conditions.",
            "score": 135.298828125
        },
        {
            "docid": "156998_72",
            "document": "Action potential . Mathematical and computational models are essential for understanding the action potential, and offer predictions that may be tested against experimental data, providing a stringent test of a theory. The most important and accurate of the early neural models is the Hodgkin\u2013Huxley model, which describes the action potential by a coupled set of four ordinary differential equations (ODEs). Although the Hodgkin\u2013Huxley model may be a simplification with few limitations compared to the realistic nervous membrane as it exists in nature, its complexity has inspired several even-more-simplified models, such as the Morris\u2013Lecar model and the FitzHugh\u2013Nagumo model, both of which have only two coupled ODEs. The properties of the Hodgkin\u2013Huxley and FitzHugh\u2013Nagumo models and their relatives, such as the Bonhoeffer\u2013van der Pol model, have been well-studied within mathematics, computation and electronics. However the simple models of generator potential and action potential fail to accurately reproduce the near threshold neural spike rate and spike shape, specifically for the mechanoreceptors like the Pacinian corpuscle. More modern research has focused on larger and more integrated systems; by joining action-potential models with models of other parts of the nervous system (such as dendrites and synapses), researchers can study neural computation and simple reflexes, such as escape reflexes and others controlled by central pattern generators.",
            "score": 134.48052978515625
        },
        {
            "docid": "43966823_21",
            "document": "Multi-state modeling of biomolecules . ML-Rules is similar to React(C), but provides the added possibility of nesting: A component species of the model, with all its attributes, can be part of a higher-order component species. This enables ML-Rules to capture multi-level models that can bridge the gap between, for instance, a series of biochemical processes and the macroscopic behaviour of a whole cell or group of cells. For instance, Maus et al. have provided a proof-of-concept model of cell division in fission yeast that includes cyclin/cdc2 binding and activation, pheromone secretion and diffusion, cell division and movement of cells. Models specified in ML-Rules can be simulated using the James II simulation framework. A similar nested language to represent multi-level biological systems has been proposed by Oury and Plotkin.",
            "score": 133.6173553466797
        },
        {
            "docid": "50311973_8",
            "document": "Microfluidic cell culture . Three-dimensional (3D) cell culture is cell culture that takes place in a biologically relevant matrix, usually this involves cells being embedded in a hydrogel containing extracellular molecules (e.g., collagen). By adding an additional dimension, more advanced cell architectures can be achieved, and cell behavior is more representative of \"in vivo\" dynamics; cells can engage in enhanced communication with neighboring cells and cell-extracellular matrix interactions can be modeled. These simplified 3D cell culture models can be combined in a manner that recapitulates tissue- and organ-level functions in devices known as organ-on-a-chip. In these devices, chambers or collagen layers containing different cell types can interact with one another for multiple days while various channels deliver nutrients to the cells. An advantage of these devices is that tissue function can be characterized and observed under controlled conditions (e.g., effect of shear stress on cells, effect of cyclic strain or other forces) to better understand the overall function of the organ. While these 3D models often better model organ function on a cellular level compared with 2D models, there are still challenges. Some of the challenges include: imaging of the cells, control of gradients in static models (i.e., without a perfusion system), and difficulty recreating vasculature. Despite these challenges, 3D models are still used as tools for studying and testing drug responses in pharmacological studies.",
            "score": 133.55657958984375
        },
        {
            "docid": "1686272_18",
            "document": "Chemical biology . Protein misfolding has previously been studied using both computational approaches as well as \"in vivo\" biological assays in model organisms such as \"Drosophila melanogaster\" and \"C. elegans\". Computational models use a \"de novo\" process to calculate possible protein structures based on input parameters such as amino acid sequence, solvent effects, and mutations. This method has the shortcoming that the cell environment has been drastically simplified, which limits the factors that influence folding and stability. On the other hand, biological assays can be quite complicated to perform \"in vivo\" with high-throughput like efficiency and there always remains the question of how well lower organism systems approximate human systems. Dobson et al. propose combining these two approaches such that computational models based on the organism studies can begin to predict what factors will lead to protein misfolding. Several experiments have already been performed based on this strategy. In experiments on \"Drosophila\", different mutations of beta amyloid peptides were evaluated based on the survival rates of the flies as well as their motile ability. The findings from the study show that the more a protein aggregates, the more detrimental the neurological dysfunction. Further studies using transthyretin, a component of cerebrospinal fluid that binds to beta amyloid peptide deterring aggregation but can itself aggregate especially when mutated, indicate that aggregation prone proteins may not aggregate where they are secreted and rather are deposited in specific organs or tissues based on each mutation. Kelly et al. have shown that the more stable, both kinetically and thermodynamically, a misfolded protein is the more likely the cell is to secrete it from the endoplasmic reticulum rather than targeting the protein for degradation. In addition, the more stress that a cell feels from misfolded proteins the more probable new proteins will misfold. These experiments as well as others having begun to elucidate both the intrinsic and extrinsic causes of misfolding as well as how the cell recognizes if proteins have folded correctly.",
            "score": 133.0515899658203
        },
        {
            "docid": "40158142_12",
            "document": "Nonlinear system identification . Structure detection forms the most fundamental part of NARMAX. For example a NARMAX model which consists of one lagged input and one lagged output term, three lagged noise terms, expanded as a cubic polynomial would consist of fifty six possible candidate terms. This number of candidate terms arises because the expansion by definition includes all possible combinations within the cubic expansion. Naively proceeding to estimate a model which includes all these terms and then pruning will cause numerical and computational problems and should always be avoided. However, only a few terms are often important in the model. Structure detection, which aims to select terms one at a time, is therefore critically important. These objectives can easily be achieved by using the Orthogonal Least Squares algorithm and its derivatives to select the NARMAX model terms one at a time. These ideas can also be adapted for pattern recognition and feature selection and provide an alternative to principal component analysis but with the advantage that the features are revealed as basis functions that are easily related back to the original problem.  NARMAX methods are designed to do far more than to just find the best approximating model. System identification can be divided into two aims. The first involves approximation where the key aim is to develop a model that approximates the data set such that good predictions can be made. There are many applications where this approach is appropriate, for example in time series prediction of the weather, stock prices, speech, target tracking, pattern classification etc. In such applications the form of the model is not that important. The objective is to find an approximation scheme which produces the minimum prediction errors. A second objective of system identification, which includes the first objective as a subset, involves much more than just finding a model to achieve the best mean squared errors. This second aim is why the NARMAX philosophy was developed and is linked to the idea of finding the simplest model structure. The aim here is to develop models that reproduce the dynamic characteristics of the underlying system, to find the simplest possible model, and if possible to relate this to components and behaviours of the system under study. The core aim of this second approach to identification is therefore to identify and reveal the rule that represents the system. These objectives are relevant to model simulation and control systems design, but increasingly to applications in medicine, neuro science, and the life sciences. Here the aim is to identify models, often nonlinear, that can be used to understand the basic mechanisms of how these systems operate and behave so that we can manipulate and utilise these. NARMAX methods have also been developed in the frequency and spatio-temporal domains.",
            "score": 132.0058135986328
        },
        {
            "docid": "387746_20",
            "document": "Social simulation . A model is a representation of a specific thing ranging from objects and people to structures and products created through mathematical equations and are designed, using computers, in such a way that they are able to stand-in as the aforementioned things in a study. Models can be either simplistic or complex, depending on the need for either; however, models are intended to be simpler than what they are representing while remaining realistically similar in order to be used accurately. They are built using a collection of data that is translated into computing languages that allow them to represent the system in question. These models, much like simulations, are used to help us better understand specific roles and actions of different things so as to predict behavior and the like.",
            "score": 131.70263671875
        },
        {
            "docid": "39198919_9",
            "document": "Cancer systems biology . Mathematical modeling can provide useful context for the rational design, validation and prioritization of novel cancer drug targets and their combinations. Network-based modeling and multi-scale modeling have begun to show promise in facilitating the process of effective cancer drug discovery. Using a systems network modeling approach, Schoerberl et al. identified a previously unknown, complementary and potentially superior mechanism of inhibiting the ErbB receptor signaling network. ErbB3 was found to be the most sensitive node, leading to Akt activation; Akt regulates many biological processes, such as proliferation, apoptosis and growth, which are all relevant to tumor progression. This target driven modelling has paved way for first of its kind clinical trials. Bekkal et al. presented a nonlinear model of the dynamics of a cell population divided into proliferative and quiescent compartments. The proliferative phase represents the complete cell cycle (G (1)-S-G (2)-M) of a population committed to divide at its end. The asymptotic behavior of solutions of the nonlinear model is analysed in two cases, exhibiting tissue homeostasis or tumor exponential growth. The model is simulated and its analytic predictions are confirmed numerically.  Furthermore, advances in hardware and software have enabled the realization of clinically feasible, quantitative multimodality imaging of tissue pathophysiology. Earlier efforts relating to multimodality imaging of cancer have focused on the integration of anatomical and functional characteristics, such as PET-CT and single-photon emission CT (SPECT-CT), whereas more-recent advances and applications have involved the integration of multiple quantitative, functional measurements (for example, multiple PET tracers, varied MRI contrast mechanisms, and PET-MRI), thereby providing a more-comprehensive characterization of the tumour phenotype. The enormous amount of complementary quantitative data generated by such studies is beginning to offer unique insights into opportunities to optimize care for individual patients. Although important technical optimization and improved biological interpretation of multimodality imaging findings are needed, this approach can already be applied informatively in clinical trials of cancer therapeutics using existing tools.",
            "score": 131.48193359375
        },
        {
            "docid": "23386350_4",
            "document": "BioSim . Diabetes Efforts concentrate on the role of mutations that effect the ion channels of the insulin-producing beta-cells, on the genetic basis for the development of neonatal diabetes, on the study of human (as opposed to mice) pancreatic cells, on the mechanisms underlying the development of insulin resistance, and on the possible role of prenatal nutrition for the development of type-2 diabetes. Models are also developed to analyse the balance between fat and glucose metabolism and to describe the rate of absorption of different insulin variants. Cancer In this area the network uses computer models of the cell cycle and of its coupling to the 24 h day-and-night rhythm to improve the treatment of patients with cancer. The use of chronotherapy implies that the administration of anti-cancer drugs is adjusted in accordance with the circadian rhythm of the patient. For certain forms of cancer this has been found to increase the efficiency of the drug by a factor of five. Efforts are also devoted to the development of new anti-cancer drugs. Hypertension and cardiovascular diseases Activities area focus on the development of 3D heart models that can be used to test how a new drug affects the regularity of the heart rhythm. Work is performed to develop detailed models of the mechanisms by which the individual nephron of the kidney regulates the incoming blood flow and how neighboring nephrons interact. Mental disorders and neuronal systems Work includes application of mathematical models to develop less invasive and demand-controlled electrical stimulation techniques for the treatment of Parkinson's disease. Modelling studies are performed to examine the effect of sleep deprivation in the treatment of depression, and bioinformatic approaches are applied to try to identify forms of depression on the basis of the information available from blood samples. Methodological issues The area encompasses description of complex networks of oscillating biological units, studies of the mechanisms of temperature stabilization in biological feedback regulations, application of new methods of data analysis, and development of modeling software and biomedical search machines. The area includes application of new experimental techniques such as interference microscopy and surface enhanced Raman spectroscopy to study cellular processes. Regulatory issues and dialogue with the public Testing in animal and human subjects is a necessary part of the development of new drugs. Such experiments clearly raises a number of complicated ethical issues that the use of simulation models may reduce. This requires that the regulatory authorities can evaluate computer models and accept them as part of the required documentation.  During the last five years the BioSim Network has published nine books and 800 scientific publications. The network has organized or co-organized 30 conferences and workshops, edited four issues of international journals, and trained about 130 PhD students. New National Centres in Systems Biology have been established in relation to the BioSim partners in Manchester, Warwick, and Edinburgh.",
            "score": 130.60829162597656
        },
        {
            "docid": "45329906_2",
            "document": "Solvent models . Within the field of computational chemistry, solvent models are a variety of methods to account for the behavior of solvated condensed phases. Solvent models enable simulations and thermodynamic calculations applicable to reactions and processes which take place in solution. These include biological, chemical and environmental processes. Such calculation can lead to predictions and improved understanding of the physical processes occurring. Such models have been extensively tested and reviewed in scientific literature. The various models have their own pros and cons. Implicit models are generally computationally efficient and can provide a reasonable description of the solvent behaviour, but fail to account for the local fluctuations in solvent density around a solute molecule. The density fluctuation behaviour is due to solvent ordering around a solute and is particularly prevalent when one is considering water as the solvent. Explicit models are often less computationally economical, but can provide a physical spatially resolved description of the solvent. However, many of these explicit models are computaionally demanding and can fail to reproduce some experimental results, often due to certain fitting methods and parametrization. Hybrid methodologies are another option. These methods incorporate aspects of implicit and explicit aiming to minimize computational cost whist retaining at least some spatial resolution of the solvent. These methods can require more experience to use them correctly and often contain post calculation correction terms.",
            "score": 130.5681610107422
        },
        {
            "docid": "706999_11",
            "document": "Atmospheric chemistry . In order to synthesise and test theoretical understanding of atmospheric chemistry, computer models (such as chemical transport models) are used. Numerical models solve the differential equations governing the concentrations of chemicals in the atmosphere. They can be very simple or very complicated. One common trade off in numerical models is between the number of chemical compounds and chemical reactions modelled versus the representation of transport and mixing in the atmosphere. For example, a box model might include hundreds or even thousands of chemical reactions but will only have a very crude representation of mixing in the atmosphere. In contrast, 3D models represent many of the physical processes of the atmosphere but due to constraints on computer resources will have far fewer chemical reactions and compounds. Models can be used to interpret observations, test understanding of chemical reactions and predict future concentrations of chemical compounds in the atmosphere. One important current trend is for atmospheric chemistry modules to become one part of earth system models in which the links between climate, atmospheric composition and the biosphere can be studied.",
            "score": 130.45587158203125
        },
        {
            "docid": "37388686_25",
            "document": "Minimal genome . May 20, 2010 \u2013 Researchers at the JCVI have successfully created a synthetic bacterial cell that is capable of replicating itself. The team has synthesized a 1.08 million base pair chromosome of a modified \"Mycoplasma mycoides\". The synthetic cell is called: \"Mycoplasma mycoides\" JCVI-syn1.0. One of the remarkable thing about this cell is that its DNA was built in the computer and transplanted into cell from which is own (origin) genome was removed. The original molecules and on-going reaction networks of the recipient cell then used the artificial DNA to generate daughter cells. These daughter cells are of synthetic origin and capable of further replication. This proves that genomes can be designed on computers. The steps they applied to build this was first they simulated a model of this genome computationally, they identified DNA via watermarks; next, they chemically produced this genome in the laboratory and finally, transplanted this genome into a recipient cell to produce a synthetic cell solely controlled by this synthetic genome.",
            "score": 130.18310546875
        },
        {
            "docid": "24044102_12",
            "document": "Cellular model . Most attempts at modeling cell cycle processes have focused on the broad, complicated molecular interactions of many different chemicals, including several cyclin and cyclin-dependent kinase molecules as they correspond to the S, M, G1 and G2 phases of the cell cycle. In a 2014 published article in PLOS computational biology, collaborators at University of Oxford, Virginia Tech and Institut de G\u00e9n\u00e9tique et D\u00e9veloppement de Rennes produced a simplified model of the cell cycle using only one cyclin/CDK interaction. This model showed the ability to control totally functional cell division through regulation and manipulation only the one interaction, and even allowed researchers to skip phases through varying the concentration of CDK. This model could help understand how the relatively simple interactions of one chemical translate to a cellular level model of cell division.",
            "score": 129.53610229492188
        },
        {
            "docid": "43966823_3",
            "document": "Multi-state modeling of biomolecules . Biological signaling systems often rely on complexes of biological macromolecules that can undergo several functionally significant modifications that are mutually compatible. Thus, they can exist in a very large number of functionally different states. Modeling such multi-state systems poses two problems: The problem of how to describe and specify a multi-state system (the \"specification problem\") and the problem of how to use a computer to simulate the progress of the system over time (the \"computation problem\"). To address the specification problem, modelers have in recent years moved away from explicit specification of all possible states, and towards rule-based formalisms that allow for implicit model specification, including the \u03ba-calculus, BioNetGen, the Allosteric Network Compiler and others. To tackle the computation problem, they have turned to particle-based methods that have in many cases proved more computationally efficient than population-based methods based on ordinary differential equations, partial differential equations, or the Gillespie stochastic simulation algorithm. Given current computing technology, particle-based methods are sometimes the only possible option. Particle-based simulators further fall into two categories: Non-spatial simulators such as StochSim, DYNSTOC, RuleMonkey, and NFSim and spatial simulators, including Meredys, SRSim and MCell. Modelers can thus choose from a variety of tools; the best choice depending on the particular problem. Development of faster and more powerful methods is ongoing, promising the ability to simulate ever more complex signaling processes in the future.",
            "score": 129.341552734375
        },
        {
            "docid": "356382_9",
            "document": "Gene regulatory network . Mathematical models of GRNs have been developed to capture the behavior of the system being modeled, and in some cases generate predictions corresponding with experimental observations. In some other cases, models have proven to make accurate novel predictions, which can be tested experimentally, thus suggesting new approaches to explore in an experiment that sometimes wouldn't be considered in the design of the protocol of an experimental laboratory. Modeling techniques include differential equations (ODEs), Boolean networks, Petri nets, Bayesian networks, graphical Gaussian models, Stochastic, and Process Calculi. Conversely, techniques have been proposed for generating models of GRNs that best explain a set of time series observations. Recently it has been shown that ChIP-seq signal of Histone modification are more correlated with transcription factor motifs at promoters in comparison to RNA level. Hence it is proposed that time-series histone modification ChIP-seq could provide more reliable inference of gene-regulatory networks in comparison to methods based on expression levels.",
            "score": 128.9505615234375
        },
        {
            "docid": "30766907_46",
            "document": "Reversible cellular automaton . As showed, billiard-ball computers may be simulated using a two-state reversible block cellular automaton with the Margolus neighborhood. In this automaton's update rule, blocks with exactly one live cell rotate by 180\u00b0, blocks with two diagonally opposite live cells rotate by 90\u00b0, and all other blocks remain unchanged. These rules cause isolated live cells to behave like billiard balls, moving on diagonal trajectories. Connected groups of more than one live cell behave instead like the fixed obstacles of the billiard-ball computer. In an appendix, Margolus also showed that a three-state second-order cellular automaton using the two-dimensional Moore neighborhood could simulate billiard-ball computers. One reason to study reversible universal models of computation such as the billiard-ball model is that they could theoretically lead to actual computer systems that consume very low quantities of energy. According to Landauer's principle, irreversible computational steps require a certain minimal amount of energy per step, but reversible steps can be performed with an amount of energy per step that is arbitrarily close to zero. However, in order to perform computation using less energy than Landauer's bound, it is not good enough for a cellular automaton to have a transition function that is globally reversible: what is required is that the local computation of the transition function also be done in a reversible way. For instance, reversible block cellular automata are always locally reversible: the behavior of each individual block involves the application of an invertible function with finitely many inputs and outputs. were the first to ask whether every reversible cellular automaton has a locally reversible update rule. showed that for one- and two-dimensional automata the answer is positive, and showed that any reversible cellular automaton could be simulated by a (possibly different) locally reversible cellular automaton. However, the question of whether every reversible transition function is locally reversible remains open for dimensions higher than two.",
            "score": 128.3907928466797
        },
        {
            "docid": "33818014_23",
            "document": "Nervous system network models . Computational science is an interdisciplinary field that combines engineering, biology, control systems, brain functions, physical sciences, and computer science. It has fundamental development models done at the lower levels of ions, neurons, and synapses, as well as information propagation between neurons. These models have established the enabling technology for higher-level models to be developed. They are based on chemical and electrical activities in the neurons for which electrical equivalent circuits are generated. A simple model for the neuron with predominantly potassium ions inside the cell and sodium ions outside establishes an electric potential on the membrane under equilibrium, i.e., no external activity, condition. This is called the resting membrane potential, which can be determined by Nernst Equation (Nernst, W. (1888)). An equivalent electrical circuit for a patch of membrane, for example an axon or dendrite, is shown in Figure 5. E and E are the potentials associated with the potassium and sodium channels respectively and R and R are the resistances associated with them. C is the capacitance of the membrane and I is the source current, which could be the test source or the signal source (action potential). The resting potential for potassium-sodium channels in a neuron is about -65 millivolts. The membrane model is for a small section of the cell membrane; for larger sections it can be extended by adding similar sections, called compartments, with the parameter values being the same or different. The compartments are cascaded by a resistance, called axial resistance. Figure 6 shows a compartmental model of a neuron that is developed over the membrane model. Dendrites are the postsynaptic receptors receiving inputs from other neurons; and the axon with one or more axon terminals transmits neurotransmitters to other neurons. The second building block is the Hodgkin-Huxley (HH) model of the action potential. When the membrane potential from the dendrites exceeds the resting membrane potential, a pulse is generated by the neuron cell and propagated along the axon. This pulse is called the action potential and HH model is a set of equations that is made to fit the experimental data by the design of the model and the choice of the parameter values.",
            "score": 127.92083740234375
        }
    ]
}