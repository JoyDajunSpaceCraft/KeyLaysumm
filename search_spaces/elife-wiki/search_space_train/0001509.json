{
    "q": [
        {
            "docid": "5664_46",
            "document": "Consciousness . A number of studies have shown that activity in primary sensory areas of the brain is not sufficient to produce consciousness: it is possible for subjects to report a lack of awareness even when areas such as the primary visual cortex show clear electrical responses to a stimulus. Higher brain areas are seen as more promising, especially the prefrontal cortex, which is involved in a range of higher cognitive functions collectively known as executive functions. There is substantial evidence that a \"top-down\" flow of neural activity (i.e., activity propagating from the frontal cortex to sensory areas) is more predictive of conscious awareness than a \"bottom-up\" flow of activity. The prefrontal cortex is not the only candidate area, however: studies by Nikos Logothetis and his colleagues have shown, for example, that visually responsive neurons in parts of the temporal lobe reflect the visual perception in the situation when conflicting visual images are presented to different eyes (i.e., bistable percepts during binocular rivalry).",
            "score": 173.19164443016052
        },
        {
            "docid": "6082997_22",
            "document": "Filling-in . The neuronal activity in different brain areas can be recorded in humans through non-invasive techniques, like fMRI (functional magnetic resonance imaging). Perna \"et al.\" (2005) used fMRI to investigate the neuronal mechanisms responsible for the Craik\u2013O'Brien\u2013Cornsweet illusion. These authors recorded the activity in different brain areas when observers were presented with a Cornsweet visual stimulus, and compared the activities with those elicited by a similar image, which however did not elicit any brightness filling-in.",
            "score": 198.15231156349182
        },
        {
            "docid": "2920040_2",
            "document": "Neuronal tuning . Neuronal tuning refers to the hypothesized property of brain cells by which they selectively represent a particular type of sensory, association, motor, or cognitive information. Some neuronal responses have been hypothesized to be optimally tuned to specific patterns through experience. Neuronal tuning can be strong and sharp, as observed in primary visual cortex (area V1) (but see Carandini et al 2005 ), or weak and broad, as observed in neural ensembles. Single neurons are hypothesized to be simultaneously tuned to several modalities, such as visual, auditory, and olfactory. Neurons hypothesized to be tuned to different signals are often hypothesized to integrate information from the different sources. In computational models called neural networks, such integration is the major principle of operation. The best examples of neuronal tuning can be seen in the visual, auditory, olfactory, somatosensory, and memory systems, although due to the small number of stimuli tested the generality of neuronal tuning claims is still an open question.",
            "score": 136.04773044586182
        },
        {
            "docid": "226722_25",
            "document": "Functional magnetic resonance imaging . Researchers have checked the BOLD signal against both signals from implanted electrodes (mostly in monkeys) and signals of field potentials (that is the electric or magnetic field from the brain's activity, measured outside the skull) from EEG and MEG. The local field potential, which includes both post-neuron-synaptic activity and internal neuron processing, better predicts the BOLD signal. So the BOLD contrast reflects mainly the inputs to a neuron and the neuron's integrative processing within its body, and less the output firing of neurons. In humans, electrodes can be implanted only in patients who need surgery as treatment, but evidence suggests a similar relationship at least for the auditory cortex and the primary visual cortex. Activation locations detected by BOLD fMRI in cortical areas (brain surface regions) are known to tally with CBF-based functional maps from PET scans. Some regions just a few millimeters in size, such as the lateral geniculate nucleus (LGN) of the thalamus, which relays visual inputs from the retina to the visual cortex, have been shown to generate the BOLD signal correctly when presented with visual input. Nearby regions such as the pulvinar nucleus were not stimulated for this task, indicating millimeter resolution for the spatial extent of the BOLD response, at least in thalamic nuclei. In the rat brain, single-whisker touch has been shown to elicit BOLD signals from the somatosensory cortex.",
            "score": 158.87110900878906
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 147.98097908496857
        },
        {
            "docid": "2860430_39",
            "document": "Neural oscillation . The functional role of synchronized oscillatory activity in the brain was mainly established in experiments performed on awake kittens with multiple electrodes implanted in the visual cortex. These experiments showed that groups of spatially segregated neurons engage in synchronous oscillatory activity when activated by visual stimuli. The frequency of these oscillations was in the range of 40\u00a0Hz and differed from the periodic activation induced by the grating, suggesting that the oscillations and their synchronization were due to internal neuronal interactions. Similar findings were shown in parallel by the group of Eckhorn, providing further evidence for the functional role of neural synchronization in feature binding. Since then, numerous studies have replicated these findings and extended them to different modalities such as EEG, providing extensive evidence of the functional role of gamma oscillations in visual perception.",
            "score": 139.3834569454193
        },
        {
            "docid": "156940_17",
            "document": "Electrophysiology . An electrode introduced into the brain of a living animal will detect electrical activity that is generated by the neurons adjacent to the electrode tip. If the electrode is a microelectrode, with a tip size of about 1 micrometre, the electrode will usually detect the activity of at most one neuron. Recording in this way is in general called \"single-unit\" recording. The action potentials recorded are very much like the action potentials that are recorded intracellularly, but the signals are very much smaller (typically about 1 mV). Most recordings of the activity of single neurons in anesthetized and conscious animals are made in this way. Recordings of single neurons in living animals have provided important insights into how the brain processes information. For example, David Hubel and Torsten Wiesel recorded the activity of single neurons in the primary visual cortex of the anesthetized cat, and showed how single neurons in this area respond to very specific features of a visual stimulus. Hubel and Wiesel were awarded the Nobel Prize in Physiology or Medicine in 1981.",
            "score": 145.24653506278992
        },
        {
            "docid": "832632_5",
            "document": "David H. Hubel . The Hubel and Wiesel experiments greatly expanded the scientific knowledge of sensory processing. The partnership lasted over twenty years and became known as one of the most prominent research pairings in science. In one experiment, done in 1959, they inserted a microelectrode into the primary visual cortex of an anesthetized cat. They then projected patterns of light and dark on a screen in front of the cat. They found that some neurons fired rapidly when presented with lines at one angle, while others responded best to another angle. Some of these neurons responded to light patterns and dark patterns differently. Hubel and Wiesel called these neurons simple cells.\" Still other neurons, which they termed complex cells, detected edges regardless of where they were placed in the receptive field of the neuron and could preferentially detect motion in certain directions. These studies showed how the visual system constructs complex representations of visual information from simple stimulus features.",
            "score": 107.07343578338623
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 140.1967740058899
        },
        {
            "docid": "7725524_14",
            "document": "Colour centre . Functional magnetic resonance imaging, or fMRI for short, has been key in determining the colour selective regions in the visual cortex. fMRI is able to track brain activity by measuring blood flow throughout the brain. Areas that have more blood flowing to them indicates an occurrence of neuronal activity. This change in blood flow is called haemodynamic response. Among the benefits of fMRI includes dynamic, real-time mapping of cortical processes. However, fMRI cannot track the actual firing of neurons, which happen on a millisecond timescale, but it can track the haemodynamic response, which happens on a seconds timescale. This method is ideal for tracking colour selective neurons because colour perception results in a visual after-image that can be observed in the neurons, which lasts about 15 seconds.",
            "score": 165.137122631073
        },
        {
            "docid": "41121858_3",
            "document": "Binocular neurons . In the 19th century Charles Wheatstone determined that retinal disparity was a large contributor to depth perception. Using a stereoscope, he showed that horizontal disparity is used by the brain to calculate the relative depths of different objects in 3-dimensional space in reference to a fixed point. This process is called stereopsis. Two main classes of cells in visual cortex were identified by David H. Hubel and Torsten Wiesel in 1962 through their investigation of the cat's primary visual cortex. These classes were called simple and complex cells, which differ in how their receptive fields respond to light and dark stimuli. B\u00e9la Julesz in 1971 used random dot stereograms to find that monocular depth cues, such as shading, are not required for stereoscopic vision. Disparity selective cells were first recorded in the striate cortex (V1) of the cat by Peter Orlebar Bishop and John Douglas Pettigrew in the late 1960s, however this discovery was unexpected and was not published until 1986. These disparity selective cells, also known as binocular neurons, were again found in the awake behaving macaque monkey in 1985. Additionally, population responses of binocular neurons have been found in human ventral and dorsal pathways using fMRI.",
            "score": 147.34439504146576
        },
        {
            "docid": "2920040_3",
            "document": "Neuronal tuning . Accepted neuronal tuning models suggest that neurons respond to different degrees based on the similarity between the optimal stimulus of the neuron and the given stimulus. (Teller (1984), however, has challenged the \"detector\" view of neurons on logical grounds) The first major evidence of neuronal tuning in the visual system was provided by Hubel and Wiesel in 1959. They discovered that oriented slits of light were the most effective (of a very small set tested) stimuli for striate cortex \u201csimple cell\u201d neurons. Other neurons, \u201ccomplex cells,\" responded best to lines of a certain orientation moving in a specific direction. Overall, the V1 neurons were found to be selectively tuned to certain orientations, sizes, positions, and forms. Hubel and Wiesel won the Nobel Prize in Physiology or Medicine in 1981 for their discoveries concerning information processing in the visual system. (More recently, Carandini et al (2005) have pointed out that the distinction between \"simple\" and \"complex\" cells may not be a valid one, observing that \"simple and complex cells may not form a dichotomy at all.\" )",
            "score": 104.95451879501343
        },
        {
            "docid": "4231622_7",
            "document": "Inferior temporal gyrus . The information for color and form comes from P-cells that receive their information mainly from cones, so they are sensitive to differences in form and color, as opposed to the M-cells that receive information about motion mainly from rods. The neurons in the inferior temporal cortex, also called the inferior temporal visual association cortex, process this information from the P-cells.  The neurons in the ITC have several unique properties that offer an explanation as to why this area is essential in recognizing patterns. They only respond to visual stimuli and their receptive fields always include the fovea, which is one of the densest areas of the retina and is responsible for acute central vision. These receptive fields tend to be larger than those in the striate cortex and often extend across the midline to unite the two visual half fields for the first time. IT neurons are selective for shape and/or color of stimulus and are usually more responsive to complex shapes as opposed to simple ones. A small percentage of them are selective for specific parts of the face. Faces and likely other complex shapes are seemingly coded by a sequence of activity across a group of cells, and IT cells can display both short or long term memory for visual stimuli based on experience.",
            "score": 124.51249206066132
        },
        {
            "docid": "3883287_8",
            "document": "Tranquillity . Within tranquillity studies, much of the emphasis has been placed on understanding the role of vision in the perception of natural environments, which is probably not surprising, considering that upon first viewing a scene its configurational coherence can be established with incredible speed. Indeed, scene information can be captured in a single glance and the gist of a scene determined in as little as 100ms. The speed of processing of complex natural images was tested by Thorpe \"et al.\" using colour photographs of a wide range of animals (mammals, birds, reptiles and fish), in their natural environments, mixed with distracters that included pictures of forests, mountains, lakes, buildings and fruit. During this experiment, subjects were shown an image for 20ms and asked to determine whether it contained an animal or not. The electrophysiological brain responses obtained in this study showed that a decision could be made within 150ms of the image being seen, indicating the speed at which cognitive visual processing occurs. However, audition, and in particular the individual components that collectively comprise the soundscape, a term coined by Schafer to describe the ever-present array of sounds that constitute the sonic environment, also significantly inform the various schemata used to characterise differing landscape types. This interpretation is supported by the auditory reaction times, which are 50 to 60ms faster than that of the visual modality. It is also known that sound can alter visual perception and that under certain conditions areas of the brain involved in processing auditory information can be activated in response to visual stimuli.  Research conducted by Pheasant \"et al.\" has shown that when individuals make tranquillity assessments based on a uni-modal auditory or visual sensory input, they characterise the environment by drawing upon a number of key landscape and soundscape characteristics. For example, when making assessments in response to visual-only stimuli the percentage of water, flora and geological features present within a scene, positively influence how tranquil a location is perceived to be. Likewise when responding to uni-modal auditory stimuli, the perceived loudness of biological sounds positively influences the perception of tranquillity, whilst the perceived loudness of mechanical sounds have a negative effect. However, when presented with bi-modal auditory-visual stimuli the individual soundscape and landscape components alone no longer influenced the perception of tranquillity. Rather configurational coherence was provided by the percentage of natural and contextual features present within the scene and the equivalent continuous sound pressure level (LAeq).",
            "score": 161.50333678722382
        },
        {
            "docid": "739262_12",
            "document": "Neural correlate . Using such design, Nikos Logothetis and colleagues discovered perception-reflecting neurons in the temporal lobe. They created an experimental situation in which conflicting images were presented to different eyes (\"i.e.\", binocular rivalry). Under such conditions, human subjects report bistable percepts: they perceive alternatively one or the other image. Logothetis and colleagues trained the monkeys to report with their arm movements which image they perceived. Interestingly, temporal lobe neurons in Logothetis experiments often reflected what the monkeys' perceived. Neurons with such properties were less frequently observed in the primary visual cortex that corresponds to relatively early stages of visual processing. Another set of experiments using binocular rivalry in humans showed that certain layers of the cortex can be excluded as candidates of the neural correlate of consciousness. Logothetis and colleagues switched the images between eyes during the percept of one of the images. Surprisingly the percept stayed stable. This means that the conscious percept stayed stable and at the same time the primary input to layer 4, which is the input layer, in the visual cortex changed. Therefore layer 4 can not be a part of the neural correlate of consciousness. Mikhail Lebedev and their colleagues observed a similar phenomenon in monkey prefrontal cortex. In their experiments monkeys reported the perceived direction of visual stimulus movement (which could be an illusion) by making eye movements. Some prefrontal cortex neurons represented actual and some represented perceived displacements of the stimulus. Observation of perception related neurons in prefrontal cortex is consistent with the theory of Christof Koch and Francis Crick who postulated that neural correlate of consciousness resides in prefrontal cortex. Proponents of distributed neuronal processing may likely dispute the view that consciousness has a precise localization in the brain.",
            "score": 172.82226705551147
        },
        {
            "docid": "525667_10",
            "document": "Human echolocation . In a 2014 study by Thaler and colleagues, the researchers first made recordings of the clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, not only did they perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. The brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any auditory area, becomes involved in the computation of echolocation tasks.",
            "score": 176.70340490341187
        },
        {
            "docid": "569399_8",
            "document": "Stimulus (physiology) . Vision provides opportunity for the brain to perceive and respond to changes occurring around the body. Information, or stimuli, in the form of light enters the retina, where it excites a special type of neuron called a photoreceptor cell. A local graded potential begins in the photoreceptor, where it excites the cell enough for the impulse to be passed along through a track of neurons to the central nervous system. As the signal travels from photoreceptors to larger neurons, action potentials must be created for the signal to have enough strength to reach the CNS. If the stimulus does not warrant a strong enough response, it is said to not reach absolute threshold, and the body does not react. However, if the stimulus is strong enough to create an action potential in neurons away from the photoreceptor, the body will integrate the information and react appropriately. Visual information is processed in the occipital lobe of the CNS, specifically in the primary visual cortex.",
            "score": 134.68676328659058
        },
        {
            "docid": "6989597_24",
            "document": "Premovement neuronal activity . Premovement neuronal activity has been widely experimented upon in three major motor fields of the frontal cortex. The goal of this experimentation is to compare the neuronal activity which comes from visual signals, versus neuronal activity which comes from non-triggered or self-paced movements. From this comparison, two changes were identified, occurring at different time scales in relation to the onset of movement. These changes are the short lead and long lead changes. The short lead changes are observed about 480ms before the movement, whereas the long lead changes occur about 1\u20132 seconds earlier. The short lead changes are exhibited in the SMA (supplementary motor area) and the PM (pre-motor area) during both the visual signal trials and the non-triggered/self-paced trials. The pre-central motor cortex was also identified in this study as having similar neuronal activities as in the PM and SMA. Experimentation found that approximately 61% of the neurons in the PM were preferentially related to the triggered (visual) movements. The long lead neuronal changes were more frequently active during the self paced stimuli than before the triggered movements. These long lead changes are particularly abundant among the SMA neurons. In summation, these experiments challenged the idea that the SMA primarily takes part in self-paced movements and the PM is only involved in visually triggered movements. Although the PM neurons showed more preference for the visual trigger signals and the SMA neurons are intimately related to initiation of self paced movements, both are involved with premovement for both types of stimuli.",
            "score": 120.72708654403687
        },
        {
            "docid": "25935238_9",
            "document": "Educational neuroscience . Almost all of the neurons in the brain are generated before birth, during the first three months of pregnancy, and the newborn child\u2019s brain has a similar number of neurons to that of an adult. Many more neurons form than are needed, and only those that form active connections with other neurons survive. In the first year after birth the infant brain undergoes an intense phase of development, during which excessive numbers of connections between neurons are formed, and many of these excess connections must be cut back through the process of synaptic pruning that follows. This pruning process is just as important a stage of development as the early rapid growth of connections between brain cells. The process during which large numbers of connections between neurons are formed is called synaptogenesis. For vision and hearing (visual and auditory cortex), there is extensive early synaptogenesis. The density of connections peaks at around 150% of adult levels between four and 12 months, and the connections are then extensively pruned. Synaptic density returns to adult levels between two and four years in the visual cortex. For other areas such as prefrontal cortex (thought to underpin planning and reasoning), density increases more slowly and peaks after the first year. Reduction to adult levels of density takes at least another 10\u201320 years; hence there is significant brain development in the frontal areas even in adolescence. Brain metabolism (glucose uptake, which is an approximate index of synaptic functioning) is also above adult levels in the early years. Glucose uptake peaks at about 150% of adult levels somewhere around four to five years. By the age of around ten years, brain metabolism has reduced to adult levels for most cortical regions. Brain development consists of bursts of synaptogenesis, peaks of density, and then synapse rearrangement and stabilisation. This occurs at different times and different rates for different brain regions, which implies that there may be different sensitive periods for the development of different types of knowledge. Neuroscience research into early brain development has informed government education policy for children under three years old in many countries including the USA and the United Kingdom. These policies have focused on enriching the environment of children during nursery and preschool years, exposing them to stimuli and experiences thought to maximise the learning potential of the young brain.",
            "score": 141.17127287387848
        },
        {
            "docid": "33246145_4",
            "document": "Neural decoding . When looking at a picture, people's brains are constantly making decisions about what object they are looking at, where they need to move their eyes next, and what they find to be the most salient aspects of the input stimulus. As these images hit the back of the retina, these stimuli are converted from varying wavelengths to a series of neural spikes called action potentials. These pattern of action potentials are different for different objects and different colors; we therefore say that the neurons are encoding objects and colors by varying their spike rates or temporal pattern. Now, if someone were to probe the brain by placing electrodes in the primary visual cortex, they may find what appears to be random electrical activity. These neurons are actually firing in response to the lower level features of visual input, possibly the edges of a picture frame. This highlights the crux of the neural decoding hypothesis: that it is possible to reconstruct a stimulus from the response of the ensemble of neurons that represent it. In other words, it is possible to look at spike train data and say that the person or animal being recorded is looking at a red ball.",
            "score": 165.86058855056763
        },
        {
            "docid": "5198024_22",
            "document": "Efficient coding hypothesis . Observed redundancy: A comparison of the number of retinal ganglion cells to the number of neurons in the primary visual cortex shows an increase in the number of sensory neurons in the cortex as compared to the retina. Simoncelli notes that one major argument of critics in that higher up in the sensory pathway there are greater numbers of neurons that handle the processing of sensory information so this should seem to produce redundancy. However, this observation may not be fully relevant because neurons have different neural coding. In his review, Simoncelli notes \"cortical neurons tend to have lower firing rates and may use a different form of code as compared to retinal neurons\". Cortical Neurons may also have the ability to encode information over longer periods of time than their retinal counterparts. Experiments done in the auditory system have confirmed that redundancy is decreased.",
            "score": 91.91443490982056
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 165.34123623371124
        },
        {
            "docid": "2664501_4",
            "document": "Microsaccade . Experiments in neurophysiology from different laboratories showed that fixational eye movements, particularly microsaccades, strongly modulate the activity of neurons in the visual areas of the macaque brain. In the lateral geniculate nucleus (LGN) and the primary visual cortex (V1), microsaccades can move a stationary stimulus in and out of a neuron's receptive field, thereby producing transient neural responses. Microsaccades might account for much of the response variability of neurons in visual area V1 of the awake monkey.",
            "score": 134.48120498657227
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 128.90027046203613
        },
        {
            "docid": "50732180_6",
            "document": "The Role of Serotonin in Visual Orientation Processing . Recent research investigating MDMA has revealed the neurotoxic effect of the drug on brain serotonin neurons. Long term and potentially permanent changes to serotonergic axons have been noted in animal and primate studies where they were administered doses of MDMA similar to those taken by some human users. MDMA has subsequently been used to investigate the role that serotonin may play in visual orientation processing. Serotonin neurons are thought to reside in the occipital lobe, which is an area of the brain responsible for visual processing of line orientation, edges, motion and stereoscopic depth perception. Because MDMA is known to affect serotonin and that serotonin is thought to be involved in vision, individuals who take MDMA may exhibit differences in their visual orientation processing.",
            "score": 136.87127816677094
        },
        {
            "docid": "599917_34",
            "document": "Mental image . Recent studies have found that individual differences in VVIQ scores can be used to predict changes in a person's brain while visualizing different activities. Functional magnetic resonance imaging (fMRI) was used to study the association between early visual cortex activity relative to the whole brain while participants visualized themselves or another person bench pressing or stair climbing. Reported image vividness correlates significantly with the relative fMRI signal in the visual cortex. Thus, individual differences in the vividness of visual imagery can be measured objectively.",
            "score": 139.23126482963562
        },
        {
            "docid": "297924_23",
            "document": "Mantis shrimp . Research also shows their visual experience of colours is not very different from humans'. The eyes are actually a mechanism that operates at the level of individual cones and makes the brain more efficient. This system allows visual information to be preprocessed by the eyes instead of the brain, which would otherwise have to be larger to deal with the stream of raw data and thus require more time and energy. While the eyes themselves are complex and not yet fully understood, the principle of the system appears to be simple. It is similar in function to the human eye but works in the opposite manner. In the human brain, the inferior temporal cortex has a huge amount of colour-specific neurons which process visual impulses from the eyes to create colourful experiences. The mantis shrimp instead uses the different types of photoreceptors in its eyes to perform the same function as the human brain neurons, resulting in a hardwired and more efficient system for an animal that requires rapid colour identification. Humans have fewer types of photoreceptors, but more colour-tuned neurons, while mantis shrimps appears to have fewer colour neurons and more classes of photoreceptors.",
            "score": 136.29167878627777
        },
        {
            "docid": "2860457_6",
            "document": "Neural ensemble . Neuronal ensembles encode information in a way somewhat similar to the principle of Wikipedia operation \u2013 multiple edits by many participants. Neuroscientists have discovered that individual neurons are very noisy. For example, by examining the activity of only a single neuron in the visual cortex, it is very difficult to reconstruct the visual scene that the owner of the brain is looking at. Like a single Wikipedia participant, an individual neuron does not 'know' everything and is likely to make mistakes. This problem is solved by the brain having billions of neurons. Information processing by the brain is population processing, and it is also distributed \u2013 in many cases each neuron knows a little bit about everything, and the more neurons participate in a job, the more precise the information encoding. In the distributed processing scheme, individual neurons may exhibit neuronal noise, but the population as a whole averages this noise out.",
            "score": 160.01049149036407
        },
        {
            "docid": "803249_7",
            "document": "Torsten Wiesel . The Hubel and Wiesel experiments greatly expanded the scientific knowledge of sensory processing. In one experiment, done in 1959, they inserted a microelectrode into the primary visual cortex of an anesthetized cat. They then projected patterns of light and dark on a screen in front of the cat. They found that some neurons fired rapidly when presented with lines at one angle, while others responded best to another angle. They called these neurons \"simple cells.\" Still other neurons, which they termed \"complex cells,\" responded best to lines of a certain angle moving in one direction. These studies showed how the visual system builds an image from simple stimuli into more complex representations.",
            "score": 97.8052875995636
        },
        {
            "docid": "2676126_6",
            "document": "Retinotopy . In many locations within the brain, adjacent neurons have receptive fields that include slightly different, but overlapping portions of the visual field. The position of the center of these receptive fields forms an orderly sampling mosaic that covers a portion of the visual field. Because of this orderly arrangement, which emerges from the spatial specificity of connections between neurons in different parts of the visual system, cells in each structure can be seen as contributing to a map of the visual field (also called a retinotopic map, or a visuotopic map). Retinotopic maps are a particular case of topographic organization. Many brain structures that are responsive to visual input, including much of the visual cortex and visual nuclei of the brain stem (such as the superior colliculus) and thalamus (such as the lateral geniculate nucleus and the pulvinar), are organized into retinotopic maps, also called visual field maps.",
            "score": 131.91636645793915
        },
        {
            "docid": "6147487_30",
            "document": "Neural coding . To account for the fast encoding of visual stimuli, it has been suggested that neurons of the retina encode visual information in the latency time between stimulus onset and first action potential, also called latency to first spike. This type of temporal coding has been shown also in the auditory and somato-sensory system. The main drawback of such a coding scheme is its sensitivity to intrinsic neuronal fluctuations. In the primary visual cortex of macaques, the timing of the first spike relative to the start of the stimulus was found to provide more information than the interval between spikes. However, the interspike interval could be used to encode additional information, which is especially important when the spike rate reaches its limit, as in high-contrast situations. For this reason, temporal coding may play a part in coding defined edges rather than gradual transitions.",
            "score": 76.50183498859406
        },
        {
            "docid": "32528_6",
            "document": "Visual cortex . Neurons in the visual cortex fire action potentials when visual stimuli appear within their receptive field. By definition, the receptive field is the region within the entire visual field that elicits an action potential. But, for any given neuron, it may respond best to a subset of stimuli within its receptive field. This property is called \"neuronal tuning\". In the earlier visual areas, neurons have simpler tuning. For example, a neuron in V1 may fire to any vertical stimulus in its receptive field. In the higher visual areas, neurons have complex tuning. For example, in the inferior temporal cortex (IT), a neuron may fire only when a certain face appears in its receptive field.",
            "score": 94.13435816764832
        }
    ],
    "r": [
        {
            "docid": "2872287_23",
            "document": "Neural binding . Much of the experimental evidence for neural binding has traditionally revolved around sensory awareness. Sensory awareness is accomplished by integrating things together by cognitively perceiving them and then segmenting them so that, in total, there is an image created. Since there can be an infinite number of possibilities in the perception of an object, this has been a unique area of study. The way the brain then collectively pieces certain things together via networking is important not only in the global way of perceiving but also in segmentation. Much of sensory awareness has to do with the taking of a single piece of an object's makeup and then binding its total characteristics so that the brain perceives the object in its final form. Much of the research for the understanding of segmentation and how the brain perceives an object has been done by studying cats. A major finding of this research has to do with the understanding of gamma waves oscillating at 40\u00a0Hz. The information was extracted from a study using the cat visual cortex. It was shown that the cortical neurons responded differently to spatially different objects. These firings of neurons ranged from 40\u201360\u00a0Hz in measure and when observed showed that they fired synchronously when observing different parts of the object. Such coherent responses point to the fact that the brain is doing a kind of coding where it is piecing certain neurons together in the works of making the form of an object. Since the brain is putting these segmented pieces together unsupervised, a significant consonance is found with many philosophers (like Sigmund Freud) who theorize an underlying subconscious that helps to form every aspect of our conscious thought processes.",
            "score": 199.9109344482422
        },
        {
            "docid": "6082997_22",
            "document": "Filling-in . The neuronal activity in different brain areas can be recorded in humans through non-invasive techniques, like fMRI (functional magnetic resonance imaging). Perna \"et al.\" (2005) used fMRI to investigate the neuronal mechanisms responsible for the Craik\u2013O'Brien\u2013Cornsweet illusion. These authors recorded the activity in different brain areas when observers were presented with a Cornsweet visual stimulus, and compared the activities with those elicited by a similar image, which however did not elicit any brightness filling-in.",
            "score": 198.15231323242188
        },
        {
            "docid": "51848234_2",
            "document": "Anion-conducting channelrhodopsin . Anion-conducting channelrhodopsins are light-gated ion channels that open in response to light and let negatively charged ions (such as chloride) enter a cell. All channelrhodopsins use retinal as light-sensitive pigment, but they differ in their ion selectivity. Anion-conducting channelrhodopsins are used as tools to manipulate brain activity in mice and fruit flies (Optogenetics). Neurons expressing anion-conducting channelrhodopsins are silenced when illuminated with light, an effect that has been used to investigate information processing in the brain. For example, suppressing dendritic calcium spikes in specific neurons with light reduced the ability of mice to perceive a light touch to a whisker. Studying how the behavior of an animal changes when specific neurons are silenced allows scientists to determine the role of these neurons in the complex circuits controlling behavior.",
            "score": 188.8225555419922
        },
        {
            "docid": "569650_4",
            "document": "Stimulus modality . Integration of all sensory modalities occurs when multimodal neurons receive sensory information which overlaps with different modalities. Multimodal neurons are found in the superior colliculus; they respond to the versatility of various sensory inputs. The multimodal neurons lead to change of behavior and assist in analyzing behavior responses to certain stimulus. Information from two or more senses is encountered. Multimodal perception is not limited to one area of the brain: many brain regions are activated when sensory information is perceived from the environment. In fact, the hypothesis of having a centralized multisensory region is receiving continually more speculation, as several regions previously uninvestigated are now considered multimodal. The reasons behind this are currently being investigated by several research groups, but it is now understood to approach these issues from a decentralized theoretical perspective. Moreover, several labs using invertebrate model organisms will provide invaluable information to the community as these are more easily studied and are considered to have decentralized nervous systems.",
            "score": 184.32540893554688
        },
        {
            "docid": "1903855_7",
            "document": "Sensory substitution . In a regular visual system, the data collected by the retina is converted into an electrical stimulus in the optic nerve and relayed to the brain, which re-creates the image and perceives it. Because it is the brain that is responsible for the final perception, sensory substitution is possible. During sensory substitution an intact sensory modality relays information to the visual perception areas of the brain so that the person can perceive to see. With sensory substitution, information gained from one sensory modality can reach brain structures physiologically related to other sensory modalities. Touch-to-visual sensory substitution transfers information from touch receptors to the visual cortex for interpretation and perception. For example, through fMRI, we can determine which parts of the brain are activated during sensory perception. In blind persons, we can see that while they are only receiving tactile information, their visual cortex is also activated as they perceive to \"see\" objects. We can also have touch to touch sensory substitution where information from touch receptors of one region can be used to perceive touch in another region. For example, in one experiment by Bach-y-Rita, he was able to restore the touch perception in a patient who lost peripheral sensation from leprosy.",
            "score": 181.8072967529297
        },
        {
            "docid": "525667_10",
            "document": "Human echolocation . In a 2014 study by Thaler and colleagues, the researchers first made recordings of the clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, not only did they perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. The brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any auditory area, becomes involved in the computation of echolocation tasks.",
            "score": 176.70339965820312
        },
        {
            "docid": "5664_46",
            "document": "Consciousness . A number of studies have shown that activity in primary sensory areas of the brain is not sufficient to produce consciousness: it is possible for subjects to report a lack of awareness even when areas such as the primary visual cortex show clear electrical responses to a stimulus. Higher brain areas are seen as more promising, especially the prefrontal cortex, which is involved in a range of higher cognitive functions collectively known as executive functions. There is substantial evidence that a \"top-down\" flow of neural activity (i.e., activity propagating from the frontal cortex to sensory areas) is more predictive of conscious awareness than a \"bottom-up\" flow of activity. The prefrontal cortex is not the only candidate area, however: studies by Nikos Logothetis and his colleagues have shown, for example, that visually responsive neurons in parts of the temporal lobe reflect the visual perception in the situation when conflicting visual images are presented to different eyes (i.e., bistable percepts during binocular rivalry).",
            "score": 173.191650390625
        },
        {
            "docid": "739262_12",
            "document": "Neural correlate . Using such design, Nikos Logothetis and colleagues discovered perception-reflecting neurons in the temporal lobe. They created an experimental situation in which conflicting images were presented to different eyes (\"i.e.\", binocular rivalry). Under such conditions, human subjects report bistable percepts: they perceive alternatively one or the other image. Logothetis and colleagues trained the monkeys to report with their arm movements which image they perceived. Interestingly, temporal lobe neurons in Logothetis experiments often reflected what the monkeys' perceived. Neurons with such properties were less frequently observed in the primary visual cortex that corresponds to relatively early stages of visual processing. Another set of experiments using binocular rivalry in humans showed that certain layers of the cortex can be excluded as candidates of the neural correlate of consciousness. Logothetis and colleagues switched the images between eyes during the percept of one of the images. Surprisingly the percept stayed stable. This means that the conscious percept stayed stable and at the same time the primary input to layer 4, which is the input layer, in the visual cortex changed. Therefore layer 4 can not be a part of the neural correlate of consciousness. Mikhail Lebedev and their colleagues observed a similar phenomenon in monkey prefrontal cortex. In their experiments monkeys reported the perceived direction of visual stimulus movement (which could be an illusion) by making eye movements. Some prefrontal cortex neurons represented actual and some represented perceived displacements of the stimulus. Observation of perception related neurons in prefrontal cortex is consistent with the theory of Christof Koch and Francis Crick who postulated that neural correlate of consciousness resides in prefrontal cortex. Proponents of distributed neuronal processing may likely dispute the view that consciousness has a precise localization in the brain.",
            "score": 172.822265625
        },
        {
            "docid": "971305_18",
            "document": "Haemodynamic response . Functional magnetic resonance imaging (fMRI), is the medical imaging technique used to measure the haemodynamic response of the brain in relation to the neural activities. It is one of the most commonly used devices to measure brain functions and is relatively inexpensive to perform in a clinical setting. The onset of neural activity leads to a systematic series of physiological changes in the local network of blood vessels that include changes in the cerebral blood volume per unit of brain tissue (CBV), changes in the rate of cerebral blood flow, and changes in the concentration of oxyhemoglobin and deoxyhemoglobin. There are different fMRI techniques that can pick up a functional signal corresponding to changes in each of the previously mentioned components of the haemodynamic response. The most common functional imaging signal is the Blood Oxygenation Level Dependent signal (BOLD), which primarily corresponds to the concentration of deoxyhemoglobin The BOLD effect is based on the fact that when neuronal activity is increased in one part of the brain, there is also an increased amount of cerebral blood flow to that area which is the basis of haemodynamic response. This increase in blood flow produces an increase in the ratio of oxygenated hemoglobin relative to deoxygenated hemoglobin in that specific area. The difference in magnetic properties of oxygenated and deoxygenated hemoglobin is what allows fMRI imaging to produce an effective map of which neurons are active and which are not. In short, deoxygenated hemoglobin is paramagnetic while oxygenated hemoglobin is diamagnetic. Diamagnetic blood (oxyhemoglobin) interferes with the magnetic resonance (MR) signal less and this leads to an improved MR signal in that area of increased neuronal activity. However, Paramagnetic blood (deoxyhemoglobin) makes the local magnetic field inhomogenous. This has the effect of dephasing the signal emitted in this domain, causing destructive interference in the observed MR signal. Therefore, greater amounts of deoxyhemoglobin lead to less signal. Neuronal activity ultimately leads to an increase in local MR signaling corresponding to a decrease in the concentration of deoxyhemoglobin.",
            "score": 172.45237731933594
        },
        {
            "docid": "987320_19",
            "document": "Neurotechnology . Magnetic resonance imaging is a vital tool in neurological research in showing activation in the brain as well as providing a comprehensive image of the brain being studied. While MRIs are used clinically for showing brain size, it still has relevance in the study of brains because it can be used to determine extent of injuries or deformation. These can have a significant effect on personality, sense perception, memory, higher order thinking, movement, and spatial understanding. However, current research tends to focus more so on fMRI or real-time functional MRI (rtfMRI). These two methods allow the scientist or the participant, respectively, to view activation in the brain. This is incredibly vital in understanding how a person thinks and how their brain reacts to a person's environment, as well as understanding how the brain works under various stressors or dysfunctions. Real-time functional MRI is a revolutionary tool available to neurologists and neuroscientists because patients can see how their brain reacts to stressors and can perceive visual feedback. CT scans are very similar to MRI in their academic use because they can be used to image the brain upon injury, but they are more limited in perceptual feedback. CTs are generally used in clinical studies far more than in academic studies, and are found far more often in a hospital than a research facility. PET scans are also finding more relevance in academia because they can be used to observe metabolic uptake of neurons, giving researchers a wider perspective about neural activity in the brain for a given condition. Combinations of these methods can provide researchers with knowledge of both physiological and metabolic behaviors of loci in the brain and can be used to explain activation and deactivation of parts of the brain under specific conditions.",
            "score": 169.85543823242188
        },
        {
            "docid": "32018467_7",
            "document": "Christian Keysers . After finishing his master, Christian Keysers decided to concentrate on a subfield of cognitive neuroscience called social neuroscience that uses neuroscience methods to understand how we process the social world. He therefore performed his doctoral studies at the University of St Andrews with David Ian Perrett, one of the founding father of the field, to understand how the brain processes faces and facial expressions. This thesis work led to new insights into how quickly the brain can process the faces of others. During this period, Keysers became fascinated with the question of how the brain can attach meaning to the faces of others. How is it for instance, that we understand that a certain grimace would signal that another person is happy? How do we understand that a certain bodily movement towards a glass indicates that the other person aims to grasp a glass? In 1999, Keysers was exposed to a visit of Vittorio Gallese, who presented his recent discovery of mirror neurons in the Psychology department lecture series. This deeply influenced Keysers who decided to move to the lab of Giacomo Rizzolatti to undertake further studies on how these fascinating neurons could contribute to social perception. In 2000, after finishing his doctorate, Christian Keysers moved to the University of Parma to study mirror neurons. In early work there demonstrated that mirror neurons in the premotor cortex not only respond to the sight of actions, but also when actions can only be deduced or heard, leading to a publication in the journal \"Science\". This work had tremendous impact on the field, as it suggested that the premotor cortex could play a central, modality independent role in perception and may lay the origin for the evolution of speech in humans.  Together this work indicated that brain regions involved in our own actions play a role in how we process the actions of others. Keysers wondered whether a similar principle may underlie how we process the tactile sensations and emotions of others, and became increasingly independent of the research focus on the motor system in Parma. At the time, Keysers had also met his to be wife, Valeria Gazzola, a biologist in the final phases of her studies, and together they decided to explore if the somatosensory system might be involved in perceiving the sensations of others. Via a fruitful collaboration with the French neuroimaging specialist Bruno Wicker, they used functional magnetic resonance imaging, and showed for the first time, that the secondary somatosensory cortex, previously thought only to represent a persons own experiences of touch, is also activated when seeing someone or something else be touched. They also showed that the insula, thought only to respond to the experience of first-hand emotions, was also activated when we see another individual experience similar emotions. Together this indicated a much more general principle than the original mirror neuron theory, in which people process the actions, sensations and emotions of others by vicariously activating owns own actions, sensations and emotions. Jointly, this work laid the foundation of the neuroscientific investigation of empathy.",
            "score": 168.7885284423828
        },
        {
            "docid": "1316947_4",
            "document": "Ambiguous image . When we see an image, the first thing we do is attempt to organize all the parts of the scene into different groups. To do this, one of the most basic methods used is finding the edges. Edges can include obvious perceptions such as the edge of a house, and can include other perceptions that the brain needs to process deeper, such as the edges of a person's facial features. When finding edges, the brain's visual system detects a point on the image with a sharp contrast of lighting. Being able to detect the location of the edge of an object aids in recognizing the object. In ambiguous images, detecting edges still seems natural to the person perceiving the image. However, the brain undergoes deeper processing to resolve the ambiguity. For example, consider an image that involves an opposite change in magnitude of luminance between the object and the background (e.g. From the top, the background shifts from black to white, and the object shifts from white to black). The opposing gradients will eventually come to a point where there is an equal degree of luminance of the object and the background. At this point, there is no edge to be perceived. To counter this, the visual system connects the image as a whole rather than a set of edges, allowing one to see an object rather than edges and non-edges. Although there is no complete image to be seen, the brain is able to accomplish this because of its understanding of the physical world and real incidents of ambiguous lighting. In ambiguous images, an illusion is often produced from illusory contours. An illusory contour is a perceived contour without the presence of a physical gradient. In examples where a white shape appears to occlude black objects on a white background, the white shape appears to be brighter than the background, and the edges of this shape produce the illusory contours. These illusory contours are processed by the brain in a similar way as real contours. The visual system accomplishes this by making inferences beyond the information that is presented in much the same way as the luminance gradient.",
            "score": 167.71261596679688
        },
        {
            "docid": "15559385_11",
            "document": "Tactile discrimination . When a person has become blind, in order to \u201csee\u201d the world, their other senses become heightened. An important sense for the blind is their sense of touch, which becomes more frequently used to help them perceive the world. People that are blind have displayed that their visual cortices become more responsive to auditory and tactile stimulation. Braille allows the blind to be able to use their sense of touch to feel the roughness, and distance of various patterns to be used as a form of language. Within the brain, the activation of the occipital cortex is functionally relevant for tactile braille reading, as well as the somatosensory cortex. These various parts of the brain function in their own way, in which they each contribute to the effectiveness of how braille is read by the blind. People that are blind also rely heavily on Tactile Gnosis, Spatial discrimination, Graphesthesia, and Two-point discrimination. Essentially, the occipital cortex allows one to effectively make judgements on the distance of braille patterns, which is related to spatial discrimination. Meanwhile, the somatosensory cortex allows one to effectively make judgements on the roughness of braille patterns, which is related to two-point discrimination. The various visual areas in the brain are very essential for a blind person to read braille, just as much as it is for a person that has sight. Essentially, whether one is blind or not, the perception of objects that involves tactile discrimination is not impaired if one cannot see. When comparing people that are blind to people that have sight, the amount of activity within the their somatosensory and visual areas of the brain do differ. The activity in the somatosensory and visual areas are not as high in tactile gnosis for people that are not blind, and are more-so active for more visual related stimuli that does not involve touch. Nonetheless, there is a difference in these various areas within the brain when comparing the blind to the sighted, which is that shape discrimination causes a difference in brain activity, as well as tactile gnosis. The visual cortices of blind individuals are active during various vision related tasks including tactile discrimination, and the function of the cortices resemble the activity of adults with sight.",
            "score": 166.77041625976562
        },
        {
            "docid": "33702464_5",
            "document": "Extrastriate body area . The experiment had subjects view images of different objects, including faces (as a control group), body parts, animals, parts of the face and intimate objects. While viewing the images, the subjects were scanned with an fMRI to see what area of the brain was activated. Through the trials a compilation of the fMRI\u2019s was made. From this compilation image a specific region was determined to have increased activity when shown visual stimuli of body parts and even more activity when viewing whole bodies. There have been no studies involving brain damage to the EBA. Thus far, only scans of brain activity, as well as transcranial magnetic stimulation, have been used to study the EBA. To find the specific functions of the EBA, Comimo Urgesi, Giovanni Berlucchi and Salvatore M. Aglioti used repetitive transcranial magnetic stimulation (rTMS) to disrupt part of the brain, making the brain less responsive in the target area. The study used event-related rTMS to disrupt the EBA, resulting in inactivation of cortical areas. This inactivation caused a slower response time in discriminating body parts. The study used facial features and motorcycle parts as non human parts for control groups. The facial features and motorcycle body parts did not display any change in response time. The neural activity data shows the EBA handles some of the visual processing of human body and parts but is not related to the processing of the face or other objects.",
            "score": 166.67471313476562
        },
        {
            "docid": "907554_25",
            "document": "History of neuroimaging . It is interesting to see how advances are split between those seeking a completely mapped brain by utilizing single neuron imaging and those utilizing images of brains as subjects perform various high-level tasks. Single neuron imaging (SNI) uses a combination of genetic engineering and optical imaging techniques to insert tiny electrodes into the brain for the purpose of measuring a single neuron's firing. Due to its damaging repercussions, this technique has only been used on animals, but it has shed a lot of light on basic emotional and motivational processes. The goal of studies in higher-level activities is to determine how a network of brain areas collaborates to perform each task. This higher-level imaging is much easier to do because researchers can easily use subjects who have a disease such as Alzheimer's. The SNI technology seems to be going after the possibility for AI while the network-probing technology seems to be more for medical purposes.",
            "score": 166.00625610351562
        },
        {
            "docid": "33246145_4",
            "document": "Neural decoding . When looking at a picture, people's brains are constantly making decisions about what object they are looking at, where they need to move their eyes next, and what they find to be the most salient aspects of the input stimulus. As these images hit the back of the retina, these stimuli are converted from varying wavelengths to a series of neural spikes called action potentials. These pattern of action potentials are different for different objects and different colors; we therefore say that the neurons are encoding objects and colors by varying their spike rates or temporal pattern. Now, if someone were to probe the brain by placing electrodes in the primary visual cortex, they may find what appears to be random electrical activity. These neurons are actually firing in response to the lower level features of visual input, possibly the edges of a picture frame. This highlights the crux of the neural decoding hypothesis: that it is possible to reconstruct a stimulus from the response of the ensemble of neurons that represent it. In other words, it is possible to look at spike train data and say that the person or animal being recorded is looking at a red ball.",
            "score": 165.86058044433594
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 165.3412322998047
        },
        {
            "docid": "7725524_14",
            "document": "Colour centre . Functional magnetic resonance imaging, or fMRI for short, has been key in determining the colour selective regions in the visual cortex. fMRI is able to track brain activity by measuring blood flow throughout the brain. Areas that have more blood flowing to them indicates an occurrence of neuronal activity. This change in blood flow is called haemodynamic response. Among the benefits of fMRI includes dynamic, real-time mapping of cortical processes. However, fMRI cannot track the actual firing of neurons, which happen on a millisecond timescale, but it can track the haemodynamic response, which happens on a seconds timescale. This method is ideal for tracking colour selective neurons because colour perception results in a visual after-image that can be observed in the neurons, which lasts about 15 seconds.",
            "score": 165.13711547851562
        },
        {
            "docid": "40618504_19",
            "document": "Memory erasure . With evidence showing that different memories excite different neurons or system of neurons in the brain the technique of destroying select neurons in the brain to erase specific memories is also being researched. Studies have started to investigate the possibility of using distinct toxins along with biotechnology that allows the researchers to see which areas of the brain are being used during the reward learning process of making a memory to destroy target neurons. In a paper published in 2009, authors showed that neurons in the lateral amygdala that had a higher level of cyclic adenosine monophosphate response element-binding protein (CREB) were activated primarily over other neurons by fear memory expression. This indicated to them that these neurons were directly involved in the making of the memory trace for that fear memory. They then proceeded to train mice using auditory fear training to produce a fear memory. They proceeded to check which of the neurons were overexpressing CREB and then, using a inducible diphtheria-toxin strategy, they destroyed those neurons, resulting in persistent and strong memory erasure of the fear memory.",
            "score": 164.10128784179688
        },
        {
            "docid": "3717_68",
            "document": "Brain . One of the most influential early contributions was a 1959 paper titled \"What the frog's eye tells the frog's brain\": the paper examined the visual responses of neurons in the retina and optic tectum of frogs, and came to the conclusion that some neurons in the tectum of the frog are wired to combine elementary responses in a way that makes them function as \"bug perceivers\". A few years later David Hubel and Torsten Wiesel discovered cells in the primary visual cortex of monkeys that become active when sharp edges move across specific points in the field of view\u2014a discovery for which they won a Nobel Prize. Follow-up studies in higher-order visual areas found cells that detect binocular disparity, color, movement, and aspects of shape, with areas located at increasing distances from the primary visual cortex showing increasingly complex responses. Other investigations of brain areas unrelated to vision have revealed cells with a wide variety of response correlates, some related to memory, some to abstract types of cognition such as space.",
            "score": 162.91836547851562
        },
        {
            "docid": "4087208_12",
            "document": "David Marks (psychologist) . Rodway, Gillies and Schepman (2006) found that high vividness participants were significantly more accurate at detecting salient changes to pictures compared to low vividness participants, replicating an earlier study by Gur and Hilgard (1975). Recently Cui et al. (2007) found that reported image vividness correlates with increased activity in the visual cortex. This study shows that the subjective experience of forming a mental image is reflected by increased visual cortical activity. Logie, Pernet, Buonocore and Della Sala (2011) used behavioural and fMRI data for mental rotation from individuals reporting vivid and poor imagery on the VVIQ. Groups differed in brain activation patterns suggesting that the groups performed the same tasks in different ways. These findings help to explain the lack of association previously reported between VVIQ scores and mental rotation performance. Lee, Kravitz and Baker (2012) used fMRI and multi-voxel pattern analysis to investigate the specificity, distribution, and similarity of information for individual seen and imagined objects. Participants either viewed or imagined individual named object images on which they had been trained prior to the scan. Correlation between fMRI and VVIQ scores showed that, in both object-selective and early visual cortex, Lee et al.'s (2012) measure of discrimination across imagery and perception correlated with the vividness of imagery.",
            "score": 162.24525451660156
        },
        {
            "docid": "599917_31",
            "document": "Mental image . As cognitive neuroscience approaches to mental imagery continued, research expanded beyond questions of serial versus parallel or topographic processing to questions of the relationship between mental images and perceptual representations. Both brain imaging (fMRI and ERP) and studies of neuropsychological patients have been used to test the hypothesis that a mental image is the reactivation, from memory, of brain representations normally activated during the perception of an external stimulus. In other words, if perceiving an apple activates contour and location and shape and color representations in the brain\u2019s visual system, then imagining an apple activates some or all of these same representations using information stored in memory. Early evidence for this idea came from neuropsychology. Patients with brain damage that impairs perception in specific ways, for example by damaging shape or color representations, seem to generally to have impaired mental imagery in similar ways. Studies of brain function in normal human brains support this same conclusion, showing activity in the brain\u2019s visual areas while subjects imagined visual objects and scenes.",
            "score": 162.11537170410156
        },
        {
            "docid": "3883287_8",
            "document": "Tranquillity . Within tranquillity studies, much of the emphasis has been placed on understanding the role of vision in the perception of natural environments, which is probably not surprising, considering that upon first viewing a scene its configurational coherence can be established with incredible speed. Indeed, scene information can be captured in a single glance and the gist of a scene determined in as little as 100ms. The speed of processing of complex natural images was tested by Thorpe \"et al.\" using colour photographs of a wide range of animals (mammals, birds, reptiles and fish), in their natural environments, mixed with distracters that included pictures of forests, mountains, lakes, buildings and fruit. During this experiment, subjects were shown an image for 20ms and asked to determine whether it contained an animal or not. The electrophysiological brain responses obtained in this study showed that a decision could be made within 150ms of the image being seen, indicating the speed at which cognitive visual processing occurs. However, audition, and in particular the individual components that collectively comprise the soundscape, a term coined by Schafer to describe the ever-present array of sounds that constitute the sonic environment, also significantly inform the various schemata used to characterise differing landscape types. This interpretation is supported by the auditory reaction times, which are 50 to 60ms faster than that of the visual modality. It is also known that sound can alter visual perception and that under certain conditions areas of the brain involved in processing auditory information can be activated in response to visual stimuli.  Research conducted by Pheasant \"et al.\" has shown that when individuals make tranquillity assessments based on a uni-modal auditory or visual sensory input, they characterise the environment by drawing upon a number of key landscape and soundscape characteristics. For example, when making assessments in response to visual-only stimuli the percentage of water, flora and geological features present within a scene, positively influence how tranquil a location is perceived to be. Likewise when responding to uni-modal auditory stimuli, the perceived loudness of biological sounds positively influences the perception of tranquillity, whilst the perceived loudness of mechanical sounds have a negative effect. However, when presented with bi-modal auditory-visual stimuli the individual soundscape and landscape components alone no longer influenced the perception of tranquillity. Rather configurational coherence was provided by the percentage of natural and contextual features present within the scene and the equivalent continuous sound pressure level (LAeq).",
            "score": 161.5033416748047
        },
        {
            "docid": "2860457_6",
            "document": "Neural ensemble . Neuronal ensembles encode information in a way somewhat similar to the principle of Wikipedia operation \u2013 multiple edits by many participants. Neuroscientists have discovered that individual neurons are very noisy. For example, by examining the activity of only a single neuron in the visual cortex, it is very difficult to reconstruct the visual scene that the owner of the brain is looking at. Like a single Wikipedia participant, an individual neuron does not 'know' everything and is likely to make mistakes. This problem is solved by the brain having billions of neurons. Information processing by the brain is population processing, and it is also distributed \u2013 in many cases each neuron knows a little bit about everything, and the more neurons participate in a job, the more precise the information encoding. In the distributed processing scheme, individual neurons may exhibit neuronal noise, but the population as a whole averages this noise out.",
            "score": 160.01048278808594
        },
        {
            "docid": "404084_25",
            "document": "Hebbian theory . Hebbian learning and spike-timing-dependent plasticity have been used in an influential theory of how mirror neurons emerge. Mirror neurons are neurons that fire both when an individual performs an action and when the individual sees or hears another perform a similar action. The discovery of these neurons has been very influential in explaining how individuals make sense of the actions of others, by showing that, when a person perceives the actions of others, the person activates the motor programs which they would use to perform similar actions. The activation of these motor programs then adds information to the perception and helps predict what the person will do next based on the perceiver's own motor program. A challenge has been to explain how individuals come to have neurons that respond both while performing an action and while hearing or seeing another perform similar actions.",
            "score": 159.93533325195312
        },
        {
            "docid": "3581220_21",
            "document": "Single-unit recording . Noninvasive tools to study the CNS have been developed to provide structural and functional information, but they do not provide very high resolution. To offset this problem invasive recording methods have been used. Single unit recording methods give high spatial and temporal resolution to allow for information assessing the relationship between brain structure, function, and behavior. By looking at brain activity at the neuron level, researchers can link brain activity to behavior and create neuronal maps describing flow of information through the brain. For example, Boraud et al. report the use of single unit recordings to determine the structural organization of the basal ganglia in patients with Parkinson's disease. Evoked potentials provide a method to couple behavior to brain function. By stimulating different responses, one can visualize what portion of the brain is activated. This method has been used to explore cognitive functions such as perception, memory, language, emotions, and motor control.",
            "score": 159.64112854003906
        },
        {
            "docid": "1168317_15",
            "document": "Mirror neuron . It is not normally possible to study single neurons in the human brain, so most evidence for mirror neurons in humans is indirect. Brain imaging experiments using functional magnetic resonance imaging (fMRI) have shown that the human inferior frontal cortex and superior parietal lobe are active when the person performs an action and also when the person sees another individual performing an action. It has been suggested that these brain regions contain mirror neurons, and they have been defined as the human mirror neuron system. More recent experiments have shown that even at the level of single participants, scanned using fMRI, large areas containing multiple fMRI voxels increase their activity both during the observation and execution of actions.",
            "score": 159.47108459472656
        },
        {
            "docid": "19628311_9",
            "document": "Earl K. Miller . Miller has innovated techniques for recording from many neurons simultaneously in multiple brain areas. This is a departure from the classic single-neuron recording approach. It allows detailed and direct comparison of neuron properties between brain areas that are not confounded by extraneous factors and examination of the temporal dynamics of activity between neurons. Miller's lab has used this approach to make a number of discoveries of how different brain areas collaborate to produce thought and action. This includes recent discoveries that oscillating \"brain waves\" may control the timing of shifts of attention and that different items simultaneously held in short-term memory line up on different phases of each brain wave. The latter may explain why we can only think about a few things at the same time.",
            "score": 159.03746032714844
        },
        {
            "docid": "226722_25",
            "document": "Functional magnetic resonance imaging . Researchers have checked the BOLD signal against both signals from implanted electrodes (mostly in monkeys) and signals of field potentials (that is the electric or magnetic field from the brain's activity, measured outside the skull) from EEG and MEG. The local field potential, which includes both post-neuron-synaptic activity and internal neuron processing, better predicts the BOLD signal. So the BOLD contrast reflects mainly the inputs to a neuron and the neuron's integrative processing within its body, and less the output firing of neurons. In humans, electrodes can be implanted only in patients who need surgery as treatment, but evidence suggests a similar relationship at least for the auditory cortex and the primary visual cortex. Activation locations detected by BOLD fMRI in cortical areas (brain surface regions) are known to tally with CBF-based functional maps from PET scans. Some regions just a few millimeters in size, such as the lateral geniculate nucleus (LGN) of the thalamus, which relays visual inputs from the retina to the visual cortex, have been shown to generate the BOLD signal correctly when presented with visual input. Nearby regions such as the pulvinar nucleus were not stimulated for this task, indicating millimeter resolution for the spatial extent of the BOLD response, at least in thalamic nuclei. In the rat brain, single-whisker touch has been shown to elicit BOLD signals from the somatosensory cortex.",
            "score": 158.87110900878906
        },
        {
            "docid": "3717_59",
            "document": "Brain . Neurophysiologists study the chemical, pharmacological, and electrical properties of the brain: their primary tools are drugs and recording devices. Thousands of experimentally developed drugs affect the nervous system, some in highly specific ways. Recordings of brain activity can be made using electrodes, either glued to the scalp as in EEG studies, or implanted inside the brains of animals for extracellular recordings, which can detect action potentials generated by individual neurons. Because the brain does not contain pain receptors, it is possible using these techniques to record brain activity from animals that are awake and behaving without causing distress. The same techniques have occasionally been used to study brain activity in human patients suffering from intractable epilepsy, in cases where there was a medical necessity to implant electrodes to localize the brain area responsible for epileptic seizures. Functional imaging techniques such as functional magnetic resonance imaging are also used to study brain activity; these techniques have mainly been used with human subjects, because they require a conscious subject to remain motionless for long periods of time, but they have the great advantage of being noninvasive. Another approach to brain function is to examine the consequences of damage to specific brain areas. Even though it is protected by the skull and meninges, surrounded by cerebrospinal fluid, and isolated from the bloodstream by the blood\u2013brain barrier, the delicate nature of the brain makes it vulnerable to numerous diseases and several types of damage. In humans, the effects of strokes and other types of brain damage have been a key source of information about brain function. Because there is no ability to experimentally control the nature of the damage, however, this information is often difficult to interpret. In animal studies, most commonly involving rats, it is possible to use electrodes or locally injected chemicals to produce precise patterns of damage and then examine the consequences for behavior.",
            "score": 158.5497589111328
        },
        {
            "docid": "1726672_11",
            "document": "Neural circuit . Different neuroimaging techniques have been developed to investigate the activity of neural circuits and networks. The use of \"brain scanners\" or functional neuroimaging to investigate the structure or function of the brain is common, either as simply a way of better assessing brain injury with high resolution pictures, or by examining the relative activations of different brain areas. Such technologies may include functional magnetic resonance imaging (fMRI), brain positron emission tomography (brain PET), and computed axial tomography (CAT) scans. Functional neuroimaging uses specific brain imaging technologies to take scans from the brain, usually when a person is doing a particular task, in an attempt to understand how the activation of particular brain areas is related to the task. In functional neuroimaging, especially fMRI, which measures hemodynamic activity that is closely linked to neural activity, PET, and electroencephalography (EEG) is used.",
            "score": 157.60910034179688
        },
        {
            "docid": "53497_13",
            "document": "Optical illusion . In the Ponzo illusion the converging parallel lines tell the brain that the image higher in the visual field is farther away therefore the brain perceives the image to be larger, although the two images hitting the retina are the same size. The optical illusion seen in a diorama/false perspective also exploits assumptions based on monocular cues of depth perception. The M.C. Escher painting \"Waterfall\" exploits rules of depth and proximity and our understanding of the physical world to create an illusion. Like depth perception, motion perception is responsible for a number of sensory illusions. Film animation is based on the illusion that the brain perceives a series of slightly varied images produced in rapid succession as a moving picture. Likewise, when we are moving, as we would be while riding in a vehicle, stable surrounding objects may appear to move. We may also perceive a large object, like an airplane, to move more slowly than smaller objects, like a car, although the larger object is actually moving faster. The phi phenomenon is yet another example of how the brain perceives motion, which is most often created by blinking lights in close succession.",
            "score": 157.2171173095703
        }
    ]
}