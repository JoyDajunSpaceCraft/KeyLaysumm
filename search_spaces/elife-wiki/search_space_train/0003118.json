{
    "q": [
        {
            "docid": "21312318_27",
            "document": "Recognition memory . Recognition memory is critically dependent on a hierarchically organized network of brain areas including the visual ventral stream, medial temporal lobe structures, frontal lobe and parietal cortices along with the hippocampus. As mentioned previously, the processes of recollection and familiarity are represented differently in the brain. As such, each of the regions listed above can be further subdivided according to which part is primarily involved in recollection or in familiarity. In the temporal cortex, for instance, the medial region is related to recollection whereas the anterior region is related to familiarity. Similarly, in the parietal cortex, the lateral region is related to recollection whereas the superior region is related to familiarity. An even more specific account divides the medial parietal region, relating the posterior cingulate to recollection and the precuneus to familiarity. The hippocampus plays a prominent role in recollection whereas familiarity depends heavily on the surrounding medial-temporal regions, especially the perirhinal cortex. Finally, it is not yet clear what specific regions of the prefrontal lobes are associated with recollection versus familiarity, although there is evidence that the left prefrontal cortex is correlated more strongly with recollection whereas the right prefrontal cortex is involved more in familiarity. Though left-side activation involved in recollection was originally hypothesized to result from semantic processing of words (many of these earlier studies used written words for stimuli) subsequent studies using nonverbal stimuli produced the same finding\u2014suggesting that prefrontal activation in the left hemisphere results from any kind of detailed remembering.  As previously mentioned, recognition memory is not a stand-alone concept; rather it is a highly interconnected and integrated sub-system of memory. Perhaps misleadingly, the regions of the brain listed above correspond to an abstract and highly generalized understanding of recognition memory, in which the stimuli or items-to-be-recognized are not specified. In reality, however, the location of brain activation involved in recognition is highly dependent on the nature of the stimulus itself. Consider the conceptual differences in recognizing written words compared to recognizing human faces. These are two qualitatively different tasks and as such it is not surprising that they involve additional, distinct regions of the brain. Recognizing words, for example, involves the visual word form area, a region in the left fusiform gyrus, which is believed to specialized in recognizing written words. Similarly, the fusiform face area, located in the right hemisphere, is linked specifically to the recognition of faces.",
            "score": 151.45396780967712
        },
        {
            "docid": "4231622_9",
            "document": "Inferior temporal gyrus . These areas must all work together, as well as with the hippocampus, in order to create an array of understanding of the physical world. The hippocampus is key for storing the memory of what an object is/what it looks like for future use so that it can be compared and contrasted with other objects. Correctly being able to recognize an object is highly dependent on this organized network of brain areas that process, share, and store information. In a study by Denys et al., functional magnetic resonance imaging (FMRI) was used to compare the processing of visual shape between humans and macaques. They found, amongst other things, that there was a degree of overlap between shape and motion sensitive regions of the cortex, but that the overlap was more distinct in humans. This would suggest that the human brain is better evolved for a high level of functioning in a distinct, three-dimensional, visual world.",
            "score": 159.26452541351318
        },
        {
            "docid": "525667_10",
            "document": "Human echolocation . In a 2014 study by Thaler and colleagues, the researchers first made recordings of the clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, not only did they perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. The brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any auditory area, becomes involved in the computation of echolocation tasks.",
            "score": 163.05597376823425
        },
        {
            "docid": "32197396_4",
            "document": "Form perception . In addition to photoreceptors, the eye requires a properly functioning lens, retina, and an undamaged optic nerve to recognize form. Light travels through the lens, hits the retina, activates the appropriate photoreceptors, depending on available light, which convert the light into an electrical signal that travels along the optic nerve to the lateral geniculate nucleus of the thalamus and then to the primary visual cortex. In the cortex, the adult brain processes information such as lines, orientation, and color. These inputs are integrated in the occipito-temporal cortex where a representation of the object as a whole is created. Visual information continues to be processed in the posterior parietal cortex, also known as the dorsal stream, where the representation of an object\u2019s shape is formed using motion-based cues. It is believed that simultaneously information is processed in the anterior temporal cortex, also known as the ventral stream, where object recognition, identification and naming occur. In the process of recognizing an object, both the dorsal and ventral streams are active, but the ventral stream is more important in discriminating between and recognizing objects. The dorsal stream contributes to object recognition only when two objects have similar shapes and the images are degraded. Observed latency in activation of different parts of the brain supports the idea of hierarchal processing of visual stimuli, with object representations progressing from simple to complex.",
            "score": 168.64369750022888
        },
        {
            "docid": "1732213_34",
            "document": "Language processing in the brain . Early auditory processing and word recognition take place in inferior temporal areas (\"what\" pathway), where the signal arrives from the primary and secondary visual cortices. The representation of the object in the \"what\" pathway and nearby inferior temporal areas itself constitutes a major aspect of the conceptual\u2013semantic representation. Additional semantic and syntactic associations are also activated, and during this interval of highly variable duration (depending on the subject, the difficulty of the current object, etc.), the word to be spoken is selected. This involves some of the same sites \u2013 prefrontal cortex (PFC), supramarginal gyrus (SMG), and other association areas \u2013 involved in the semantic selection stage of verb generation.",
            "score": 125.95558941364288
        },
        {
            "docid": "534400_5",
            "document": "Semantic memory . Recent research has focused on the idea that when people access a word's meaning, sensorimotor information that is used to perceive and act on the concrete object the word suggests is automatically activated. In the theory of grounded cognition, the meaning of a particular word is grounded in the sensorimotor systems. For example, when one thinks of a pear, knowledge of grasping, chewing, sights, sounds, and tastes used to encode episodic experiences of a pear are recalled through sensorimotor simulation. A grounded simulation approach refers to context-specific re-activations that integrate the important features of episodic experience into a current depiction. Such research has challenged previously utilized amodal views. The brain encodes multiple inputs such as words and pictures to integrate and create a larger conceptual idea by using amodal views (also known as amodal perceptions. Instead of being representations in modality-specific systems, semantic memory representations had previously been viewed as redescriptions of modality-specific states. Some accounts of category-specific semantic deficits that are amodal remain even though researchers are beginning to find support for theories in which knowledge is tied to modality-specific brain regions. This research defines a clear link between episodic experiences and semantic memory. The concept that semantic representations are grounded across modality-specific brain regions can be supported by the fact that episodic and semantic memory appear to function in different yet mutually dependent ways. The distinction between semantic and episodic memory has become a part of the broader scientific discourse. For example, it has been speculated that semantic memory captures the stable aspects of our personality while episodes of illness may have a more episodic nature.",
            "score": 157.79710364341736
        },
        {
            "docid": "51496920_5",
            "document": "James V. Haxby . Haxby's scientific contributions span several topics in cognitive neuroscience. He has published numerous papers using functional neuroimaging to investigate the cortical organization underlying visual perception and semantic memory. He has also proposed an influential model of face perception where certain brain areas process invariant face properties such identity, while others process dynamic features critical for social interaction, such as emotional expressions and eye gaze. Haxby has played a critical role in introducing machine learning methods to functional magnetic resonance imaging (fMRI) data analysis. This approach was popularized by a paper demonstrating that neural representations of faces and object categories are encoded in a distributed fashion in human ventral temporal cortex, a position that is typically contrasted with more modular accounts of the functional neuroanatomy of face processing. More recently, Haxby's research has focused on the cortical topographies mediating fine-grained semantic representation, methods for functional brain alignment, and using naturalistic stimuli (e.g., movies) to build computational models of neural representation that are common across individuals. He is a vocal proponent of open science.",
            "score": 101.71150720119476
        },
        {
            "docid": "4231622_5",
            "document": "Inferior temporal gyrus . The temporal lobe is unique to primates. In humans, the IT cortex is more complex than their relative primate counterparts. The human inferior temporal cortex consists of the inferior temporal gyrus, the middle temporal gyrus, and the fusiform gyrus. When looking at the brain laterally \u2013 that is from the side and looking at the surface of the temporal lobe \u2013 the inferior temporal gyrus is along the bottom portion of the temporal lobe, and is separated from the middle temporal gyrus located directly above by the inferior temporal sulcus. Additionally, some processing of the visual field that corresponds to the ventral stream of visual processing occurs in the lower portion of the superior temporal gyrus closest to the superior temporal sulcus. The medial and ventral view of the brain \u2013 meaning looking at the medial surface from below the brain, facing upwards \u2013 reveals that the inferior temporal gyrus is separated from the fusiform gyrus by the occipital-temporal sulcus. This human inferior temporal cortex is much more complex than that of other primates: non-human primates have an inferior temporal cortex that is not divided into unique regions such as humans' inferior temporal gyrus, fusiform gyrus, or middle temporal gyrus.  This region of the brain corresponds to the inferior temporal cortex and is responsible for visual object recognition and receives processed visual information. The inferior temporal cortex in primates has specific regions dedicated to processing different visual stimuli processed and organized by the different layers of the striate cortex and extra-striate cortex. The information from the V1 \u2013V5 regions of the geniculate and tectopulvinar pathways are radiated to the IT cortex via the ventral stream: visual information specifically related to the color and form of the visual stimuli. Through comparative research between primates \u2013 humans and non-human primates \u2013 results indicate that the IT cortex plays a significant role in visual shape processing. This is supported by functional magnetic resonance imaging (fMRI) data collected by researchers comparing this neurological process between humans and macaques.",
            "score": 131.44719326496124
        },
        {
            "docid": "25146378_12",
            "document": "Functional specialization (brain) . One of the most well known examples of functional specialization is the fusiform face area (FFA). Justine Sergent was one of the first researchers that brought forth evidence towards the functional neuroanatomy of face processing. Using positron emission tomography (PET), Sergent found that there were different patterns of activation in response to the two different required tasks, face processing verses object processing. These results can be linked with her studies of brain-damaged patients with lesions in the occipital and temporal lobes. Patients revealed that there was an impairment of face processing but no difficulty recognizing everyday objects, a disorder also known as prosopagnosia. Later research by Nancy Kanwisher using functional magnetic resonance imaging (fMRI), found specifically that the region of the inferior temporal cortex, known as the fusiform gyrus, was significantly more active when subjects viewed, recognized and categorized faces in comparison to other regions of the brain. Lesion studies also supported this finding where patients were able to recognize objects but unable to recognize faces. This provided evidence towards domain specificity in the visual system, as Kanwisher acknowledges the Fusiform Face Area as a module in the brain, specifically the extrastriate cortex, that is specialized for face perception.",
            "score": 170.9164216518402
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 153.24618017673492
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 138.52333211898804
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 144.28607153892517
        },
        {
            "docid": "534400_40",
            "document": "Semantic memory . Other researchers believe the hippocampus is only involved in episodic memory and spatial cognition. This then raises the question where semantic memory may be located. Some believe semantic memory lives in temporal neocortex. Others believe that semantic knowledge is widely distributed across all brain areas. To illustrate this latter view, consider your knowledge of dogs. Researchers holding the 'distributed semantic knowledge' view believe that your knowledge of the sound a dog makes exists in your auditory cortex, whilst your ability to recognize and imagine the visual features of a dog resides in your visual cortex. Recent evidence supports the idea that the temporal pole bilaterally is the convergence zone for unimodal semantic representations into a multimodal representation. These regions are particularly vulnerable to damage in semantic dementia, which is characterised by a global semantic deficit.",
            "score": 123.2337806224823
        },
        {
            "docid": "534400_54",
            "document": "Semantic memory . Neuroimaging studies suggest a large, distributed network of semantic representations that are organized minimally by attribute, and perhaps additionally by category. These networks include \"extensive regions of ventral (form and color knowledge) and lateral (motion knowledge) temporal cortex, parietal cortex (size knowledge), and premotor cortex (manipulation knowledge). Other areas, such as more anterior regions of temporal cortex, may be involved in the representation of nonperceptual (e.g. verbal) conceptual knowledge, perhaps in some categorically-organized fashion.\" It is suggested that within the temperoparietal network, the anterior temporal lobe is relatively more important for semantic processing, and posterior language regions are relatively more important for lexical retrieval.",
            "score": 84.33850765228271
        },
        {
            "docid": "485309_16",
            "document": "Face perception . There are several parts of the brain that play a role in face perception. Rossion, Hanseeuw, and Dricot used BOLD fMRI mapping to identify activation in the brain when subjects viewed both cars and faces. The majority of BOLD fMRI studies use blood oxygen level dependent (BOLD) contrast to determine which areas of the brain are activated by various cognitive functions. They found that the occipital face area, located in the occipital lobe, the fusiform face area, the superior temporal sulcus, the amygdala, and the anterior/inferior cortex of the temporal lobe, all played roles in contrasting the faces from the cars, with the initial face perception beginning in the area and occipital face areas. This entire region links to form a network that acts to distinguish faces. The processing of faces in the brain is known as a \"sum of parts\" perception. However, the individual parts of the face must be processed first in order to put all of the pieces together. In early processing, the occipital face area contributes to face perception by recognizing the eyes, nose, and mouth as individual pieces. Furthermore, Arcurio, Gold, and James used BOLD fMRI mapping to determine the patterns of activation in the brain when parts of the face were presented in combination and when they were presented singly. The occipital face area is activated by the visual perception of single features of the face, for example, the nose and mouth, and preferred combination of two-eyes over other combinations. This research supports that the occipital face area recognizes the parts of the face at the early stages of recognition. On the contrary, the fusiform face area shows no preference for single features, because the fusiform face area is responsible for \"holistic/configural\" information, meaning that it puts all of the processed pieces of the face together in later processing. This theory is supported by the work of Gold et al. who found that regardless of the orientation of a face, subjects were impacted by the configuration of the individual facial features. Subjects were also impacted by the coding of the relationships between those features. This shows that processing is done by a summation of the parts in the later stages of recognition.",
            "score": 113.04677844047546
        },
        {
            "docid": "599917_31",
            "document": "Mental image . As cognitive neuroscience approaches to mental imagery continued, research expanded beyond questions of serial versus parallel or topographic processing to questions of the relationship between mental images and perceptual representations. Both brain imaging (fMRI and ERP) and studies of neuropsychological patients have been used to test the hypothesis that a mental image is the reactivation, from memory, of brain representations normally activated during the perception of an external stimulus. In other words, if perceiving an apple activates contour and location and shape and color representations in the brain\u2019s visual system, then imagining an apple activates some or all of these same representations using information stored in memory. Early evidence for this idea came from neuropsychology. Patients with brain damage that impairs perception in specific ways, for example by damaging shape or color representations, seem to generally to have impaired mental imagery in similar ways. Studies of brain function in normal human brains support this same conclusion, showing activity in the brain\u2019s visual areas while subjects imagined visual objects and scenes.",
            "score": 153.29429507255554
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 155.01602292060852
        },
        {
            "docid": "2640086_28",
            "document": "Affective neuroscience . Instead of investigating specific emotions, Kober, et al. 2008 reviewed 162 neuroimaging studies published between 1990-2005 to determine if groups of brain regions show consistent patterns of activation during emotional experience (that is, actively experiencing an emotion first-hand) and during emotion perception (that is, perceiving a given emotion as experienced by another). This meta-analysis used multilevel kernal density analysis (MKDA) to examine fMRI and PET studies, a technique that prevents single studies from dominating the results (particularly if they report multiple nearby peaks) and that enables studies with large sample sizes (those involving more participants) to exert more influence upon the results. MKDA was used to establish a neural reference space that includes the set of regions showing consistent increases across all studies (for further discussion of MDKA see Wager et al. 2007). Next, this neural reference space was partitioned into functional groups of brain regions showing similar activation patterns across studies by first using multivariate techniques to determine co-activation patterns and then using data-reduction techniques to define the functional groupings (resulting in six groups). Consistent with a psychological construction approach to emotion, the authors discuss each functional group in terms more basic psychological operations. The first \u201cCore Limbic\u201d group included the left amygdala, hypothalamus, periaqueductal gray/thalamus regions, and amygdala/ventral striatum/ventral globus pallidus/thalamus regions, which the authors discuss as an integrative emotional center that plays a general role in evaluating affective significance. The second \u201cLateral Paralimbic\u201d group included the ventral anterior insula/frontal operculum/right temporal pole/ posterior orbitofrontal cortex, the anterior insula/ posterior orbitofrontal cortex, the ventral anterior insula/ temporal cortex/ orbitofrontal cortex junction, the midinsula/ dorsal putamen, and the ventral striatum /mid insula/ left hippocampus, which the authors suggest plays a role in motivation, contributing to the general valuation of stimuli and particularly in reward. The third \u201cMedial Prefrontal Cortex\u201d group included the dorsal medial prefrontal cortex, pregenual anterior cingulate cortex, and rostral dorsal anterior cingulate cortex, which the authors discuss as playing a role in both the generation and regulation of emotion. The fourth \u201cCognitive/ Motor Network\u201d group included right frontal operculum, the right interior frontal gyrus, and the pre-supplementray motor area/ left interior frontal gyrus, regions that are not specific to emotion, but instead appear to play a more general role in information processing and cognitive control. The fifth \u201cOccipital/ Visual Association\u201d group included areas V8 and V4 of the primary visual cortex, the medial temporal lobe, and the lateral occipital cortex, and the sixth \u201cMedial Posterior\u201d group included posterior cingulate cortex and area V1 of the primary visual cortex. The authors suggest that these regions play a joint role in visual processing and attention to emotional stimuli.",
            "score": 111.60575842857361
        },
        {
            "docid": "4231622_3",
            "document": "Inferior temporal gyrus . The inferior temporal gyrus is the anterior region of the temporal lobe located underneath the central temporal sulcus. The primary function of the occipital temporal gyrus \u2013 otherwise referenced as IT cortex \u2013 is associated with visual stimuli processing, namely visual object recognition, and has been suggested by recent experimental results as the final location of the ventral cortical visual system. The IT cortex in humans is also known as the Inferior Temporal Gyrus since it has been located to a specific region of the human temporal lobe. The IT processes visual stimuli of objects in our field of vision, and is involved with memory and memory recall to identify that object; it is involved with the processing and perception created by visual stimuli amplified in the V1, V2, V3, and V4 regions of the occipital lobe. This region processes the color and form of the object in the visual field and is responsible for producing the \u201cwhat\u201d from this visual stimuli, or in other words identifying the object based on the color and form of the object and comparing that processed information to stored memories of objects to identify that object.",
            "score": 118.74949371814728
        },
        {
            "docid": "24965027_13",
            "document": "Cognitive neuroscience of visual object recognition . The lateral occipital complex (LOC) has been found to be particularly important for object recognition at the perceptual structural level. In an event-related fMRI study that looked at the adaptation of neurons activated in visual processing of objects, it was discovered that the similarity of an object's shape is necessary for subsequent adaptation in the LOC, but specific object features such as edges and contours are not. This suggests that activation in the LOC represents higher-level object shape information and not simple object features. In a related fMRI study, the activation of the LOC, which occurred regardless of the presented object's visual cues such as motion, texture, or luminance contrasts, suggests that the different low-level visual cues used to define an object converge in \"object-related areas\" to assist in the perception and recognition process. None of the mentioned higher-level object shape information seems to provide any semantic information about the object as the LOC shows a neuronal response to varying forms including non-familiar, abstract objects.",
            "score": 165.53655672073364
        },
        {
            "docid": "32197396_5",
            "document": "Form perception . By five months of age infants are capable of using line junction information to perceive three-D images, including depth and shape, like adults are able. However, there are differences between younger infants and adults in the ability to use motion and color cues to discriminate between two objects. Visual information then continues to be processed in the posterior parietal cortex, also known as the dorsal stream, where the representation of an objects shape is formed using motion-based cues. The identification of differences between the infant and adult brain make it clear that there is either functional reorganization of the infant\u2019s cortex or simply age related differences in which the breed impulses have been observed in infants. Although the infant brain is not identical to the adult brain, it is similar with areas of specialization and a hierarchy of processing,[7] however, adult abilities to perceive form from stationary viewing are not fully understood.",
            "score": 146.60335850715637
        },
        {
            "docid": "53953041_3",
            "document": "Predictive coding . Theoretical ancestors to predictive coding date back as early as 1860 with Helmholz\u2019s concept of unconscious inference (Clark, 2013). Unconscious inference refers to the idea that the human brain fills in visual information to make sense of a scene. For example, if something is relatively smaller than another object in the visual field, the brain uses that information as a likely cue of depth, such that the perceiver ultimately (and involuntarily) experiences depth. The understanding of perception as the interaction between sensory stimuli (bottom-up) and conceptual knowledge (top-down) continued to be established by Jerome Bruner (psychologist) who, starting in the 1940s, studied the ways in which needs, motivations and expectations influence perception, research that came to be known as 'New Look' psychology. In 1981, McClelland and Rumelhart in their seminal paper examined the interaction between processing features (lines and contours) which form letters, which in turn form words. While the features suggest the presence of a word, they found that when letters were situated in the context of a word, people were able to identify them faster than when they were situated in a non-word without semantic context. McClelland and Rumelhart\u2019s parallel processing model describes perception as the meeting of top-down (conceptual) and bottom-up (sensory) elements.",
            "score": 115.29631423950195
        },
        {
            "docid": "59604_12",
            "document": "Epiphenomenon . Zenon Pylyshyn suggested a propositional model of cognition where people do not conceptualize ideas in images but rather in meaningful relationships. In this theory, epiphenomena refer to images because they are merely products people conceptualize from their actual thought processes. Pylyshyn defends his claim by explaining that we only see images when we envision the form of an object. While visualizing objects or actions is a frequent process in our mind, it does not occur when we are considering the meaning behind an action or the non-visual properties of an object. There are many concepts we simply cannot envision. Additionally, when envisioning an image, it changes based on our preconceived notions, suggesting that semantic relations precede visual images. Unfortunately, the idea of epiphenomena in propositional theory is largely subjective and not falsifiable.",
            "score": 99.82167458534241
        },
        {
            "docid": "734667_8",
            "document": "Iconic memory . Although less research exists regarding the neural representation of informational persistence compared to visual persistence, new electrophysiological techniques have begun to reveal cortical areas involved. Unlike visible persistence, informational persistence is thought to rely on higher-level visual areas beyond the visual cortex. The anterior superior temporal sulcus (STS), a part of the ventral stream, was found to be active in macaques during iconic memory tasks. This brain region is associated with object recognition and object identity. Iconic memory's role in change detection has been related to activation in the middle occipital gyrus (MOG). MOG activation was found to persist for approximately 2000ms suggesting a possibility that iconic memory has a longer duration than what was currently thought. Iconic memory is also influenced by genetics and proteins produced in the brain. Brain-derived neurotrophic factor (BDNF) is a part of the neurotrophin family of nerve growth factors. Individuals with mutations to the BDNF gene which codes for BDNF have been shown to have shortened, less stable informational persistence.",
            "score": 140.60574066638947
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 139.1269074678421
        },
        {
            "docid": "1215674_34",
            "document": "Visual memory . Studies have shown that there is an effect of alcohol on visual memory. In a recent study visual working memory and its neutral correlates was assessed in university students who partake in binge drinking, the intermittent consumption of large amounts of alcohol. The findings revealed that there may be binge-drinking related functional alteration in recognition working memory processes. This suggests that impaired prefrontal cortex function may occur at an early age in binge drinkers. Another study conducted in 2004 examined the level of response to alcohol and brain response during visual working memory. This study looked at the neural correlated of the low level of response to alcohol using functional magnetic resonance imaging during a challenging visual memory task. The results were that young people who report having needed more alcohol to feel the effects showed higher levels of brain response during visual working memory, this suggests that the individual\u2019s capacity to adjust to cognitive processing decreases, they are less able to adjust cognitive processing to contextual demands.",
            "score": 84.91433501243591
        },
        {
            "docid": "24965027_11",
            "document": "Cognitive neuroscience of visual object recognition . The visual processing of objects in the brain can be divided into two processing pathways: the dorsal stream (how/where), which extends from the visual cortex to the parietal lobes, and ventral stream (what), which extends from the visual cortex to the inferotemporal cortex (IT). The existence of these two separate visual processing pathways was first proposed by Ungerleider and Mishkin (1982) who, based on their lesion studies, suggested that the dorsal stream is involved in the processing of visual spatial information, such as object localization (where), and the ventral stream is involved in the processing of visual object identification information (what). Since this initial proposal, it has been alternatively suggested that the dorsal pathway should be known as the 'How' pathway as the visual spatial information processed here provides us with information about how to interact with objects, For the purpose of object recognition, the neural focus is on the ventral stream.",
            "score": 160.63025164604187
        },
        {
            "docid": "2230911_13",
            "document": "Semantic dementia . It is currently unknown why semantic memory is impaired and semantic knowledge deteriorates in SD patients, though the cause may be due to damage to an amodal semantic system. This theory is supported by the atrophy of the anterior temporal lobe, which is believed to contain a component of the semantic system that integrates conceptual information. Others hypothesize that the damage is predominantly to the ventral temporal cortex, since SD patients remember numbers and music, but have trouble associating visual cues to concrete words.",
            "score": 99.69154191017151
        },
        {
            "docid": "21312318_37",
            "document": "Recognition memory . Damage to the temporal lobes can also result in visual agnosia, a deficit in which patients are unable to properly recognize objects, either due to a perceptive deficit, or a deficit in semantic memory. In the process of object recognition, visual information from the occipital lobes (such as lines, movement, colour etc.) must at some point be actively interpreted by the brain and attributed meaning. This is commonly referred to in terms of the ventral, or \"what\" pathway, which leads to the temporal lobes. People with visual agnosia are often able to identify features of an object (it is small, cylindrical, has a handle etc.), but are unable to recognize the object as a whole (a tea cup). This has been termed specifically as integrative agnosia.",
            "score": 132.07773649692535
        },
        {
            "docid": "8680973_17",
            "document": "Negative priming . Neurological evidence of negative priming effects is being researched to help understand the physiological aspects and to develop more accurate models. The most common method to find such neurological evidence is by neuroimaging the brain using fMRI while subjects go through experiments of tasks that prompt negative priming effects. The two primary bases for neurological evidence are the internal representations of stimuli and memory retrieval. Most significantly activated regions of the brain are the left temporal lobe, inferior parietal lobe, and the prefrontal cortex of the frontal lobe. Evidence for internal representations are found in the left anterior temporal cortex, which has been associated with abstract semantic knowledge representations. Left anterolateral temporal cortex was found to be directly related to the magnitude of negative priming effect. The inferior parietal lobe is connected to the shifts in attention that occurs when attending to the distractors and the target. The inferior parietal cortex activated whenever attention shifted from the distractor to target stimulus or vice versa. Another significant area of activation was found in the prefrontal cortex. The superior, inferior, and medial frontal gyri, and the medial prefrontal cortex exhibited activation during the negative priming tasks. Activations in the frontal lobe has been associated with inhibitory network and selective attention. Similarly, evidences for semantic representations and temporal lobe activations are used to support the episode retrieval model. Additional investigations of the neurophysiological data of negative priming are necessary to further clarify the relationship between selective attention and memory in negative priming.",
            "score": 119.42242228984833
        },
        {
            "docid": "1038052_32",
            "document": "Neuroesthetics . Different artistic styles may also be processed differently by the brain. In a study between filtered forms of abstract and representation art, the bilateral occipital gyri, left cingulate sulcus, and bilateral fusiform gyrus showed increased activation with increased preference when viewing art. However, activation in the bilateral occipital gyri may be caused by the large processing requirements placed on the visual system when viewing high levels of visual detail in artwork such as representational paintings. Several areas of the brain have been shown to respond particularly to forms representational art perhaps due to the brain's ability to make object associations and other functions relating to attention and memory. This form of stimuli leads to increased activation in the left frontal lobe and bilaterally in the parietal and limbic lobes. Also, the left superior parietal lobule, Brodmann's area 7, has been shown to play a role in active image construction during the viewing of art specifically containing indeterminate forms such as soft edge paintings. Bottom up processes such as edge detection and the exploration of visual stimuli are engaged during this type of aesthetic perception. These roles are consistent with previously known parietal lobe responsibilities in spatial cognition and visual imagery.",
            "score": 131.6395548582077
        },
        {
            "docid": "5664_64",
            "document": "Consciousness . In neuroscience, a great deal of effort has gone into investigating how the perceived world of conscious awareness is constructed inside the brain. The process is generally thought to involve two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals arising from sensory organs are transmitted to the brain and then processed in a series of stages, which extract multiple types of information from the raw input. In the visual system, for example, sensory signals from the eyes are transmitted to the thalamus and then to the primary visual cortex; inside the cerebral cortex they are sent to areas that extract features such as three-dimensional structure, shape, color, and motion. Memory comes into play in at least two ways. First, it allows sensory information to be evaluated in the context of previous experience. Second, and even more importantly, working memory allows information to be integrated over time so that it can generate a stable representation of the world\u2014Gerald Edelman expressed this point vividly by titling one of his books about consciousness \"The Remembered Present\". In computational neuroscience, Bayesian approaches to brain function have been used to understand both the evaluation of sensory information in light of previous experience, and the integration of information over time. Bayesian models of the brain are probabilistic inference models, in which the brain takes advantage of prior knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian models have successfully predicted many perceptual phenomena in vision and the nonvisual senses.",
            "score": 128.49892354011536
        }
    ],
    "r": [
        {
            "docid": "24965027_25",
            "document": "Cognitive neuroscience of visual object recognition . Loss of object recognition is called \"visual object agnosia\". There are two broad categories of visual object agnosia: apperceptive and associative. When object agnosia occurs from a lesion in the dominant hemisphere, there is often a profound associated language disturbance, including loss of word meaning.  Object recognition is a complex task and involves several different areas of the brain \u2013 not just one. If one area is damaged then object recognition can be impaired. The main area for object recognition takes place in the temporal lobe. For example, it was found that lesions to the perirhinal cortex in rats causes impairments in object recognition especially with an increase in feature ambiguity. Neonatal aspiration lesions of the amygdaloid complex in monkeys appear to have resulted in a greater object memory loss than early hippocampal lesions. However, in adult monkeys, the object memory impairment is better accounted for by damage to the perirhinal and entorhinal cortex than by damage to the amygdaloid nuclei. Combined amygdalohippocampal (A + H) lesions in rats impaired performance on an object recognition task when the retention intervals were increased beyond 0s and when test stimuli were repeated within a session. Damage to the amygdala or hippocampus does not affect object recognition, whereas A + H damage produces clear deficits. In an object recognition task, the level of discrimination was significantly lower in the electrolytic lesions of globus pallidus (part of the basal ganglia) in rats compared to the Substantia- Innominata/Ventral Pallidum which was in turn worse compared to Control and Medial Septum/Vertical Diagonal Band of Broca groups; however, only globus pallidus did not discriminate between new and familiar objects. These lesions damage the ventral (what) pathway of the visual processing of objects in the brain.",
            "score": 179.6417694091797
        },
        {
            "docid": "25146378_12",
            "document": "Functional specialization (brain) . One of the most well known examples of functional specialization is the fusiform face area (FFA). Justine Sergent was one of the first researchers that brought forth evidence towards the functional neuroanatomy of face processing. Using positron emission tomography (PET), Sergent found that there were different patterns of activation in response to the two different required tasks, face processing verses object processing. These results can be linked with her studies of brain-damaged patients with lesions in the occipital and temporal lobes. Patients revealed that there was an impairment of face processing but no difficulty recognizing everyday objects, a disorder also known as prosopagnosia. Later research by Nancy Kanwisher using functional magnetic resonance imaging (fMRI), found specifically that the region of the inferior temporal cortex, known as the fusiform gyrus, was significantly more active when subjects viewed, recognized and categorized faces in comparison to other regions of the brain. Lesion studies also supported this finding where patients were able to recognize objects but unable to recognize faces. This provided evidence towards domain specificity in the visual system, as Kanwisher acknowledges the Fusiform Face Area as a module in the brain, specifically the extrastriate cortex, that is specialized for face perception.",
            "score": 170.9164276123047
        },
        {
            "docid": "32197396_4",
            "document": "Form perception . In addition to photoreceptors, the eye requires a properly functioning lens, retina, and an undamaged optic nerve to recognize form. Light travels through the lens, hits the retina, activates the appropriate photoreceptors, depending on available light, which convert the light into an electrical signal that travels along the optic nerve to the lateral geniculate nucleus of the thalamus and then to the primary visual cortex. In the cortex, the adult brain processes information such as lines, orientation, and color. These inputs are integrated in the occipito-temporal cortex where a representation of the object as a whole is created. Visual information continues to be processed in the posterior parietal cortex, also known as the dorsal stream, where the representation of an object\u2019s shape is formed using motion-based cues. It is believed that simultaneously information is processed in the anterior temporal cortex, also known as the ventral stream, where object recognition, identification and naming occur. In the process of recognizing an object, both the dorsal and ventral streams are active, but the ventral stream is more important in discriminating between and recognizing objects. The dorsal stream contributes to object recognition only when two objects have similar shapes and the images are degraded. Observed latency in activation of different parts of the brain supports the idea of hierarchal processing of visual stimuli, with object representations progressing from simple to complex.",
            "score": 168.64370727539062
        },
        {
            "docid": "24965027_13",
            "document": "Cognitive neuroscience of visual object recognition . The lateral occipital complex (LOC) has been found to be particularly important for object recognition at the perceptual structural level. In an event-related fMRI study that looked at the adaptation of neurons activated in visual processing of objects, it was discovered that the similarity of an object's shape is necessary for subsequent adaptation in the LOC, but specific object features such as edges and contours are not. This suggests that activation in the LOC represents higher-level object shape information and not simple object features. In a related fMRI study, the activation of the LOC, which occurred regardless of the presented object's visual cues such as motion, texture, or luminance contrasts, suggests that the different low-level visual cues used to define an object converge in \"object-related areas\" to assist in the perception and recognition process. None of the mentioned higher-level object shape information seems to provide any semantic information about the object as the LOC shows a neuronal response to varying forms including non-familiar, abstract objects.",
            "score": 165.53656005859375
        },
        {
            "docid": "37198050_9",
            "document": "Body part as an object . There have been many studies relating activated brain areas to tool-use, in both physical object manipulation and pantomimes. Meta-analyses have found that tool-use is largely lateralized in the left-hemisphere of the brain and independent of handedness. Specifically, the brain region which showed the greatest activity was the left superior parietal lobule. Other areas that showed significant activity was bilaterally in both the ventral and dorsolateral premotor cortex, areas by the inferior parietal lobule, and tissue around the medial temporal gyrus. Furthermore, even when object-use was imagined, activation was found to be largely lateralized in the left hemisphere and was very similar to the brain activation in actual tool-use and pantomiming. The only significant difference was additional activation in the left occipito-parietal region.",
            "score": 165.12875366210938
        },
        {
            "docid": "176997_5",
            "document": "Blindsight . Patients with blindsight have damage to the visual system that allows perception (the visual cortex of the brain and some of the nerve fibers that bring information to it from the eyes) rather than the system that controls eye movements. This phenomenon shows how, after the more complex visual system is damaged, people can use the latter visual system of their brains to guide hand movements towards an object even though they cannot see what they are reaching for. Hence, visual information can control behavior without producing a conscious sensation. This ability of those with blindsight to \"see\" objects that they are unconscious of suggests that consciousness is not a general property of all parts of the brain; yet it suggests that only certain parts of the brain play a special role in consciousness.",
            "score": 164.2266387939453
        },
        {
            "docid": "525667_10",
            "document": "Human echolocation . In a 2014 study by Thaler and colleagues, the researchers first made recordings of the clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, not only did they perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. The brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any auditory area, becomes involved in the computation of echolocation tasks.",
            "score": 163.05596923828125
        },
        {
            "docid": "24965027_6",
            "document": "Cognitive neuroscience of visual object recognition . A significant aspect of object recognition is that of object constancy: the ability to recognize an object across varying viewing conditions. These varying conditions include object orientation, lighting, and object variability (size, colour, and other within-category differences). For the visual system to achieve object constancy, it must be able to extract a commonality in the object description across different viewpoints and the retinal descriptions.[9] Participants who did categorization and recognition tasks while undergoing a functional magnetic found as increased blood flow indicating activation in specific regions of the brain. The categorization task consisted of participants placing objects from canonical or unusual views as either indoor or outdoor objects. The recognition task occurs by presenting the participants with images that they had viewed previously. Half of these images were in the same orientation as previously shown, while the other half were presented in the opposing viewpoint. The brain regions implicated in mental rotation, such as the ventral and dorsal visual pathways and the prefrontal cortex, showed the greatest increase in blood flow during these tasks, demonstrating that they are critical for the ability to view objects from multiple angles. Several theories have been generated to provide insight on how object constancy may be achieved for the purpose of object recognition including, viewpoint-invariant, viewpoint-dependent and multiple views theories.",
            "score": 162.8639678955078
        },
        {
            "docid": "1385766_6",
            "document": "Cognitive map . Cognitive mapping is believed to largely be a function of the hippocampus. The hippocampus is connected to the rest of the brain in such a way that it is ideal for integrating both spatial and nonspatial information. Connections from the postrhinal cortex and the medial entorhinal cortex provide spatial information to the hippocampus. Connections from the perirhinal cortex and lateral entorhinal cortex provide nonspatial information. The integration of this information in the hippocampus makes the hippocampus a practical location for cognitive mapping, which necessarily involves combining information about an object's location and its other features.",
            "score": 162.0494842529297
        },
        {
            "docid": "51462681_3",
            "document": "Objective vision . This is the story of what's happening when you see a picture, even too fast, the brain's visual cortex recognizes what it sees immediately. The visual cortex has a critical job in processing and it's the most complex part of brain. The human brain is much more aware of how it solves complex problems such as playing chess or solving algebra equations, which is why computer programmers have had so much success building machines that emulate this type of activity. but when entities visionary system starts to convert the signals to image(actually the separated shapes and colors) to find a relation between brain's information and those images. The system actually is concentrating on the separable sections, this separation gives the brain a visionary system the excellence processing result, because with this method the system do not waste much time on processing non significant sections and signals. this operation in the Objective Vision project called objective processing and because the O.V. mission is around human visionary simulation, so the developer refers with Objective Vision.",
            "score": 161.76290893554688
        },
        {
            "docid": "227183_9",
            "document": "Binswanger's disease . There is a difference between cortical and subcortical dementia. Cortical dementia is atrophy of the cortex which affects \u2018higher\u2019 functions such as memory, language, and semantic knowledge whereas subcortical dementia affects mental manipulation, forgetfulness, and personality/emotional changes. Binswanger\u2019s Disease has shown correlations with impairment in executive functions, but have normal episodic or declarative memory. Executive functions are brain processes that are responsible for planning, cognitive flexibility, abstract thinking, rule acquisition, initiating appropriate actions and inhibiting inappropriate actions, and selecting relevant sensory information. There have been many studies done comparing the mental deterioration of Binswanger patients and Alzheimer patients. It has been found in the Graphical Sequence Test that Binswanger patients have hyperkinetic perseveration errors which cause the patients to repeat motion even when not asked whereas Alzheimer patients have semantic perseveration because when asked to write a word they will instead draw the object of the word.",
            "score": 161.5780792236328
        },
        {
            "docid": "24965027_11",
            "document": "Cognitive neuroscience of visual object recognition . The visual processing of objects in the brain can be divided into two processing pathways: the dorsal stream (how/where), which extends from the visual cortex to the parietal lobes, and ventral stream (what), which extends from the visual cortex to the inferotemporal cortex (IT). The existence of these two separate visual processing pathways was first proposed by Ungerleider and Mishkin (1982) who, based on their lesion studies, suggested that the dorsal stream is involved in the processing of visual spatial information, such as object localization (where), and the ventral stream is involved in the processing of visual object identification information (what). Since this initial proposal, it has been alternatively suggested that the dorsal pathway should be known as the 'How' pathway as the visual spatial information processed here provides us with information about how to interact with objects, For the purpose of object recognition, the neural focus is on the ventral stream.",
            "score": 160.6302490234375
        },
        {
            "docid": "33246145_4",
            "document": "Neural decoding . When looking at a picture, people's brains are constantly making decisions about what object they are looking at, where they need to move their eyes next, and what they find to be the most salient aspects of the input stimulus. As these images hit the back of the retina, these stimuli are converted from varying wavelengths to a series of neural spikes called action potentials. These pattern of action potentials are different for different objects and different colors; we therefore say that the neurons are encoding objects and colors by varying their spike rates or temporal pattern. Now, if someone were to probe the brain by placing electrodes in the primary visual cortex, they may find what appears to be random electrical activity. These neurons are actually firing in response to the lower level features of visual input, possibly the edges of a picture frame. This highlights the crux of the neural decoding hypothesis: that it is possible to reconstruct a stimulus from the response of the ensemble of neurons that represent it. In other words, it is possible to look at spike train data and say that the person or animal being recorded is looking at a red ball.",
            "score": 159.83213806152344
        },
        {
            "docid": "24965027_19",
            "document": "Cognitive neuroscience of visual object recognition . Another condition that affects successful object recognition performance is that of contextual facilitation. It is thought that during tasks of object recognition, an object is accompanied by a \"context frame\", which offers semantic information about the object's typical context. It has been found that when an object is out of context, object recognition performance is hindered with slower response times and greater inaccuracies in comparison to recognition tasks when an object was in an appropriate context. Based on results from a study using fMRI, it has been proposed that there is a \"context network\" in the brain for contextually associated objects with activity largely found in the Parahippocampal cortex (PHC) and the Retrosplenial Complex (RSC). Within the PHC, activity in the Parahippocampal Place Area (PPA), has been found to be preferential to scenes rather than objects; however, it has been suggested that activity in the PHC for solitary objects in tasks of contextual facilitation may be due to subsequent thought of the spatial scene in which the object is contextually represented. Further experimenting found that activation was found for both non-spatial and spatial contexts in the PHC, although activation from non-spatial contexts was limited to the anterior PHC and the posterior PHC for spatial contexts.",
            "score": 159.68736267089844
        },
        {
            "docid": "27693293_8",
            "document": "Approximate number system . Brain imaging studies have identified the parietal lobe as being a key brain region for numerical cognition. Specifically within this lobe is the intraparietal sulcus which is \"active whenever we think about a number, whether spoken or written, as a word or as an Arabic digit, or even when we inspect a set of objects and think about its cardinality\". When comparing groups of objects, activation of the intraparietal sulcus is greater when the difference between groups is numerical rather than an alternative factor, such as differences in shape or size. This indicates that the intraparietal sulcus plays an active role when the ANS is employed to approximate magnitude.",
            "score": 159.51808166503906
        },
        {
            "docid": "4231622_9",
            "document": "Inferior temporal gyrus . These areas must all work together, as well as with the hippocampus, in order to create an array of understanding of the physical world. The hippocampus is key for storing the memory of what an object is/what it looks like for future use so that it can be compared and contrasted with other objects. Correctly being able to recognize an object is highly dependent on this organized network of brain areas that process, share, and store information. In a study by Denys et al., functional magnetic resonance imaging (FMRI) was used to compare the processing of visual shape between humans and macaques. They found, amongst other things, that there was a degree of overlap between shape and motion sensitive regions of the cortex, but that the overlap was more distinct in humans. This would suggest that the human brain is better evolved for a high level of functioning in a distinct, three-dimensional, visual world.",
            "score": 159.2645263671875
        },
        {
            "docid": "5978961_6",
            "document": "Perirhinal cortex . The perirhinal cortex is also involved in item memory, especially in coding familiarity or recency of items. Rats with a damaged perirhinal cortex seemed unable to tell novel objects from familiar ones\u2014they were still more interested in exploring when novel objects were present, but examined the novel and familiar objects equally, unlike undamaged rats. Thus, other brain regions are capable of noticing unfamiliarity, but the perirhinal cortex is needed to associate the feeling with a specific source.",
            "score": 157.82728576660156
        },
        {
            "docid": "534400_5",
            "document": "Semantic memory . Recent research has focused on the idea that when people access a word's meaning, sensorimotor information that is used to perceive and act on the concrete object the word suggests is automatically activated. In the theory of grounded cognition, the meaning of a particular word is grounded in the sensorimotor systems. For example, when one thinks of a pear, knowledge of grasping, chewing, sights, sounds, and tastes used to encode episodic experiences of a pear are recalled through sensorimotor simulation. A grounded simulation approach refers to context-specific re-activations that integrate the important features of episodic experience into a current depiction. Such research has challenged previously utilized amodal views. The brain encodes multiple inputs such as words and pictures to integrate and create a larger conceptual idea by using amodal views (also known as amodal perceptions. Instead of being representations in modality-specific systems, semantic memory representations had previously been viewed as redescriptions of modality-specific states. Some accounts of category-specific semantic deficits that are amodal remain even though researchers are beginning to find support for theories in which knowledge is tied to modality-specific brain regions. This research defines a clear link between episodic experiences and semantic memory. The concept that semantic representations are grounded across modality-specific brain regions can be supported by the fact that episodic and semantic memory appear to function in different yet mutually dependent ways. The distinction between semantic and episodic memory has become a part of the broader scientific discourse. For example, it has been speculated that semantic memory captures the stable aspects of our personality while episodes of illness may have a more episodic nature.",
            "score": 157.79710388183594
        },
        {
            "docid": "2353294_3",
            "document": "Martha Farah . Farah\u2019s early work focused on the neural bases of vision and memory. In her 1990 book, Visual Agnosia: Disorders of Object Recognition and What They Tell Us about Normal Vision (MIT Press), she framed many of the questions about visual recognition that the next two decades of cognitive neuroscience research addressed. These questions include whether the human brain uses a general-purpose pattern recognition system for all classes of visual object or whether there is specialization for face recognition and/or printed word recognition, and whether semantic memory knowledge is organized in the brain by category (e.g., living vs nonliving things) or modality (e.g. visual vs motoric information). Her research revealed a striking degree of division of labor, with specialized systems for a various categories of stimuli and types of information, and was summarized in The Cognitive Neuroscience of Vision (Wiley-Blackwell, 2000) and in the second edition of Visual Agnosia (MIT Press, 2004).",
            "score": 157.73609924316406
        },
        {
            "docid": "1626279_17",
            "document": "Anne Treisman . Treisman linked the process of binding that occurs in the focused attention stage to physiology by noting that an object causes activity in both the '\u2019what'\u2019 and '\u2019where'\u2019 streams of the cortex (see Two-streams hypothesis). Activity in the '\u2019what'\u2019 stream would include information about color and form, while activity in the '\u2019where'\u2019 stream would include information about location and motion. According to Treisman, attention is the \"glue\" that combines the information from both streams and causes us to perceive all the features of an object as combined at one specific location. It is easy to consider perceiving one object in isolation, but when we consider multiple objects, numerous features exist at many locations. The perceptual system's task is to associate each of these features with the object to which it belongs. Feature integration theory proposes that in order for this to occur, we need to focus our attention on each object in turn. Once we attend to a particular location, the features at that location are bound together and are associated with the object at that location.",
            "score": 157.48526000976562
        },
        {
            "docid": "32197396_6",
            "document": "Form perception . Dysfunctions in distinguishing differences in sizes and shapes of objects can have many causes, including brain injury, stroke, epilepsy, and oxygen deprivation. Lesions on the brain that develop as a result of injury or illness impair object recognition. Regions that specifically lead to deficits in object recognition when a lesion is present include the right lateral fusiform gyrus and the ventrolateral occipito-temporal cortex. These areas are crucial to the processing of shape and contour information, which is the basis for object recognition. Although there is evidence to support that damage to the areas mentioned leads to deficits in object recognition, it is important to note that brain damage, regardless of the cause, typically is extensive and present on both halves of the brain, complicating the identification of key structures.[12] Although most damage cannot be undone, there is evidence of reorganization in the unaffected areas of the affected hemisphere, making it possible for patients to regain some abilities.",
            "score": 157.2434539794922
        },
        {
            "docid": "18517835_4",
            "document": "Elizabeth Warrington . Elizabeth Warrington played a key role in the British development of Cognitive Neuropsychology a research approach that has had implications beyond the clinical sphere, providing important insights into the way that the normal human brain perceives, remembers, and talk about words, objects and events. Elizabeth Warrington's work has established a number of important differences (dissociations) between superficially similar cognitive abilities, for example in defining the differences between episodic memory and semantic memory and in establishing the evidence for category specific disorders of semantic knowledge; her work also defined a pattern of clinical impairment that became recognised as defining a form of dementia semantic dementia. Her work is a foundation for understanding normal function as well as for innovating clinical methods in the development of numerous tests that can be used in the diagnosis of brain injuries and diseases including dementia, Alzheimer's disease, and brain injuries resulting from a stroke and tumours. Her tests may also be used to track recovery and to plan rehabilitation",
            "score": 157.20814514160156
        },
        {
            "docid": "2872287_23",
            "document": "Neural binding . Much of the experimental evidence for neural binding has traditionally revolved around sensory awareness. Sensory awareness is accomplished by integrating things together by cognitively perceiving them and then segmenting them so that, in total, there is an image created. Since there can be an infinite number of possibilities in the perception of an object, this has been a unique area of study. The way the brain then collectively pieces certain things together via networking is important not only in the global way of perceiving but also in segmentation. Much of sensory awareness has to do with the taking of a single piece of an object's makeup and then binding its total characteristics so that the brain perceives the object in its final form. Much of the research for the understanding of segmentation and how the brain perceives an object has been done by studying cats. A major finding of this research has to do with the understanding of gamma waves oscillating at 40\u00a0Hz. The information was extracted from a study using the cat visual cortex. It was shown that the cortical neurons responded differently to spatially different objects. These firings of neurons ranged from 40\u201360\u00a0Hz in measure and when observed showed that they fired synchronously when observing different parts of the object. Such coherent responses point to the fact that the brain is doing a kind of coding where it is piecing certain neurons together in the works of making the form of an object. Since the brain is putting these segmented pieces together unsupervised, a significant consonance is found with many philosophers (like Sigmund Freud) who theorize an underlying subconscious that helps to form every aspect of our conscious thought processes.",
            "score": 156.6299591064453
        },
        {
            "docid": "24965027_26",
            "document": "Cognitive neuroscience of visual object recognition . Agnosia is a rare occurrence and can be the result of a stroke, dementia, head injury, brain infection, or hereditary. Apperceptive agnosia is a deficit in object perception creating an inability to understand the significance of objects. Similarly, associative visual agnosia is the inability to understand the significance of objects; however, this time the deficit is in semantic memory. Both of these agnosias can affect the pathway to object recognition, like Marr's Theory of Vision. More specifically unlike apperceptive agnosia, associative agnosic patients are more successful at drawing, copying, and matching tasks; however, these patients demonstrate that they can perceive but not recognize. Integrative agnosia(a subtype of associative agnosia) is the inability to integrate separate parts to form a whole image. With these types of agnosias there is damage to the ventral (what) stream of the visual processing pathway. Object orientation agnosia is the inability to extract the orientation of an object despite adequate object recognition. With this type of agnosia there is damage to the dorsal (where) stream of the visual processing pathway. This can affect object recognition in terms of familiarity and even more so in unfamiliar objects and viewpoints. A difficulty in recognizing faces can be explained by prosopagnosia. Someone with prosopagnosia cannot identify the face but is still able to perceive age, gender, and emotional expression. The brain region that specifies in facial recognition is the fusiform face area. Prosopagnosia can also be divided into apperceptive and associative subtypes. Recognition of individual chairs, cars, animals can also be impaired; therefore, these object share similar perceptual features with the face that are recognized in the fusiform face area.",
            "score": 156.24557495117188
        },
        {
            "docid": "32197396_8",
            "document": "Form perception . Potential injuries to the brain include but are not limited to stroke, oxygen deprivation, blunt force trauma, and surgical injuries. When patients have lesions on their brain that develop as a result of injury or illness, such as multiple sclerosis or epilepsy, it is possible that they may have impaired object recognition which can manifest in the form of many different agnosias. Similar deficits have also been observed adults that have suffered blunt force trauma, strokes, severe carbon monoxide poisoning as well as in adults that have surgical damage following removal of tumors. Deficits have also been observed in children with types of epilepsy that do not lead to the formation of lesions. It is believed that in these cases the seizures cause a functional disruption that is capable of interfering with the processing of objects. Regions that specifically lead to deficits in object recognition when a lesion is present include the right lateral fusiform gyrus and the ventrolateral or ventromedial occipito-temporal cortex. These structures have all been identified as being crucial to the processing of shape and contour information, which is the basis for object recognition. Although people with damage to these structures are not able to properly recognize objects, they are still capable of discerning the movement of objects. Only lesions in the parietal lobe have been associated with deficits in identifying the location of an object. Although there is strong evidence to support that damage to the above-mentioned areas leads to deficits in object recognition it is important to note that brain damage, regardless of the cause, is typically extensive and present on both halves of the brain, complicating the identification of key structures. Although most damage cannot be undone, there is evidence of reorganization in the unaffected areas of the affected hemisphere, making it possible for patients to regain some function.",
            "score": 155.85055541992188
        },
        {
            "docid": "25146378_20",
            "document": "Functional specialization (brain) . Other researchers who provide evidence to support the theory of distributive processing include Anthony McIntosh and William Uttal, who question and debate localization and modality specialization within the brain. McIntosh's research suggests that human cognition involves interactions between the brain regions responsible for processes sensory information, such as vision, audition, and other mediating areas like the prefrontal cortex. McIntosh explains that modularity is mainly observed in sensory and motor systems, however, beyond these very receptors, modularity becomes \"fuzzier\" and you see the cross connections between systems increase. He also illustrates that there is an overlapping of functional characteristics between the sensory and motor systems, where these regions are close to one another. These different neural interactions influence each other, where activity changes in one area influence other connected areas. With this, McIntosh suggest that if you only focus on activity in one area, you may miss the changes in other integrative areas. Neural interactions can be measured using analysis of covariance in neuroimaging. McIntosh used this analysis to convey a clear example of the interaction theory of distributive processing. In this study, subjects learned that an auditory stimulus signalled a visual event. McIntosh found activation (an increase blood flow), in an area of the occipital cortex, a region of the brain involved in visual processing, when the auditory stimulus was presented alone. Correlations between the occipital cortex and different areas of the brain such as the prefrontal cortex, premotor cortex and superior temporal cortex showed a pattern of co-variation and functional connectivity.",
            "score": 155.01602172851562
        },
        {
            "docid": "23416874_29",
            "document": "Sense . Recognition memory is sometimes divided into two functions by neuroscientists: familiarity and recollection. A strong sense of familiarity can occur without any recollection, for example in cases of deja vu. The temporal lobe, in particular the perirhinal cortex, responds differently to stimuli which feel novel than to things which feel familiar. Firing rates in the perirhinal cortex are connected with the sense of familiarity in humans and other mammals. In tests, stimulating this area at 10\u201315\u00a0Hz caused animals to treat even novel images as familiar, and stimulation at 30\u201340\u00a0Hz caused novel images to be partially treated as familiar. Specifically, stimulation at 30\u201340\u00a0Hz led to animals looking at a familiar image for longer periods, as they would for an unfamiliar one; but it did not lead to the same exploration behavior normally associated with novelty. Recent studies on lesions in the area concluded that rats with a damaged perirhinal cortex were still more interested in exploring when novel objects were present, but seemed unable to tell novel objects from familiar ones \u2014 they examined both equally. Thus, other brain regions are involved with noticing unfamiliarity, but the perirhinal cortex is needed to associate the feeling with a specific source.",
            "score": 154.659423828125
        },
        {
            "docid": "53686950_6",
            "document": "Bi-directional hypothesis of language and action . Language stimuli influence electrical activity in sensorimotor areas of the brain that are specific to the bodily-association of the words presented. This is referred to as semantic somatotopy, which indicates activation of sensorimotor areas that are specific to the bodily association implied by the word. For example, when processing the meaning of the word \u201ckick,\u201d the regions in the motor and somatosensory cortices that represent the legs will become more active. Boulenger et al. demonstrated this effect by presenting subjects with action-related language while measuring neural activity using fMRI. Subjects were presented with action sentences that were either associated with the legs (e.g. \u201cJohn kicked the object\u201d) or with the arms (e.g. \u201cJane grasped the object\u201d). The medial region of the motor cortex, known to represent the legs, was more active when subjects were processing leg-related sentences, whereas the lateral region of the motor cortex, known to represent the arms, was more active with arm-related sentences. This body-part-specific increase in activation was exhibited about 3 seconds after presentation of the word, a time window that is thought to indicate semantic processing. In other words, this activation was associated with subjects comprehending the meaning of the word. This effect held true, and was even intensified, when subjects were presented with idiomatic sentences. Abstract language that implied more figurative actions were used, either associated with the legs (e.g. \u201cJohn kicked the habit\u201d) or the arms (e.g. \u201cJane grasped the idea\u201d). Increased neural activation of leg motor regions were demonstrated with leg-related idiomatic sentences, whereas arm-related idiomatic sentences were associated with increased activation of arm motor regions. This activation was larger than that demonstrated by more literal sentences (e.g. \u201cJohn kicked the object\u201d), and was also present in the time window associated with semantic processing.",
            "score": 154.37326049804688
        },
        {
            "docid": "599917_31",
            "document": "Mental image . As cognitive neuroscience approaches to mental imagery continued, research expanded beyond questions of serial versus parallel or topographic processing to questions of the relationship between mental images and perceptual representations. Both brain imaging (fMRI and ERP) and studies of neuropsychological patients have been used to test the hypothesis that a mental image is the reactivation, from memory, of brain representations normally activated during the perception of an external stimulus. In other words, if perceiving an apple activates contour and location and shape and color representations in the brain\u2019s visual system, then imagining an apple activates some or all of these same representations using information stored in memory. Early evidence for this idea came from neuropsychology. Patients with brain damage that impairs perception in specific ways, for example by damaging shape or color representations, seem to generally to have impaired mental imagery in similar ways. Studies of brain function in normal human brains support this same conclusion, showing activity in the brain\u2019s visual areas while subjects imagined visual objects and scenes.",
            "score": 153.29429626464844
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 153.24618530273438
        },
        {
            "docid": "31133385_21",
            "document": "Misattribution of memory . The researchers found that perirhinal cortex activation was greater for objects recalled, and parahippocampal cortex activation was greater when scenes were recalled. The results provide evidence of distinct encoding activation in the subregions of the medial temporal lobe. The first subregion is the perirhinal cortex, which encodes item information. The second subregion, the parahippocampal cortex, is involved in source information. The evidence provides support for the role of the right perirhinal cortex in attributing an object to the right source. As decreased activation was associated with poorer performance, decreased activation of the right perirhinal cortex could be a possible mechanism for source confusion.",
            "score": 153.0160369873047
        },
        {
            "docid": "14158261_18",
            "document": "Temporoparietal junction . Theory of mind requires the collaboration of functionally related regions of the brain to form the distinction between self and other mental states and to create a comprehensive understanding of those mental states so that we may recognize, understand, and predict behavior. In general the theory of mind process is mediated by the dopaminergic-serotonergic system, which involves the TPJ as well as other associative regions necessary for mentalizing. Recent studies suggest that both the left TPJ, working in conjunction with the frontal cortex, and the right TPJ are involved in the representation of mental states; furthermore they suggest that the TPJ is particularly active in making the distinction between the mental states of self and others. A study in \"Nature Neuroscience\" from 2004 describes how the TPJ is involved in processing socially relevant cues including gaze direction and goal-directed action and also explains that results from the study show that lesions to this area of the brain result in an impaired ability to detect another persons belief. Moreover, studies have reported an increase in activity in the TPJ when patients are absorbing information through reading or images regarding other peoples' beliefs but not while observing information about physical control stimuli. Some studies, however, have shown that the TPJ, along with the cingulate cortex, is more specifically involved with attributing beliefs, but the process of mentalizing more generally is associated more with the medial prefrontal cortex. Another study in \"Current Biology\" from 2012 identifies the importance of the TPJ in both low-level, such as simple discrimination, and high-level, such as the ability to empathize, sociocognitive operations. In July 2011, a review from \"Neuropsychologia\" presented a model of the mentalizing network that established that mental states are first detected in the TPJ. The TPJ is composed of two discrete anatomical regions, the inferior parietal lobule (IPL) and the caudal parts of the superior temporal sulcus (pSTS), and both are active in the process of distinction between mental states of different individuals; thus, it is probable that this detection is the outcome of the combination and coordination of these two parts. Additionally, the right TPJ is involved in the ventral attention stream and contributes to the ability to focus attention on a particular stimuli or objective. It has also been observed that the interaction and communication between the dorsal and ventral streams involves the TPJ.",
            "score": 152.68760681152344
        }
    ]
}