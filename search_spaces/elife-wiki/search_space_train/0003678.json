{
    "q": [
        {
            "docid": "433584_4",
            "document": "McGurk effect . Vision is the primary sense for humans, but speech perception is multimodal, which means that it involves information from more than one sensory modality, in particular, audition and vision. The McGurk effect arises during phonetic processing because the integration of audio and visual information happens early in speech perception. The McGurk effect is very robust; that is, knowledge about it seems to have little effect on one's perception of it. This is different from certain optical illusions, which break down once one 'sees through' them. Some people, including those that have been researching the phenomenon for more than twenty years, experience the effect even when they are aware that it is taking place. With the exception of people who can identify most of what is being said from speech-reading alone, most people are quite limited in their ability to identify speech from visual-only signals. A more extensive phenomenon is the ability of visual speech to increase the intelligibility of heard speech in a noisy environment. Visible speech can also alter the perception of perfectly audible speech sounds when the visual speech stimuli are mismatched with the auditory speech. Normally, speech perception is thought to be an auditory process; however, our use of information is immediate, automatic, and, to a large degree, unconscious and therefore, despite what is widely accepted as true, speech is not only something we hear. Speech is perceived by all of the senses working together (seeing, touching, and listening to a face move). The brain is often unaware of the separate sensory contributions of what it perceives. Therefore, when it comes to recognizing speech the brain cannot differentiate whether it is seeing or hearing the incoming information.",
            "score": 125.07471334934235
        },
        {
            "docid": "24034128_2",
            "document": "Assistive listening device . An Assistive listening device (ALD) is used to improve hearing ability for people in a variety of situations where they are unable to distinguish speech in noise. Often in a noisy or crowded room it is almost impossible for an individual who is hard of hearing to distinguish one voice among many. The hard of hearing listener has to distinguish between background noise, noise between them and the speaker and then there will be the effect of room acoustics on the quality of sound reaching their ears. Hearing aids are able to amplify and process these sounds and improve the speech to noise ratio but if the sound is too distorted by the time it reaches the listener even the best hearing aids will struggle to unscramble the signal.",
            "score": 78.27667212486267
        },
        {
            "docid": "433584_25",
            "document": "McGurk effect . People of all languages rely to some extent on visual information in speech perception, but the intensity of the McGurk effect can change between languages. Dutch, English, Spanish, German and Italian language listeners experience a robust McGurk effect, while it is weaker for Japanese and Chinese listeners. Most research on the McGurk effect between languages has been conducted between English and Japanese. There is a smaller McGurk effect in Japanese listeners than in English listeners. The cultural practice of face avoidance in Japanese people may have an effect on the McGurk effect, as well as tone and syllabic structures of the language. This could also be why Chinese listeners are less susceptible to visual cues, and similar to Japanese, produce a smaller effect than English listeners. Studies have also shown that Japanese listeners do not show a developmental increase in visual influence after the age of six, as English children do. Japanese listeners are more able to identify an incompatibility between the visual and auditory stimulus than English listeners are. This result could be in relation to the fact that in Japanese, consonant clusters do not exist. In noisy environments where speech is unintelligible, however, people of all languages resort to using visual stimuli and are then equally subject to the McGurk effect. The McGurk effect works with speech perceivers of every language for which it has been tested.",
            "score": 58.411267042160034
        },
        {
            "docid": "752723_2",
            "document": "Dichotic listening test . The Dichotic listening test is a psychological test commonly used to investigate selective attention within the auditory system and is a subtopic of cognitive psychology and neuroscience. Specifically, it is \"used as a behavioral test for hemispheric lateralization of speech sound perception.\" During a standard dichotic listening test, a participant is presented with two different auditory stimuli simultaneously (usually speech). The different stimuli are directed into different ears over headphones. Research Participants were instructed to repeat aloud the words they heard in one ear while a different message was presented to the other ear. As a result of focusing to repeat the words, participants noticed little of the message to the other ear, often not even realizing that at some point it changed from English to German. At the same time, participants did notice when the voice in the unattended ear changed from a male\u2019s to a female\u2019s, suggesting that the selectivity of consciousness can work to tune in some information.\"",
            "score": 58.40592122077942
        },
        {
            "docid": "10269587_2",
            "document": "Echoic memory . Echoic memory is the sensory memory register specific to auditory information (sounds). The sensory memory for sounds that people have just perceived is the form of echoic memory. Unlike visual memory, in which our eyes can scan the stimuli over and over, the auditory stimuli cannot be scanned over and over, although from a classical physics definition they both can and can not be so equally. Imaging input will always be at least slightly different due to other stray bits of light, just as a recorded sound will almost never have an identical total sound profile when played at different times. Time itself affects the sound every bit as much as photons such as in things seen. etc. even when the image being looked at is the same. So true with sound. Playing a digital music selection for example, through noise controlling headphones over and over again, is every bit as accurate with relation to sound as reading the same few words over and over again. Overall, echoic memories are stored for slightly longer periods of time than iconic memories (visual memories). Auditory stimuli are received by the ear one at a time before they can be processed and understood. For instance, hearing the radio is very different from reading a magazine. A person can only hear the radio once at a given time, while the magazine can be read over and over again. It can be said that the echoic memory is like a \"holding tank\" concept, because a sound is unprocessed (or held back) until the following sound is heard, and only then can it be made meaningful. This particular sensory store is capable of storing large amounts of auditory information that is only retained for a short period of time (3\u20134 seconds). This echoic sound resonates in the mind and is replayed for this brief amount of time shortly after the presentation of auditory stimuli. Echoic memory encrypts only moderately primitive aspects of the stimuli, for example pitch, which specifies localization to the non-association brain regions.",
            "score": 86.2304036617279
        },
        {
            "docid": "433584_2",
            "document": "McGurk effect . The McGurk effect is a perceptual phenomenon that demonstrates an interaction between hearing and vision in speech perception. The illusion occurs when the auditory component of one sound is paired with the visual component of another sound, leading to the perception of a third sound. The visual information a person gets from seeing a person speak changes the way they hear the sound. If a person is getting poor quality auditory information but good quality visual information, they may be more likely to experience the McGurk effect. Integration abilities for audio and visual information may also influence whether a person will experience the effect. People who are better at sensory integration have been shown to be more susceptible to the effect. Many people are affected differently by the McGurk effect based on many factors, including brain damage and other disorders. It was first described in 1976 in a paper by Harry McGurk and John MacDonald, titled \"Hearing Lips and Seeing Voices\" in \"Nature\" (23 Dec 1976). This effect was discovered by accident when McGurk and his research assistant, MacDonald, asked a technician to dub a video with a different phoneme from the one spoken while conducting a study on how infants perceive language at different developmental stages. When the video was played back, both researchers heard a third phoneme rather than the one spoken or mouthed in the video.",
            "score": 98.33654880523682
        },
        {
            "docid": "32116125_2",
            "document": "Amblyaudia . Amblyaudia (amblyos- blunt; audia-hearing) is a term coined by Dr. Deborah Moncrieff from the University of Pittsburgh to characterize a specific pattern of performance from dichotic listening tests. Dichotic listening tests are widely used to assess individuals for binaural integration, a type of auditory processing skill. During the tests, individuals are asked to identify different words presented simultaneously to the two ears. Normal listeners can identify the words fairly well and show a small difference between the two ears with one ear slightly dominant over the other. For the majority of listeners, this small difference is referred to as a \"right-ear advantage\" because their right ear performs slightly better than their left ear. But some normal individuals produce a \"left-ear advantage\" during dichotic tests and others perform at equal levels in the two ears. Amblyaudia is diagnosed when the scores from the two ears are significantly different with the individual's dominant ear score much higher than the score in the non-dominant ear  Researchers interested in understanding the neurophysiological underpinnings of amblyaudia consider it to be a brain based hearing disorder that may be inherited or that may result from auditory deprivation during critical periods of brain development. Individuals with amblyaudia have normal hearing sensitivity (in other words they hear soft sounds) but have difficulty hearing in noisy environments like restaurants or classrooms. Even in quiet environments, individuals with amblyaudia may fail to understand what they are hearing, especially if the information is new or complicated. Amblyaudia can be conceptualized as the auditory analog of the better known central visual disorder amblyopia. The term \u201clazy ear\u201d has been used to describe amblyaudia although it is currently not known whether it stems from deficits in the auditory periphery (middle ear or cochlea) or from other parts of the auditory system in the brain, or both. A characteristic of amblyaudia is suppression of activity in the non-dominant auditory pathway by activity in the dominant pathway which may be genetically determined and which could also be exacerbated by conditions throughout early development.",
            "score": 65.47953426837921
        },
        {
            "docid": "433584_21",
            "document": "McGurk effect . The McGurk effect can be observed when the listener is also the speaker or articulator. While looking at oneself in the mirror and articulating visual stimuli while listening to another auditory stimulus, a strong McGurk effect can be observed. In the other condition, where the listener speaks auditory stimuli softly while watching another person articulate the conflicting visual gestures, a McGurk effect can still be seen, although it is weaker.",
            "score": 47.92988324165344
        },
        {
            "docid": "5442380_25",
            "document": "Sensory cue . When one sound is presented for a long interval before the introduction of a second one originating from a different location, individuals will hear them as two distinct sounds, each originating from the correct location. However, when the delay between the onset of the first and second sound is shortened, listeners are unable to distinguish between the two sounds. Instead, they perceive them as both coming from the location of the lead sound. This effect counteracts the small disparity between the perception of sound caused by the difference in distance between each ear and the source of the auditory stimuli.",
            "score": 56.960134983062744
        },
        {
            "docid": "35988494_6",
            "document": "Selective auditory attention . The prevalence of selective hearing has not been clearly researched yet. However, there are some that have argued that the proportion of selective hearing is particularly higher in males than females. Ida Z\u00fcndorf, Hans-Otto Karnath and J\u00f6rg Lewald carried out a study in 2010 which investigated the advantages and abilities males have in the localization of auditory information. A sound localization task centered on the cocktail party effect was utilized in their study. The male and female participants had to try to pick out sounds from a specific source, on top of other competing sounds from other sources. The results showed that the males had a better performance overall. Female participants found it more difficult to locate target sounds in a multiple-source environment. Z\u00fcndorf et al. suggested that there may be sex differences in the attention processes that helped locate the target sound from a multiple-source auditory field. While men and women do have some differences when it comes to selective auditory hearing, they both struggle when presented with the challenge of multitasking, especially when tasks that are to be attempted concurrently are very similar in nature (Dittrich, and Stahl, 2012, p.\u00a0626).",
            "score": 90.41316795349121
        },
        {
            "docid": "32036278_2",
            "document": "Dichotic listening . Dichotic Listening is a psychological test commonly used to investigate selective attention within the auditory system and is a subtopic of cognitive psychology and neuroscience. Specifically, it is \"used as a behavioral test for hemispheric lateralization of speech sound perception.\" During a standard dichotic listening test, a participant is presented with two different auditory stimuli simultaneously (usually speech). The different stimuli are directed into different ears over headphones. Participants are asked to pay attention to one or both of the stimuli. Later, they are asked about the content of either the message they were asked to attend to or the message that they were not told to listen to.",
            "score": 35.170888900756836
        },
        {
            "docid": "3295580_14",
            "document": "Reflex seizure . Musicogenic epilepsy is a rare reflex epilepsy that is thought to be an abnormal sensitivity of the brain to musical stimuli, however, the exact mechanism of these seizures is unknown. People with musicogenic epilepsy may have seizures triggered not just by musical stimuli but also by the emotional content or memory associated with that melody or rhythm. Seizures can also be triggered when people with this condition think about certain kinds of music without actually hearing the musical stimulus. In addition, musicogenic epilepsy may occur with auditory sounds that one would not usually associate with music, the sounds of machinery for example may also be an auditory trigger for a musicogenic epilepsy. While certain types of music may induce a seizure in a certain person, listening to other kinds of music may prevent or terminate the epileptic activity.",
            "score": 58.52598166465759
        },
        {
            "docid": "23060403_12",
            "document": "Motor theory of speech perception . Using a speech synthesizer, speech sounds can be varied in place of articulation along a continuum from to to , or in voice onset time on a continuum from to (for example). When listeners are asked to discriminate between two different sounds, they perceive sounds as belonging to discrete categories, even though the sounds vary continuously. In other words, 10 sounds (with the sound on one extreme being and the sound on the other extreme being , and the ones in the middle varying on a scale) may all be acoustically different from one another, but the listener will hear all of them as either or . Likewise, the English consonant may vary in its acoustic details across different phonetic contexts (the /d/ in does not technically sound the same as the one in , for example), but all 's as perceived by a listener fall within one category (voiced alveolar plosive) and that is because \"linguistic representations are abstract, canonical, phonetic segments or the gestures that underlie these segments.\" This suggests that humans identify speech using categorical perception, and thus that a specialized module, such as that proposed by the motor theory of speech perception, may be on the right track.",
            "score": 72.53509259223938
        },
        {
            "docid": "25140_47",
            "document": "Perception . \"Speech perception\" is the process by which spoken languages are heard, interpreted and understood. Research in speech perception seeks to understand how human listeners recognize speech sounds and use this information to understand spoken language. The sound of a word can vary widely according to words around it and the tempo of the speech, as well as the physical characteristics, accent and mood of the speaker. Listeners manage to perceive words across this wide range of different conditions. Another variation is that reverberation can make a large difference in sound between a word spoken from the far side of a room and the same word spoken up close. Experiments have shown that people automatically compensate for this effect when hearing speech.",
            "score": 63.6878342628479
        },
        {
            "docid": "2485942_5",
            "document": "Audiogram . Hearing thresholds of humans and other mammals can be found by using behavioural hearing tests or physiological tests. An audiogram can be obtained using a behavioural hearing test called Audiometry. For humans the test involves different tones being presented at a specific frequency (pitch) and intensity (loudness). When the person hears the sound they raise their hand or press a button so that the tester knows that they have heard it. The lowest intensity sound they can hear is recorded. The test varies for children, their response to the sound can be a head turn or using a toy. The child learns what they can do when they hear the sound, for example they are taught that when they heard the sound they can put a toy man in a boat. This is referred to as conditioned play audiometry. Visual reinforcement audiometry is also used with children. When the child hears the sound, they look in the direction the sound came from and are reinforced with a light and/or animated toy. A similar technique can be used when testing some animals but instead of a toy, food can be used as a reward for responding to the sound.  Physiological tests do not need the patient to respond (Katz 2002). For example when performing the brainstem auditory evoked potentials the patient\u2019s brainstem responses are being measured when a sound is played into their ear, or otoacoustic emissions (OAEs) which are generated by a healthy inner ear either spontaneously or evoked by an outside stimulus.  In the US, the NIOSH recommends that people who are regularly exposed to hazardous noise have their hearing tested once a year, or every three years otherwise.",
            "score": 98.95740735530853
        },
        {
            "docid": "51547415_5",
            "document": "Interindividual differences in perception . The McGurk effect is an auditory illusion in which people perceive a different syllable when incongruent audiovisual speech is presented: an auditory syllable \"ba\" is presented while the mouth movement is \"ga\". As a result, the listener perceives the syllable \"da\". However, according to Gentilucci and Cattaneo (2005), not everyone perceives this illusion; only about 26% to 98% of the population are susceptible to this illusion. One of the psychological models that explains the interindividual differences in speech perception is the fuzzy logic model of speech perception According to this model, a categorization process is carried out when processing speech sounds. When listening to a stimulus, the features of the acoustic signal are analyzed. Subsequently, this signal is compared with the features that are stored in the memory; finally the sound is classified into the category that best fits. However, this classification may have a blurred boundary respectively to the category which the sound belongs to. As a result, the final decision may depend on integration of multiple sources of information. When the McGurk effect is presented the auditory and visual components of the speech are separately evaluated before being integrated. In those who perceive the McGurk effect, the visual information has a higher influence on the perception of the ambiguous audiovisual information and thus the sound is classified as \"da\".",
            "score": 58.18228530883789
        },
        {
            "docid": "32116125_4",
            "document": "Amblyaudia . Amblyaudia is a deficit in binaural integration of environmental information entering the auditory system. It is a disorder related to brain organization and function rather than what is typically considered a \u201chearing loss\u201d (damage to the cochlea). It may be genetic or developmentally acquired or both. When animals are temporarily deprived of hearing from an early age, profound changes occur in the brain. Specifically, cell sizes in brainstem nuclei are reduced, the configuration of brainstem dendrites are altered and neurons respond in different ways to sounds presented to both the deprived and non-deprived ears (in cases of asymmetric deprivation). This last point is particularly important for listening tasks that require inputs from two ears to perform well. There are multiple auditory functions that rely on the computation of well calibrated inputs from the two ears. Chief among these is the ability to localize sound sources and separate what we want to hear from a background of noise. In the brainstem, the auditory system compares the timing and levels of sounds between the two ears to encode the location of sound sources (sounds that originate from our right as opposed to left side are louder and arrive earlier in our right ear). This ability to separate sound sources not only helps us locate the trajectories of moving objects, but also to separate different sound sources in noisy environments.",
            "score": 119.11449217796326
        },
        {
            "docid": "5366050_57",
            "document": "Speech perception . Some of the earliest work in the study of how humans perceive speech sounds was conducted by Alvin Liberman and his colleagues at Haskins Laboratories. Using a speech synthesizer, they constructed speech sounds that varied in place of articulation along a continuum from to to . Listeners were asked to identify which sound they heard and to discriminate between two different sounds. The results of the experiment showed that listeners grouped sounds into discrete categories, even though the sounds they were hearing were varying continuously. Based on these results, they proposed the notion of categorical perception as a mechanism by which humans can identify speech sounds.",
            "score": 58.82606911659241
        },
        {
            "docid": "9736652_8",
            "document": "Auditory masking . The filters that distinguish one sound from another are called auditory filters, listening channels or critical bandwidths. Frequency resolution occurs on the basilar membrane due to the listener choosing a filter which is centered over the frequency they expect to hear, the signal frequency. A sharply tuned filter has good frequency resolution as it allows the center frequencies through but not other frequencies (Pickles 1982). Damage to the cochlea and the outer hair cells in the cochlea can impair the ability to tell sounds apart (Moore 1986). This explains why someone with a hearing loss due to cochlea damage would have more difficulty than a normal hearing person in distinguishing between different consonants in speech.",
            "score": 52.980520248413086
        },
        {
            "docid": "8953380_4",
            "document": "Auditory scene analysis . Sound reaches the ear and the eardrum vibrates as a whole. This signal has to be analyzed (in some way). Bregman's ASA model proposes that sounds will either be heard as \"integrated\" (heard as a whole \u2013 much like harmony in music), or \"segregated\" into individual components (which leads to counterpoint). For example, a bell can be heard as a 'single' sound (integrated), or some people are able to hear the individual components \u2013 they are able to segregate the sound. This can be done with chords where it can be heard as a 'color', or as the individual notes. Natural sounds, such as the human voice, musical instruments, or cars passing in the street, are made up of many frequencies, which contribute to the perceived quality (like timbre) of the sounds. When two or more natural sounds occur at once, all the components of the simultaneously active sounds are received at the same time, or overlapped in time, by the ears of listeners. This presents their auditory systems with a problem: which parts of the sound should be grouped together and treated as parts of the same source or object? Grouping them incorrectly can cause the listener to hear non-existent sounds built from the wrong combinations of the original components.",
            "score": 72.43626046180725
        },
        {
            "docid": "3883287_8",
            "document": "Tranquillity . Within tranquillity studies, much of the emphasis has been placed on understanding the role of vision in the perception of natural environments, which is probably not surprising, considering that upon first viewing a scene its configurational coherence can be established with incredible speed. Indeed, scene information can be captured in a single glance and the gist of a scene determined in as little as 100ms. The speed of processing of complex natural images was tested by Thorpe \"et al.\" using colour photographs of a wide range of animals (mammals, birds, reptiles and fish), in their natural environments, mixed with distracters that included pictures of forests, mountains, lakes, buildings and fruit. During this experiment, subjects were shown an image for 20ms and asked to determine whether it contained an animal or not. The electrophysiological brain responses obtained in this study showed that a decision could be made within 150ms of the image being seen, indicating the speed at which cognitive visual processing occurs. However, audition, and in particular the individual components that collectively comprise the soundscape, a term coined by Schafer to describe the ever-present array of sounds that constitute the sonic environment, also significantly inform the various schemata used to characterise differing landscape types. This interpretation is supported by the auditory reaction times, which are 50 to 60ms faster than that of the visual modality. It is also known that sound can alter visual perception and that under certain conditions areas of the brain involved in processing auditory information can be activated in response to visual stimuli.  Research conducted by Pheasant \"et al.\" has shown that when individuals make tranquillity assessments based on a uni-modal auditory or visual sensory input, they characterise the environment by drawing upon a number of key landscape and soundscape characteristics. For example, when making assessments in response to visual-only stimuli the percentage of water, flora and geological features present within a scene, positively influence how tranquil a location is perceived to be. Likewise when responding to uni-modal auditory stimuli, the perceived loudness of biological sounds positively influences the perception of tranquillity, whilst the perceived loudness of mechanical sounds have a negative effect. However, when presented with bi-modal auditory-visual stimuli the individual soundscape and landscape components alone no longer influenced the perception of tranquillity. Rather configurational coherence was provided by the percentage of natural and contextual features present within the scene and the equivalent continuous sound pressure level (LAeq).",
            "score": 70.90934598445892
        },
        {
            "docid": "404084_27",
            "document": "Hebbian theory . Evidence for that perspective comes from many experiments that show that motor programs can be triggered by novel auditory or visual stimuli after repeated pairing of the stimulus with the execution of the motor program (for a review of the evidence, see Giudice et al., 2009). For instance, people who have never played the piano do not activate brain regions involved in playing the piano when listening to piano music. Five hours of piano lessons, in which the participant is exposed to the sound of the piano each time he presses a key, suffices to later trigger activity in motor regions of the brain upon listening to piano music. Consistent with the fact that spike-timing-dependent plasticity occurs only if the presynaptic neuron's firing predicts the post-synaptic neuron's firing, the link between sensory stimuli and motor programs also only seem to be potentiated if the stimulus is contingent on the motor program.",
            "score": 57.251201033592224
        },
        {
            "docid": "6894544_2",
            "document": "Noise-induced hearing loss . Noise-induced hearing loss (NIHL) is hearing impairment resulting from exposure to loud sound. People may have a loss of perception of a narrow range of frequencies, impaired cognitive perception of sound including sensitivity to sound or ringing in the ears. When exposure to hazards such as noise occur at work and is associated with hearing loss, it is referred to as occupational hearing loss.  Hearing may deteriorate gradually from chronic and repeated noise exposure, such as to loud music or background noise, or suddenly, from exposure to impulse noise (a short high intensity noise), such as a gunshot or airhorn. In both types, loud sound overstimulates delicate hearing cells, leading to the permanent injury or death of the cells. Once lost this way, hearing cannot be restored in humans.  There are a variety of prevention strategies available to avoid or reduce hearing loss. Lowering the volume of sound at its source, limiting the time of exposure and physical protection can reduce the impact of excessive noise. If not prevented, hearing loss can be managed through assistive devices and cognitive therapies. The largest burden of NIHL has been through occupational exposures; however, noise-induced hearing loss can also be due to unsafe recreational, residential, social and military service-related noise exposures. It is estimated that 15% of young people are exposed to sufficient leisure noises (i.e. concerts, sporting events, daily activities, personal listening devices, etc.) to cause NIHL. There is not a limited list of noise sources that can cause hearing loss; rather, it is important to understand that exposure to excessively high decibel (dB) levels from any sound source over time, can cause hearing loss. The first symptom of NIHL may be difficulty hearing a conversation against a noisy background. The effect of hearing loss on speech perception has two components. The first component is the loss of audibility, which may be perceived as an overall decrease in volume. Modern hearing aids compensate this loss with amplification. The second component is known as \u201cdistortion\" or \u201cclarity loss\u201d due to selective frequency loss.\u201d Consonants, due to their higher frequency, are typically affected first. For example, the sounds \u201cs\u201d and \u201ct\u201d are often difficult to hear for those with hearing loss, affecting clarity of speech. NIHL can affect either one or both ears. Monaural hearing loss causes problems with directional hearing, affecting the ability to localize sound.",
            "score": 101.22123444080353
        },
        {
            "docid": "32116125_3",
            "document": "Amblyaudia . Children with amblyaudia experience difficulties in speech perception, particularly in noisy environments, sound localization, and binaural unmasking (using interaural cues to hear better in noise) despite having normal hearing sensitivity (as indexed through pure tone audiometry). These symptoms may lead to difficulty attending to auditory information causing many to speculate that language acquisition and academic achievement may be deleteriously affected in children with amblyaudia. A significant deficit in a child's ability to use and comprehend expressive language may be seen in children who lacked auditory stimulation throughout the critical periods of auditory system development. A child suffering from amblyaudia may have trouble in appropriate vocabulary comprehension and production and the use of past, present and future tenses. Amblyaudia has been diagnosed in many children with reported difficulties understanding and learning from listening and adjudicated adolescents are at a significantly high risk for amblyaudia (Moncrieff, et al., 2013, Seminars in Hearing). Families report the presence of amblyaudia in several individuals, suggesting that it may be genetic in nature. It is possible that abnormal auditory input during the first two years of life may increase a child\u2019s risk for amblyaudia, although the precise relationship between deprivation timing and development of amblyaudia is still unclear. Recurrent ear infections (otitis media) are the leading cause of temporary auditory deprivation in young children. During ear infection bouts, the quality of the signal that reaches the auditory regions of the brains of a subset of children with OM is degraded in both timing and magnitude. When this degradation is asymmetric (worse in one ear than the other) the binaural cues associated with sound localization can also be degraded. Aural atresia (a closed external auditory canal) also causes temporary auditory deprivation in young children. Hearing can be restored to children with ear infections and aural atresia through surgical intervention (although ear infections will also resolve spontaneously). Nevertheless, children with histories of auditory deprivation secondary to these diseases can experience amblyaudia for years after their hearing has been restored.",
            "score": 71.53190422058105
        },
        {
            "docid": "39265695_9",
            "document": "Stimulus filtering . Female midshipman fish undergo stimulus filtering when it comes time to mate with a male. Midshipman fish use stimulus filtering when listening to sounds produced by underwater species. Dominant signals underwater range between 60\u2013120\u00a0Hz, which is the most normally the most sensitive to the fish\u2019s auditory receptor. However, the female auditory system changes seasonally to acoustical stimuli in the songs of male midshipman fish. In the summer when female midshipman fish are reproducing they listen to a male humming song that can be produce a frequency level of 400\u00a0Hz. The summer is reproducing season for the females so their hearing is more sensitive to the high frequency of the male humming.",
            "score": 53.834760665893555
        },
        {
            "docid": "17523336_22",
            "document": "Olivocochlear system . Although Scharf et al.\u2019s (1993, 1994, 1997) experiments failed to produce any clear differences in the basic psychophysical characteristics of hearing (other than the detection of unexpected sounds), many other studies using both animals and humans have implicated the OCB in listening-in-noise tasks using more complex stimuli. In constant BGN, rhesus monkeys with intact OCBs have been observed to perform better in vowel discrimination tasks than those without (Dewson, 1968). In cats, an intact OCB is associated with better vowel identification (Heinz et al., 1998), sound localisation (May et al., 2004), and intensity discrimination (May and McQuone, 1995). All of these studies were performed in constant BGN. In humans, speech-in-noise discrimination measurements have been performed on individuals who had undergone unilateral vestibular neurectomy (resulting in OCB sectioning). Giraud et al. (1997) observed a small advantage in the healthy ear over the operated ear for phoneme recognition and speech intelligibility in BGN. Scharf et al. (1988) had previously investigated the role of auditory attention during speech perception, and suggested that speech-in-noise discrimination is assisted by attentional focus on frequency regions. In 2000, Zeng et al., reported that vestibular neurectomy did not directly affect pure-tone thresholds or intensity discrimination, confirming earlier findings of Scharf et al. 1994; 1997. For the listening-in-noise tasks, they observed a number of discrepancies between the healthy and operated ear. Consistent with the earlier findings of May and McQuone (1995), intensity discrimination in noise was observed to be slightly worse in the ear without olivocochlear bundle (OCB) input. However, Zeng et al.\u2019s main finding related to the \u201covershoot\u201d effect, which was found to be significantly reduced (~50%) in the operated ears. This effect was first observed by Zwicker (1965), and was characterised as an increased detection threshold of a tone when it is presented at the onset of the noise compared to when it is presented in constant, steady-state noise. Zeng et al. proposed that this finding is consistent with MOCS-evoked antimasking; that is, MOCS-evoked antimasking being absent at the onset of noise however becoming active during steady-state noise. This theory was supported by the time course of MOC activation; being similar to the time course of the overshoot effect (Zwicker, 1965), as well as the overshoot effect being disrupted in subjects with sensorineural hearing loss, for whom the MOCS would be most likely ineffectual (Bacon and Takahashi, 1992).",
            "score": 99.44787430763245
        },
        {
            "docid": "56533741_11",
            "document": "American Epic (documentary) . Extensive tracking shots were filmed of the landscape in each state and used as a device to demonstrate how much the geography influenced the music of the musicians in the 1920s. MacMahon explained, \u201cAs a filmmaker, I\u2019m fascinated by how the eye informs the heart. Driving through these remote locations with the film crew, we would play the music from that area in the van and it was extraordinary how closely the melodies and rhythms reflected the terrain from which they sprung. I see music visually and I think it mirrors its environment perfectly. The music of the Hopi sounded otherworldly when I first heard it, but after traveling to the Hopi reservation and having the honor of being allowed to film there, I started humming their songs. 'Chant of the Eagle Dance' now sounds like a pop single to me.\u201d He added, \u201cThings sound like the place they\u2019re from, the music makes sense. You\u2019re never going to hear Miles Davis make more sense than listening to him in a New York cab, and the Carter Family will never make more sense than if you listen to the music, watching the farm scenes from the 1920s from right where they lived.\u201d MacMahon coined the term \u201cgeographonics\u201d for this phenomenon. MacMahon went to great lengths to find the locations of old historic photographs related to the stories and made frequent use of dissolves between these old photographs and contemporary footage he shot to show the passage of time. The interviews were all filmed using an Arri Alexa on a slider or a camera dolly. All the interviews and the occasional musical performances were storyboarded by MacMahon prior to filming. \u201cWe set out to explore why particular recordings gave us particular feelings and touched particular emotions and found that an important part of that was the way they reflected particular communities and the particular geography of the places where those people lived. The more we traveled, the more we became convinced that sounds and styles arise from specific environments, and you can only truly understand them when you go where they came from. Of course, you can enjoy music without hearing it in its native setting, but we kept finding that we had never fully experienced a recording or felt it to the depth of our souls until we listened to it in its home.\u201d",
            "score": 99.61607229709625
        },
        {
            "docid": "5442380_26",
            "document": "Sensory cue . There are strong interactions between visual and auditory stimuli. Since both auditory and visual cues provide an accurate source of information about the location of an object, most times there will be minimal discrepancy between the two. However, it is possible to have a disparity in the information provided by the two sets of cues. Visual capture, also known as the ventriloquism effect, occurs when an individual\u2019s visual system locates the source of an auditory stimulus at a different position than where the auditory system locates it. When this occurs, the visual cues will override the auditory ones. The individual will perceive the sound as coming from the location where the object is seen. Audition can also affect visual perception. Research has demonstrated this effect by showing two objects on a screen, one moving diagonally from top-right to bottom-left and the other from top-left to bottom-right, intersecting in the middle. The paths of these identical objects could have been interpreted as crossing over each other, or as bouncing off each other. Without any auditory cue, a vast majority of subjects saw the objects crossing paths and continuing in their original trajectory. But with the addition of a small \u201cclick\u201d sound, a majority of subjects perceived the objects as bouncing off each other. In this case, auditory cues help interpret visual cues.",
            "score": 70.12464773654938
        },
        {
            "docid": "41045246_3",
            "document": "Sound map . The term \u201csoundscape\u201d refers to the sonic environment of a specific locale. It may also refer to actual environments, or to abstract constructions such as musical compositions and tape montages, particularly when considered as an artificial environment. The objective of sound maps is to represent a specific environment using its soundscape as primary references as opposed to visual cues. Sound maps are in many ways the most effective auditory archive of an environment. Sound maps are similar to sound walks which are a form of active participation in the soundscape. Soundwalks and indeed, sound maps encourage the participants to listen discriminatively, and moreover, to make critical judgments about the sounds heard and their contribution to the balance or imbalance of the sonic environment. However, soundwalks will plot out a route for the user to follow and give guidance as to what the user may be hearing at each checkpoint. Sound maps, on the other hand, have specific soundscapes recorded that users can listen to at each checkpoint.",
            "score": 65.21352207660675
        },
        {
            "docid": "1555553_18",
            "document": "Unilateral hearing loss . When wearing stereo headphones, people with unilateral hearing loss can hear only one channel, hence the panning information (volume and time differences between channels) is lost; some instruments may be heard better than others if they are mixed predominantly to one channel, and in extreme cases of sound production, such as complete stereo separation or stereo-switching, only part of the composition can be heard; in games using 3D audio effects, sound may not be perceived appropriately due to coming to the disabled ear. This can be corrected by using settings in the software or hardware\u2014audio player, OS, amplifier or sound source\u2014to adjust balance to one channel (only if the setting downmixes sound from both channels to one), or there may be an option to outright downmix both channels to mono. Such settings may be available via the device or software's accessibility features. As hardware solutions, stereo-to-mono adapters may be available to receive mono sound in stereo headphones from a stereo sound source, or some monaural headsets for cellphones and VOIP communication may combine stereo sound to mono (though headphones for voice communication typically offer lower audio quality than headphones targeted for listening to music). From the standpoint of sound fidelity, sound information in downmixed mono channel will, in any case, differ from that in either of the source channels or what is perceived by a normal-hearing person, thus technically some audio quality is lost (for example, the same or slightly different sound occurrences in two channels, with time delay between them, will be merged to a sound in the mono channel that unavoidably cannot correspond to the intent of the sound producer); however, such loss is most probably unnoticeable, especially compared to other distortions inherent in sound reproduction, and to the person's problems from hearing loss.",
            "score": 99.73328948020935
        },
        {
            "docid": "41087200_3",
            "document": "Perceptual-based 3D sound localization . Human listeners combine information from two ears to localize and separate sound sources originating in different locations in a process called binaural hearing. The powerful signal processing methods found in the neural systems and brains of humans and other animals are flexible, environmentally adaptable, and take place rapidly and seemingly without effort. Emulating the mechanisms of binaural hearing can improve recognition accuracy and signal separation in DSP algorithms, especially in noisy environments. Furthermore, by understanding and exploiting biological mechanisms of sound localization, virtual sound scenes may be rendered with more perceptually relevant methods, allowing listeners to accurately perceive the locations of auditory events.",
            "score": 62.46747636795044
        },
        {
            "docid": "29708051_6",
            "document": "Mary Florentine . Softness Imperception (SI) is a term coined by Florentine and colleagues to describe the inability to hear quiet sounds that are audible to normal listeners. This phenomenon is particularly common among people with cochlear hearing loss. When a person with SI hears a sound at threshold, it sounds louder than a sound at threshold would do for a normal listener. Therefore, people with hearing loss may find softer sounds more intrusive when fitted with hearing aids that simply amplify all soft sounds to threshold.",
            "score": 60.69335412979126
        }
    ],
    "r": [
        {
            "docid": "21161742_21",
            "document": "Dream speech . Words like 'carapace', 'krapkea', and 'crap' constitute the 'Kraepelin' code, a set of words that sound like parts of the proper name Kraepelin and influence/direct associational processes. The key role of the proper name can be explained by referring to the so-called cocktail party effect, which states that during a cocktail party we tune in on our discussion partner, neglecting background noise. However, we notice when someone in the background pronounces our name. This cocktail party effect has been replicated in an experimental set up using the dichotic listening technique. It has been shown that only our proper name tends to break through the attentional barrier, i.e. breaks through amidst other, neglected, sounds offered to the unattended ear. Thus it follows that our proper name is detected even under conditions of low attention. What happens within outer speech during a cocktail-party, likewise occurs within inner speech in dreams. Code words - linked in sound to our proper name - will be detected in the set of potential associations during thinking. The ongoing thinking process will then deviate because code words will act as priming-words, influencing the direction in which associations will go (Engels, 2005, p.\u00a0187).",
            "score": 135.34169006347656
        },
        {
            "docid": "4788296_38",
            "document": "Plato's Problem . Some examples from auditory perception research will be helpful in explaining the fact that our perceptual faculties naturally enhance and supplement our conscious experience. First, there is the \"cocktail party phenomenon\" (Moray, 1959). When someone is engaged in conversation with a group of people in a noisy room, but then they suddenly hear something or hear their name from across the room, when they were completely inattentive to the input before, that is the cocktail party phenomenon. This phenomenon also occurs with words associated with danger and sex. Although people may be inattentive to a portion of their environment, when they hear specific \"trigger\" words, their auditory capacities are redirected to another dimension of perceptual awareness. This shows that we do process information outside of our immediate conscious experience. Similar to visual perception, auditory perception also enhances and supplements our experience by searching out and extracting meaningful information from our environment.",
            "score": 134.9295196533203
        },
        {
            "docid": "1781678_9",
            "document": "Cocktail party effect . Selective attention shows up across all ages. Starting with infancy, babies begin to turn their heads toward a sound that is familiar to them, such as their parents' voices. This shows that infants selectively attend to specific stimuli in their environment. Furthermore, reviews of selective attention indicate that infants favor \"baby\" talk over speech with an adult tone. This preference indicates that infants can recognize physical changes in the tone of speech. However, the accuracy in noticing these physical differences, like tone, amid background noise improves over time. Infants may simply ignore stimuli because something like their name, while familiar, holds no higher meaning to them at such a young age. However, research suggests that the more likely scenario is that infants do not understand that the noise being presented to them amidst distracting noise is their own name, and thus do not respond. The ability to filter out unattended stimuli reaches its prime in young adulthood. In reference to the cocktail party phenomenon, older adults have a harder time than younger adults focusing in on one conversation if competing stimuli, like \"subjectively\" important messages, make up the background noise.",
            "score": 128.07827758789062
        },
        {
            "docid": "433584_4",
            "document": "McGurk effect . Vision is the primary sense for humans, but speech perception is multimodal, which means that it involves information from more than one sensory modality, in particular, audition and vision. The McGurk effect arises during phonetic processing because the integration of audio and visual information happens early in speech perception. The McGurk effect is very robust; that is, knowledge about it seems to have little effect on one's perception of it. This is different from certain optical illusions, which break down once one 'sees through' them. Some people, including those that have been researching the phenomenon for more than twenty years, experience the effect even when they are aware that it is taking place. With the exception of people who can identify most of what is being said from speech-reading alone, most people are quite limited in their ability to identify speech from visual-only signals. A more extensive phenomenon is the ability of visual speech to increase the intelligibility of heard speech in a noisy environment. Visible speech can also alter the perception of perfectly audible speech sounds when the visual speech stimuli are mismatched with the auditory speech. Normally, speech perception is thought to be an auditory process; however, our use of information is immediate, automatic, and, to a large degree, unconscious and therefore, despite what is widely accepted as true, speech is not only something we hear. Speech is perceived by all of the senses working together (seeing, touching, and listening to a face move). The brain is often unaware of the separate sensory contributions of what it perceives. Therefore, when it comes to recognizing speech the brain cannot differentiate whether it is seeing or hearing the incoming information.",
            "score": 125.07471466064453
        },
        {
            "docid": "32116125_4",
            "document": "Amblyaudia . Amblyaudia is a deficit in binaural integration of environmental information entering the auditory system. It is a disorder related to brain organization and function rather than what is typically considered a \u201chearing loss\u201d (damage to the cochlea). It may be genetic or developmentally acquired or both. When animals are temporarily deprived of hearing from an early age, profound changes occur in the brain. Specifically, cell sizes in brainstem nuclei are reduced, the configuration of brainstem dendrites are altered and neurons respond in different ways to sounds presented to both the deprived and non-deprived ears (in cases of asymmetric deprivation). This last point is particularly important for listening tasks that require inputs from two ears to perform well. There are multiple auditory functions that rely on the computation of well calibrated inputs from the two ears. Chief among these is the ability to localize sound sources and separate what we want to hear from a background of noise. In the brainstem, the auditory system compares the timing and levels of sounds between the two ears to encode the location of sound sources (sounds that originate from our right as opposed to left side are louder and arrive earlier in our right ear). This ability to separate sound sources not only helps us locate the trajectories of moving objects, but also to separate different sound sources in noisy environments.",
            "score": 119.11448669433594
        },
        {
            "docid": "10156148_4",
            "document": "Communication noise . Psychological noise results from preconceived notions we bring to conversations, such as racial stereotypes, reputations, biases, and assumptions. When we come into a conversation with ideas about what the other person is going to say and why, we can easily become blinded to their original message. Most of the time psychological noise is impossible to free ourselves from, and we must simply strive to recognize that it exists and take those distractions into account when we converse with others.",
            "score": 117.20285034179688
        },
        {
            "docid": "26063832_3",
            "document": "Partial concurrent thinking aloud . In general, in the usability evaluation both retrospective and concurrent TAP could be used according to the aims and goals of the study. Nevertheless, when a usability evaluation is carried out with blind people several studies propose to use the retrospective TAP: indeed, using a screen reader and talking about the way of interacting with the computer implies a structural interference between action and verbalization. Undoubtedly, cognitive studies provided a lot of evidence supporting the idea that individuals can listen, verbalize, or manipulate, and rescue information in multiple task condition. As Colin Cherry showed, subjects, when listening to two different messages from a single loudspeaker, can separate sounds from background noise, recognize the gender of the speaker, the direction, and the pitch (cocktail party effect). At the same time, subjects that must verbalize the content of a message (attended message) listening to two different message simultaneously (attended and unattended message) have a reduced ability to report the content of the attended massage, while they are unable to report the content of the unattended message. Moreover, K. Anders Ericsson and Walter Kintsch showed that, in a multiple task condition, subjects' ability of rescuing information is not compromised by an interruption of the action flow (as it happens in the concurrent thinking aloud technique), thanks to the \u201cLong Term Working Memory mechanism\u201d of information retrieval (Working Memory section Ericsson and Kintsch).  Even if users can listen, recognize, and verbalize multiple messages in a multiple task condition and they can stop and restart actions without losing any information, other cognitive studies underlined that the overlap of activities in a multiple task condition have an effect on the goal achievement: Kemper, Herman and Lian, analysing the users' abilities to verbalize actions in a multiple task condition, showed that the fluency of a user's conversation is influenced by the overlap of actions. Adults are likely to continue to talk as they navigate in a complex physical environment. However, the fluency of their conversation is likely to change: Older adults are likely to speak more slowly than they would if resting; Young adults continue to speak just as rapidly while walking as while resting, but they adopt a further set of speech accommodations, reducing sentence length, grammatical complexity, and propositional density. Just by reducing length, complexity, and propositional density adults free up working memory resources. We do not know how and how much the content of verbalizations could be influenced by the strategy of verbalization (i.e. the modification of fluency and the complexity in a multiple task condition). Anyway, we well know that users in the concurrent thinking aloud verbalize the problems in a more accurate and pertinent way (i.e. more focused on the problems directly perceived during the interaction) then in the retrospective one. The pertinence is granted to the user by the proximity of action-verbalization-next action; this multiple task proximity compels the subject to apply a strategy of verbalization that reduce the overload of the working memory. However, for blind users this time proximity between action and verbalization is lost: the use of the screen reader, in fact, increase the time for verbalization (i.e. in order to verbalize, blind users must first stop the [screen reader] and then restart it).",
            "score": 113.47718048095703
        },
        {
            "docid": "2856189_7",
            "document": "Caleb Gattegno . However, there is another way of functioning, which Gattegno called retention. An example of retention is the reception of sensory images. When we look at something \u2013 a street, a film, a person, a fine view \u2013 photons move from what we are contemplating and enter our eyes to strike the retina. When we listen to something, we create auditory images in a similar way, that is, through energy that enters our system, rather than energy we allocate from inside, to memorize an arbitrary item. To retain an auditory or visual image, we have to use perhaps only an insignificant amount of our own to retain it; the amount is so small we are not aware of any effort. Such images are easily acquired and generally remain for long periods. We all have experiences similar to the following examples Gattegno offered:",
            "score": 113.43490600585938
        },
        {
            "docid": "344859_26",
            "document": "New media . When we think of interactivity and its meaning, we assume that it is only prominent in the conversational dynamics of individuals who are face-to-face. This restriction of opinion does not allow us to see its existence in mediated communication forums. Interactivity is present in some programming work, such as video games. It's also viable in the operation of traditional media. In the mid 1990s, filmmakers started using inexpensive digital cameras to create films. It was also the time when moving image technology had developed, which was able to be viewed on computer desktops in full motion. This development of new media technology was a new method for artists to share their work and interact with the big world. Other settings of interactivity include radio and television talk shows, letters to the editor, listener participation in such programs, and computer and technological programming. Interactive new media has become a true benefit to every one because people can express their artwork in more than one way with the technology that we have today and there is no longer a limit to what we can do with our creativity.",
            "score": 113.22439575195312
        },
        {
            "docid": "54542174_3",
            "document": "Rain (The Script song) . The Script described the track as a \"feel-good summer tune\". \"After a very long process of making 'Album 5', the song 'Rain' came right at the end. It's a summer song so we thought, only The Script can make it 'Rain in Summer'\" the band stated. In an interview with \"Metro\", the band regarded the single as a progression. \"I think we have afforded ourselves a little bit of leeway. The past four records have been not the same sound but we've been progressing at a slow rate. It's been two years since we had something out so there's two years worth of progression in our music. I'm sure to a lot of people it might sound quite drastic at first but if they heard the 60 songs we've put out you'd hear a slower progression.\" When asked if their change in sound was deliberate, they said:\"When we started this record we wanted to do something where people would hear a song and go 'oh I love that song!' and then look it up and find it's us. We wanted to change our sound a push our sound a bit. It's either adapt, change or die in this industry. It's very difficult in this industry. We wanted to revamp and reboot the sound and at the end of the day we're still the same songwriters and that's never going to go away.\"The band said that they always \"want something different in our lives\" and \"hoping our songs penetrate different markets and gain new fans\", They referred themselves as an ambitious band. \"With Rain we just decided we needed something a bit lighter, you can't just walk into a party of people and start with a heavy topic. It's nice to have a bit of escapism that people can bob their head to and not be so serious about but when people peel the layers of the song they realise that lyrically we've gone deep but on the surface we wanted people to have a bit of fun.\"",
            "score": 113.18375396728516
        },
        {
            "docid": "1781678_2",
            "document": "Cocktail party effect . The cocktail party effect is the phenomenon of the brain's ability to focus one's auditory attention (an effect of selective attention in the brain) on a particular stimulus while filtering out a range of other stimuli, as when a partygoer can focus on a single conversation in a noisy room. Listeners have the ability to both segregate different stimuli into different streams, and subsequently decide which streams are most pertinent to them. Thus, it has been proposed that one's sensory memory subconsciously parses all stimuli, identifying discrete pieces of information and classifying them by salience. This effect is what allows most people to \"tune into\" a single voice and \"tune out\" all others. It may also describe a similar phenomenon that occurs when one may immediately detect words of importance originating from unattended stimuli, for instance hearing one's name among a wide range of auditory input.",
            "score": 113.18087005615234
        },
        {
            "docid": "43894656_7",
            "document": "Agents of S.H.I.E.L.D. (season 2) . In September 2014, talking about whether the ending of the season would also be a satisfying end to the series, Bell said \"we're not thinking of it as a series finale as much as a season finale ... I think we have some momentum coming in [to season 2] and I think we pick up on it. I'm optimistic that we can keep the plane in the air a little longer.\" He also talked about whether the themes of family and connectedness from the first season would be re-explored in the second, saying \"What we always look for are the human elements in the big story. That's what television does well, it makes you care about people, and whether it's literal family or anytime you have a team of people working together, it takes on some sort of family metaphor.\" Bell reiterated the idea of family following the end of the season, saying \"In many ways, the whole metaphor at the heart of the show is family\u2014you've got Coulson and May and then a bunch of younger people, and it allows us to play out different dynamics; literally, this season, we had Skye's biological parents versus her surrogate parents. And at the same time, we had Skye growing up. We had her going from a slightly sulky hacker season one to training to become an agent to becoming our first full-fledged superhero and so as we grow up, we separate from our parents... In our minds, her mom wasn't a villain so much; she was an antagonist, but if you look at why she feels the way she does, Jiaying really earned that position.\" Discussing the reveal that Skye is actually Daisy Johnson, Maurissa Tancharoen explained thatJohnson is a character that we always liked. We always knew there was a potential to evolve Skye into something else. It took a little bit of time, but we were happy when we were able to land on Daisy Johnson, and actually have that work in our mythology. But as with everything that we do on the show, we pull from the properties, and we do our own spin to it. So we are kind of merging a few concepts and storylines. We've spent a season and a half with Skye. We've seen her evolve as a person, we've grown to like her as a person, we've seen her evolve as an agent. And now, finally bringing her to her origin story\u2014I think there's just a lot more emotional weight to it, because you already know her as just Skye, and now she will have this ability that she may not understand, that she may not want ... We're going to focus on Skye, and how that affects the people around her, and how the relationships may shift. Because we've seen through the course of our series so far; we've spoken about how S.H.I.E.L.D. treats gifteds or views them, and they're categorized, things like that. What does that mean when one of your own is now considered someone with an ability? How do you categorize her?Whedon elaborated that \"We're going to walk her through the steps of discovering what this really means, and coming to terms with it. All that stuff is really interesting to us, and in television, because we have time to explore, we can take her origin on all sorts of different paths.\" Additionally, Whedon talked about how the character would be referred to on the show after the reveal, saying, \"She's still Skye, because \"she\" thinks she's Skye. I think her dad thinks she's Daisy, and we'll see if she ever gets to the point where she believes that that's something that she would want to call herself. But right now, she has her own identity.\"",
            "score": 111.66963195800781
        },
        {
            "docid": "34259469_10",
            "document": "Arike . The film uses sync sound recording or live sound recording. Shyamaprasad brought in Sohel Sanwari from Bollywood to record the sound. Says Shyamaprasad, \"This is something I\u2019ve always wanted to do. The early talkies had speech recorded live but the change to outdoor locations made carrying recording cameras cumbersome. Added to this was the fact that technicians and stars started travelling and this started the trend of dubbing. I feel that we lose 50 to 60 per cent of the performance when we post-synchronise voices. Take for example a scene on the seashore \u2014 our body, voice modulation and mannerisms are in sync with the surroundings. Dubbing in a studio means that a lot of vocal nuances get lost!\" Lead player Dileep describes the sync sound recording experience, \"I had to memorise the entire dialogues beforehand and deliver them at one go after umpteen rehearsals. It was a very novel experience for me and I personally feel that it increases one\u2019s memory power.\" Samvrutha Sunil says, \"This is my first film where our voices have been recorded live during our respective performances. The sync sound recording actually threw open many challenges - one, you can't console yourself for a not-up-to-the-mark performance saying that you can cover it up with a good dubbing and two, you have to byheart the dialogues thoroughly as there is no prompting.\"",
            "score": 111.63941192626953
        },
        {
            "docid": "35988494_3",
            "document": "Selective auditory attention . The cocktail party problem was first brought up in 1953 by Colin Cherry. This common problem is how our minds solves the issue of knowing what in the auditory scene is important and combining those in a coherent whole, such as the problem of how we can perceive our friend talking in the midst of a crowded cocktail party. He suggested that the auditory system can filter sounds being heard. Physical characteristics of the auditory information such as speaker's voice or location can improve a person's ability to focus on certain stimuli even if there is other auditory stimuli present. Cherry also did work with shadowing which involves different information being played into both ears and only one ear's information can be processed and remembered (Eysneck, 2012, p.\u00a084). Another psychologist, Albert Bregman, came up with the auditory scene analysis model. The model has three main characteristics: segmentation, integration, and segregation. Segmentation involves the division of auditory messages into segments of importance. The process of combining parts of an auditory message to form a whole is associated with integration. Segregation is the separation of important auditory messages and the unwanted information in the brain. It is important to note that Bregman also makes a link back to the idea of perception. He states that it is essential for one to make a useful representation of the world from sensory inputs around us. Without perception, an individual will not recognize or have the knowledge of what is going on around them. While Begman's seminal work is critical to understanding selective auditory attention, his studies did not focus on the way in which an auditory message is selected, if and when it was correctly segregated from other sounds in a mixture, which is a critical stage of selective auditory attention. Inspired in part by Bregman's work, a number of researchers then set out to link directly work on auditory scene analysis to the processes governing attention, including Maria Chait, Mounya Elhilali, Shihab Shamma, and Barbara Shinn-Cunningham.",
            "score": 110.21430969238281
        },
        {
            "docid": "2973525_7",
            "document": "Confidence . It is suggested that the confidence bias can be explained by a noisy conversion of objective evidence (observation) into subjective estimates (judgment), whereas noise is defined as the mixing of memories during the storing (observing/learning) and retrieval process (remembering/judgment). The information-theoretic logic behind this explanation is very similar to the mechanism that can also lead to the conservatism bias, and holds that we mix true and false evidence during storage and retrieval of evidence to and from our memories. The confidence bias results because as judges we \"look inside our own memory\" (evaluate our confidence) and find evidence that is more extreme than when we retrieve evidence for our judgements (which are conservative due to mixing of extreme values during retrieval). This explanation is very simple and straightforward, but nevertheless sufficient mechanism to generate both, overconfidence (in situations where judges are very sure) and underconfidence (in cases when judges openly state to lack the required knowledge).",
            "score": 109.97503662109375
        },
        {
            "docid": "36449834_3",
            "document": "Voxeet . During a real-life conversation, sounds follow a complex journey before reaching the listener's ears for decoding by the brain. The human brain analyses the sounds and all their alterations to determine the source's position in the room. This enables the brain to know instantly who the speaker is, even without recognizing his voice or seeing the speaker. In a crowded room with lots of background noise, the brain can isolate specific sounds and can focus on decoding the information or voice that matters while disregarding the others, a phenomenon also called the cocktail party effect.",
            "score": 109.91014862060547
        },
        {
            "docid": "91452_18",
            "document": "John B. Watson . Watson called language a \"manipulative habit.\" He called it this because when we speak language, the sound originates in our larynx, which is a body instrument that we manipulate every time we talk in order to hear our \"voice.\" As we change our throat shape and tongue position, different sounds are made. Watson says when a baby first cries, or first says \"da\" or \"ma,\" that it is learning language. Watson also used an experiment that he and his wife conducted, in which they conditioned a baby to say \"da-da\" when he wanted his bottle. Although the baby was conditioned and was a success for a short while, the conditioning was eventually lost. Watson does say, however, that as the child got older, he would imitate Watson as a result of Watson imitating him. By three years old, the child needed no help developing his vocabulary because he was learning from others. Thus, language is imitative.",
            "score": 109.88629150390625
        },
        {
            "docid": "1244240_11",
            "document": "Noise shaping . Noise shaping in audio is most commonly applied as a bit-reduction scheme. The most basic form of dither is flat, white noise. The ear, however, is less sensitive to certain frequencies than others at low levels (see Fletcher-Munson curves). By using noise shaping we can effectively spread the quantization error around so that more of it is focused on frequencies that we can't hear as well and less of it is focused on frequencies that we can hear. The result is that where the ear is most critical the quantization error can be reduced greatly and where our ears are less sensitive the noise is much greater. This can give a perceived noise reduction of 4 bits compared to straight dither. While 16-bit audio is typically thought to have 96 dB of dynamic range (see quantization distortion calculations), it can actually be increased to 120 dB using noise-shaped dither.",
            "score": 108.73930358886719
        },
        {
            "docid": "309379_13",
            "document": "Symbolic interactionism . Symbolic interactionists describe thinking as an inner conversation (Griffin 62). Mead called this inner dialogue minding, which is the delay in one's thought process that happens when one thinks about what they will do next. These meanings are handled in, and modified through, an interpretative process used by the person in dealing with the things he encounters. We naturally talk to ourselves in order to sort out the meaning of a difficult situation. But first, we need language. Before we can think, we must be able to interact symbolically (Griffin 62). The emphasis on symbols, negotiated meaning, and social construction of society brought on attention to the roles people play. Role-taking is a key mechanism that permits people to see another person's perspective to understand what an action might mean to another person. Role-taking is a part of our lives at an early age, for instance, playing house and pretending to be someone else. There is an improvisational quality of roles; however, actors often take on a script that they follow. Because of the uncertainty of roles in social contexts, the burden of role-making is on the person in the situation. In this sense, we are proactive participants in our environment.",
            "score": 108.20085144042969
        },
        {
            "docid": "914661_18",
            "document": "Revis . Davis summed up the band's label issues and eventual demise: We had no contract with the label the whole time we were working with them, and they were helping us start our career and put money towards a tour...We went back to the same studio and had this conversation with Jay Baumgardner, and he said he\u2019d love to sign us but they weren\u2019t close to getting contracts done. So we said let\u2019s start recording and get the ball rolling, and we did, but then this contract got presented to us that just wasn\u2019t fair. It just didn\u2019t make any sense, and we wouldn\u2019t have been able to survive off the terms. We went out and did a little bit of touring, and that got cut short because of the financing, and then we couldn\u2019t see eye to eye about the choice to keep going. I wanted to keep touring, Justin didn\u2019t. He wanted something more secure, and I said let\u2019s just play the shows because there were fans out there, but we just didn\u2019t see eye to eye. I\u2019m not saying I was right or I was wrong, we just couldn\u2019t decide what we should do and we couldn\u2019t be together any more. Later on we had some more conversations that went in the same direction, and we couldn\u2019t see eye to eye. Eventually we just stopped talking. There were so many good songs that I want to get out there, but we just can\u2019t put them out with that band. I\u2019m doing everything I can to help [the songs] see the light of day through other projects. Davis did iterate that some of the songs may still see release as part of the future \"Save Our Souls\" documentary soundtrack, which, despite the name, is not about the Revis song, but about the effects of Hurricane Katrina on the burlesque industry of New Orleans.",
            "score": 108.01273345947266
        },
        {
            "docid": "7015435_6",
            "document": "New Test Leper . \"<nowiki>'New Test Leper'</nowiki> is something that we only played at soundcheck, like, twice,\" Buck explained in another interview, this time to \"Addicted to Noise\"'s Michael Goldberg, also in 1996. \"And for some reason, we just forgot about it and never really played it. I don\u2019t know why. Michael just happened to luckily enough have it on tape. He says, \u2018I\u2019ve got this great stuff for that song and none of us even remember playing it. So we cut it here in Seattle when we did the record. I think it\u2019s probably the most R.E.M.-ish sounding thing on the record. Literally, Michael was watching one of those talk shows and I think the subject was \u2018People judge me by the way I look\u2019 or something. Whereas I, when I have the misfortune to look for two minutes at one of those Oprah, Geraldo things, I just get revolted at everyone concerned: the audience, me. Michael actually looked at it and felt like, \u2018Gosh, what if someone\u2019s actually trying to communicate something to these people and this person who\u2019s in this awful, tacky, degrading situation?\u2019 So it\u2019s written from that perspective. And I think probably having done press conferences in the past and being in those kinds of situations, there might be a little empathy from experience that we\u2019ve had.\u201d",
            "score": 107.91951751708984
        },
        {
            "docid": "7344_24",
            "document": "Cogito, ergo sum . Bernard Williams claims that what we are dealing with when we talk of thought, or when we say \"I am thinking,\" is something conceivable from a third-person perspective; namely objective \"thought-events\" in the former case, and an objective thinker in the latter. He argues, first, that it is impossible to make sense of \"there is thinking\" without relativizing it to \"something.\" However, this something cannot be Cartesian egos, because it is impossible to differentiate objectively between things just on the basis of the pure content of consciousness. The obvious problem is that, through introspection, or our experience of consciousness, we have no way of moving to conclude the existence of any third-personal fact, to conceive of which would require something above and beyond just the purely subjective contents of the mind.",
            "score": 107.89659118652344
        },
        {
            "docid": "31052882_7",
            "document": "Close to Home (band) . \"\"Never Back Down\" is our first label debut album! We spent all of 2010 creating this record and getting everything in place to release it! I just wanted to take a moment to tell you a little about the process of making this record and what the concept for it was. When we were first told we would be doing a full length we sat down and put a lot of thought in what direction we wanted to go with it, musically and lyrically. We have always tried our best to be real in everything we do and write what is real to us so the concept of the record formed there. We decided to make a record that would be an exact reflection of our lives, in a way that any one can appreciate. For those who have been supporting us for a long time you know about the struggles we have gone through personally and business wise in pursuit of what we love. It has never been an easy journey but we have always been relentless and 'DIY' in our efforts. The album title and artwork are fairly simple in what it portrays. Being the underdog and coming up against something massive in front of you. The content of the record itself is something we are all very proud of. Musically it is influenced by everything we have ever loved and we believe will take the listener on a journey. It shows the good and the bad of going after what you love and sacrificing everything. We tried to show that also musically as much as lyrically. Some songs are a lot more fun and tell the good side of our lives. The friendship, traveling, partying, creating memorable moments in life worth fighting for and just a love for the people and music itself. The other side to that is some of the heaviest music we have wrote yet and portrays the downsides and struggles. Always being gone and slipping away from understanding what it will ever be like to be 'normal' again. The strain it puts on friendships and all relationships in life. The people who want to pollute the music, talk shit, and infect it with impure intentions. We shot a music video to the song 'All We Know' which is a summary of what the record is about. The album name \"Never Back Down\" comes out of this song. We wanted the record to be something anyone who has ever pursued what they love in life, sacrificed or overcome great obstacles could appreciate. Can't wait for people to give it a listen from beginning to end! To hear it as one total work and give us feedback\". - Close to Home",
            "score": 107.68096923828125
        },
        {
            "docid": "3218480_10",
            "document": "Katt Williams . On September 3, 2015, during an interview, Williams would announce and describe the name of his new upcoming tour entitled \"Conspiracy Theory\" stating, \"The conspiracy conversation is a conversation that we are all familiar with. We know that there are conspiracies out there, but this is a conversation that encompasses a lot of things that aren't being discussed other places. That's the basis for all conspiracy theories: the fact that there is hidden information out there, and how our process changes about things that we thought we used to know. We all, at some point, if we're are at a certain age, we grew up thinking Pluto was a planet. This is probably going to go down as one of my finest works, just because it's a collection of forbidden topics that we can't seem to get answered. I am one of the rare urban public officials. Part of my guarantee in my ticket price is that I'm going to be talking about what we are talking about now, and discussing from now to the next time we see [me] again. This is the open discussion that we've had since 2003. This is what it is about.\"",
            "score": 107.60064697265625
        },
        {
            "docid": "54730019_11",
            "document": "Human Flow . Ai's outspoken activism and artistic purpose constantly challenges issues in regards to freedom and human rights. Ai's social commentaries on the refugee crisis relate to his personal life, as he was forced out of Beijing with his family, as a young child during China's Cultural Revolution. He is open about his dehumanizing experience of living in a Chinese camp with terrible conditions. His art has often been at the forefront in bringing about awareness to the refugee crisis, he was quoted explaining that Human Flow attempts to show the viewer the similarities between individuals \"Understanding of humanity is above all. It's about, We're all the same. If someone being hurt, we are being hurt. So that kind of ideology has to be shared only by doing that have we had compassion for other people. We lost our home too. So that kind of ideology has to be shared only by doing so that have we have compassion for other people. We can tolerate something we'd normally think is so so foreign and so different. Someone lost their education, you feel, Oh, that could be my son. Some women have no place to deliver their children, you will say, That could be my mom or my wife. So those things we have to sounds very simple but we have to repeatedly talk about that. That makes us better as a society\". Ai's efforts have gone on to explain that this issue would sooner be solved when we all realize this crisis is \"about all of us\".",
            "score": 107.33515167236328
        },
        {
            "docid": "35568995_20",
            "document": "Hannibal (TV series) . In March 2016, De Laurentiis blamed online piracy of the series as part of the reason for cancellation. In May 2016, Mikkelsen commented on a possible revival, stating, \"It all depends on Bryan. He is the key, the base, the heart. We will wait and see what happens next in his career. But we all know that we can easily pick this up in two or three years, there are breaks in the stories. We could pick it up, say, four years later. If Bryan is up for it, we will all go for it.\" In June 2016, Fuller stated, \"The cast is game, I'm game, it's just a matter of finding the right time where everybody's schedules sync up, but I would love to continue to tell the story with Hugh Dancy and Mads Mikkelsen. They're such fantastic collaborators, and one of the most satisfying actor-showrunner relationships I've ever had in this industry. So I would love to continue this story.\" He also revealed other information dealing with rights: \"Two years after the last airing of the show, we can investigate our options [...] August 2017 is when we can actually start talking about it. That's when we would have to see what the rights are for the character and for the story, and see who's interested and how we get it done. I have the story, and the cast is excited for the story, so we're ready to go if somebody wants to go.\" In December 2016, Fuller confirmed his plans for a \"Silence of the Lambs\" miniseries in an interview on the Blumhouse Productions podcast, stating, \"I think the film adaptation is a perfect film, but there are a lot of interesting nooks and crannies in that book to explore in a television series.\" In August 2017, formal conversations on the revival had begun.",
            "score": 107.09213256835938
        },
        {
            "docid": "41358018_4",
            "document": "V\u00f6lkerpsychologie . Wundt was very interested in the human nature of language. He wanted to know how apperception and thinking were related to language. V\u00f6lkerpsychologie was a great way to study and research this, which is what he did. Before Wundt, there were many other theorists that associated thought with language. Many argued that silent thinking was a form of talking with oneself. Wundt did not agree with this idea. He came up with several situations in which a person\u2019s thoughts do not fully do justice to what they are actually thinking. When having conversations, people may tend to say \u201cThat\u2019s not what I had meant to say\u201d or may wonder why they said something, when they realize that they are saying something which might not accurately depict what they are thinking internally. People will do this all the time, and this was a topic that Wundt used V\u00f6lkerpsychologie to study. When someone disagrees with a statement that someone has made in conversation, we may find ourselves interrupting with a \u201cWhat? Wait a minute, you are incorrect!\u201d long before we can actually describe the actual point of disagreement. We tend to say things before our mind understands exactly why we say them. These examples are the exact reasons that Wundt used to promote his new branch of psychology, and why he thought that words and thoughts are different things.",
            "score": 107.0054931640625
        },
        {
            "docid": "55214999_7",
            "document": "When We . The music video for \"When We\" premiered via Tank's YouTube channel on August 16, 2017. While talking about the video in an interview with \"Billboard\", Tank said: \"Well, I wanted the song to sound literal. But, I also wanted people to explore their horizons, in terms of their sexuality. I think sometimes people can be basic in these moments. And, it is not because they are trying to be basic. Sometimes, you just get accustomed to doing a certain thing all the time. And it works for you. Sometimes we forget to be creative [in bed]. We forget to use our imagination. So, even though the song has a very literal word, that word can go so many different ways. That is what I wanted to show. How deep, and how dark this word can be. And, how beautiful at the same time.\"",
            "score": 106.81848907470703
        },
        {
            "docid": "2218939_13",
            "document": "Dove Campaign for Real Beauty . With the positive and negative feedback received from the viewers and consumers of the campaign the Dove Company did not just want to \u201ctalk\u201d to media about the problem they wanted to \u201cact\u201d on the issues and embrace the advantages of the campaign for the future. In the article, \"\u201cDove\u2019 Real Beauty Campaign Turns 10: How a Brand Tried To Change The Conversation About Female Beauty\u201d\", written by Nina Bahadur from the HuffPost interviewed a spokesperson for the Dove Company about the types of feed back they have got from the Dove Real Beauty Campaign and how it has impacted the company. Sharon MacLeod, vice president of Unilever North America Personal Care, told HuffPost\"[We were thinking], we have to walk the talk\u201d she also stated \u201cWe can't just be getting people stirred up; awareness and conversation isn't enough. We actually have to do something to change what's happening.\u201d Since the start of the campaign, Dove has started funds for women and girls to promote their message along with more advertisings in attempt to bring more awareness to women of different ages and cultural background. The company of Dove believes they still have a chance to bring a greater impact on society and the generations to come when it comes to the impact of societies views of beauty and the impact it has on women and young girls. As stated in the interview with MacLeod \"We're going to try to change a generation,\" MacLeod tells HuffPost\u201dYou have to wait until they grow up to see what happens.\u201d Some critiques on the other hand believe that the campaign focuses to greatly on the physical aspect of beauty instead of other areas that should have more focus. From The Cut, Ann Friedman states the following about the Dove Real Beauty Campaign: \u201cThese ads still uphold the notion that, when it comes to evaluating ourselves and other women, beauty is paramount. The goal shouldn\u2019t be to get women to focus on how we are all gorgeous in our own way. It should be to get women to do for ourselves what we wish the broader culture would do: judge each other based on intelligence and wit and ethical sensibility, not just our faces and bodies.\u201d Critics and defenders of the Dove Real Beauty Campaign have both pointed out on occasion that because just cause Dove is trying to redefine what society and women believe as beauty does not essentially mean that women and younger girls will feel different about themselves, this is also stated by Ann Friedman when she suggests to the HuffPost as evidence that Dove's message about beauty is important and necessary. An estimated 80 percent of American women feel dissatisfied with their bodies, and 81 percent of 10-year-old girls are afraid of becoming \"fat.\" Can a series of ad campaigns really change institutionalized body hatred?",
            "score": 106.63333129882812
        },
        {
            "docid": "20261591_12",
            "document": "Covering: The Hidden Assault on Our Civil Rights . \"The gay critique of assimilation begins here. Conversion is the ultimate demand for assimilation- while passing and covering leave the underlying identity relatively intact, conversion destroys it. When someone asks for conversion, the difference between the two available refusals is immense. Which will we choose? Will we say we cannot change? Or will we, like the early gay activists, say we will not change, meeting the demands for conversion with a demand for equality?\" While in Oxford, Yoshino had fallen in love. The person he loved was not a woman. He had to tell his dad this. He then came out to his mom. Though they were both supportive, he knew that this was not what they wanted. Passing is best defined through the \u201cDon\u2019t ask, don\u2019t tell\u201d policy, which has been in effect since the Congress and the Department of Defense put it in place in 1993. Rather than trying to change a gay person\u2019s perspective and likings, they would just ignore the fact that a person was gay. The shift from conversion to passing was gradual and did not necessary represent an advance in society's acceptance of homosexuals, because of their overlapping. Passing was an act that his parents demonstrated. Though they accepted the fact that Kenji was gay, it was not something talked about, and more ignored from their thought of their son.",
            "score": 106.4069595336914
        },
        {
            "docid": "29329_18",
            "document": "Spectrum . A source of sound can have many different frequencies mixed. A Musical tone's timbre is characterized by its harmonic spectrum. Sound in our environment that we refer to as \"noise\" includes many different frequencies. When a sound signal contains a mixture of all audible frequencies, distributed equally over the audio spectrum, it is called white noise.",
            "score": 106.32760620117188
        },
        {
            "docid": "2384297_6",
            "document": "The Lives of a Cell: Notes of a Biology Watcher . This essay focuses on how connected humanity is to nature and how we must make strides to understand our role. Thomas argues that even our own bodies are not solely ours since the mitochondria and other organelles are descended from other organisms. He creates a metaphor of the Earth as a giant cell itself with humans just as one part of a vast system. Astronauts must be decontaminated before they are allowed to interact on Earth. Thomas states that this is an act of \u201chuman chauvinism.\u201d Most organisms on Earth are symbiotic or, if harmful, have both adapted to warn the other. All organisms on Earth are interdependent and a stray virus or bacteria from the moon will not be adapted to harm us since it is not part of this connection. Bacteria are interconnected to the point where some cannot survive without others and some even live within others. We must recognize how interconnected even the smallest organisms are on Earth; especially if we must interact with life outside our planet. Thomas introduces one of his key metaphors of humans behaving like ants. He suggests that this metaphor is not used because humans do not like to be compared to insects that, as a society, can function as an organism. There are many examples of animals acting as a large organism when in large groups from termites and slime molds to birds and fish. Thomas argues that the communication of results in science puts humans in the same model as these other species. As all scientists communicate and build on each other\u2019s work in order to explore that which we do not know. Humans fear pheromones because we believe we have gone above the basic secretion of chemicals in our communication. However, there are signs that point to humans relying on pheromones as well as our most technological forms of communication. Thomas shows pheromones in the animal world with examples of moths and fish. He then goes on to explain what impact pheromones in humans could have on the future such as in the perfume industry and finding histocompatible donors. Music is the only form of communication that saves us from an overwhelming amount of small talk. This is not only a human phenomenon, but happens throughout the animal world. Thomas makes examples of animals from termites and earthworms to gorillas and alligators that perform some sort of rhythmic noise making that can be interpreted as music if we had full range of hearing. From the vast number of animals that participate in music it is clear that the need to make music is a fundamental characteristic of biology. Thomas proposes that the animal world is continuing a musical memory that has been going since the beginning of time. Thomas argues that even though we have the technological advancements to destroy the Earth that we do not know near enough about the world in which we live. To solve this problem he suggests that we should not be able to fire nuclear weapons without being able to explain one living thing fully. The organism that Thomas proposes is the protozoan Myxotricha paradoxa. There is information known about this protozoan that lives in the digestive tract of Australian termites but with more study it could be a model for how our cells developed. It is seen throughout nature that organisms cooperate and progress into more complex forms. We cannot destroy vast amounts of Earth with nuclear weapons until we understand how interconnected we all are. Thomas presents the three levels of technology in medicine: \u201cnontechnology\u201d that helps patients with diseases that are not well understood but does not help solve the underlying mechanisms of the disease, \u201chalfway technology\u201d that makes up for disease or postpones death for diseases whose courses we cannot do much about, and \u201chigh technology\u201d that from understanding the mechanism of the disease we are now able to cure. When looking at the costs of the three different technologies they are all needed, but once a \u201chigh technology\u201d is found for a disease the benefits outweigh the costs of studying the mechanism of the disease so thoroughly. Thomas suggests that in order to save money in health care, the highest priority in funding should be given to basic research. Humans leave a trace of chemicals in every place they go and on everything they touch. Other animals use signaling mechanisms to leave trails or identify each other. The sense of smell is an important sense in using these mechanisms, but it is still not well understood. Humans, compared to the rest of the animal world, do not have a good olfactory sense though we may be better than we first assume. Johannes Kepler once argued that the Earth is an immense organism itself, with chemical signals spreading across the globe through various organisms in order to keep the world functioning and well informed. Tau Ceti is a nearby sun-like star that we are on the verge of being able to begin making contact with, as well as other celestial bodies, to search for life. We have been attracted to the vast regions of space outside our Earth bubble and what they could hold. If extraterrestrial life is found, it scientifically would make sense, but the social impact of no longer being unique would give humans a new sense of community. The question of what information to send out is answered by Thomas by sending music, specifically Bach. It is timeless and the best language we have to express who we are. If possible Thomas also suggests sending art. However, the questions of what to send will not stop once we receive a reply. As humans we always evade death, despite how it is a natural part of our lives. Unless it is far removed, as in war or on television, then we can discuss it without a problem. It is a subconscious effort that by not thinking about death we may continue to live. Nevertheless, even if we cured all diseases we still would die one day. We must not fear death and research the dying process just as we would any other biological process. Most people who have a near death experience do not recall any pain or fear. It is perhaps the loss of consciousness that people fear more than death itself. Thomas returns to his pondering of the social behaviors of insects in this essay. He discusses the change in behavior of insects in groups and singular insects. We have used insects and their behavior to convey lessons, rules, and virtues and now they have been used in art. Thomas describes an art exhibit with living ants, surrounded by humans who act in a similar manner to the ants themselves. Thomas praises the Marine Biological Laboratory as \u201ca paradigm, a human institution possessed of a life of its own, self-regenerating, touched all around by human meddle but consistently improved, embellished by it.\u201d It attracts the brightest minds and makes great strides in science autonomously. Thomas paints pictures with his description of scientists covering the beach with their diagrams and making \u201cmusic\u201d of discussion after a lecture at the MBL. Humans have to learn how to walk, skip, and ride a bicycle but inside our bodies perform specific manipulations from birth that we do not need to learn. There is new research that suggests humans may be able to change these inner processes with teaching. Thomas reasons that his body has been functioning fine without him trying to control every little process so he will let it continue to do so. He suggests to try the exact opposite and try to disconnect from your body altogether. The biologic revolution is filling in the gaps in understanding about how our cells function. As we begin to understand more about organelles it is clear that they are not originally created from our cells. Mitochondria and chloroplasts most likely have a bacterial ancestry and flagellae and cilia most likely were once spirochetes. It is not necessarily a master-slave relationship that we have with our organelles, but one where their ancestors found an easy way to stay protected and secure. We have brought them along with us as we evolved and yet we do not understand them completely. Organelles and eukaryotic cells are one of the most established symbiotic relationships. We treat bacteria as an ever present enemy even though there are only a small number that actually cause disease, and by accident in most cases. Bacteria normally do not gain anything by causing illness or death in their hosts. Our illness is mostly caused by our immune system doing too great of a job in response to bacteria in our system. The strength of our response is not necessary for most cases, but remains from a primitive time. Health care has become the new name for medicine though this is a misnomer since illness and death cannot be totally eradicated. Thomas argues that to understand how medicine should be used we should look to those internists that are involved in the system. Most things get better in a short while by themselves, so we should no longer be instilling in the public a constant fear of failed health. This will be the best way to solve the problem of funding health care since people will only use it when it is necessary. There are different degrees of social behavior in animals. However, it is not clear where humans fit on the scale. Most signs point that we are above the social behavior of ants and bees that go about a singular task as a whole community. Language is the one trait that brings us to the level of such animals. All humans engage in language and are born with the understanding of language. Language, and perhaps along with art and music, is the core of our social behavior. The human mind comes with the understanding of how to deal with and use language. We store up information as a cell stores energy, though with language, this information can be put to further use. Another main difference between language and other communication systems in biology is the ambiguity that is a necessity in language which would cause the other communication systems to fail. Death is not supposed to happen in the open, along highways and in sight of others. Everything is in the process of dying all around us, though we keep it hidden from our sight and minds. Death is part of the cycle and we need to understand we are part of a larger process. The process of dying is necessary for the birth of the new and we will all experience it together. Thomas explains science as a wild manifestation of human behavior. He explains that science and discovery is a compulsion that scientists seem to have written in their very genes. Science cannot be organized and forced; it must be free to go where the next question leads. It is similar to a bee hive in some sense, but also to animals on a hunt. The activity is never ending and the conglomeration of minds always yearning for the next discovery cannot be kept under control. How humans approach nature has been changing throughout recent years. We used to view nature as ours to control and use to better mankind. Now we have moved away from this view and seen that we are part of the larger system and not the ruler of it. However Thomas argues that we must see ourselves as \u201cindispensable elements of nature\u201d and work for the betterment of the Earth but also be able to protect ourselves. This essay focuses on the tribe of Iks in northern Uganda. Thomas comments on an anthropologist\u2019s report on the Iks that argues that they represent the basic elements of mankind. Thomas instead thinks that each Ik acts as a group and that by observing the whole tribe of Iks you can see how we behave in groups ranging from committees to nations. In order to improve upon our group interactions, we must stay human even when in masses. Computers are approaching humanity, but they will never be able to fully replace us for they will not be able to replicate our collective behavior because we do not understand it ourselves. We are involved in a never ending transfer of information and collective thinking. This is the cause of the unpredictability in our future. The one problem with our information transfer is that we are much better at gaining information than giving output back. Thomas explains in this essay his view on scientific funding and planning. He believes that research should be focused in basic science. Unlike basic science, disease problems do not have the right type of questions to allow for great discoveries. The distinguishing factor of basic science is that there can be an element of surprise that allows for even more discoveries to be made. It is difficult to organize plans for this type of surprise in research even though it may seem a better business model to do so. It is the improbability and maze of puzzles that occur in basic research that Thomas believes will lead us to the most knowledge. Mythical creatures were created by our ancestors but even though we presently have no need for these beasts we continue to use them. The hybridization of animals in mythology is present from multiple ancient people such as the Ganesha, Griffon, Centaur, and Sphinx. Thomas suggests that perhaps we look to replace these mythological creatures which are more biological. He suggests the Myxotricha paradoxa, blepharisma, bacteria, and plant-animal combinations that are either made up of different organisms or set up joint endeavors with more than one organism to survive. From Thomas\u2019s metaphor on how humans behave like ants, he again argues that language is the quality that best resembles social insects. Without any outside direction, humans continually change language. We build language like ants build their hill, without ever knowing what the final result is and how our minuscule changes affect any other part. Thomas explains how some words have changed and developed different meanings. Two words, gene and bheu, are two words that we have derived a great number of current words from. Their descended words: kind, nature, physics are related in the present but also in its ancestry. Thomas compares language to the social behavior of termites in this essay. He thinks of language as an organism that is alive and changing. The genes of language are how words originated when you look into each of their histories. He traces multiple words to their origins to prove his point. He comments that it would be near impossible to keep track of all roots of words back to Indo-European that you use. We should be in awe that we exist and are unique among all the humans on Earth according to probability. Though we are indeed individual organisms, Thomas argues that one\u2019s own self is a myth. He believes we are part of a larger organization of information sharing. Through this system we are adapting and creating. By being more open with communication and less restrictive we will be able to uncover even more surprising discoveries. Thomas compares the Earth to a living cell, one with its own membrane that allows it to keep out disorder. He shows how the evolution of cells was closely tied to the \u201cbreath\u201d of the Earth, the cycling of oxygen concentration in the atmosphere. The atmosphere is \u201cfor sheer size and perfection of function, it is far and away the grandest product of collaboration in all of nature.\u201d It gives us the oxygen we need, protection from UV light, and protection from the millions of meteorites.",
            "score": 106.04205322265625
        }
    ]
}