{
    "q": [
        {
            "docid": "25335695_4",
            "document": "Perceptual learning . Laboratory studies reported many examples of dramatic improvements in sensitivities from appropriately structured perceptual learning tasks. In visual Vernier acuity tasks, observers judge whether one line is displaced above or below a second line. Untrained observers are often already very good with this task, but after training, observers' threshold has been shown to improve as much as 6 fold. Similar improvements have been found for visual motion discrimination and orientation sensitivity. In visual search tasks, observers are asked to find a target object hidden among distractors or in noise. Studies of perceptual learning with visual search show that experience leads to great gains in sensitivity and speed. In one study by Karni and Sagi, the time it took for subjects to search for an oblique line among a field of horizontal lines was found to improve dramatically, from about 200ms in one session to about 50ms in a later session. With appropriate practice, visual search can become automatic and very efficient, such that observers do not need more time to search when there are more items present on the search field. Tactile perceptual learning has been demonstrated on spatial acuity tasks such as tactile grating orientation discrimination, and on vibrotactile perceptual tasks such as frequency discrimination; tactile learning on these tasks has been found to transfer from trained to untrained fingers. Practice with Braille reading and daily reliance on the sense of touch may underlie the enhancement in tactile spatial acuity of blind compared to sighted individuals.",
            "score": 151.68303906917572
        },
        {
            "docid": "25335695_22",
            "document": "Perceptual learning . However, not all perceptual learning tasks are specific to the trained stimuli or tasks. Sireteanu and Rettenback discussed discrimination learning effects that generalize across eyes, retinal locations and tasks. Ahissar and Hochstein used visual search to show that learning to detect a single line element hidden in an array of differently-oriented line segments could generalize to positions at which the target was never presented. In human vision, not enough receptive field modification has been found in early visual areas to explain perceptual learning. Training that produces large behavioral changes such as improvements in discrimination does not produce changes in receptive fields. In studies where changes have been found, the changes are too small to explain changes in behavior.",
            "score": 130.951993227005
        },
        {
            "docid": "4236583_34",
            "document": "Visual search . Studies have consistently shown that autistic individuals performed better and with lower reaction times in feature and conjunctive visual search tasks than matched controls without autism. Several explanations for these observations have been suggested. One possibility is that people with autism have enhanced perceptual capacity. This means that autistic individuals are able to process larger amounts of perceptual information, allowing for superior parallel processing and hence faster target location. Second, autistic individuals show superior performance in discrimination tasks between similar stimuli and therefore may have an enhanced ability to differentiate between items in the visual search display. A third suggestion is that autistic individuals may have stronger top-down target excitation processing and stronger distractor inhibition processing than controls. Keehn et al. (2008) used an event-related functional magnetic resonance imaging design to study the neurofunctional correlates of visual search in autistic children and matched controls of typically developing children. Autistic children showed superior search efficiency and increased neural activation patterns in the frontal, parietal, and occipital lobes when compared to the typically developing children. Thus, autistic individuals' superior performance on visual search tasks may be due to enhanced discrimination of items on the display, which is associated with occipital activity, and increased top-down shifts of visual attention, which is associated with the frontal and parietal areas.",
            "score": 104.80755949020386
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 112.7045521736145
        },
        {
            "docid": "35982062_9",
            "document": "Biased Competition Theory . A Top-down process is characterized by a high level of direction of sensory processing by more cognition; Top-down processing is based on pre-existing knowledge when interpreting sensory information. Top-down guidance of attention refers to when the properties of an object (i.e. color, shape) are activated and held in working memory to facilitate the visual search for that object. This controls visual search by guiding attention only to objects that could be the target and avoiding attention on irrelevant objects. Top-down processes are not a complete representation of the object but are coarse, which is why objects similar in color, shape or meaning are often attended to in the process of discriminating irrelevant objects. There is evidence that observers have Top-down control over the locations that will benefit from biased competition in spatial selection visual tasks. Evidence supports that observers can make voluntary decision about which locations are selected. or features that capture the attention in a stimulus-driven manner. Neurophysiology studies have showed that the neural mechanisms in Top-down processing are also seen in attention and working memory, suggesting Top-down processes play an important role in those functions as well. Additionally, Top-down processes can modulate Bottom-up processes by suppressing the \u201cpop-out\u201d features of Bottom-up processing from distracting from the visual search. fMRI studies have investigated the Top-down and Bottom-up processes involved in biased competition theory. Results of fMRI suggest that both Bottom-up and Top-down processes work in parallel to bias competition. Multiple studies have shown that stimuli in the visual field suppress each other when presented together, but not when each stimulus is presented alone. Kastner and colleagues also found that directing attention to the specific location of a stimulus reduces the suppressive effect. Increased activity in the visual cortex was also observed; this was the result of Top-down biasing due to the favoring of the attended location.",
            "score": 126.20528483390808
        },
        {
            "docid": "42980268_15",
            "document": "Visual spatial attention . It is debated in research on visual spatial attention whether it is possible to split attention across different areas in the visual field. The \u2018spotlight\u2019 and \u2018zoom-lens\u2019 accounts postulate that attention uses a single unitary focus. Therefore, spatial attention can only be allocated to adjacent areas in the visual field and consequently cannot be split. This was supported by an experiment that altered the spatial cueing paradigm by using two cues, a primary and a secondary cue. It was found that the secondary cue was only effective in focusing attention when its location was adjacent to the primary cue. In addition, it has been demonstrated that observers are unable to ignore stimuli presented in areas situated between two cued locations. These findings have proposed that attention cannot be split across two non-contiguous regions. However, other studies have demonstrated that spatial attention can be split across two locations. For example, observers were able to attend simultaneously to two different targets located in opposite hemifields. Research has even suggested that humans are able to focus attention across two to four locations in the visual field. Another perspective is that spatial attention can be split only under certain conditions. This perspective suggests that the splitting of spatial attention is flexible. Research demonstrated that whether spatial attention is unitary or divided depends on the goals of the task. Therefore, if dividing attention is beneficial to the observer then a divided focus of attention will be utilised.",
            "score": 57.42024219036102
        },
        {
            "docid": "41848173_14",
            "document": "Surround suppression . Surround suppression likely participates in context-dependent perceptual tasks. Some specific tasks in which surround suppression may aid include: These tasks require the use of inputs over wide regions of visual space, meaning that independent responses to small parts of the visual field (a classical linear model of V1) would not be able to produce these effects. There is evidence that surround suppression participates in these tasks by either adjusting the representation of the classical receptive field or representing entirely different features that include both the classical receptive field and the surround. Direct comparison between physiology and psychophysical experiments have been done on several perceptual effects. These include: (1) the reduced apparent contrast of a grating texture embedded in a surrounding grating, (2) target identification when flanked by other features, (3) saliency of broken contours surrounded by edge segments of different orientations, and (4) orientation discrimination when surrounded by features of different orientations and spatial frequencies.",
            "score": 71.50637018680573
        },
        {
            "docid": "25335695_39",
            "document": "Perceptual learning . An important potential application of perceptual learning is the acquisition of skill for practical purposes. Thus it is important to understand whether training for increased resolution in lab conditions induces a general upgrade which transfers to other environmental contexts, or results from mechanisms which are context specific. Improving complex skills is typically gained by training under complex simulation conditions rather than one component at a time. Recent lab-based training protocols with complex action computer games have shown that such practice indeed modifies visual skills in a general way, which transfers to new visual contexts. In 2010, Achtman, Green, and Bavelier reviewed the research on video games to train visual skills. They cite a previous review by Green & Bavelier (2006) on using video games to enhance perceptual and cognitive abilities. A variety of skills were upgraded in video game players, including \"improved hand-eye coordination, increased processing in the periphery, enhanced mental rotation skills, greater divided attention abilities, and faster reaction times, to name a few\". An important characteristic is the functional increase in the size of the effective visual field (within which viewers can identify objects), which is trained in action games and transfers to new settings. Whether learning of simple discriminations, which are trained in separation, transfers to new stimulus contexts (e.g. complex stimulus conditions) is still an open question.",
            "score": 133.39763593673706
        },
        {
            "docid": "68753_22",
            "document": "Attention . \"Covert orienting\" is the act to mentally shifting one's focus without moving one's eyes. Simply, it is changes in attention that are not attributable to overt eye movements. Covert orienting has the potential to affect the output of perceptual processes by governing attention to particular items or locations (for example, the activity of a V4 neuron whose receptive field lies on an attended stimuli will be enhanced by covert attention) but does not influence the information that is processed by the senses. Researchers often use \"filtering\" tasks to study the role of covert attention of selecting information. These tasks often require participants to observe a number of stimuli, but attend to only one. The current view is that visual covert attention is a mechanism for quickly scanning the field of view for interesting locations. This shift in covert attention is linked to eye movement circuitry that sets up a slower saccade to that location.",
            "score": 100.05991339683533
        },
        {
            "docid": "33431597_15",
            "document": "Attentional control . Our brains have distinct attention systems that have been shaped throughout time by evolution. Visual attention operates mainly on three different representations: location , feature, and object-based. The spatial separation between two objects has an effect on attention. People can selectively pay attention to one of two objects in the same general location. Research has also been done on attention to non-object based things like motion. When directing attention to a feature like motion, neuronal activity increases in areas specific for the feature. When visually searching for a non-spatial feature or a perceptual feature, selectively enhancing the sensitivity to that specific feature plays a role in directing attention. When people are told to look for motion, then motion will capture their attention, but attention is not captured by motion if they are told to look for color.",
            "score": 95.7160873413086
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 97.9640439748764
        },
        {
            "docid": "25335695_23",
            "document": "Perceptual learning . The Reverse Hierarchy Theory (RHT), proposed by Ahissar & Hochstein, aims to link between learning dynamics and specificity and the underlying neuronal sites. RHT proposes that na\u00efve performance is based on responses at high-level cortical areas, where crude, categorical level representations of the environment are represented. Hence initial learning stages involve understanding global aspects of the task. Subsequent practice may yield better perceptual resolution as a consequence of accessing lower-level information via the feedback connections going from high to low levels. Accessing the relevant low-level representations requires a backward search during which informative input populations of neurons in the low level are allocated. Hence, subsequent learning and its specificity reflect the resolution of lower levels. RHT thus proposes that initial performance is limited by the high-level resolution whereas post-training performance is limited by the resolution at low levels. Since high-level representations of different individuals differ due to their prior experience, their initial learning patterns may differ. Several imaging studies are in line with this interpretation, finding that initial performance is correlated with average (BOLD) responses at higher-level areas whereas subsequent performance is more correlated with activity at lower-level areas. RHT proposes that modifications at low levels will occur only when the backward search (from high to low levels of processing) is successful. Such success requires that the backward search will \"know\" which neurons in the lower level are informative. This \"knowledge\" is gained by training repeatedly on a limited set of stimuli, such that the same lower-level neuronal populations are informative during several trials. Recent studies found that mixing a broad range of stimuli may also yield effective learning if these stimuli are clearly perceived as different, or are explicitly tagged as different. These findings further support the requirement for top-down guidance in order to obtain effective learning.",
            "score": 97.25635409355164
        },
        {
            "docid": "25335695_31",
            "document": "Perceptual learning . Learning easy examples first may lead to better transfer and better learning of more difficult cases.  By recording ERPs from human adults, Ding and Colleagues investigated the influence of task difficulty on the brain mechanisms of visual perceptual learning. Results showed that difficult task training affected earlier visual processing stage and broader visual cortical regions than easy task training.",
            "score": 98.64012897014618
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 97.65502262115479
        },
        {
            "docid": "34176994_11",
            "document": "Cerebellar cognitive affective syndrome . The current treatments for CCAS focus on relieving the symptoms. One treatment is a cognitive-behavioral therapy (CBT) technique that involves making the patient aware of his or hers cognitive problems. For example, many CCAS patients struggle with multitasking. With CBT, the patient would have to be aware of this problem and focus on just one task at a time. This technique is also used to relieve some motor symptoms. In a case study with a patient who had a stroke and developed CCAS, improvements in mental function and attention were achieved through reality orientation therapy and attention process training. Reality orientation therapy consists of continually exposing the patient to stimuli of past events, such as photos. Attention process training consists of visual and auditory tasks that have been shown to improve attention. The patient struggled in applying these skills to \u201creal-life\u201d situations. It was the help of his family at home that significantly helped him regain his ability to perform activities of daily living. The family would motivate the patient to perform basic tasks and made a regular schedule for him to follow.",
            "score": 59.87660264968872
        },
        {
            "docid": "1215674_31",
            "document": "Visual memory . Findings surrounding sleep and visual memory have been mixed. Studies have reported performance increases after a bout of sleep compared with the same period of waking. The implications of this are that there is a slow, offline process during sleep that strengthens and enhances the memory trace. Further studies have found that quiet rest has shown the same learning benefits as sleep. Replay has been found to occur during post-training quiet wakefulness as well as sleep. In a recent study where a visual search task was administered quiet rest or sleep is found to be necessary for increasing the amount of associations between configurations and target locations that can be learned within a day. Reactivation in sleep was only observed after extensive training of rodents on familiar tasks. It rapidly dissipates; it also makes up a small proportion of total recorded activity in sleep.  It has also been found that there are gender differences between males and females in regards to visual memory and sleep. In a study done testing sleep and memory for pictures it was found that daytime sleep contributed to retention of source memory rather than item memory in females, females did not have recollection or familiarity influenced by daytime sleep, whereas males undergoing daytime sleep had a trend towards increased familiarity. The reasons for this may be linked to different memory traces resulting from different encoding strategies, as well as with different electrophysiological changes during daytime sleep.",
            "score": 61.471463203430176
        },
        {
            "docid": "25335695_19",
            "document": "Perceptual learning . However, recent studies suggest that perceptual learning occurs without selective attention. Studies of such task-irrelevant perceptual learning (TIPL) show that the degree of TIPL is similar to that found through direct training procedures. TIPL for a stimulus depends on the relationship between that stimulus and important task events or upon stimulus reward contingencies. It has thus been suggested that learning (of task irrelevant stimuli) is contingent upon spatially diffusive learning signals. Similar effects, but upon a shorter time scale, have been found for memory processes and in some cases is called attentional boosting. Thus, when an important (alerting) event occurs, learning may also affect concurrent, non-attended and non-salient stimuli.",
            "score": 101.82352662086487
        },
        {
            "docid": "21312297_20",
            "document": "Memory consolidation . Rapid eye movement (REM) sleep has been thought of to be an important concept in the overnight learning in humans by establishing information in the hippocampal and cortical regions of the brain. REM sleep elicits an increase in neuronal activity following an enriched or novel waking experience, thus increasing neuronal plasticity and therefore playing an essential role in the consolidation of memories. This has come into question in recent years however and studies on sleep deprivation have shown that animals and humans who are denied REM sleep do not show deficits in task learning. It has been proposed that since the brain is in a non-memory encoding state during sleep, consolidation would be unlikely to occur. Recent studies have examined the relationship between REM sleep and procedural learning consolidation.  In particular studies have been done on sensory and motor related tasks. In one study testing finger-tapping, people were split into two groups and tested post-training with or without intervening sleep; results concluded that sleep post-training increases both speed and accuracy in this particular task, while increasing the activation of both cortical and hippocampal regions; whereas the post-training awake group had no such improvements. It has been theorized that this may be related more-so to a process of synaptic consolidation rather than systems consolidation because of the short-term nature of the process involved. Researchers examining the effect of sleep on motor learning have noted that while consolidation occurs over a period of 4\u20136 hours during sleep, this is also true during waking hours, which may negate any role of sleep in learning. In this sense sleep would serve no special purpose to enhance consolidation of memories because it occurs independently of sleep. Other studies have examined the process of replay which has been described as a reactivation of patterns that were stimulated during a learning phase. Replay has been demonstrated in the hippocampus and this has lent support to the notion that it serves a consolidation purpose. However, replay is not specific to sleep and both rats and primates show signs during restful-awake periods. Also, replay may simply be residual activation in areas that were involved previously in the learning phase and may have no actual effect on consolidation. This reactivation of the memory traces has also been seen in non-REM sleep specifically for hippocampus-dependant memories. Researchers have noted strong reactivation of the hippocampus during sleep immediately after a learning task. This reactivation led to enhanced performance on the learned task. Researchers following this line of work have come to assume that dreams are a by-product of the reactivation of the brain areas and this can explain why dreams may be unrelated to the information being consolidated. The dream experience itself is not what enhances memory performance but rather it is the reactivation of the neural circuits that causes this.",
            "score": 100.29164123535156
        },
        {
            "docid": "25335695_13",
            "document": "Perceptual learning . Since the mid-1980s, there has been a new wave of interest in perceptual learning due to findings of cortical plasticity at the lowest sensory levels of sensory systems. Our increased understanding of the physiology and anatomy of our cortical systems has been used to connect the behavioral improvement to the underlying cortical areas. This trend began with earlier findings of Hubel and Wiesel that perceptual representations at sensory areas of the cortex are substantially modified during a short (\"critical\") period immediately following birth. Merzenich, Kaas and colleagues showed that though neuroplasticity is diminished, it is not eliminated when the critical period ends. Thus, when the external pattern of stimulation is substantially modified, neuronal representations in lower-level (e.g. primary) sensory areas are also modified. Research in this period centered on basic sensory discriminations, where remarkable improvements were found on almost any sensory task through discrimination practice. Following training, subjects were tested with novel conditions and learning transfer was assessed. This work departed from earlier work on perceptual learning, which spanned different tasks and levels.",
            "score": 105.80271804332733
        },
        {
            "docid": "4236583_12",
            "document": "Visual search . A popular explanation for the different reaction times of feature and conjunction searches is the feature integration theory (FIT), introduced by Treisman and Gelade in 1980. This theory proposes that certain visual features are registered early, automatically, and are coded rapidly in parallel across the visual field using preattentive processes. Experiments show that these features include luminance, colour, orientation, motion direction, and velocity, as well as some simple aspects of form. For example, a red X can be quickly found among any number of black Xs and Os because the red X has the discriminative feature of colour and will \"pop out.\" In contrast, this theory also suggests that in order to integrate two or more visual features belonging to the same object, a later process involving integration of information from different brain areas is needed and is coded serially using focal attention. For example, when locating an orange square among blue squares and orange triangles, neither the colour feature \"orange\" nor the shape feature \"square\" is sufficient to locate the search target. Instead, one must integrate information of both colour and shape to locate the target.",
            "score": 62.67137312889099
        },
        {
            "docid": "25335695_18",
            "document": "Perceptual learning . Indeed, a relevant signal in a given behavioral condition may be considered noise in another. For example, when presented with two similar stimuli, one might endeavor to study the differences between their representations in order to improve one's ability to discriminate between them, or one may instead concentrate on the similarities to improve one's ability to identify both as belonging to the same category. A specific difference between them could be considered 'signal' in the first case and 'noise' in the second case. Thus, as we adapt to tasks and environments, we pay increasingly more attention to the perceptual features that are relevant and important for the task at hand, and at the same time, less attention to the irrelevant features. This mechanism is called attentional weighting.",
            "score": 116.71846890449524
        },
        {
            "docid": "8165347_43",
            "document": "Psychology of art . Humans innately tend to see and have a visual preference for symmetry, an identified quality yielding a positive aesthetic experience that uses an automatic bottom-up factor. This bottom-up factor is speculated to rely on learning experience and visual processing in the brain, suggesting a biological basis. Many studies have ventured to explain this innate preference for symmetry with methods including the Implicit Association Test (IAT). Research suggests that we may prefer symmetry because it is easy to process; hence we have a higher perceptual fluency when works are symmetrical. Fluency research draws on evidence from humans and animals that point to the importance of symmetry regardless of biological necessity. This research highlights the efficiency with which computers recognize and process symmetrical objects relative to non-symmetrical models. There have been investigations regarding the objective features that stimuli contain that may affect the fluency and therefore the preferences. Factors such as amount of information given, the extent of symmetry, and figure-ground contrast are only a few listed in the literature. This preference for symmetry has led to question on how fluency affects our implicit preferences by using the Implicit Association Test. Findings suggest that perceptual fluency is a factor that elicits implicit responses, as shown with the Implicit Association Test results. Research has branched from studying aesthetic pleasure and symmetry on an explicit but also implicit level. In fact, research tries to integrate priming (psychology), cultural influences and the different types of stimuli that may elicit an aesthetic preference.",
            "score": 105.41160941123962
        },
        {
            "docid": "41848173_11",
            "document": "Surround suppression . Lateral connections are connections between neurons in the same layer. There are many of these connections in all areas of the visual system, which means that a neuron representing one piece of the visual field can influence a neuron representing another piece. Even within lateral connections, there are potentially different mechanisms at play. Monocular mechanisms, requiring stimulation in only one eye, may drive this effect with stimuli with high spatial frequency. When the stimulus frequency is lowered, however, binocular mechanisms come into play, where neurons from different eyes may suppress each other. Model based on this idea have been shown to reproduce surround suppressive effects.",
            "score": 53.65420603752136
        },
        {
            "docid": "26685741_39",
            "document": "Sleep and memory . REM sleep is known for its vivid creations and similarity to the bioelectric outputs of a waking person. This stage of sleep is characterized by muscle atonia, fast but low voltage EEG and, as the name suggests, rapid eye movement. It is difficult to attribute memory gains to a single stage of sleep when it may be the entire sleep cycle that is responsible for memory consolidation. Recent research conducted by Datta et al. used an avoidance task followed by a post-training REM sleep period to examine changes in P waves affecting reprocessing of recently acquired stimuli. It was found that not only were the P waves increased during post-training sleep but also the density of the waves. These findings may imply that P waves during REM sleep may help to activate critical forebrain and cortical structures dealing with memory consolidation. In a Hennevin et al. study, 1989, the mesencephalic reticular formation (MRF) was given light electrical stimulation, during REM sleep, which is known to have an advantageous effect for learning when applied after training. The rats in the experiment were trained to run a maze in search of a food reward. One group of rats was given non-awakening MRF electrical stimulations after each of their maze trials compared to a control group which did not receive any electrical stimulation. It was noticed that the stimulated rats performed significantly better in respect to error reduction. These findings imply that dynamic memory processes occur both during training as well as during post-training sleep. Another study by Hennevin et al. (1998) conditioned rats to fear a noise that is associated with a subsequent foot shock. The interesting part of the experiment is that fear responding to the noise (measured in the amygdala) was observed when the noise was presented during REM sleep. This was compared to a group of pseudo-conditioned rats who did not display the same amygdalar activation during post-training sleep. This would suggest that neural responding to previously salient stimuli is maintained even during REM sleep. There is no shortage of research conducted on the effects that REM sleep has on the working brain but consistency in the findings is what plagues recent research. There is no guarantee as to what functions REM sleep may perform for our bodies and brains but modern research is always expanding and assimilating new ideas to further our understanding of such processes.",
            "score": 94.12948381900787
        },
        {
            "docid": "4236583_2",
            "document": "Visual search . Visual search is a type of perceptual task requiring attention that typically involves an active scan of the visual environment for a particular object or feature (the target) among other objects or features (the distractors). Visual search can take place with or without eye movements. The ability to consciously locate an object or target amongst a complex array of stimuli has been extensively studied over the past 40 years. Practical examples of using visual search can be seen in everyday life, such as when one is picking out a product on a supermarket shelf, when animals are searching for food amongst piles of leaves, when trying to find your friend in a large crowd of people, or simply when playing visual search games such as \"Where's Wally?\" Many visual search paradigms have used eye movement as a means to measure the degree of attention given to stimuli. However, vast research to date suggests that eye movements move independently of attention, and therefore are not a reliable method to examine the role of attention. Much previous literature on visual search uses reaction time in order to measure the time it takes to detect the target amongst its distractors. An example of this could be a green square (the target) amongst a set of red circles (the distractors).",
            "score": 104.26230812072754
        },
        {
            "docid": "1215674_37",
            "document": "Visual memory . These parts are the sustained and transient visual processing systems. The sustained system is responsible for fine detail such as word and letter recognition and is very important in encoding words in their correct order. The transient system is responsible for controlling eye movements, and processing the larger visual environment around us. When these two processes do not work in synchronization this can cause reading disabilities. This has been tested by having children with and without reading disabilities perform on tasks related to the transient systems, where the children with reading disabilities did very poorly. It has also been found in postmortem examinations of the brains of people with reading disabilities that they have fewer neurons and connections in the areas representing the transient visual systems. However there is debate over whether this is the only reason for reading disabilities, scotopic sensitivity syndrome, deficits in verbal memory and orthographic knowledge are other proposed factors.  Deficits in visual memory can also be caused by disease and/or trauma to the brain. These can lead to the patient losing their spatial memory, and/or their visual memory for specific things. For example a patient \u201cL.E.\u201d suffered brain damage and her ability to draw from memory was severely diminished, whilst her spatial memory remained normal. Other patients represent the opposite, where memory for colors and shapes is unaffected but spatial memory for previously known places is greatly impaired. These case studies show that these two types of visual memory are located in different parts of the brain and are somewhat unrelated in terms of functioning in daily life.",
            "score": 61.6301771402359
        },
        {
            "docid": "23690864_5",
            "document": "Working memory training . Working memory training tasks are conducted on computers and are often paired with positive reinforcement, feedback of the individual's performance, and other motivational features such as displaying the individual's current score beside their personal best score. Practicing these tasks demands numerous processes such as encoding, inhibition, maintenance, manipulation, shifting and controlling attention, and the ability to manage two tasks simultaneously or dividing attention. Possible forms of the tasks include recalling a series of locations of items on the screen, recalling digits or letters in either the order presented or reverse order, or recalling specifically where a particular number or digit was in a sequence. Computers are additionally programmed to adjust the difficulty of the task to the individual's performance with each trial in order to maximize learning and overall improvement. If the individual does poorer on one trial, the difficulty will decrease. Similarly, if the individual excels on the next few trials, the difficulty will increase. Two ways of altering the difficulty are adjusting the number of stimuli to be remembered and adding visual distractions.",
            "score": 68.2512526512146
        },
        {
            "docid": "2363287_12",
            "document": "Visual learning . Here we categorize middle childhood as ages 9 to 14. By this stage in a child's normal development vision is sharp and learning processes are well underway. Most studies that have focused their efforts on visual learning have found that visual learning styles as opposed to traditional learning styles greatly improve the totality of a student's learning experience. First off, visual learning engages students and student engagement is one of the most important factors that motivated students to learn. Visuals increase student interest with the use of graphics animation, and video. Consequently, it has been found that student pay greater attention to lecture material when visuals are used. With increased attention to lesson material, many positive outcomes have been seen with the use of visual tactics in the classrooms of middle aged students. Students organize and process information more thoroughly when they learn visually which helps them to understand the information better. Students are more likely to remember information that is learned with a visual aid. When teachers used visual tactics to teach middle aged students they found that students had more positive attitudes about the material they were learning. Students also exemplified higher test performance, higher standard achievement scores, thinking on levels that require higher order thinking, and more engagement. One study also found that learning about emotional events, such as the Holocaust, with visual aids increase middle aged children's empathy.",
            "score": 77.64626061916351
        },
        {
            "docid": "7800961_12",
            "document": "Fusiform face area . The FFA is underdeveloped in children and does not fully develop until adolescence. This calls into question the evolutionary purpose of the FFA, as children show the ability to differentiate faces. Two-year-old babies have been shown to prefer the face of their mother. Although the FFA is underdeveloped in two-year-old babies, they have the ability to recognize their mother. Babies as early as three months old have shown the ability to distinguish between faces. During this time, babies exhibit the ability to differentiate between genders, showing a clear preference for female faces. It is theorized that, in terms of evolution, babies focus on women for food, although the preference could simply reflect a bias for the caregivers they experience. Infants do not appear to use this area for the perception of faces. Recent fMRI work has found no face selective area in the brain of infants 4 to 6 months old. However, given that the adult human brain has been studied far more extensively than the infant brain, and that infants are still undergoing major neurodevelopmental processes, it may simply be that the FFA is not located in anatomically familiar area. It may also be that activation for many different percepts and cognitive tasks in infants is diffuse in terms of neural circuitry, as infants are still undergoing periods of neurogenesis and neural pruning; this may make it more difficult to distinguish the signal, or what we would imagine as visual and complex familiar objects (like faces), from the noise, including static firing rates of neurons, and activity that is dedicated to a different task entirely than the activity of face processing. Infant vision involves only light and dark recognition, recognizing only major features of the face, activating the amygdala. These findings question the evolutionary purpose of the FFA.",
            "score": 66.06379723548889
        },
        {
            "docid": "176997_24",
            "document": "Blindsight . To test the relationship between attention and awareness, they had the participant try to determine where a target was and whether it was oriented horizontally or vertically on a computer screen. The target line would appear at one of two different locations and would be oriented in one of two directions. Before the target would appear an arrow would become visible on the screen and sometimes it would point to the correct position of the target line and less frequently it would not, this arrow was the cue for the subject. The participant would press a key to indicate whether the line was horizontal or vertical, and could then also indicate to an observer whether or not he/she actually had a feeling that any object was there or not\u2014even if they couldn't see anything. The participant was able to accurately determine the orientation of the line when the target was cued by an arrow before the appearance of the target, even though these visual stimuli did not equal awareness in the subject who had no vision in that area of his/her visual field. The study showed that even without the ability to be visually aware of a stimulus the participant could still focus his/her attention on this object.",
            "score": 74.74313485622406
        },
        {
            "docid": "2060392_5",
            "document": "Pair by association . Paired association learning can be defined as a system of learning in which items (such as words, letters, numbers, symbols etc.) are matched so that presentation of one member of the pair will cue the recall of the other member. It is this learning which constitutes the basics in a paired-associate task. These tasks can be divided into the following: visual-visual, verbal-verbal, and visual-verbal. In visual-visual both members of the pair are in a visual form (e.g. the picture of a blue circle paired with that of a picture of a yellow triangle). The verbal-verbal is when the members of the pair are both verbally presented (e.g. listening to the word cat followed by the word hat spoken to a participant). The last form, visual-verbal is when one member of the pair is spoken out loud while the other member is presented in a visual form (e.g. listening to the word box and seeing a picture of a house). It should be noted that visual associative learning has a positive association with age. In school age children, their visual association ability grows in conjunction with their age; younger children made more errors while older children made less. The paired association task broken down to its basics is: a stimuli, response, and the consequence of the cue association. This is best seen in a study where Naya, Sakai, & Miyashita performed one version of the task on monkeys. In the study a primate was given a visual-visual paired-associate task where they were shown all the pairs in the set. Then after a long delay they displayed one picture of a pair to the primate. When the correct picture was paired by the monkey, showing that the pictures were cueing the response, they were given rewards in the form of food. What this study shows is that it is possible for associations to occur for two previously unrelated items. The monkeys showed they had actually remembered what was shown to them. In visual associative learning, the efficiency of the participant/subject in making these connections actually will decrease as the \u201cmemory load\u201d increases. The more items/the higher the complexity that one has to keep in their memory leads to poorer performance on paired associative learning tasks. Gluck, Mercado, and Myers explain how paired-association is possibly tied to encoding rather than retrieval. In the study presented by Gluck et al., there was a paired associates test where after studying word pairs the participants were presented with one word from the pair and required to recall the match there was a noticeable difference in accuracy between the young adult and older adults. At the start of the study each pair was shown for 15 seconds, in this the older adults had much worse performance; their recall abilities paled in comparison to the younger adults. This however did change when the time was doubled to that of 30 seconds; here the elderly were able to have a much improved performance level. It is an accepted understanding that in associative learning there is a negative regression, as one ages their performance levels decrease. The regression remains even after addressing the possible interfering variables such as attention or spatial memory.",
            "score": 87.52214109897614
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 101.9560512304306
        }
    ],
    "r": [
        {
            "docid": "25335695_4",
            "document": "Perceptual learning . Laboratory studies reported many examples of dramatic improvements in sensitivities from appropriately structured perceptual learning tasks. In visual Vernier acuity tasks, observers judge whether one line is displaced above or below a second line. Untrained observers are often already very good with this task, but after training, observers' threshold has been shown to improve as much as 6 fold. Similar improvements have been found for visual motion discrimination and orientation sensitivity. In visual search tasks, observers are asked to find a target object hidden among distractors or in noise. Studies of perceptual learning with visual search show that experience leads to great gains in sensitivity and speed. In one study by Karni and Sagi, the time it took for subjects to search for an oblique line among a field of horizontal lines was found to improve dramatically, from about 200ms in one session to about 50ms in a later session. With appropriate practice, visual search can become automatic and very efficient, such that observers do not need more time to search when there are more items present on the search field. Tactile perceptual learning has been demonstrated on spatial acuity tasks such as tactile grating orientation discrimination, and on vibrotactile perceptual tasks such as frequency discrimination; tactile learning on these tasks has been found to transfer from trained to untrained fingers. Practice with Braille reading and daily reliance on the sense of touch may underlie the enhancement in tactile spatial acuity of blind compared to sighted individuals.",
            "score": 151.6830291748047
        },
        {
            "docid": "25335695_39",
            "document": "Perceptual learning . An important potential application of perceptual learning is the acquisition of skill for practical purposes. Thus it is important to understand whether training for increased resolution in lab conditions induces a general upgrade which transfers to other environmental contexts, or results from mechanisms which are context specific. Improving complex skills is typically gained by training under complex simulation conditions rather than one component at a time. Recent lab-based training protocols with complex action computer games have shown that such practice indeed modifies visual skills in a general way, which transfers to new visual contexts. In 2010, Achtman, Green, and Bavelier reviewed the research on video games to train visual skills. They cite a previous review by Green & Bavelier (2006) on using video games to enhance perceptual and cognitive abilities. A variety of skills were upgraded in video game players, including \"improved hand-eye coordination, increased processing in the periphery, enhanced mental rotation skills, greater divided attention abilities, and faster reaction times, to name a few\". An important characteristic is the functional increase in the size of the effective visual field (within which viewers can identify objects), which is trained in action games and transfers to new settings. Whether learning of simple discriminations, which are trained in separation, transfers to new stimulus contexts (e.g. complex stimulus conditions) is still an open question.",
            "score": 133.3976287841797
        },
        {
            "docid": "25335695_22",
            "document": "Perceptual learning . However, not all perceptual learning tasks are specific to the trained stimuli or tasks. Sireteanu and Rettenback discussed discrimination learning effects that generalize across eyes, retinal locations and tasks. Ahissar and Hochstein used visual search to show that learning to detect a single line element hidden in an array of differently-oriented line segments could generalize to positions at which the target was never presented. In human vision, not enough receptive field modification has been found in early visual areas to explain perceptual learning. Training that produces large behavioral changes such as improvements in discrimination does not produce changes in receptive fields. In studies where changes have been found, the changes are too small to explain changes in behavior.",
            "score": 130.95199584960938
        },
        {
            "docid": "35982062_9",
            "document": "Biased Competition Theory . A Top-down process is characterized by a high level of direction of sensory processing by more cognition; Top-down processing is based on pre-existing knowledge when interpreting sensory information. Top-down guidance of attention refers to when the properties of an object (i.e. color, shape) are activated and held in working memory to facilitate the visual search for that object. This controls visual search by guiding attention only to objects that could be the target and avoiding attention on irrelevant objects. Top-down processes are not a complete representation of the object but are coarse, which is why objects similar in color, shape or meaning are often attended to in the process of discriminating irrelevant objects. There is evidence that observers have Top-down control over the locations that will benefit from biased competition in spatial selection visual tasks. Evidence supports that observers can make voluntary decision about which locations are selected. or features that capture the attention in a stimulus-driven manner. Neurophysiology studies have showed that the neural mechanisms in Top-down processing are also seen in attention and working memory, suggesting Top-down processes play an important role in those functions as well. Additionally, Top-down processes can modulate Bottom-up processes by suppressing the \u201cpop-out\u201d features of Bottom-up processing from distracting from the visual search. fMRI studies have investigated the Top-down and Bottom-up processes involved in biased competition theory. Results of fMRI suggest that both Bottom-up and Top-down processes work in parallel to bias competition. Multiple studies have shown that stimuli in the visual field suppress each other when presented together, but not when each stimulus is presented alone. Kastner and colleagues also found that directing attention to the specific location of a stimulus reduces the suppressive effect. Increased activity in the visual cortex was also observed; this was the result of Top-down biasing due to the favoring of the attended location.",
            "score": 126.20528411865234
        },
        {
            "docid": "1095131_20",
            "document": "Kinesthetic learning . The cerebral cortex is the brain tissue covering the top and sides of the brain in most vertebrates. It is involved in storing and processing of sensory inputs and motor outputs. In the human brain, the cerebral cortex is actually a sheet of neural tissue about 1/8th inch thick. The sheet is folded so that it can fit inside the skull. The neural circuits in this area of the brain expand with practice of an activity, just like the synaptic plasticity grows with practice. Clarification of some of the mechanisms of learning by neuro science has been advanced, in part, by the advent of non-invasive imaging technologies, such as positron emission tomography (PET) and functional magnetic resonance imaging (FMRI). These technologies have allowed researchers to observe human learning processes directly. Through these types of technologies, we are now able to see and study what happens in the process of learning. In different tests performed the brain being imaged showed a greater blood flow and activation to that area of the brain being stimulated through different activities such as finger tapping in a specific sequence. It has been revealed that the process at the beginning of learning a new skill happens quickly, and later on slows down to almost a plateau. This process can also be referred to as The Law of Learning. The slower learning showed in the FMRI that in the cerebral cortex this was when the long term learning was occurring, suggesting that the structural changes in the cortex reflect the enhancement of skill memories during later stages of training. When a person studies a skill for a longer duration of time, but in a shorter amount of time they will learn quickly, but also only retain the information into their short-term memory. Just like studying for an exam; if a student tries to learn everything the night before, it will not stick in the long run. If a person studies a skill for a shorter duration of time, but more frequently and long-term, their brain will retain this information much longer as it is stored in the long-term memory. Functional and structural studies of the brain have revealed a vast interconnectivity between diverse regions of the cerebral cortex. For example, large numbers of axons interconnect the posterior sensory areas serving vision, audition, and touch with anterior motor regions. Constant communication between sensation and movement makes sense, because to execute smooth movement through the environment, movement must be continuously integrated with knowledge about one's surroundings obtained via sensory perception. The cerebral cortex plays a role in allowing humans to do this.",
            "score": 124.2483901977539
        },
        {
            "docid": "40018674_23",
            "document": "Stereopsis recovery . Scientists at the University of California, Berkeley have stated that perceptual learning appears to play an important role. One investigation, published 2011, reported on a study on human stereopsis recovery using perceptual learning which was inspired by Barry's work. In this study, a small number of stereoblind subjects who had initially been stereoblind or stereoanomalous recovered stereopsis using perceptual learning exercises. Alongside the scientific assessment of the extent of recovery, also the subjective outcomes are described: \"After achieving stereopsis, our observers reported that the depth \u201cpopped out,\u201d which they found very helpful and joyful in their everyday life. The anisometropic observer GD noticed \u201ca surge in depth\u201d one day when shopping in a supermarket. While playing table tennis, she feels that she is able to track a ping-pong ball more accurately and therefore can play better. Strabismic observer AB is more confident now when walking down stairs because she can judge the depth of the steps better. Strabismics AB, DP, and LR, are able to enjoy 3D movies for the first time, and strabismic GJ finds it easier to catch a fly ball while playing baseball.\" In a follow-up study, the authors of this study pointed out that the stereopsis that was recovered following perceptual learning was more limited in resolution and precision compared to normal subjects' stereopsis. Dennis M. Levi was awarded the 2011 Charles F. Prentice Medal of the American Academy of Optometry for this work. There have been several attempts to make use of modern technology for enhanced binocular eye training, in particular for treating amblyopia and interocular suppression. In some cases these modern techniques have improved patients' stereoacuity. Very early technology-enhanced vision therapy efforts have included the cheiroscope, which is a haploscope in which left- and or right-eye images can be blended into view over a drawing pad, and the subject may be given a task such as to reproduce a line image presented to one eye. However, historically these approaches were not developed much further and they were not put to widespread use. Recent systems are based on dichoptic presentation of the elements of a video game or virtual reality such that each eye receives different signals of the virtual world that the player's brain must combine in order to play successfully.",
            "score": 124.24569702148438
        },
        {
            "docid": "18345264_13",
            "document": "Neural correlates of consciousness . The possibility of precisely manipulating visual percepts in time and space has made vision a preferred modality in the quest for the NCC. Psychologists have perfected a number of techniques \u2013 masking, binocular rivalry, continuous flash suppression, motion induced blindness, change blindness, inattentional blindness \u2013 in which the seemingly simple and unambiguous relationship between a physical stimulus in the world and its associated percept in the privacy of the subject's mind is disrupted. In particular a stimulus can be perceptually suppressed for seconds or even minutes at a time: the image is projected into one of the observer's eyes but is invisible, not seen. In this manner the neural mechanisms that respond to the subjective percept rather than the physical stimulus can be isolated, permitting visual consciousness to be tracked in the brain. In a \"perceptual illusion\", the physical stimulus remains fixed while the percept fluctuates. The best known example is the \"Necker cube\" whose 12 lines can be perceived in one of two different ways in depth. A perceptual illusion that can be precisely controlled is \"binocular rivalry\". Here, a small image, e.g., a horizontal grating, is presented to the left eye, and another image, e.g., a vertical grating, is shown to the corresponding location in the right eye. In spite of the constant visual stimulus, observers consciously see the horizontal grating alternate every few seconds with the vertical one. The brain does not allow for the simultaneous perception of both images.",
            "score": 123.16610717773438
        },
        {
            "docid": "25140_19",
            "document": "Perception . \"Perceptual constancy\" is the ability of perceptual systems to recognize the same object from widely varying sensory inputs. For example, individual people can be recognized from views, such as frontal and profile, which form very different shapes on the retina. A coin looked at face-on makes a circular image on the retina, but when held at angle it makes an elliptical image. In normal perception these are recognized as a single three-dimensional object. Without this correction process, an animal approaching from the distance would appear to gain in size. One kind of perceptual constancy is \"color constancy\": for example, a white piece of paper can be recognized as such under different colors and intensities of light. Another example is \"roughness constancy\": when a hand is drawn quickly across a surface, the touch nerves are stimulated more intensely. The brain compensates for this, so the speed of contact does not affect the perceived roughness. Other constancies include melody, odor, brightness and words. These constancies are not always total, but the variation in the percept is much less than the variation in the physical stimulus. The perceptual systems of the brain achieve perceptual constancy in a variety of ways, each specialized for the kind of information being processed, with phonemic restoration as a notable example from hearing.",
            "score": 121.31771850585938
        },
        {
            "docid": "25140_24",
            "document": "Perception . With experience, organisms can learn to make finer perceptual distinctions, and learn new kinds of categorization. Wine-tasting, the reading of X-ray images and music appreciation are applications of this process in the human sphere. Research has focused on the relation of this to other kinds of learning, and whether it takes place in peripheral sensory systems or in the brain's processing of sense information. Empirical research show that specific practices (such as yoga, mindfulness, Tai Chi, meditation, Daoshi and other mind-body disciplines) can modify human perceptual modality. Specifically, these practices enable perception skills to switch from the external (exteroceptive field) towards a higher ability to focus on internal signals (proprioception). Also, when asked to provide verticality judgments, highly self-transcendent yoga practitioners were significantly less influenced by a misleading visual context. Increasing self-transcendence may enable yoga practitioners to optimize verticality judgment tasks by relying more on internal (vestibular and proprioceptive) signals coming from their own body, rather than on exteroceptive, visual cues.",
            "score": 118.08242797851562
        },
        {
            "docid": "25335695_18",
            "document": "Perceptual learning . Indeed, a relevant signal in a given behavioral condition may be considered noise in another. For example, when presented with two similar stimuli, one might endeavor to study the differences between their representations in order to improve one's ability to discriminate between them, or one may instead concentrate on the similarities to improve one's ability to identify both as belonging to the same category. A specific difference between them could be considered 'signal' in the first case and 'noise' in the second case. Thus, as we adapt to tasks and environments, we pay increasingly more attention to the perceptual features that are relevant and important for the task at hand, and at the same time, less attention to the irrelevant features. This mechanism is called attentional weighting.",
            "score": 116.71846771240234
        },
        {
            "docid": "25335695_21",
            "document": "Perceptual learning . Research on basic sensory discriminations often show that perceptual learning effects are specific to the trained task or stimulus. Many researchers take this to suggest that perceptual learning may work by modifying the receptive fields of the cells (e.g., V1 and V2 cells) that initially encode the stimulus. For example, individual cells could adapt to become more sensitive to important features, effectively recruiting more cells for a particular purpose, making some cells more specifically tuned for the task at hand. Evidence for receptive field change has been found using single-cell recording techniques in primates in both tactile and auditory domains.",
            "score": 114.7834243774414
        },
        {
            "docid": "98292_3",
            "document": "Impossible cube . The impossible cube draws upon the ambiguity present in a Necker cube illustration, in which a cube is drawn with its edges as line segments, and can be interpreted as being in either of two different three-dimensional orientations. An impossible cube is usually rendered as a Necker cube in which the line segments representing the edges have been replaced by what are apparently solid beams. In Escher's print, the top four joints of the cube, and the upper of the two crossings between its beams, match one of the two interpretations of the Necker cube, while the bottom four joints and the bottom crossing match the other interpretation. Other variations of the impossible cube combine these features in different ways; for instance, the one shown in the illustration draws all eight joints according to one interpretation of the Necker cube and both crossings according to the other interpretation. The apparent solidity of the beams gives the impossible cube greater visual ambiguity than the Necker cube, which is less likely to be perceived as an impossible object. The illusion plays on the human eye's interpretation of two-dimensional pictures as three-dimensional objects. It is possible for three-dimensional objects to have the visual appearance of the impossible cube when seen from certain angles, either by making carefully placed cuts in the supposedly solid beams or by using forced perspective, but human experience with right-angled objects makes the impossible appearance seem more likely than the reality.",
            "score": 114.6900405883789
        },
        {
            "docid": "7316408_4",
            "document": "Eleanor J. Gibson . Gibson believed that a radically different new view of perceptual learning was needed. Gibson worked with her husband James on a joint study to explore the perception of nonsense scribbles to clarify this concept of perceptual learning. The participants were tasked to identify one standard scribble from a set of similar scribbles varying in many different dimensions. At first the standard scribble was imperceptible from the other scribbles but after repeated tests the standard scribble became clear. The participants were tested until the standard was identified correctly without any correction given. The Gibson's then stated that the stimulus held all the information for perception rather than the participants learning to perceive through an associative process. This resulted in perceptual learning as being redefined as a change in what was perceived by an observer became more sensitive to the different aspects of a stimulus.",
            "score": 114.63036346435547
        },
        {
            "docid": "386062_12",
            "document": "Wishful thinking . Some speculate that wishful seeing results from cognitive penetrability in that higher cognitive functions are able to directly influence perceptual experience instead of only influencing perception at higher levels of processing. Those that argue against cognitive penetrability feel that sensory systems operate in a modular fashion with cognitive states exerting their influence only after the stimuli has been perceived. The phenomenon of wishful seeing implicates cognitive penetrability in the perceptual experience. Wishful seeing has been observed to occur in early stages of categorization. Research using ambiguous figures and binocular rivalry exhibit this tendency. Perception is influenced by both top-down and bottom-up processing. In visual processing, bottom-up processing is a rigid route compared to flexible top-down processing. Within bottom-up processing, the stimuli are recognized by fixation points, proximity and focal areas to build objects, while top-down processing is more context sensitive. This effect can be observed via priming as well as with emotional states. The traditional hierarchical models of information processing describe early visual processing as a one-way street: early visual processing goes into conceptual systems, but conceptual systems do not affect visual processes. Currently, research rejects this model and suggests conceptual information can penetrate early visual processing rather than just biasing the perceptual systems. This occurrence is called conceptual or cognitive penetrability. Research on conceptual penetrability utilize stimuli of conceptual-category pairs and measure the reaction time to determine if the category effect influenced visual processing, The category effect is the difference in reaction times within the pairs such as \"Bb\" to \"Bp\". To test conceptual penetrability, there were simultaneous and sequential judgments of pairs. The reaction times decreased as the stimulus onset asynchrony increased, supporting categories affect visual representations and conceptual penetrability. Research with richer stimuli such as figures of cats and dogs allow for greater perceptual variability and analysis of stimulus typicality (cats and dogs were arranged in various positions, some more or less typical for recognition). Differentiating the pictures took longer when they were within the same category (dog-dog) compared between categories (dog-cat) supporting category knowledge influences categorization. Therefore, visual processing measured by physical differential judgments is affected by non-visual processing supporting conceptual penetrability.",
            "score": 114.29635620117188
        },
        {
            "docid": "2094955_21",
            "document": "Salience (language) . Guido\u2019s Principle one is Figure-ground, which is the means the perceptual field from which people direct their attention towards something that stands out. Figurality is the brightness, complexity, and energy (movement) of a stimulus. It is thought that these aspects trigger cognitions and thought processes in the brain that lead to salience. Brightness includes the magnitude and the colors of the object. Studies have shown that bright, vibrant colors more easily capture the attention and are easier to remember (Guido, 1998). Complexity builds upon the contextual factors (the number of perceptible qualities about the stimulus object that one can distinguish) and learning (what we perceive as unfamiliar). Complexity is the interaction of the familiarity, unfamiliarity, and the number of aspects of the stimulus object that we can resolve. Complexity is the interaction of these stimuli interact to engage affect and cognitions developed about the object (Guido, 1998). Movement of an object engages sensory receptors, which when sparked, send stimuli to the body and brain. Moving pictures, signs and eyes are used to capture our attention and make us pay attention (Guido, 1998).",
            "score": 113.17351531982422
        },
        {
            "docid": "19389176_15",
            "document": "Manual labour . Informal learning can be summarized as any activity which concerns the pursuit of understanding, knowledge, or skill that occurs without an imposed curriculum and explicit assessment. It typically manifests itself as practical engagement in the pursuit of knowledge.  There are several ways which informal learning is conducted, that range from self-directed learning, observational learning, where there is intention to seek specific information outside of formal environments, to the coincidental learning that comes out of experiences. Informal training differs from informal training in that it focuses on the acquisition of a skill, understanding, or job-specific knowledge. The cognitive skills acquired outside of formal learning environment also help to define the mastery of what are considered \"blue collar\" jobs. The understanding of technique and method taken from formal training is expanded on in developing contextual application, situational awareness, and innovation based skills. Informal learning provides workers with opportunities of cognitive development unique to their field's context.That knowledge of context, derived from past experiences in comparable situations, dictates the use of one technique or plan over another. Plumbing, as an example, requires knowledge of piping and the mechanics of water systems, but also relies on details such as house age, the materials from which the specific plumbing system is made, how those materials react given different external changes or alterations, and a comprehension of hypothetical conditions and the resulting behavior of the problem and other related components when said conditions are brought into effect. These skills and understandings are inherent in both learning processes. As a whole, this type of knowledge is more learner-centered and situational in response to the interests or needed application of the skill to a particular workforce.",
            "score": 112.92798614501953
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 112.70455169677734
        },
        {
            "docid": "422247_33",
            "document": "Self-awareness . Autism spectrum disorder (ASD) is a range of neurodevelopmental disabilities that can adversely impact social communication and create behavioral challenges (Understanding Autism, 2003). \"Autism spectrum disorder (ASD) and autism are both general terms for a group of complex disorders of brain development. These disorders are characterized, in varying degrees, by difficulties in social interaction, verbal and nonverbal communication and repetitive behaviors.\" ASDs can also cause imaginative abnormalities and can range from mild to severe, especially in sensory-motor, perceptual and affective dimensions. Children with ASD may struggle with self-awareness and self acceptance. Their different thinking patterns and brain processing functions in the area of social thinking and actions may compromise their ability to understand themselves and social connections to others. About 75% diagnosed autistics are mentally handicapped in some general way and the other 25% diagnosed with Asperger's Syndrome show average to good cognitive functioning. When we compare our own behavior to the morals and values that we were taught, we can focus more attention on ourselves which increases self-awareness. To understand the many effects of autism spectrum disorders on those afflicted have led many scientists to theorize what level of self-awareness occurs and in what degree. Research found that ASD can be associated with intellectual disability and difficulties in motor coordination and attention. It can also result in physical health issues as well, such as sleep and gastrointestinal disturbances. As a result of all those problems, individuals are literally unaware of themselves. It is well known that children suffering from varying degrees of autism struggle in social situations. Scientists at the University of Cambridge have produced evidence that self-awareness is a main problem for people with ASD. Researchers used functional magnetic resonance scans (FMRI) to measure brain activity in volunteers being asked to make judgments about their own thoughts, opinions, preferences, as well as about someone else's. One area of the brain closely examined was the ventromedial pre-frontal cortex (vMPFC) which is known to be active when people think about themselves. A study out of Stanford University has tried to map out brain circuits with understanding self-awareness in Autism Spectrum Disorders. This study suggests that self-awareness is primarily lacking in social situations but when in private they are more self-aware and present. It is in the company of others while engaging in interpersonal interaction that the self-awareness mechanism seems to fail. Higher functioning individuals on the ASD scale have reported that they are more self-aware when alone unless they are in sensory overload or immediately following social exposure. Self-awareness dissipates when an autistic is faced with a demanding social situation. This theory suggests that this happens due to the behavioral inhibitory system which is responsible for self-preservation. This is the system that prevents human from self-harm like jumping out of a speeding bus or putting our hand on a hot stove. Once a dangerous situation is perceived then the behavioral inhibitory system kicks in and restrains our activities. \"For individuals with ASD, this inhibitory mechanism is so powerful, it operates on the least possible trigger and shows an over sensitivity to impending danger and possible threats. Some of these dangers may be perceived as being in the presence of strangers, or a loud noise from a radio. In these situations self-awareness can be compromised due to the desire of self preservation, which trumps social composure and proper interaction. The Hobson hypothesis reports that autism begins in infancy due to the lack of cognitive and linguistic engagement which in turn results in impaired reflective self-awareness. In this study ten children with Asperger's Syndrome were examined using the Self-understanding Interview. This interview was created by Damon and Hart and focuses on seven core areas or schemas that measure the capacity to think in increasingly difficult levels. This interview will estimate the level of self understanding present. \"The study showed that the Asperger group demonstrated impairment in the 'self-as-object' and 'self-as-subject' domains of the Self-understanding Interview, which supported Hobson's concept of an impaired capacity for self-awareness and self-reflection in people with ASD.\". Self-understanding is a self description in an individual's past, present and future. Without self-understanding it is reported that self-awareness is lacking in people with ASD. Joint attention (JA) was developed as a teaching strategy to help increase positive self-awareness in those with autism spectrum disorder. JA strategies were first used to directly teach about reflected mirror images and how they relate to their reflected image. Mirror Self Awareness Development (MSAD) activities were used as a four-step framework to measure increases in self-awareness in those with ASD. Self-awareness and knowledge is not something that can simply be taught through direct instruction. Instead, students acquire this knowledge by interacting with their environment. Mirror understanding and its relation to the development of self leads to measurable increases in self-awareness in those with ASD. It also proves to be a highly engaging and highly preferred tool in understanding the developmental stages of self- awareness. There have been many different theories and studies done on what degree of self-awareness is displayed among people with autism spectrum disorder. Scientists have done research about the various parts of the brain associated with understanding self and self-awareness. Studies have shown evidence of areas of the brain that are impacted by ASD. Other theories suggest that helping an individual learn more about themselves through Joint Activities, such as the Mirror Self Awareness Development may help teach positive self-awareness and growth. In helping to build self-awareness it is also possible to build self-esteem and self acceptance. This in turn can help to allow the individual with ASD to relate better to their environment and have better social interactions with others.",
            "score": 112.368408203125
        },
        {
            "docid": "25948_6",
            "document": "Refraction . Refraction can be seen when looking into a bowl of water. Air has a refractive index of about 1.0003, and water has a refractive index of about 1.3333. If a person looks at a straight object, such as a pencil or straw, which is placed at a slant, partially in the water, the object appears to bend at the water's surface. This is due to the bending of light rays as they move from the water to the air. Once the rays reach the eye, the eye traces them back as straight lines (lines of sight). The lines of sight (shown as dashed lines) intersect at a higher position than where the actual rays originated. This causes the pencil to appear higher and the water to appear shallower than it really is. The depth that the water appears to be when viewed from above is known as the \"apparent depth\". This is an important consideration for spearfishing from the surface because it will make the target fish appear to be in a different place, and the fisher must aim lower to catch the fish. Conversely, an object above the water has a higher \"apparent height\" when viewed from below the water. The opposite correction must be made by an archer fish. For small angles of incidence (measured from the normal, when sin \u03b8 is approximately the same as tan \u03b8), the ratio of apparent to real depth is the ratio of the refractive indexes of air to that of water. But, as the angle of incidence approaches 90, the apparent depth approaches zero, albeit reflection increases, which limits observation at high angles of incidence. Conversely, the apparent height approaches infinity as the angle of incidence (from below) increases, but even earlier, as the angle of total internal reflection is approached, albeit the image also fades from view as this limit is approached. The diagram on the right shows an example of refraction in water waves. Ripples travel from the left and pass over a shallower region inclined at an angle to the wavefront. The waves travel slower in the more shallow water, so the wavelength decreases and the wave bends at the boundary. The dotted line represents the normal to the boundary. The dashed line represents the original direction of the waves. This phenomenon explains why waves on a shoreline tend to strike the shore close to a perpendicular angle. As the waves travel from deep water into shallower water near the shore, they are refracted from their original direction of travel to an angle more normal to the shoreline. Refraction is also responsible for rainbows and for the splitting of white light into a rainbow-spectrum as it passes through a glass prism. Glass has a higher refractive index than air. When a beam of white light passes from air into a material having an index of refraction that varies with frequency, a phenomenon known as dispersion occurs, in which different coloured components of the white light are refracted at different angles, i.e., they bend by different amounts at the interface, so that they become separated. The different colors correspond to different frequencies.",
            "score": 112.25718688964844
        },
        {
            "docid": "386062_19",
            "document": "Wishful thinking . Emotion is often interpreted through visual cues on the face, body language and context. However, context and cultural backgrounds have been shown to influence the visual perception and interpretation of emotion. Cross-cultural differences in change blindness have been associated with perceptual set, or a tendency to attend to visual scenes in a particular way. For example, eastern cultures tend to emphasize background of an object, while western cultures focus on central objects in a scene. Perceptual sets are also the result of cultural aesthetic preferences. Therefore, cultural context can influence how people sample information from a face, just like they would do in a situational context. For example, Caucasians generally fixate around eyes, nose and mouth, while Asians fixate on eyes. Individuals from different cultural backgrounds who were shown a series of faces and asked to sort them into piles in which every face showed the same emotion. Fixation on different features of the face leads to disparate reading of emotions. Asians' focus on the eyes lead to the perception of startled faces as surprise rather than fear. As a result, previous associations or customs of an individual can lead to different categorization or recognition of emotion. This particular difference in visual perception of emotion seems to suggest an attention bias mechanism for wishful seeing, since certain visual cues were attended to (e.g. nose, eyes) and the others were ignored (e.g. mouth).",
            "score": 112.1962661743164
        },
        {
            "docid": "2138419_3",
            "document": "Rapid serial visual presentation . There is a delay of several hundred milliseconds. A person might be asked to identify numbers in a string of letters which are shown one by one. The first number which is an important target, would be caught by the person, however, the second number flashed seconds later might not be observed. RSVP asks the question, What would reading be like if there were no eye movements? A text is delivered at a spot on the screen, like a series of flash cards. The user can set how long each card is to be displayed. The readers are liberated from having to decide how much time to spend on each word because that is set in advance, and saccades, regressive eye movements, line sweeps, and page turning have been eliminated. A reader can fully concentrate on comprehending the text as it flashes through, however, with longer texts the reading experience is found to be monotonous and exhausting. There are a number of theories to explain how and why this works and studies have explored its limitations and parameters to learn more about visual perception. The brain deals with a quick stream of incoming information at all times. With the attentional blink, the brain has to distribute its attentional resources to comprehend, interpret, and store the information properly. The human brain is capable of processing complex tasks, but it has restrictions. The attentional blink is an illustration that has a significant insinuation for individuals who work in environments where they are usually swamped with information. An example of this is an airport baggage screener who might see a knife in one bag, but misses a second knife in another bag that is right behind the first bag. The failure to recognize the second target is because of the attentional processes that are linked with the identification of the first target.",
            "score": 111.17212677001953
        },
        {
            "docid": "25335695_41",
            "document": "Perceptual learning . In educational domains, recent efforts by Philip Kellman and colleagues showed that perceptual learning can be systematically produced and accelerated using specific, computer-based technology. Their approach to perceptual learning methods take the form of perceptual learning modules (PLMs): sets of short, interactive trials that develop, in a particular domain, learners' pattern recognition, classification abilities, and their abilities to map across multiple representations. As a result of practice with mapping across transformations (e.g., algebra, fractions) and across multiple representations (e.g., graphs, equations, and word problems), students show dramatic gains in their structure recognition in fraction learning and algebra. They also demonstrated that when students practice classifying algebraic transformations using PLMs, the results show remarkable improvements in fluency at algebra problem solving. These results suggests that perceptual learning can offer a needed complement to conceptual and procedural instructions in the classroom.",
            "score": 110.56634521484375
        },
        {
            "docid": "30052276_14",
            "document": "Christoph Wulf . In a study about mimesis carried out together with Gunter Gebauer. For culture, art, and society, it was about the reconstruction of mimetic phenomenon, beginning in antiquity and ending with Derrida. This study was not about developing a history of mimetic thought. The research was instead carried out in the sense of the concept of family resemblance (Wittgenstein) with the objective of investigating how mimesis and mimetic processes were understood in various eras and in different contexts. Here it was found that the richness of the mimesis concept is in the fact that it has no narrowly delineated meaning, but that it changes and further develops in the course of historical development in the sense of family resemblance. It was about showing how mimesis was understood in the various historical contexts. For this reason research was carried out into how mimetic phenomena were conceptualized in antiquity and how these concepts changed in the Middle Ages, in the Renaissance, and in the modern era. The reconstruction and analysis of the mimesis concept of Walter Benjamin, Theodor Adorno, and Jacques Derridas were particularly interesting. Mimetic processes also have as their aim an assimilation to the work of art, which allows the work of art to remain as it is and which gives the person who is behaving mimetically the opportunity to include the forms of the work of art in her imagination. With the mimetic appropriation of works of art, an assimilation to an exterior and an incorporation of the exterior into the world of the imaginary occurs. This process also takes place in the opposite direction. Mental images are brought to the outside and objectified in a mimetic process. This happens with artistic works, but also with text and action plans. The mimetic process is a bridging process that on the one hand converts the exterior world into the interior world and on the other hand conveys the interior world into the exterior world. In the mimetic process, what occurs is not just an assimilation to a work of art or another person to which one mimetically relates in order to become the person that one is or can become through this assimilation. In mimetic processes, one does not become like the other, but one needs the other in order to be able to develop in relation to the other. In the relationship between children and parents, these processes play a central role. Because children want to grow up, they first need to become like their parents. Mimetic processes take place not just through seeing and hearing. Experiences of touching, smelling, tasting are also mimetically processed. Mimetic processes contribute to the partial overcoming of the subject/object split. In the mimetic process, the person emerges from himself and clings to an exterior. This often occurs pre-consciously and without thinking. This approaching of an assimilation to the other is an important form of appropriation of an exterior, an alterity. These processes take place even before thinking and speaking develop. They are physical processes, often sensuous ones, which take place even before the question of whether something is right or wrong is asked. Mimetic processes are polycentric. People hardly know what is happening with them when they are in a mimetic relationship and appropriate something in the process. What is mimetically learned can change again in response to later references and stimuli. Mimetically obtained knowledge is not clearly definable knowledge. In mimetic learning, a figure or a totality that is often not yet differentiated in the mimetic process is acquired. The mimetic movement aims at taking a symbolically generated world and interpreting a prior world that itself is already interpreted. A new interpretation of an already interpreted world takes place. This applies even to the repetition. The gesture of reproduction creates structures of meaning different from the prior givens. It isolates an object from the general context and establishes a perspective of reception that is different from the one perceived in the prior world. Isolation and change of perspective are characteristics of aesthetic processes that tie in with the close relationship between mimesis and aesthetics that has been seen since Plato. The mimetic new interpretation is a new perception, \u201ca seeing as,\u201d as formulated by Wittgenstein. The mimetic action involves the intention of showing a symbolically generated world in such a way that it can be seen as a distinct one. Mimetic processes do not just relate to other people. The recognition that cultural life is largely mimetic learning goes back to Plato and Aristotle. Plato already spoke about how there is a mimetic dynamic that one cannot resist, especially as a child and adolescent. We need to imitate other people, images, and models. According to Plato's interpretation, the (young) person cannot resist the power of the mimetic, but is subject to it. For this reason the negative occurrences and images from the ideal state need to be disregarded. Homer, who was long seen as a master teacher of the Greeks, should no longer play the central role in the education of the youth, but instead the philosophers. In contrast to Homer, who reported about the misdeeds of the gods, thereby creating negative role models, the philosophers were to become role models of the youth exclusively as models of the good. Aristotle set a different accent. He pleaded not simply for the exclusion of the negative, but instead demanded an examination of it in order to immunize the youth against the negative. In spite of points of view that differed, Plato and Aristotle agreed that the human is a \u201cmimetic animal\u201d and that culture is learned in mimetic processes. Here mimesis becomes a synonym for upbringing. Mimetic processes do not just aim at creating a copy like a photocopier. In the mimetic process, children, adolescents, and adults are active. They relate to an exterior, assimilate it, and become similar to it. For example, if children mimetically relate to a teacher that they really like, these children do not become like their role model. But they need this role model to which they can relate in order to be able to develop certain traits to bring themselves forth as they would like to be. These insights about the central role of mimetic learning are also supported today through Michael Tomasello's research, which shows that mimetic processes allow children who are just eight months old to understand the intentions of adults before they are manifested. Non-human primates are never able to do this. The neuroscientific research about the mirror neuron system makes the importance of mimetic processes clear. In this research it is shown that when people carry out an action, such as when they hit someone, neural processes occur that are similar to those of people watching these actions. Thus when people see an action, their brain reacts in a manner that is similar to if they had carried out this action themselves. When people dissipate in social situations and see how other people react, this generates nearly the same processes, with the only difference being that they are more weakly articulated. Several different methodologies support Wulf's theory that cultural life largely takes place mimetically.",
            "score": 110.38069152832031
        },
        {
            "docid": "4643899_24",
            "document": "Categorical perception . In studying learned categorical perception, themes are important. Learning categories is influenced by the presence of themes. Themes increase quality of learning. This is seen especially in cases where the existing themes are opposite. In learned categorical perception, themes serve as cues for different categories. They assist in designating what to look for when placing objects into their categories. For example, when perceiving shapes, angles are a theme. The number of angles and their size provide more information about the shape and cue different categories. Three angles would cue a triangle, whereas four might cue a rectangle or a square. Opposite to the theme of angles would be the theme of circularity. The stark contrast between the sharp contour of an angle and the round curvature of a circle make it easier to learn.",
            "score": 110.28228759765625
        },
        {
            "docid": "17994_32",
            "document": "Learning theory (education) . The integration and application to education of what we know about the brain was strengthened in 2000 when the American Federation of Teachers stated: \"It is vital that we identify what science tells us about how people learn in order to improve the education curriculum.\" What is exciting about this new field in education is that modern brain imaging techniques now make it possible, in some sense, to watch the brain as it learns, and the question then arises: can the results of neuro-scientific studies of brains as they are learning usefully inform practice in this area? The neuroscience field is young. Researchers expected that new technologies and ways of observing will produce new scientific evidence that helps refine the paradigms of what students need and how they learn best. In particular, it may bring more informed strategies for teaching students with learning disabilities.",
            "score": 110.23711395263672
        },
        {
            "docid": "4643899_21",
            "document": "Categorical perception . Learning is a cognitive process that results in a relatively permanent change in behavior. Learning can influence perceptual processing. Learning influences perceptual processing by altering the way in which an individual perceives a given stimulus based on prior experience or knowledge. This means that the way something is perceived is changed by how it was seen, observed, or experienced before. The effects of learning can be studied in categorical perception by looking at the processes involved.",
            "score": 109.1234130859375
        },
        {
            "docid": "25335695_14",
            "document": "Perceptual learning . A question still debated today is to what extent improvements from perceptual learning stems from peripheral modifications compared with improvement in higher-level readout stages. Early interpretations, such as that suggested by William James, attributed it to higher-level categorization mechanisms whereby initially blurred differences are gradually associated with distinctively different labels. The work focused on basic sensory discrimination, however, suggests that the effects of perceptual learning are specific to changes in low-levels of the sensory nervous system (i.e., primary sensory cortices). More recently, research suggest that perceptual learning processes are multilevel and flexible. This cycles back to the earlier Gibsonian view that low-level learning effects are modulated by high-level factors, and suggests that improvement in information extraction may not involve only low-level sensory coding but also apprehension of relatively abstract structure and relations in time and space.",
            "score": 108.21748352050781
        },
        {
            "docid": "34760855_9",
            "document": "Word learning biases . Similar to the taxonomic constraint researchers have looked into the principle of categorical scope, which also follows the assumption that children will believe new object labels refer to objects within taxonomic categories. An example of categorical scope and perceptual similarity can be illustrated when children learn animal names. Studies show that children think the identity of an animal only changes if its internal properties change. Children extended labels to two perceptually similar animals more often than when they were dissimilar.",
            "score": 108.00224304199219
        },
        {
            "docid": "2175836_3",
            "document": "Hering illusion . There are several possible explanations for why perceptual distortion produced by the radiating pattern. The illusion was ascribed by Hering to an overestimation of the angle made at the points of intersection. If true, it is interesting that what yields is the straightness of the parallel lines and not of the radiating lines, implying that there is a hierarchical ordering among components of such illusion. Others have suggested that angle overestimation results from lateral inhibition in visual cortex, while others have postulated a bias inherent in extrapolating 3D angle information from 2D projections.",
            "score": 107.7388687133789
        },
        {
            "docid": "41149597_5",
            "document": "Social learning in animals . Social learning occurs when one individual influences the learning of another through various processes. In local enhancement and opportunity providing, the attention of an individual is drawn to a specific location or situation. In stimulus enhancement, emulation, observational conditioning, the observer learns the relationship between a stimulus and a result but does not directly copy the behavior of the experienced individual. In imitation, the observer directly copies the behavior of the animal in order to complete a novel task. All of these mechanisms are possible through inadvertent social learning, without active facilitation from the experienced individual. When an individual more actively influences another's behavior through any one of these mechanisms, the individual becomes a teacher.",
            "score": 107.13928985595703
        },
        {
            "docid": "4230598_22",
            "document": "Optical flat . Counterintuitively, the fringes do not exist within the gap or the flat itself. The interference fringes actually form when the light waves all converge at the eye or camera, forming the image. Because the image is the compilation of all converging wavefronts interfering with each other, the flatness of the test piece can only be measured relative to the flatness of the optical flat. Any deviations on the flat will be added to the deviations on the test surface. Therefore, a surface polished to a flatness of \u03bb/4 cannot be effectively tested with a \u03bb/4 flat, as it is not possible to determine where the errors lie, but its contours can be revealed by testing with more accurate surfaces like a \u03bb/20 or \u03bb/50 optical flat. This also means that both the lighting and viewing angle have an effect on the accuracy of the results. When lighted or viewed at an angle, the distance that the light must travel across the gap is longer than when viewed and illuminated straight on. Thus, as the angle of incidence becomes steeper, the fringes will also appear to move and change. A zero degree angle of incidence is usually the most desirable angle, both for lighting and viewing. Unfortunately, this is usually impossible to achieve with the naked eye. Many interferometers use beamsplitters to obtain such an angle. Because the results are relative to the wavelength of the light, accuracy can also be increased by using light of shorter wavelengths, although the 632\u00a0nm line from a helium\u2013neon laser is often used as the standard.",
            "score": 107.07076263427734
        },
        {
            "docid": "6060077_4",
            "document": "Flash lag illusion . A second proposed explanation is that the visual system processes moving objects more quickly than flashed objects. This latency-difference hypothesis asserts that by the time the flashed object is processed, the moving object has already moved to a new position. The latency-difference proposal tacitly rests on the assumption that awareness (what the subject reports) is an on-line phenomenon, coming about as soon as a stimulus reaches its \"perceptual end-point\".",
            "score": 105.84952545166016
        }
    ]
}