{
    "q": [
        {
            "docid": "4231622_9",
            "document": "Inferior temporal gyrus . These areas must all work together, as well as with the hippocampus, in order to create an array of understanding of the physical world. The hippocampus is key for storing the memory of what an object is/what it looks like for future use so that it can be compared and contrasted with other objects. Correctly being able to recognize an object is highly dependent on this organized network of brain areas that process, share, and store information. In a study by Denys et al., functional magnetic resonance imaging (FMRI) was used to compare the processing of visual shape between humans and macaques. They found, amongst other things, that there was a degree of overlap between shape and motion sensitive regions of the cortex, but that the overlap was more distinct in humans. This would suggest that the human brain is better evolved for a high level of functioning in a distinct, three-dimensional, visual world.",
            "score": 129.3391091823578
        },
        {
            "docid": "24965027_8",
            "document": "Cognitive neuroscience of visual object recognition . This model, proposed by Marr and Nishihara (1978), states that object recognition is achieved by matching 3-D model representations obtained from the visual object with 3-D model representations stored in memory as veridical shape precepts. Through the use of computer programs and algorithms, Yi Yungfeng (2009) was able to demonstrate the ability for the human brain to mentally construct 3D images using only the 2D images that appear on the retina. Their model also demonstrates a high degree of shape constancy conserved between 2D images, which allow the 3D image to be recognized. The 3-D model representations obtained from the object are formed by first identifying the concavities of the object, which separate the stimulus into individual parts. Recent research suggests that an area of the brain, known as the caudal intraparietal area (CIP), is responsible for storing the slant and tilt of a plan surface that allow for concavity recognition. Rosenburg et al. implanted monkeys with a scleral search coil for monitoring eye position while simultaneously recording single neuron activation from neurons within the CIP. During the experiment, monkeys sat 30\u00a0cm away from an LCD screen that displayed the visual stimuli. Binocular disparity cues were displayed on the screen by rendering stimuli as green-red anaglyphs and the slant-tilt curves ranged from 0 to 330. A single trial consisted of a fixation point and then the presentation of a stimulus for 1 second. Neuron activations were then recorded using the surgically inserted microelectrodes. These single neuron activations for specific concavities of objects lead to the discovery that each axis of an individual part of an object containing concavity are found in memory stores. Identifying the principal axis of the object assists in the normalization process via mental rotation that is required because only the canonical description of the object is stored in memory. Recognition is acquired when the observed object viewpoint is mentally rotated to match the stored canonical description.[11] An extension of Marr and Nishihara's model, the recognition-by-components theory, proposed by Biederman (1987), proposes that the visual information gained from an object is divided into simple geometric components, such as blocks and cylinders, also known as \"geons\" (geometric ions), and are then matched with the most similar object representation that is stored in memory to provide the object's identification (see Figure 1).",
            "score": 117.70403909683228
        },
        {
            "docid": "32197396_2",
            "document": "Form perception . Form perception is the recognition of visual elements of objects, specifically those to do with shapes, patterns and previously identified important characteristics. An object is perceived by the retina as a two-dimensional image, but the image can vary for the same object in terms of the context with which it is viewed, the apparent size of the object, the angle from which it is viewed, how illuminated it is, as well as where it resides in the field of vision.  Despite the fact that each instance of observing an object leads to a unique retinal response pattern, the visual processing in the brain is capable of recognizing these experiences as analogous, allowing invariant object recognition. Visual processing occurs in a hierarchy with the lowest levels recognizing lines and contours, and slightly higher levels performing tasks such as completing boundaries and recognizing contour combinations. The highest levels integrate the perceived information to recognize an entire object. Essentially object recognition is the ability to assign labels to objects in order to categorize and identify them, thus distinguishing one object from another. During visual processing information is not created, but rather reformatted in a way that draws out the most detailed information of the stimulus.",
            "score": 138.51471376419067
        },
        {
            "docid": "44632031_32",
            "document": "M-Theory (learning framework) . M-theory is based on a quantitative theory of the ventral stream of visual cortex. Understanding how visual cortex works in object recognition is still a challenging task for neuroscience. Humans and primates are able to memorize and recognize objects after seeing just couple of examples unlike any state-of-the art machine vision systems that usually require a lot of data in order to recognize objects. Prior to the use of visual neuroscience in computer vision has been limited to early vision for deriving stereo algorithms (e.g.,) and to justify the use of DoG (derivative-of-Gaussian) filters and more recently of Gabor filters. No real attention has been given to biologically plausible features of higher complexity. While mainstream computer vision has always been inspired and challenged by human vision, it seems to have never advanced past the very first stages of processing in the simple cells in V1 and V2. Although some of the systems inspired - to various degrees - by neuroscience, have been tested on at least some natural images, neurobiological models of object recognition in cortex have not yet been extended to deal with real-world image databases.",
            "score": 151.00359272956848
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 154.99357664585114
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 189.28539776802063
        },
        {
            "docid": "27179535_7",
            "document": "Leah Krubitzer . The parietal cortex is another area of interest for Krubitzer. The parietal cortex allows us to coordinate movements between our eyes and our hands. This ability allows for smooth reaching movements, as well as, grasping. Past research has been done on Old and New World monkeys, as well as humans, to see how the parietal cortex functions in hand use. Imaging used on humans shows that there are similar cortical patterns shared across human and non-human primates, but the extent to which these pathways are used depends on the somatosensory organization and connectivity in the parietal cortex. Krubitzer and her team took this information and investigated a little deeper. Because humans have an opposable thumb, our ability to grip objects and reach for objects is much greater than monkeys. For this reason, the connectivity in the human parietal cortex is much more complex than that of a non-human primate. In Krubitzer's lab, her team investigated different areas of the parietal cortex in order to better pin point which part controls which motor movement. Krubitzer found that when one area of the cortex responsible for a certain motor movement is compromised, the rest of the cortex will reorganize itself to make up for the loss. This finding shows how the parietal cortex can rewire itself in order to maintain functional motor capabilities. Currently in the lab, Krubitzer and colleagues are testing a microchip that may be placed in the posterior parietal cortex of the brain to deactivate certain areas at a time. Using this technique, they are able to see how deactivation of a certain portion of the cortex impacts hand grasping and reaching in monkeys. This technique is performed while the monkeys are performing different manual tasks in order to see the action of the cortex live.",
            "score": 140.70316922664642
        },
        {
            "docid": "4231622_5",
            "document": "Inferior temporal gyrus . The temporal lobe is unique to primates. In humans, the IT cortex is more complex than their relative primate counterparts. The human inferior temporal cortex consists of the inferior temporal gyrus, the middle temporal gyrus, and the fusiform gyrus. When looking at the brain laterally \u2013 that is from the side and looking at the surface of the temporal lobe \u2013 the inferior temporal gyrus is along the bottom portion of the temporal lobe, and is separated from the middle temporal gyrus located directly above by the inferior temporal sulcus. Additionally, some processing of the visual field that corresponds to the ventral stream of visual processing occurs in the lower portion of the superior temporal gyrus closest to the superior temporal sulcus. The medial and ventral view of the brain \u2013 meaning looking at the medial surface from below the brain, facing upwards \u2013 reveals that the inferior temporal gyrus is separated from the fusiform gyrus by the occipital-temporal sulcus. This human inferior temporal cortex is much more complex than that of other primates: non-human primates have an inferior temporal cortex that is not divided into unique regions such as humans' inferior temporal gyrus, fusiform gyrus, or middle temporal gyrus.  This region of the brain corresponds to the inferior temporal cortex and is responsible for visual object recognition and receives processed visual information. The inferior temporal cortex in primates has specific regions dedicated to processing different visual stimuli processed and organized by the different layers of the striate cortex and extra-striate cortex. The information from the V1 \u2013V5 regions of the geniculate and tectopulvinar pathways are radiated to the IT cortex via the ventral stream: visual information specifically related to the color and form of the visual stimuli. Through comparative research between primates \u2013 humans and non-human primates \u2013 results indicate that the IT cortex plays a significant role in visual shape processing. This is supported by functional magnetic resonance imaging (fMRI) data collected by researchers comparing this neurological process between humans and macaques.",
            "score": 157.57229959964752
        },
        {
            "docid": "1008632_19",
            "document": "Baddeley's model of working memory . There are two different pathways in the brain that control different functions of what is known inclusively as the visuo-spatial sketchpad. The sketchpad consists of the spatial short-term memory and the object memory. The spatial short-term memory is how one is able to learn and thus remember \"where\" they are in comparative representation to other objects. The object memory of the visuo-spatial sketchpad is essential in learning and remembering \"what\" an object is. It should be noted that the differences between these two differing visual abilities is due in large part because of different pathways of each of the abilities in the brain. The visual pathway in the brain that detects spatial representation of a person to and within their environment is the dorsal stream. The visual pathway that determines objects shapes, sizes, colors and other definitive characteristics is called the ventral stream. Each of these two streams runs independent of one another so that the visual system may process one without the other (like in brain damage for instance) or both simultaneously. The two streams do not depend on one another, so if one is functioning manipulatively, the other can still send its information through.",
            "score": 108.22040116786957
        },
        {
            "docid": "24965027_6",
            "document": "Cognitive neuroscience of visual object recognition . A significant aspect of object recognition is that of object constancy: the ability to recognize an object across varying viewing conditions. These varying conditions include object orientation, lighting, and object variability (size, colour, and other within-category differences). For the visual system to achieve object constancy, it must be able to extract a commonality in the object description across different viewpoints and the retinal descriptions.[9] Participants who did categorization and recognition tasks while undergoing a functional magnetic found as increased blood flow indicating activation in specific regions of the brain. The categorization task consisted of participants placing objects from canonical or unusual views as either indoor or outdoor objects. The recognition task occurs by presenting the participants with images that they had viewed previously. Half of these images were in the same orientation as previously shown, while the other half were presented in the opposing viewpoint. The brain regions implicated in mental rotation, such as the ventral and dorsal visual pathways and the prefrontal cortex, showed the greatest increase in blood flow during these tasks, demonstrating that they are critical for the ability to view objects from multiple angles. Several theories have been generated to provide insight on how object constancy may be achieved for the purpose of object recognition including, viewpoint-invariant, viewpoint-dependent and multiple views theories.",
            "score": 159.2381490468979
        },
        {
            "docid": "24965027_25",
            "document": "Cognitive neuroscience of visual object recognition . Loss of object recognition is called \"visual object agnosia\". There are two broad categories of visual object agnosia: apperceptive and associative. When object agnosia occurs from a lesion in the dominant hemisphere, there is often a profound associated language disturbance, including loss of word meaning.  Object recognition is a complex task and involves several different areas of the brain \u2013 not just one. If one area is damaged then object recognition can be impaired. The main area for object recognition takes place in the temporal lobe. For example, it was found that lesions to the perirhinal cortex in rats causes impairments in object recognition especially with an increase in feature ambiguity. Neonatal aspiration lesions of the amygdaloid complex in monkeys appear to have resulted in a greater object memory loss than early hippocampal lesions. However, in adult monkeys, the object memory impairment is better accounted for by damage to the perirhinal and entorhinal cortex than by damage to the amygdaloid nuclei. Combined amygdalohippocampal (A + H) lesions in rats impaired performance on an object recognition task when the retention intervals were increased beyond 0s and when test stimuli were repeated within a session. Damage to the amygdala or hippocampus does not affect object recognition, whereas A + H damage produces clear deficits. In an object recognition task, the level of discrimination was significantly lower in the electrolytic lesions of globus pallidus (part of the basal ganglia) in rats compared to the Substantia- Innominata/Ventral Pallidum which was in turn worse compared to Control and Medial Septum/Vertical Diagonal Band of Broca groups; however, only globus pallidus did not discriminate between new and familiar objects. These lesions damage the ventral (what) pathway of the visual processing of objects in the brain.",
            "score": 152.98792266845703
        },
        {
            "docid": "33702464_5",
            "document": "Extrastriate body area . The experiment had subjects view images of different objects, including faces (as a control group), body parts, animals, parts of the face and intimate objects. While viewing the images, the subjects were scanned with an fMRI to see what area of the brain was activated. Through the trials a compilation of the fMRI\u2019s was made. From this compilation image a specific region was determined to have increased activity when shown visual stimuli of body parts and even more activity when viewing whole bodies. There have been no studies involving brain damage to the EBA. Thus far, only scans of brain activity, as well as transcranial magnetic stimulation, have been used to study the EBA. To find the specific functions of the EBA, Comimo Urgesi, Giovanni Berlucchi and Salvatore M. Aglioti used repetitive transcranial magnetic stimulation (rTMS) to disrupt part of the brain, making the brain less responsive in the target area. The study used event-related rTMS to disrupt the EBA, resulting in inactivation of cortical areas. This inactivation caused a slower response time in discriminating body parts. The study used facial features and motorcycle parts as non human parts for control groups. The facial features and motorcycle body parts did not display any change in response time. The neural activity data shows the EBA handles some of the visual processing of human body and parts but is not related to the processing of the face or other objects.",
            "score": 115.35775363445282
        },
        {
            "docid": "525667_10",
            "document": "Human echolocation . In a 2014 study by Thaler and colleagues, the researchers first made recordings of the clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, not only did they perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. The brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any auditory area, becomes involved in the computation of echolocation tasks.",
            "score": 132.8572337627411
        },
        {
            "docid": "1619306_63",
            "document": "Multisensory integration . Additionally, to rationalize sensory dominance, Gori et al. (2008) advocates that the brain utilises the most direct source of information during sensory immaturity. In this case, orientation is primarily a visual characteristic. It can be derived directly from the object image that forms on the retina, irrespective of other visual factors. In fact, data shows that a functional property of neurons within primate visual cortices' are their discernment to orientation. In contrast, haptic orientation judgements are recovered through collaborated patterned stimulations, evidently an indirect source susceptible to interference. Likewise, when size is concerned haptic information coming from positions of the fingers is more immediate. Visual-size perceptions, alternatively, have to be computed using parameters such as slant and distance. Considering this, sensory dominance is a useful instinct to assist with calibration. During sensory immaturity, the more simple and robust information source could be used to tweak the accuracy of the alternate source. Follow-up work by Gori et al. (2012) showed that, at all ages, vision-size perceptions are near perfect when viewing objects within the haptic workspace (i.e. at arm's reach). However, systematic errors in perception appeared when the object was positioned beyond this zone. Children younger than 14 years tend to underestimate object size, whereas adults overestimated. However, if the object was returned to the haptic workspace, those visual biases disappeared. These results support the hypothesis that haptic information may educate visual perceptions. If sources are used for cross-calibration they cannot, therefore, be combined (integrated). Maintaining access to individual estimates is a trade-off for extra plasticity over accuracy, which could be beneficial in retrospect to the developing body. Alternatively, Ernst (2008) advocates that efficient integration initially relies upon establishing correspondence \u2013 which sensory signals belong together. Indeed, studies have shown that visuo-haptic integration fails in adults when there is a perceived spatial separation, suggesting sensory information is coming from different targets. Furthermore, if the separation can be explained, for example viewing an object through a mirror, integration is re-established and can even be optimal. Ernst (2008) suggests that adults can obtain this knowledge from previous experiences to quickly determine which sensory sources depict the same target, but young children could be deficient in this area. Once there is a sufficient bank of experiences, confidence to correctly integrate sensory signals can then be introduced in their behaviour.",
            "score": 129.8794583082199
        },
        {
            "docid": "51462681_3",
            "document": "Objective vision . This is the story of what's happening when you see a picture, even too fast, the brain's visual cortex recognizes what it sees immediately. The visual cortex has a critical job in processing and it's the most complex part of brain. The human brain is much more aware of how it solves complex problems such as playing chess or solving algebra equations, which is why computer programmers have had so much success building machines that emulate this type of activity. but when entities visionary system starts to convert the signals to image(actually the separated shapes and colors) to find a relation between brain's information and those images. The system actually is concentrating on the separable sections, this separation gives the brain a visionary system the excellence processing result, because with this method the system do not waste much time on processing non significant sections and signals. this operation in the Objective Vision project called objective processing and because the O.V. mission is around human visionary simulation, so the developer refers with Objective Vision.",
            "score": 127.3878458738327
        },
        {
            "docid": "45350085_6",
            "document": "Visual computing . At least the following disciplines are sub-fields of visual computing. More detailed descriptions of each of these fields can be found on the linked special pages. Computer graphics is a general term for all techniques that produce images as result with the help of a computer. To transform the description of objects to nice images is called rendering which is always a compromise between image quality and run-time. Techniques that can extract content information from images are called image analysis techniques. Computer vision is the ability of computers (or of robots) to recognize their environment and to interpret it correctly. Visualization is used to produce images that shall communicate messages. Data may be abstract or concrete, often with no a priori geometrical components. Visual analytics describes the discipline of interactive visual analysis of data, also described as \u201cthe science of analytical reasoning supported by the interactive visual interface\u201d. To represent objects for rendering it needs special methods and data structures, which subsumed with the term geometric modeling. In addition to describing and interactive geometric techniques, sensor data are more and more used to reconstruct geometrical models. Algorithms for the efficient control of 3D printers also belong to the field of visual computing. In contrast to image analysis image processing manipulates images to produce better images. \u201cBetter\u201d can have very different meanings subject to the respective application. Also, it has to be discriminated from image editing which describes interactive manipulation of images based on human validation. Techniques that produce the feeling of immersion into a fictive world are called virtual reality (VR). Requirements for VR include head-mounted displays, real-time tracking, and high-quality real-time rendering. Augmented reality enables the user to see the real environment in addition to the virtual objects, which augment this reality. Accuracy requirements on rendering speed and tracking precision are significantly higher here. The planning, design and uses of interfaces between people and computers is not only part of every system involving images. Due to the high bandwidth of the human visual channel (eye), images are also a preferred part of ergonomic user interfaces in any system, so that human-computer interaction is also an integral part of visual computing.",
            "score": 89.85903668403625
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 123.6228197813034
        },
        {
            "docid": "24965027_11",
            "document": "Cognitive neuroscience of visual object recognition . The visual processing of objects in the brain can be divided into two processing pathways: the dorsal stream (how/where), which extends from the visual cortex to the parietal lobes, and ventral stream (what), which extends from the visual cortex to the inferotemporal cortex (IT). The existence of these two separate visual processing pathways was first proposed by Ungerleider and Mishkin (1982) who, based on their lesion studies, suggested that the dorsal stream is involved in the processing of visual spatial information, such as object localization (where), and the ventral stream is involved in the processing of visual object identification information (what). Since this initial proposal, it has been alternatively suggested that the dorsal pathway should be known as the 'How' pathway as the visual spatial information processed here provides us with information about how to interact with objects, For the purpose of object recognition, the neural focus is on the ventral stream.",
            "score": 127.73220324516296
        },
        {
            "docid": "4231622_3",
            "document": "Inferior temporal gyrus . The inferior temporal gyrus is the anterior region of the temporal lobe located underneath the central temporal sulcus. The primary function of the occipital temporal gyrus \u2013 otherwise referenced as IT cortex \u2013 is associated with visual stimuli processing, namely visual object recognition, and has been suggested by recent experimental results as the final location of the ventral cortical visual system. The IT cortex in humans is also known as the Inferior Temporal Gyrus since it has been located to a specific region of the human temporal lobe. The IT processes visual stimuli of objects in our field of vision, and is involved with memory and memory recall to identify that object; it is involved with the processing and perception created by visual stimuli amplified in the V1, V2, V3, and V4 regions of the occipital lobe. This region processes the color and form of the object in the visual field and is responsible for producing the \u201cwhat\u201d from this visual stimuli, or in other words identifying the object based on the color and form of the object and comparing that processed information to stored memories of objects to identify that object.",
            "score": 155.33101534843445
        },
        {
            "docid": "47152350_18",
            "document": "Human performance modeling . A developed area in attention is the control of visual attention - models that attempt to answer, \"where will an individual look next?\" A subset of this concerns the question of visual search: How rapidly can a specified object in the visual field be located? This is a common subject of concern for human factors in a variety of domains, with a substantial history in cognitive psychology. This research continues with modern conceptions of salience and salience maps. Human performance modeling techniques in this area include the work of Melloy, Das, Gramopadhye, and Duchowski (2006) regarding Markov models designed to provide upper and lower bound estimates on the time taken by a human operator to scan a homogeneous display. Another example from Witus and Ellis (2003) includes a computational model regarding the detection of ground vehicles in complex images. Facing the nonuniform probability that a menu option is selected by a computer user when certain subsets of the items are highlighted, Fisher, Coury, Tengs, and Duffy (1989) derived an equation for the optimal number of highlighted items for a given number of total items of a given probability distribution. Because visual search is an essential aspect of many tasks, visual search models are now developed in the context of integrating modeling systems. For example, Fleetwood and Byrne (2006) developed an ACT-R model of visual search through a display of labeled icons - predicting the effects of icon quality and set size not only on search time but on eye movements.",
            "score": 90.84841275215149
        },
        {
            "docid": "55422632_5",
            "document": "Darren Gergle . Visual information processing is the use of our \u201cvisual reasoning skills\u201d which allows us to \u201cprocess and interpret meaning\u201d from \u201cvisual information\u201d derived from our optics. In his Doctoral Dissertation, he investigated the impact that shared visual information has on task-oriented collaboration. He developed a \u201cpuzzle study paradigm\u201d, an online collaborative experiment where a \u201cHelper\u201d directs a \u201cWorker\u201d how to solve the given puzzle pieces. Pairs of individuals were given no visuals (relied upon linguistics only), shared visuals (relied upon shared visuals only) or both (relied upon shared visuals and linguistics). This mimicked distance collaborations where individuals of greater knowledge may instruct persons of lesser expertise. Data from his experiments concluded that both linguistics and shared visuals are equally critical in effective and efficient distance collaborations. <br> These findings built the foundation for further research. New technologies can be designed with in depth understanding of \u201cthe ways in which shared visual information influences collaborative performance\u201d. Usability for the Web: Designing Web Sites That Work is a book which Professor Gergle co-authored. He applied principles of design theory and visual information processing to guide web designers in using a systematic website design model where the user\u2019s needs are the focal point. <br> In 2003, he investigated the impact of the size of displays on comprehension and spatial tasks. This ignited further research. <br> In 2004, investigations into whether physically large displays can improve path integration in 3D virtual navigation tasks were conducted. Their findings are significant for collaborative designers who have empirical data to support the use of larger 3D displays.<br> He explored collaborative systems further, by examining the use of \u201cdyadic mobile eye tracking to study collaborative reference\u201d. In order to understand how to create \u201cintelligent collaborative systems\u201d he first had to observe how humans interact in their natural environment and use those parameters to design intelligent systems. He observed the methods used by humans to \u201creference\u201d. The way by which \u201cwe specify the particular person, object or entity that we are talking about\u201d is called \u201creferencing\u201d (Carlson, 2004 as cited in Gergle & Clark, 2011). Gergle & Clark (2011) iterated their novel methodology:",
            "score": 96.22529196739197
        },
        {
            "docid": "45464854_3",
            "document": "Sensory memory . Iconic memory. The mental representation of the visual stimuli are referred to as icons (fleeting images.) Iconic memory was the first sensory store to be investigated with experiments dating back as far as 1740. One of the earliest investigations into this phenomenon was by J\u00e1n Andrej Segner, a German physicist and mathematician. In his experiment, Segner attached a glowing coal to a cart wheel and rotated the wheel at increasing speed until an unbroken circle of light was perceived by the observer. He calculated that the glowing coal needed to make a complete circle in under 100ms to achieve this effect, which he determined was the duration of this visual memory store. In 1960, George Sperling conducted a study where participants were shown a set of letters for a brief amount of time and were asked to recall the letters they were shown afterwards. Participants were less likely to recall more letters when asked about the whole group of letters, but recalled more when asked about specific subgroups of the whole. These findings suggest that iconic memory in humans has a large capacity, but decays very rapidly . In a 2001 experiment, Vogel et al. presented a display of between 3 and 12 objects. After 900ms, a second display was presented that was either the same or had one object changed. The result was that the participants ability to decide if the two displays were identical was almost perfect with four objects, but steadily declined as the number of items in the display increased above four. This determined the capacity to be around four items. Another study set out to test the idea that visual sensory memory consists of coarse-grained and fine-grained memory traces using a mathematical model to quantify each. The study suggested that the dual-trace model of visual memory out performed single-trace models .",
            "score": 118.03624415397644
        },
        {
            "docid": "8165347_43",
            "document": "Psychology of art . Humans innately tend to see and have a visual preference for symmetry, an identified quality yielding a positive aesthetic experience that uses an automatic bottom-up factor. This bottom-up factor is speculated to rely on learning experience and visual processing in the brain, suggesting a biological basis. Many studies have ventured to explain this innate preference for symmetry with methods including the Implicit Association Test (IAT). Research suggests that we may prefer symmetry because it is easy to process; hence we have a higher perceptual fluency when works are symmetrical. Fluency research draws on evidence from humans and animals that point to the importance of symmetry regardless of biological necessity. This research highlights the efficiency with which computers recognize and process symmetrical objects relative to non-symmetrical models. There have been investigations regarding the objective features that stimuli contain that may affect the fluency and therefore the preferences. Factors such as amount of information given, the extent of symmetry, and figure-ground contrast are only a few listed in the literature. This preference for symmetry has led to question on how fluency affects our implicit preferences by using the Implicit Association Test. Findings suggest that perceptual fluency is a factor that elicits implicit responses, as shown with the Implicit Association Test results. Research has branched from studying aesthetic pleasure and symmetry on an explicit but also implicit level. In fact, research tries to integrate priming (psychology), cultural influences and the different types of stimuli that may elicit an aesthetic preference.",
            "score": 109.7062656879425
        },
        {
            "docid": "25146378_12",
            "document": "Functional specialization (brain) . One of the most well known examples of functional specialization is the fusiform face area (FFA). Justine Sergent was one of the first researchers that brought forth evidence towards the functional neuroanatomy of face processing. Using positron emission tomography (PET), Sergent found that there were different patterns of activation in response to the two different required tasks, face processing verses object processing. These results can be linked with her studies of brain-damaged patients with lesions in the occipital and temporal lobes. Patients revealed that there was an impairment of face processing but no difficulty recognizing everyday objects, a disorder also known as prosopagnosia. Later research by Nancy Kanwisher using functional magnetic resonance imaging (fMRI), found specifically that the region of the inferior temporal cortex, known as the fusiform gyrus, was significantly more active when subjects viewed, recognized and categorized faces in comparison to other regions of the brain. Lesion studies also supported this finding where patients were able to recognize objects but unable to recognize faces. This provided evidence towards domain specificity in the visual system, as Kanwisher acknowledges the Fusiform Face Area as a module in the brain, specifically the extrastriate cortex, that is specialized for face perception.",
            "score": 136.3061422109604
        },
        {
            "docid": "4087208_12",
            "document": "David Marks (psychologist) . Rodway, Gillies and Schepman (2006) found that high vividness participants were significantly more accurate at detecting salient changes to pictures compared to low vividness participants, replicating an earlier study by Gur and Hilgard (1975). Recently Cui et al. (2007) found that reported image vividness correlates with increased activity in the visual cortex. This study shows that the subjective experience of forming a mental image is reflected by increased visual cortical activity. Logie, Pernet, Buonocore and Della Sala (2011) used behavioural and fMRI data for mental rotation from individuals reporting vivid and poor imagery on the VVIQ. Groups differed in brain activation patterns suggesting that the groups performed the same tasks in different ways. These findings help to explain the lack of association previously reported between VVIQ scores and mental rotation performance. Lee, Kravitz and Baker (2012) used fMRI and multi-voxel pattern analysis to investigate the specificity, distribution, and similarity of information for individual seen and imagined objects. Participants either viewed or imagined individual named object images on which they had been trained prior to the scan. Correlation between fMRI and VVIQ scores showed that, in both object-selective and early visual cortex, Lee et al.'s (2012) measure of discrimination across imagery and perception correlated with the vividness of imagery.",
            "score": 147.69576621055603
        },
        {
            "docid": "32197396_4",
            "document": "Form perception . In addition to photoreceptors, the eye requires a properly functioning lens, retina, and an undamaged optic nerve to recognize form. Light travels through the lens, hits the retina, activates the appropriate photoreceptors, depending on available light, which convert the light into an electrical signal that travels along the optic nerve to the lateral geniculate nucleus of the thalamus and then to the primary visual cortex. In the cortex, the adult brain processes information such as lines, orientation, and color. These inputs are integrated in the occipito-temporal cortex where a representation of the object as a whole is created. Visual information continues to be processed in the posterior parietal cortex, also known as the dorsal stream, where the representation of an object\u2019s shape is formed using motion-based cues. It is believed that simultaneously information is processed in the anterior temporal cortex, also known as the ventral stream, where object recognition, identification and naming occur. In the process of recognizing an object, both the dorsal and ventral streams are active, but the ventral stream is more important in discriminating between and recognizing objects. The dorsal stream contributes to object recognition only when two objects have similar shapes and the images are degraded. Observed latency in activation of different parts of the brain supports the idea of hierarchal processing of visual stimuli, with object representations progressing from simple to complex.",
            "score": 163.11884582042694
        },
        {
            "docid": "18689983_14",
            "document": "Human-based computation game . \"Foldit\", while also a GWAP, has a different type of method for tapping the collective human brain. This game challenges players to use their human intuition of 3-dimensional space to help with protein folding algorithms. Unlike the ESP game, which focuses on the results that humans are able to provide, Foldit is trying to understand how humans approach complicated 3 dimensional objects. By 'watching' how humans play the game, researchers hope to be able to improve their own computer programs. Instead of simply performing tasks that computers cannot do, this GWAP is asking humans to help make current machine algorithms better.",
            "score": 70.6075439453125
        },
        {
            "docid": "5212945_3",
            "document": "Visual neuroscience . A recent study using Event-Related Potentials (ERPs) linked an increased neural activity in the occipito-temporal region of the brain to the visual categorization of facial expressions. Results focus on a negative peak in the ERP that occurs 170 milliseconds after the stimulus onset. This action potential, called the N170, was measured using electrodes in the occipito-temporal region, an area already known to be changed by face stimuli. Studying by using the EEG, and ERP methods allow for an extremely high temporal resolution of 4 milliseconds, which makes these kinds of experiments extremely well suited for accurately estimating and comparing the time it takes the brain to perform a certain function. Scientists used classification image techniques, to determine what parts of complex visual stimuli (such as a face) will be relied on when patients are asked to assign them to a category, or emotion. They computed the important features when the stimulus face exhibited one of five different emotions. Stimulus faces exhibiting fear had the distinguishing feature of widening eyes, and stimuli exhibiting happiness exhibited a change in the mouth to make a smile. Regardless of the expression of the stimuli's face, the region near the eyes affected the EEG before the regions near the mouth. This revealed a sequential, and predetermined order to the perception and processing of faces, with the eye being the first, and the mouth, and nose being processed after. This process of downward integration only occurred when the inferior facial features were crucial to the categorization of the stimuli. This is best explained by comparing what happens when participants were shown a face exhibiting fear, versus happiness. The N170 peaked slightly earlier for the fear stimuli at about 175 milliseconds, meaning that it took a participants less time to recognize the facial expression. This is expected because only the eyes need to be processed to recognize the emotion. However, when processing a happy expression, where the mouth is crucial to categorization, downward integration must take place, and thus the N170 peak occurred later at around 185 milliseconds. Eventually visual neuroscience aims to completely explain how the visual system processes all changes in faces as well as objects. This will give a complete view to how the world is constantly visually perceived, and may provide insight into a link between perception and consciousness.",
            "score": 110.6855878829956
        },
        {
            "docid": "2872287_23",
            "document": "Neural binding . Much of the experimental evidence for neural binding has traditionally revolved around sensory awareness. Sensory awareness is accomplished by integrating things together by cognitively perceiving them and then segmenting them so that, in total, there is an image created. Since there can be an infinite number of possibilities in the perception of an object, this has been a unique area of study. The way the brain then collectively pieces certain things together via networking is important not only in the global way of perceiving but also in segmentation. Much of sensory awareness has to do with the taking of a single piece of an object's makeup and then binding its total characteristics so that the brain perceives the object in its final form. Much of the research for the understanding of segmentation and how the brain perceives an object has been done by studying cats. A major finding of this research has to do with the understanding of gamma waves oscillating at 40\u00a0Hz. The information was extracted from a study using the cat visual cortex. It was shown that the cortical neurons responded differently to spatially different objects. These firings of neurons ranged from 40\u201360\u00a0Hz in measure and when observed showed that they fired synchronously when observing different parts of the object. Such coherent responses point to the fact that the brain is doing a kind of coding where it is piecing certain neurons together in the works of making the form of an object. Since the brain is putting these segmented pieces together unsupervised, a significant consonance is found with many philosophers (like Sigmund Freud) who theorize an underlying subconscious that helps to form every aspect of our conscious thought processes.",
            "score": 125.45472311973572
        },
        {
            "docid": "26685721_33",
            "document": "Methods used to study memory . The textbook \"Fundamentals of Human Neuropsychology\" by Kolb and Whishaw describes some designs used to study memory in the macaque monkey. Elizabeth Murray and her colleagues trained monkeys to reach through the bars of their cage after a brief delay in order to displace objects under which a reward may be located. During the brief delay the monkey had to use either object recognition memory, or contextual memory to remember where the reward was located. Object recognition is tested with a matching-to-sample task where the monkey had to remember visual characteristics of the object in order to obtain the reward. Alternatively, in the non-matching-to-sample design the monkey must remember the location of the previously seen object. The monkey must then use context and spatial memory in order to correctly displace an object in the same location as previous, in order to obtain the food reward. These two tasks can be used to differentiate between object recognition memory and contextual memory. Murray and her colleagues were able to show that hippocampal lesions impaired contextual memory whereas rhinal cortex lesions impaired object recognition memory. This experimental design allowed for the dissociation of two mutually exclusive brain regions devoted to specific types of memory.",
            "score": 128.738365650177
        },
        {
            "docid": "24965027_2",
            "document": "Cognitive neuroscience of visual object recognition . Object recognition is the ability to perceive an object's physical properties (such as shape, colour and texture) and apply semantic attributes to it (such as identifying the object as an apple). This process includes the understanding of its use, previous experience with the object, and how it relates to others. Regardless of an object's position or illumination, humans possess the ability to effectively identify and label an object. Humans are one of the few species that possess the ability of invariant visual object recognition. Both \"front end\" (knowledge/goal driven) and \"back end\" (sensory driven) processing are required for a species to be able to recognize objects at varying distances, angles, lighting, etc...",
            "score": 135.15500259399414
        },
        {
            "docid": "45218019_15",
            "document": "Cultural-historical activity theory . \"Activity systems analysis\" is a CHAT-based method, discussed in / and in Cole & Engestr\u00f6m, 1993, for understanding human activity in real-world situations with data collection, analysis, and presentation methods that address the complexities of human activity in natural settings aimed to advance both theory and practice. It is based on Vygotsky's concept of mediated action and captures human activity in a triangle model that includes the subject, tool, object, rule, community, and division of labor. Subjects are participants in an activity, motivated toward a purpose or attainment of the object. The object can be the goal of an activity, the subject's motives for participating in an activity, and the material products that subjects gain through an activity. Tools are socially shared cognitive and/or material resources that subjects can use to attain the object. Informal or formal rules regulate the subject's participation while engaging in an activity. The community is the group or organization to which subjects belong. The division of labor is the shared participation responsibilities in the activity determined by the community. Finally, the outcome is the consequences that the subject faces because of his/her actions driven by the object. These outcomes can encourage or hinder the subject's participation in future activities. In Part 2 of her video \"\"Using Activity Theory to understand human behaviour\"\", shows how activity theory is applied to the problem of behavior change and HIV and AIDs (in South Africa). The video focuses on sexual activity as the activity of the system, and illustrates how an \"Activity System Analysis\", through a historical and current account of the activity, provides a way of understanding lack of behavior change in response to HIV and AIDS. In her eponymous book \"\"Activity Systems Analysis Methods.\"\", describes seven ASA case studies which fall \"\"into four distinct work clusters. These clusters include works that help (a) understand developmental work research (DWR), (b) describe real-world learning situations, (c) design human computer interaction systems, and (d) plan solutions to complicated work-based problems\"\". Other uses of ASA: Summarizing organizational change; Identifying guidelines for designing Constructivist Learning Environments; Identifying contradictions and tensions that shape developments in educational settings; Demonstrating historical developments in organizational learning., and Evaluating K\u201312 school and university partnership relations.",
            "score": 103.1124860048294
        }
    ],
    "r": [
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 189.285400390625
        },
        {
            "docid": "4231622_10",
            "document": "Inferior temporal gyrus . Prosopagnosia, also called face blindness, is a disorder that results in the inability to recognize or discriminate between faces. It can often be associated with other forms of recognition impairment, such as place, car, or emotional recognition. A study conducted by Gross et all in 1969 found that certain cells were selective for the shape of a monkey hand, and they observed that as the stimulus they provided began to further resemble a monkey hand, those cells became more active. A few years later, in 1972, Gross et al. discovered that certain IT cells were selective for faces. Although it is not conclusive, \u2018face-selective\u2019 IT cortex cells are assumed to play a large role in facial recognition in monkeys. After the extensive research into the result of damage to the IT cortex in monkeys, it is theorized that lesions in the IT gyrus in humans result in prosopagnosia. Rubens and Benson\u2019s 1971 study of a subject in life with prosopagnosia reveals that the patient is able to name common objects on visual presentation flawlessly, however she cannot recognize faces. Upon necropsy conducted by Benson et al., it was apparent that a discrete lesion in the right fusiform gyrus, a part of the inferior temporal gyrus, was one of the main causes of the subject\u2019s symptoms.",
            "score": 166.9019317626953
        },
        {
            "docid": "32197396_4",
            "document": "Form perception . In addition to photoreceptors, the eye requires a properly functioning lens, retina, and an undamaged optic nerve to recognize form. Light travels through the lens, hits the retina, activates the appropriate photoreceptors, depending on available light, which convert the light into an electrical signal that travels along the optic nerve to the lateral geniculate nucleus of the thalamus and then to the primary visual cortex. In the cortex, the adult brain processes information such as lines, orientation, and color. These inputs are integrated in the occipito-temporal cortex where a representation of the object as a whole is created. Visual information continues to be processed in the posterior parietal cortex, also known as the dorsal stream, where the representation of an object\u2019s shape is formed using motion-based cues. It is believed that simultaneously information is processed in the anterior temporal cortex, also known as the ventral stream, where object recognition, identification and naming occur. In the process of recognizing an object, both the dorsal and ventral streams are active, but the ventral stream is more important in discriminating between and recognizing objects. The dorsal stream contributes to object recognition only when two objects have similar shapes and the images are degraded. Observed latency in activation of different parts of the brain supports the idea of hierarchal processing of visual stimuli, with object representations progressing from simple to complex.",
            "score": 163.1188507080078
        },
        {
            "docid": "24965027_6",
            "document": "Cognitive neuroscience of visual object recognition . A significant aspect of object recognition is that of object constancy: the ability to recognize an object across varying viewing conditions. These varying conditions include object orientation, lighting, and object variability (size, colour, and other within-category differences). For the visual system to achieve object constancy, it must be able to extract a commonality in the object description across different viewpoints and the retinal descriptions.[9] Participants who did categorization and recognition tasks while undergoing a functional magnetic found as increased blood flow indicating activation in specific regions of the brain. The categorization task consisted of participants placing objects from canonical or unusual views as either indoor or outdoor objects. The recognition task occurs by presenting the participants with images that they had viewed previously. Half of these images were in the same orientation as previously shown, while the other half were presented in the opposing viewpoint. The brain regions implicated in mental rotation, such as the ventral and dorsal visual pathways and the prefrontal cortex, showed the greatest increase in blood flow during these tasks, demonstrating that they are critical for the ability to view objects from multiple angles. Several theories have been generated to provide insight on how object constancy may be achieved for the purpose of object recognition including, viewpoint-invariant, viewpoint-dependent and multiple views theories.",
            "score": 159.23814392089844
        },
        {
            "docid": "4231622_5",
            "document": "Inferior temporal gyrus . The temporal lobe is unique to primates. In humans, the IT cortex is more complex than their relative primate counterparts. The human inferior temporal cortex consists of the inferior temporal gyrus, the middle temporal gyrus, and the fusiform gyrus. When looking at the brain laterally \u2013 that is from the side and looking at the surface of the temporal lobe \u2013 the inferior temporal gyrus is along the bottom portion of the temporal lobe, and is separated from the middle temporal gyrus located directly above by the inferior temporal sulcus. Additionally, some processing of the visual field that corresponds to the ventral stream of visual processing occurs in the lower portion of the superior temporal gyrus closest to the superior temporal sulcus. The medial and ventral view of the brain \u2013 meaning looking at the medial surface from below the brain, facing upwards \u2013 reveals that the inferior temporal gyrus is separated from the fusiform gyrus by the occipital-temporal sulcus. This human inferior temporal cortex is much more complex than that of other primates: non-human primates have an inferior temporal cortex that is not divided into unique regions such as humans' inferior temporal gyrus, fusiform gyrus, or middle temporal gyrus.  This region of the brain corresponds to the inferior temporal cortex and is responsible for visual object recognition and receives processed visual information. The inferior temporal cortex in primates has specific regions dedicated to processing different visual stimuli processed and organized by the different layers of the striate cortex and extra-striate cortex. The information from the V1 \u2013V5 regions of the geniculate and tectopulvinar pathways are radiated to the IT cortex via the ventral stream: visual information specifically related to the color and form of the visual stimuli. Through comparative research between primates \u2013 humans and non-human primates \u2013 results indicate that the IT cortex plays a significant role in visual shape processing. This is supported by functional magnetic resonance imaging (fMRI) data collected by researchers comparing this neurological process between humans and macaques.",
            "score": 157.57229614257812
        },
        {
            "docid": "4231622_3",
            "document": "Inferior temporal gyrus . The inferior temporal gyrus is the anterior region of the temporal lobe located underneath the central temporal sulcus. The primary function of the occipital temporal gyrus \u2013 otherwise referenced as IT cortex \u2013 is associated with visual stimuli processing, namely visual object recognition, and has been suggested by recent experimental results as the final location of the ventral cortical visual system. The IT cortex in humans is also known as the Inferior Temporal Gyrus since it has been located to a specific region of the human temporal lobe. The IT processes visual stimuli of objects in our field of vision, and is involved with memory and memory recall to identify that object; it is involved with the processing and perception created by visual stimuli amplified in the V1, V2, V3, and V4 regions of the occipital lobe. This region processes the color and form of the object in the visual field and is responsible for producing the \u201cwhat\u201d from this visual stimuli, or in other words identifying the object based on the color and form of the object and comparing that processed information to stored memories of objects to identify that object.",
            "score": 155.3310089111328
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 154.9935760498047
        },
        {
            "docid": "24965027_25",
            "document": "Cognitive neuroscience of visual object recognition . Loss of object recognition is called \"visual object agnosia\". There are two broad categories of visual object agnosia: apperceptive and associative. When object agnosia occurs from a lesion in the dominant hemisphere, there is often a profound associated language disturbance, including loss of word meaning.  Object recognition is a complex task and involves several different areas of the brain \u2013 not just one. If one area is damaged then object recognition can be impaired. The main area for object recognition takes place in the temporal lobe. For example, it was found that lesions to the perirhinal cortex in rats causes impairments in object recognition especially with an increase in feature ambiguity. Neonatal aspiration lesions of the amygdaloid complex in monkeys appear to have resulted in a greater object memory loss than early hippocampal lesions. However, in adult monkeys, the object memory impairment is better accounted for by damage to the perirhinal and entorhinal cortex than by damage to the amygdaloid nuclei. Combined amygdalohippocampal (A + H) lesions in rats impaired performance on an object recognition task when the retention intervals were increased beyond 0s and when test stimuli were repeated within a session. Damage to the amygdala or hippocampus does not affect object recognition, whereas A + H damage produces clear deficits. In an object recognition task, the level of discrimination was significantly lower in the electrolytic lesions of globus pallidus (part of the basal ganglia) in rats compared to the Substantia- Innominata/Ventral Pallidum which was in turn worse compared to Control and Medial Septum/Vertical Diagonal Band of Broca groups; however, only globus pallidus did not discriminate between new and familiar objects. These lesions damage the ventral (what) pathway of the visual processing of objects in the brain.",
            "score": 152.9879150390625
        },
        {
            "docid": "44632031_32",
            "document": "M-Theory (learning framework) . M-theory is based on a quantitative theory of the ventral stream of visual cortex. Understanding how visual cortex works in object recognition is still a challenging task for neuroscience. Humans and primates are able to memorize and recognize objects after seeing just couple of examples unlike any state-of-the art machine vision systems that usually require a lot of data in order to recognize objects. Prior to the use of visual neuroscience in computer vision has been limited to early vision for deriving stereo algorithms (e.g.,) and to justify the use of DoG (derivative-of-Gaussian) filters and more recently of Gabor filters. No real attention has been given to biologically plausible features of higher complexity. While mainstream computer vision has always been inspired and challenged by human vision, it seems to have never advanced past the very first stages of processing in the simple cells in V1 and V2. Although some of the systems inspired - to various degrees - by neuroscience, have been tested on at least some natural images, neurobiological models of object recognition in cortex have not yet been extended to deal with real-world image databases.",
            "score": 151.00360107421875
        },
        {
            "docid": "4087208_12",
            "document": "David Marks (psychologist) . Rodway, Gillies and Schepman (2006) found that high vividness participants were significantly more accurate at detecting salient changes to pictures compared to low vividness participants, replicating an earlier study by Gur and Hilgard (1975). Recently Cui et al. (2007) found that reported image vividness correlates with increased activity in the visual cortex. This study shows that the subjective experience of forming a mental image is reflected by increased visual cortical activity. Logie, Pernet, Buonocore and Della Sala (2011) used behavioural and fMRI data for mental rotation from individuals reporting vivid and poor imagery on the VVIQ. Groups differed in brain activation patterns suggesting that the groups performed the same tasks in different ways. These findings help to explain the lack of association previously reported between VVIQ scores and mental rotation performance. Lee, Kravitz and Baker (2012) used fMRI and multi-voxel pattern analysis to investigate the specificity, distribution, and similarity of information for individual seen and imagined objects. Participants either viewed or imagined individual named object images on which they had been trained prior to the scan. Correlation between fMRI and VVIQ scores showed that, in both object-selective and early visual cortex, Lee et al.'s (2012) measure of discrimination across imagery and perception correlated with the vividness of imagery.",
            "score": 147.69577026367188
        },
        {
            "docid": "1626279_21",
            "document": "Anne Treisman . In the early 1980s, neuroscientists such as Torston Wiesel and David H. Hubel were discovering that different areas of the primate visual cortex were finely tuned to selective features, such as line orientation, luminance, color, movement, etc. These findings prompted the question of how these distinct features are connected into a unified whole, e.g., the binding problem. For example, when you see a red ball roll by, cells sensitive to movement fire in the medial temporal cortex, while cells sensitive to color, shape and location fire in other areas. Despite all this distinct neuronal firing, you don't perceive the ball as separated by shape, movement and color perceptions; you experience an integrated experience with all these components occurring together. The question of how these elements are combined is the essence of the binding problem and continued into the late 1990s. A number of possible mechanisms were envisaged, including grandmother cells responding to specific conjunctions of features that uniquely identify a particular object; local cell assemblies onto which the pathways from different feature maps converge, perhaps with adjustable connections allowing flexible routing of signals; a serial scan of different spatial areas selected by an adjustable attention window, conjoining the features that each contains and excluding features from adjacent areas; detection of temporal contiguity \u2013 parts and properties whose onset, offset or motion coincide probably belong to the same object synchronised firing of cells responding to features of the same object, perhaps assisted by oscillatory neural activity. Treisman used failures of binding to shed light on its underlying mechanisms. Specifically, she found that left-brain-damaged patients have increasing illusory conjunctions and decreased performance in a spatially cued attention task, which suggests a link between attentional binding and the parietal lobes. Treisman also cited corroborating evidence from positron emission tomography and event-related potential studies which were consistent with the spatial attention account of feature integration.",
            "score": 146.3356170654297
        },
        {
            "docid": "1038052_31",
            "document": "Neuroesthetics . Emotions play a large role in aesthetic processing. Experiments designed specifically to force the subjects to view the artwork subjectively (by inquiring of its aesthetic appeal) rather than simply with the visual systems, revealed a higher activation in the brain's emotional circuitry. Results from these experiments revealed high activation in the bilateral insula which can be attributed to the emotional experience of viewing art. This correlates with other known emotional roles of the insula. However, the correlation between the insula's varying states of activation and positive or negative emotions in this context is unknown. The emotional view of art can be contrasted with perception related to object recognition when pragmatically viewing art. The right fusiform gyrus has been revealed to show activation to visual stimuli such as faces and representational art. This holds importance in the field because as Ramachandran also speculated, object recognition and the search for meaning can evoke a pleasant emotional response. The motor cortex was also shown to be involved in aesthetic perception. However, it displayed opposite trends of activation from the OFC. It may be a common correlate for the perception of emotionally charged stimuli despite its previously known roles. Several other areas of the brain were shown to be slightly activated during certain studies such as the anterior cingulate cortex, previously known for its involvement in the feeling of romance, and the left parietal cortex, whose purpose may be to direct spatial attention.",
            "score": 146.07472229003906
        },
        {
            "docid": "9186444_5",
            "document": "Visual modularity . Another clinical case that would a priori suggest a module for modularity in visual processing is visual agnosia. The well studied patient DF is unable to recognize or discriminate objects owing to damage in areas of the lateral occipital cortex although she can see scenes without problem \u2013 she can literally see the forest but not the trees. Neuroimaging of intact individuals reveals strong occipito-temporal activation during object presentation and greater activation still for object recognition. Of course, such activation could be due to other processes, such as visual attention. However, other evidence that shows a tight coupling of perceptual and physiological changes suggests activation in this area does underpin object recognition. Within these regions are more specialized areas for face or fine grained analysis, place perception and human body perception. Perhaps some of the strongest evidence for the modular nature of these processing systems is the double dissociation between object- and face (prosop-) agnosia. However, as with color and motion, early areas (see for a comprehensive review) are implicated too, lending support to the idea of a multistage stream terminating in the inferotemporal cortex rather than an isolated module.",
            "score": 145.99313354492188
        },
        {
            "docid": "21312318_27",
            "document": "Recognition memory . Recognition memory is critically dependent on a hierarchically organized network of brain areas including the visual ventral stream, medial temporal lobe structures, frontal lobe and parietal cortices along with the hippocampus. As mentioned previously, the processes of recollection and familiarity are represented differently in the brain. As such, each of the regions listed above can be further subdivided according to which part is primarily involved in recollection or in familiarity. In the temporal cortex, for instance, the medial region is related to recollection whereas the anterior region is related to familiarity. Similarly, in the parietal cortex, the lateral region is related to recollection whereas the superior region is related to familiarity. An even more specific account divides the medial parietal region, relating the posterior cingulate to recollection and the precuneus to familiarity. The hippocampus plays a prominent role in recollection whereas familiarity depends heavily on the surrounding medial-temporal regions, especially the perirhinal cortex. Finally, it is not yet clear what specific regions of the prefrontal lobes are associated with recollection versus familiarity, although there is evidence that the left prefrontal cortex is correlated more strongly with recollection whereas the right prefrontal cortex is involved more in familiarity. Though left-side activation involved in recollection was originally hypothesized to result from semantic processing of words (many of these earlier studies used written words for stimuli) subsequent studies using nonverbal stimuli produced the same finding\u2014suggesting that prefrontal activation in the left hemisphere results from any kind of detailed remembering.  As previously mentioned, recognition memory is not a stand-alone concept; rather it is a highly interconnected and integrated sub-system of memory. Perhaps misleadingly, the regions of the brain listed above correspond to an abstract and highly generalized understanding of recognition memory, in which the stimuli or items-to-be-recognized are not specified. In reality, however, the location of brain activation involved in recognition is highly dependent on the nature of the stimulus itself. Consider the conceptual differences in recognizing written words compared to recognizing human faces. These are two qualitatively different tasks and as such it is not surprising that they involve additional, distinct regions of the brain. Recognizing words, for example, involves the visual word form area, a region in the left fusiform gyrus, which is believed to specialized in recognizing written words. Similarly, the fusiform face area, located in the right hemisphere, is linked specifically to the recognition of faces.",
            "score": 145.43017578125
        },
        {
            "docid": "2970322_9",
            "document": "Visual agnosia . More specifically, the lateral occipital complex appears to respond to many different types of objects. Prosopagnosia (inability to recognize faces) is due to damage of the fusiform face area (FFA). An area in the fusiform gyrus of the temporal lobe that has been strongly associated with a role in facial recognition. However, this area is not exclusive to faces; recognition of other objects of expertise are also processed in this area. The extrastriate body cortex (EBA) was found to be activated by photographs, silhouettes, or stick drawings of human bodies. The parahippocampal place area (PPA) of the limbic cortex has been found to be activated by the sight of scenes and backgrounds. Cerebral achromatopsia (the inability to discriminate between different hues) is caused by damage to the V8 area of the visual association cortex. The left hemisphere seems to play a critical role in recognizing the meaning of common objects.",
            "score": 141.77810668945312
        },
        {
            "docid": "27179535_7",
            "document": "Leah Krubitzer . The parietal cortex is another area of interest for Krubitzer. The parietal cortex allows us to coordinate movements between our eyes and our hands. This ability allows for smooth reaching movements, as well as, grasping. Past research has been done on Old and New World monkeys, as well as humans, to see how the parietal cortex functions in hand use. Imaging used on humans shows that there are similar cortical patterns shared across human and non-human primates, but the extent to which these pathways are used depends on the somatosensory organization and connectivity in the parietal cortex. Krubitzer and her team took this information and investigated a little deeper. Because humans have an opposable thumb, our ability to grip objects and reach for objects is much greater than monkeys. For this reason, the connectivity in the human parietal cortex is much more complex than that of a non-human primate. In Krubitzer's lab, her team investigated different areas of the parietal cortex in order to better pin point which part controls which motor movement. Krubitzer found that when one area of the cortex responsible for a certain motor movement is compromised, the rest of the cortex will reorganize itself to make up for the loss. This finding shows how the parietal cortex can rewire itself in order to maintain functional motor capabilities. Currently in the lab, Krubitzer and colleagues are testing a microchip that may be placed in the posterior parietal cortex of the brain to deactivate certain areas at a time. Using this technique, they are able to see how deactivation of a certain portion of the cortex impacts hand grasping and reaching in monkeys. This technique is performed while the monkeys are performing different manual tasks in order to see the action of the cortex live.",
            "score": 140.7031707763672
        },
        {
            "docid": "39151518_10",
            "document": "Neuronal recycling hypothesis . As was stated in the neuronal recycling hypothesis, brain circuits bias what we are able to learn. One bias identified involves the preference of central versus peripheral images at different points along the cerebral cortex. It was observed that in all individuals, the visual word form area fell on the region of the cortex with a massive preference for fine-grained, central images. This area is most suitable to accommodate reading ability, due to the high degree of visual precision necessary to perform this function effectively. Another cortical bias relevant to reading comes from the lateralization of cerebral hemispheres. Reading consistently activates the left hemisphere, which is associated with language abilities and discriminating between small shapes, showing a clear bias towards reading functions. There is a preadaptation of the inferior temporal cortex that we use when learning to read. It is the area activated during invariant object recognition, and it's sufficient plasticity allows it to accommodate the new shapes and symbols necessary for reading.",
            "score": 140.6103057861328
        },
        {
            "docid": "24965027_7",
            "document": "Cognitive neuroscience of visual object recognition . Viewpoint-invariant theories suggest that object recognition is based on structural information, such as individual parts, allowing for recognition to take place regardless of the object's viewpoint. Accordingly, recognition is possible from any viewpoint as individual parts of an object can be rotated to fit any particular view.[10] This form of analytical recognition requires little memory as only structural parts need to be encoded, which can produce multiple object representations through the interrelations of these parts and mental rotation.[10] Participants in a study were presented with one encoding view from each of 24 preselected objects, as well as five filler images. Objects were then represented in the central visual field at either the same orientation or a different orientation than the original image. Then participants were asked to name if the same or different depth- orientation views of these objects presented. The same procedure was then executed when presenting the images to the left or right visual field. Viewpoint-dependent priming was observed when test views were presented directly to the right hemisphere, but not when test views were presented directly to the left hemisphere. The results support the model that objects are stored in a manner that is viewpoint dependent because the results did not depend on whether the same or a different set of parts could be recovered from the different-orientation views.",
            "score": 140.59213256835938
        },
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 140.45046997070312
        },
        {
            "docid": "24965027_5",
            "document": "Cognitive neuroscience of visual object recognition . Visual recognition processing has been typically viewed as a bottom-up hierarchy in which information is processed sequentially with increasing complexities, where lower-level cortical processors, such as the primary visual cortex, are at the bottom of the processing hierarchy and higher-level cortical processors, such as the inferotemporal cortex (IT), are at the top, where recognition is facilitated. A most recognized bottom-up hierarchical theory is David Marr's theory of vision. In contrast, an increasingly popular recognition processing theory, is that of top-down processing. One model, proposed by Moshe Bar (2003), describes a \"shortcut\" method in which early visual inputs are sent, partially analyzed, from the early visual cortex to the prefrontal cortex (PFC). Possible interpretations of the crude visual input is generated in the PFC and then sent to the inferotemporal cortex (IT) subsequently activating relevant object representations which are then incorporated into the slower, bottom-up process. This \"shortcut\" is meant to minimize the amount of object representations required for matching thereby facilitating object recognition. Lesion studies have supported this proposal with findings of slower response times for individuals with PFC lesions, suggesting use of only the bottom-up processing.",
            "score": 140.22000122070312
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 140.12240600585938
        },
        {
            "docid": "32197396_2",
            "document": "Form perception . Form perception is the recognition of visual elements of objects, specifically those to do with shapes, patterns and previously identified important characteristics. An object is perceived by the retina as a two-dimensional image, but the image can vary for the same object in terms of the context with which it is viewed, the apparent size of the object, the angle from which it is viewed, how illuminated it is, as well as where it resides in the field of vision.  Despite the fact that each instance of observing an object leads to a unique retinal response pattern, the visual processing in the brain is capable of recognizing these experiences as analogous, allowing invariant object recognition. Visual processing occurs in a hierarchy with the lowest levels recognizing lines and contours, and slightly higher levels performing tasks such as completing boundaries and recognizing contour combinations. The highest levels integrate the perceived information to recognize an entire object. Essentially object recognition is the ability to assign labels to objects in order to categorize and identify them, thus distinguishing one object from another. During visual processing information is not created, but rather reformatted in a way that draws out the most detailed information of the stimulus.",
            "score": 138.51470947265625
        },
        {
            "docid": "386062_15",
            "document": "Wishful thinking . Magnocellular (M) and parvocellular (P) pathways, which feed into the orbitofrontal cortex, play important roles in top-down processes that are susceptible to cognitive penetrability. Magnocellular processing biased stimuli deferentially activates the orbitofrontal cortex; fast magnocellular projections link early visual and inferotemporal object recognition and work with the orbitofrontal cortex by helping generate early object predictions based on perceptual sets. Stimuli were M-biased with low-luminance, achromatic line drawings or P-biased with isoluminate, chromatic line drawings and participants were asked if the drawing was larger or smaller than a shoebox. Functional magnetic resonance imaging was used to monitor brain activity in the orbitofrontal cortex and ventrotemporal regions to determine which pathway aided faster object recognition. The results supported that magnocellular neurons play a vital role in low-resolution object recognition as the neurons aid in quickly triggering top-down processes that provide initial guesses that lead to faster object recognition.",
            "score": 137.90994262695312
        },
        {
            "docid": "18345264_14",
            "document": "Neural correlates of consciousness . Logothetis and colleagues recorded a variety of visual cortical areas in awake macaque monkeys performing a binocular rivalry task. Macaque monkeys can be trained to report whether they see the left or the right image. The distribution of the switching times and the way in which changing the contrast in one eye affects these leaves little doubt that monkeys and humans experience the same basic phenomenon. In the primary visual cortex (V1) only a small fraction of cells weakly modulated their response as a function of the percept of the monkey while most cells responded to one or the other retinal stimulus with little regard to what the animal perceived at the time. But in a high-level cortical area such as the inferior temporal cortex along the ventral stream almost all neurons responded only to the perceptually dominant stimulus, so that a \"face\" cell only fired when the animal indicated that it saw the face and not the pattern presented to the other eye. This implies that NCC involve neurons active in the inferior temporal cortex: it is likely that specific reciprocal actions of neurons in the inferior temporal and parts of the prefrontal cortex are necessary.",
            "score": 136.81057739257812
        },
        {
            "docid": "25146378_12",
            "document": "Functional specialization (brain) . One of the most well known examples of functional specialization is the fusiform face area (FFA). Justine Sergent was one of the first researchers that brought forth evidence towards the functional neuroanatomy of face processing. Using positron emission tomography (PET), Sergent found that there were different patterns of activation in response to the two different required tasks, face processing verses object processing. These results can be linked with her studies of brain-damaged patients with lesions in the occipital and temporal lobes. Patients revealed that there was an impairment of face processing but no difficulty recognizing everyday objects, a disorder also known as prosopagnosia. Later research by Nancy Kanwisher using functional magnetic resonance imaging (fMRI), found specifically that the region of the inferior temporal cortex, known as the fusiform gyrus, was significantly more active when subjects viewed, recognized and categorized faces in comparison to other regions of the brain. Lesion studies also supported this finding where patients were able to recognize objects but unable to recognize faces. This provided evidence towards domain specificity in the visual system, as Kanwisher acknowledges the Fusiform Face Area as a module in the brain, specifically the extrastriate cortex, that is specialized for face perception.",
            "score": 136.30613708496094
        },
        {
            "docid": "31148473_12",
            "document": "Transsaccadic memory . This is an area within the visual cortex that has been found to play an important role in the target selection of saccades. In other words, this area is important for determining which objects our eyes shift to when they move. Studies have shown that there is a large amount of activation within the visual area V4 before the saccade even takes place. This occurs in the form of shrinking receptive fields. The receptive fields of these brain cells tend to shift towards the object that the eye is about to move towards, generally more so if the object is close to the original fixation point. This dynamic change in receptive fields is thought to enhance the perception and recognition of objects in a visual scene. Because the receptive fields become smaller around the targeted objects, attention within the visual scene is very focused on these objects. Increased attention to target objects within a visual scene help direct eye movements from one object to another. Understanding of the visual scene becomes more efficient because these attention shifts guide the eyes towards relevant objects as opposed to objects that may not be as important.",
            "score": 135.76797485351562
        },
        {
            "docid": "39151518_9",
            "document": "Neuronal recycling hypothesis . Reading has only been a part of human culture for approximately 5400\u00a0years, and therefore many conclude that it is too modern to be the result of evolution. The neuronal recycling hypothesis proposes that visual word recognition is a result of recycling cortical structures whose initial functions were for object recognition. The visual word form area is situated next to a number of cortical areas activated by object images, suggesting it was previously biased to play a role in object recognition. Also, recycled structures acquire new functions such as the ability to recognize letters regardless of their size, shape, or case.",
            "score": 135.66317749023438
        },
        {
            "docid": "24965027_2",
            "document": "Cognitive neuroscience of visual object recognition . Object recognition is the ability to perceive an object's physical properties (such as shape, colour and texture) and apply semantic attributes to it (such as identifying the object as an apple). This process includes the understanding of its use, previous experience with the object, and how it relates to others. Regardless of an object's position or illumination, humans possess the ability to effectively identify and label an object. Humans are one of the few species that possess the ability of invariant visual object recognition. Both \"front end\" (knowledge/goal driven) and \"back end\" (sensory driven) processing are required for a species to be able to recognize objects at varying distances, angles, lighting, etc...",
            "score": 135.15499877929688
        },
        {
            "docid": "734667_8",
            "document": "Iconic memory . Although less research exists regarding the neural representation of informational persistence compared to visual persistence, new electrophysiological techniques have begun to reveal cortical areas involved. Unlike visible persistence, informational persistence is thought to rely on higher-level visual areas beyond the visual cortex. The anterior superior temporal sulcus (STS), a part of the ventral stream, was found to be active in macaques during iconic memory tasks. This brain region is associated with object recognition and object identity. Iconic memory's role in change detection has been related to activation in the middle occipital gyrus (MOG). MOG activation was found to persist for approximately 2000ms suggesting a possibility that iconic memory has a longer duration than what was currently thought. Iconic memory is also influenced by genetics and proteins produced in the brain. Brain-derived neurotrophic factor (BDNF) is a part of the neurotrophin family of nerve growth factors. Individuals with mutations to the BDNF gene which codes for BDNF have been shown to have shortened, less stable informational persistence.",
            "score": 134.12623596191406
        },
        {
            "docid": "35075711_28",
            "document": "Spontaneous recovery . The pathway of recall associated with the retrieval of visual memories is the visual system. The image is captured by the eye and then transmitted to the brain by the optic nerve, which terminated on the cells of the lateral geniculate nucleus. The main target that the lateral geniculate nucleus projects onto is the primary visual cortex, which is the part of the cerebral cortex responsible for processing visual information. The analysis of visual stimuli continues through two major cortical systems for processing. The first is the ventral pathway, which extends to the temporal lobe and is involved in recognizing objects (the \"what\" pathway). The second is the dorsal pathway, which projects to the parietal lobe and is essential in locating objects (the \"where\" pathway).",
            "score": 134.04608154296875
        },
        {
            "docid": "1664561_19",
            "document": "Intentional stance . Robbins and Jack point to a 2003 study in which participants viewed animated geometric shapes in different \"vignettes,\" some of which could be interpreted as constituting social interaction, while others suggested mechanical behavior. Viewing social interactions elicited activity in brain regions associated with identifying faces and biological objects (posterior temporal cortex), as well as emotion processing (right amygdala and ventromedial prefrontal cortex). Meanwhile, the mechanical interactions activated regions related to identifying objects like tools that can be manipulated (posterior temporal lobe). The authors suggest \"that these findings reveal putative 'core systems' for social and mechanical understanding that are divisible into constituent parts or elements with distinct processing and storage capabilities.\"",
            "score": 133.03045654296875
        },
        {
            "docid": "525667_10",
            "document": "Human echolocation . In a 2014 study by Thaler and colleagues, the researchers first made recordings of the clicks and their very faint echoes using tiny microphones placed in the ears of the blind echolocators as they stood outside and tried to identify different objects such as a car, a flag pole, and a tree. The researchers then played the recorded sounds back to the echolocators while their brain activity was being measured using functional magnetic resonance imaging. Remarkably, when the echolocation recordings were played back to the blind experts, not only did they perceive the objects based on the echoes, but they also showed activity in those areas of their brain that normally process visual information in sighted people, primarily primary visual cortex or V1. This result is surprising, as visual areas, as their names suggest, are only active during visual tasks. The brain areas that process auditory information were no more activated by sound recordings of outdoor scenes containing echoes than they were by sound recordings of outdoor scenes with the echoes removed. Importantly, when the same experiment was carried out with sighted people who did not echolocate, these individuals could not perceive the objects and there was no echo-related activity anywhere in the brain. This suggests that the cortex of blind echolocators is plastic and reorganizes such that primary visual cortex, rather than any auditory area, becomes involved in the computation of echolocation tasks.",
            "score": 132.85723876953125
        }
    ]
}