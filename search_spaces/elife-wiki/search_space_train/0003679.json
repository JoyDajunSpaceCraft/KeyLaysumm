{
    "q": [
        {
            "docid": "37759941_5",
            "document": "Crossmodal attention . While research on cross-modal attention has found that deficits in attending often occur, this research has led to a better understanding of attentional processing. Some studies have used positron emission tomography (PET) to examine the neurological basis for how we selectively attend to information using different sensory modalities. Event related potentials (ERPs). have also been used to help researchers measure how humans encode and process attended information in the brain. By increasing our understanding of modality-specific and cross-modal attention, we are better able to understand how we think and direct our attention.",
            "score": 153.82357120513916
        },
        {
            "docid": "20544661_3",
            "document": "The Happiness Project . The project sprang from casual interviews with people in Spearin's neighbourhood on the subject of happiness. After each interview I would listen back to the recording for moments that were interesting in both meaning and melody. By meaning I mean the thoughts expressed, by melody I mean the cadence and inflection that give the voice a sing-song quality. It has always been interesting to me how we use sounds to convey concepts. Normally, we don\u2019t pay any attention to the movement of our lips and tongue, and the rising and falling of our voices as we toss our thoughts back and forth to each other. We just talk and listen. The only time we pay attention to these qualities is in song. (Just as when we read we don\u2019t pay attention to the curl and swing of the letters as though they were little drawings.)",
            "score": 133.39960837364197
        },
        {
            "docid": "68753_29",
            "document": "Attention . There exist both overlaps and differences in the areas of the brain that are responsible for endogenous and exogenous orientating. Another approach to this discussion has been covered under the topic heading of \"bottom-up\" versus \"top-down\" orientations to attention. Researchers of this school have described two different aspects of how the mind focuses attention to items present in the environment. The first aspect is called bottom-up processing, also known as stimulus-driven attention or exogenous attention. These describe attentional processing which is driven by the properties of the objects themselves. Some processes, such as motion or a sudden loud noise, can attract our attention in a pre-conscious, or non-volitional way. We attend to them whether we want to or not. These aspects of attention are thought to involve parietal and temporal cortices, as well as the brainstem.",
            "score": 128.67792439460754
        },
        {
            "docid": "42382929_3",
            "document": "Now You See It (Cathy Davidson book) . In \"Now You See It: How the Brain Science of Attention Will Transform the Way We Live, Work, and Learn,\" Cathy Davidson suggests that breakthroughs in cognitive science should recalibrate our sense of what it means to learn. According to Davidson, those of us in higher education are paradoxically obsessed with the implications of living in the \"digital age,\" even though we have \u201cyet to rethink how we need to be organizing our institutions\u2014our schools, our offices\u2014to maximize the opportunities of our digital era\u201d (12). We tend to uphold models of teaching and assessments that no longer serve a generation of students who face a myriad of new challenges, as they attempt to learn to think critically in an era of information overload. Technology in all its forms is playing an increasingly important role in the lives of students. Colleges and universities, therefore, need to pay attention to the impact that the appropriate uses of digital tools can have on extending, enhancing, and enriching the student learning experience, both on and off campus. Moreover, and more importantly, Davidson argues that sustained exposure to such a range of digital media demands a different kind of attention than we previously required.",
            "score": 126.103954911232
        },
        {
            "docid": "35988494_3",
            "document": "Selective auditory attention . The cocktail party problem was first brought up in 1953 by Colin Cherry. This common problem is how our minds solves the issue of knowing what in the auditory scene is important and combining those in a coherent whole, such as the problem of how we can perceive our friend talking in the midst of a crowded cocktail party. He suggested that the auditory system can filter sounds being heard. Physical characteristics of the auditory information such as speaker's voice or location can improve a person's ability to focus on certain stimuli even if there is other auditory stimuli present. Cherry also did work with shadowing which involves different information being played into both ears and only one ear's information can be processed and remembered (Eysneck, 2012, p.\u00a084). Another psychologist, Albert Bregman, came up with the auditory scene analysis model. The model has three main characteristics: segmentation, integration, and segregation. Segmentation involves the division of auditory messages into segments of importance. The process of combining parts of an auditory message to form a whole is associated with integration. Segregation is the separation of important auditory messages and the unwanted information in the brain. It is important to note that Bregman also makes a link back to the idea of perception. He states that it is essential for one to make a useful representation of the world from sensory inputs around us. Without perception, an individual will not recognize or have the knowledge of what is going on around them. While Begman's seminal work is critical to understanding selective auditory attention, his studies did not focus on the way in which an auditory message is selected, if and when it was correctly segregated from other sounds in a mixture, which is a critical stage of selective auditory attention. Inspired in part by Bregman's work, a number of researchers then set out to link directly work on auditory scene analysis to the processes governing attention, including Maria Chait, Mounya Elhilali, Shihab Shamma, and Barbara Shinn-Cunningham.",
            "score": 155.35224187374115
        },
        {
            "docid": "2094955_21",
            "document": "Salience (language) . Guido\u2019s Principle one is Figure-ground, which is the means the perceptual field from which people direct their attention towards something that stands out. Figurality is the brightness, complexity, and energy (movement) of a stimulus. It is thought that these aspects trigger cognitions and thought processes in the brain that lead to salience. Brightness includes the magnitude and the colors of the object. Studies have shown that bright, vibrant colors more easily capture the attention and are easier to remember (Guido, 1998). Complexity builds upon the contextual factors (the number of perceptible qualities about the stimulus object that one can distinguish) and learning (what we perceive as unfamiliar). Complexity is the interaction of the familiarity, unfamiliarity, and the number of aspects of the stimulus object that we can resolve. Complexity is the interaction of these stimuli interact to engage affect and cognitions developed about the object (Guido, 1998). Movement of an object engages sensory receptors, which when sparked, send stimuli to the body and brain. Moving pictures, signs and eyes are used to capture our attention and make us pay attention (Guido, 1998).",
            "score": 113.98887479305267
        },
        {
            "docid": "42382929_8",
            "document": "Now You See It (Cathy Davidson book) . Technology, Davidson argues, re-shapes the way we learn and process new information in some fundamental ways. We surf hundreds of news feeds, immediately discriminating between the ones we need to read and the ones we don't. In our work environments, we are forced to focus, divide, and re-focus our attention as we are dealing with multiple tasks at the same time. Within this multitasking that the new workplace requires, Davidson urges her readers to re-imagine the concept of distraction. We are cultured to imagine that shopping online while finishing a report or answering personal emails and simultaneously working on a project are distractions which are detrimental to our productivity and efficiency. Every time we switch tasks, we are hurting our work. Davidson argues, however, that these small distractions afforded by technology should be thought of as innovations. \"When we feel distracted, something\u2019s up. Distraction is really another word for saying that something is new, strange or different. We should pay attention to that feeling\u2026 Distraction is one of the best tools for innovation we have at our disposal\u2014for changing patterns of attention and beginning the process of learning new patterns\"",
            "score": 129.16712534427643
        },
        {
            "docid": "5366050_50",
            "document": "Speech perception . Neurophysiological methods rely on utilizing information stemming from more direct and not necessarily conscious (pre-attentative) processes. Subjects are presented with speech stimuli in different types of tasks and the responses of the brain are measured. The brain itself can be more sensitive than it appears to be through behavioral responses. For example, the subject may not show sensitivity to the difference between two speech sounds in a discrimination test, but brain responses may reveal sensitivity to these differences. Methods used to measure neural responses to speech include event-related potentials, magnetoencephalography, and near infrared spectroscopy. One important response used with event-related potentials is the mismatch negativity, which occurs when speech stimuli are acoustically different from a stimulus that the subject heard previously.",
            "score": 115.58540439605713
        },
        {
            "docid": "33477918_11",
            "document": "Ira Hyman . In 2009, Ira Hyman conducted one of his most widely cited studies along with S. Matthew Boss, Breanne M. Wise, Kira E. McKenzie and Jenna M. Coggiano. The article was called \"Did you see the Unicycling Clown? Inattentional Blindness while Walking and Talking on a Cell Phone.\" The researchers had a clown unicycle around a plaza on a college campus, and observed the students walking through the plaza. They interviewed students after they had been exposed to the clown, and found that only a quarter of those using a cell phone saw the clown. They compared this to three other groups: those walking alone, those listening to music, and those walking in a pair or group. They found that it wasn't the use of an electronic device that impaired the students attention, because more than twice as many students saw the clown while listening to music, than while on the phone. They concluded that it is using a cellphone, and having to divide attention between the conversation and the surroundings, what makes people less likely to notice the clown. They observed that many of the students using their cells walked slower, changed directions more often and weaved more than other students. They also noted that individuals walking in pairs were more likely to notice the clown, simply because they could also rely on their companion to pay attention, and that it is unlikely that the conversation itself was the reason why the cellphones users were less attentive to their surroundings. This research offers an important finding in what dictates our attention, and shows just how unaware of many things around us we are at any given time. It also shows the dangers of cellphone distraction, that can be applied to areas other than just walking, such as working machinery or attempting to drive while talking on a cellphone. A recreation of this study was featured on the CBC Documentary \"Are We Digital Dummies\" and on News10 in Sacramento, California.",
            "score": 116.57425856590271
        },
        {
            "docid": "2094955_34",
            "document": "Salience (language) . Once the attention is engaged, our brain will begin to process this information and make assessments and judgements about the encounter. Our minds and bodies will activate useful memories, biological responses and feelings that were generated from prior encounters with the object of similar objects. These memory-evaluative-feeling-biology responses will determine if the object is salient. If it is salient, we will devote more cognitive processing resources to the encounter and it will enhance or protect us in that moment. Communication scholars have found that a number of different factors have a direct effect on the salience of attitude objects.",
            "score": 123.47019219398499
        },
        {
            "docid": "21161742_21",
            "document": "Dream speech . Words like 'carapace', 'krapkea', and 'crap' constitute the 'Kraepelin' code, a set of words that sound like parts of the proper name Kraepelin and influence/direct associational processes. The key role of the proper name can be explained by referring to the so-called cocktail party effect, which states that during a cocktail party we tune in on our discussion partner, neglecting background noise. However, we notice when someone in the background pronounces our name. This cocktail party effect has been replicated in an experimental set up using the dichotic listening technique. It has been shown that only our proper name tends to break through the attentional barrier, i.e. breaks through amidst other, neglected, sounds offered to the unattended ear. Thus it follows that our proper name is detected even under conditions of low attention. What happens within outer speech during a cocktail-party, likewise occurs within inner speech in dreams. Code words - linked in sound to our proper name - will be detected in the set of potential associations during thinking. The ongoing thinking process will then deviate because code words will act as priming-words, influencing the direction in which associations will go (Engels, 2005, p.\u00a0187).",
            "score": 183.76498365402222
        },
        {
            "docid": "34780199_12",
            "document": "Broadbent's filter model of attention . Attention is commonly understood as the ability to select some things while ignoring others. Attention is controllable, selective, and limited. It is the progression by which external stimuli form internal representations that gain conscious awareness. Attention is part of nearly every waking moment for humans, as it is the focusing of one's thoughts. Selective attention utilizes cognitive processes to focus on relevant targets on input, thoughts or actions while neglecting irrelevant sources of input. This is the basis for how we attend to specific stimuli. Voluntary attention, otherwise known as top-down attention, is the aspect over which we have control, enabling us to act in a goal-directed manner. In contrast, reflexive attention is driven by exogenous stimuli redirecting our current focus of attention to a new stimulus, thus it is a bottom-up influence. These two divisions of attention are continuously competing to be the momentary foci of attention. Selection models of attention theorize how specific stimuli gain our awareness. Early selection models emphasize physical features of stimuli are attended to, while late selection models argue that semantic features are what determine our current focus of attention. These selection models are utilized by researchers to propose when stimulus information is attended to.",
            "score": 110.17854189872742
        },
        {
            "docid": "35988494_2",
            "document": "Selective auditory attention . Selective auditory attention or selective hearing is a type of selective attention and involves the auditory system of the nervous system. Selective hearing is characterized as the action in which people focus their attention on a specific source of a sound or spoken words. The sounds and noise in the surrounding environment is heard by the auditory system but only certain parts of the auditory information are processed in the brain. Most often, auditory attention is directed at things people are most interested in hearing. In an article by Krans, Isbell, Giuliano, and Neville (2013), selective auditory attention is defined as the ability to acknowledge some stimuli while ignoring other stimuli that is occurring at the same time. An example of this is a student focusing on a teacher giving a lesson and ignoring the sounds of classmates in a rowdy classroom (p.\u00a053). This is an example of bottlenecking which means that information cannot be processed simultaneously so only some sensory information gets through the \"bottleneck\" and is processed. A brain simply cannot process all sensory information that is occurring in an environment so only that which is most important is thoroughly processed. Selective hearing is not a physiological disorder but rather it is the capability of humans to block out sounds and noise. It is the notion of ignoring certain things in the surrounding environment. Over the years, there has been increased research in the selectivity of auditory attention, namely selective hearing.",
            "score": 153.69249868392944
        },
        {
            "docid": "31329046_13",
            "document": "Pre-attentive processing . Training can lead to changes in activity and brain structures involved in pre-attentive processing. Professional musicians, in particular, show larger ERP (Event-related potential) responses to deviations in auditory stimuli and have possibly related structural differences in their brains (Heschl\u2019s gyrus, corpus callosum, and pyramidal tracts). This plasticity of pre-attentive processing has also been shown in perception. Using EEG (electroencephalography) methods in pre-attentive colour perception, a study observed how easy it was for bilinguals to adapt to the linguistic constructs of a different culture. This means that pre-attentive processes are not hard-wired but malleable.",
            "score": 92.66783165931702
        },
        {
            "docid": "749745_18",
            "document": "Aging brain . If older adults have fewer attentional resources than younger adults, we would expect that when two tasks must be carried out at the same time, older adults' performance will decline more than that of younger adults. However, a large review of studies on cognition and aging suggest that this hypothesis has not been wholly supported. While some studies have found that older adults have a more difficult time encoding and retrieving information when their attention is divided, other studies have not found meaningful differences from younger adults. Similarly, one might expect older adults to do poorly on tasks of sustained attention, which measure the ability to attend to and respond to stimuli for an extended period of time. However, studies suggest that sustained attention shows no decline with age. Results suggest that sustained attention increases in early adulthood and then remains relatively stable, at least through the seventh decade of life. More research is needed on how normal aging impacts attention after age eighty.",
            "score": 103.90357208251953
        },
        {
            "docid": "32018467_7",
            "document": "Christian Keysers . After finishing his master, Christian Keysers decided to concentrate on a subfield of cognitive neuroscience called social neuroscience that uses neuroscience methods to understand how we process the social world. He therefore performed his doctoral studies at the University of St Andrews with David Ian Perrett, one of the founding father of the field, to understand how the brain processes faces and facial expressions. This thesis work led to new insights into how quickly the brain can process the faces of others. During this period, Keysers became fascinated with the question of how the brain can attach meaning to the faces of others. How is it for instance, that we understand that a certain grimace would signal that another person is happy? How do we understand that a certain bodily movement towards a glass indicates that the other person aims to grasp a glass? In 1999, Keysers was exposed to a visit of Vittorio Gallese, who presented his recent discovery of mirror neurons in the Psychology department lecture series. This deeply influenced Keysers who decided to move to the lab of Giacomo Rizzolatti to undertake further studies on how these fascinating neurons could contribute to social perception. In 2000, after finishing his doctorate, Christian Keysers moved to the University of Parma to study mirror neurons. In early work there demonstrated that mirror neurons in the premotor cortex not only respond to the sight of actions, but also when actions can only be deduced or heard, leading to a publication in the journal \"Science\". This work had tremendous impact on the field, as it suggested that the premotor cortex could play a central, modality independent role in perception and may lay the origin for the evolution of speech in humans.  Together this work indicated that brain regions involved in our own actions play a role in how we process the actions of others. Keysers wondered whether a similar principle may underlie how we process the tactile sensations and emotions of others, and became increasingly independent of the research focus on the motor system in Parma. At the time, Keysers had also met his to be wife, Valeria Gazzola, a biologist in the final phases of her studies, and together they decided to explore if the somatosensory system might be involved in perceiving the sensations of others. Via a fruitful collaboration with the French neuroimaging specialist Bruno Wicker, they used functional magnetic resonance imaging, and showed for the first time, that the secondary somatosensory cortex, previously thought only to represent a persons own experiences of touch, is also activated when seeing someone or something else be touched. They also showed that the insula, thought only to respond to the experience of first-hand emotions, was also activated when we see another individual experience similar emotions. Together this indicated a much more general principle than the original mirror neuron theory, in which people process the actions, sensations and emotions of others by vicariously activating owns own actions, sensations and emotions. Jointly, this work laid the foundation of the neuroscientific investigation of empathy.",
            "score": 103.17846620082855
        },
        {
            "docid": "38937712_5",
            "document": "Dick Swaab . Swaab is best known for his research and discoveries in the field of brain anatomy and physiology, in particular the impact that various hormonal and biochemical factors in the womb have on brain development. Another area of Swaab's work, which has drawn much attention, is his research on how sexual dimorphism relates to brain anatomy, as well as research relating to sexual orientation and transsexuality. Through his years of research, Swaab, according to his own words, came to the deterministic and materialistic conclusion that brains are not things we have, but rather brains are what we are: the physical and chemical processes in our brains determine how we react and who we are. Currently, Swaab is most active in the field of depression and Alzheimer's research.",
            "score": 123.51609754562378
        },
        {
            "docid": "179092_31",
            "document": "Neurolinguistics . Some experiments give subjects a \"distractor\" task to ensure that subjects are not consciously paying attention to the experimental stimuli; this may be done to test whether a certain computation in the brain is carried out automatically, regardless of whether the subject devotes attentional resources to it. For example, one study had subjects listen to non-linguistic tones (long beeps and buzzes) in one ear and speech in the other ear, and instructed subjects to press a button when they perceived a change in the tone; this supposedly caused subjects not to pay explicit attention to grammatical violations in the speech stimuli. The subjects showed a mismatch response (MMN) anyway, suggesting that the processing of the grammatical errors was happening automatically, regardless of attention\u2014or at least that subjects were unable to consciously separate their attention from the speech stimuli.",
            "score": 94.9405460357666
        },
        {
            "docid": "26069731_7",
            "document": "Phoebe Caldwell . Phoebe Caldwell has created a system based on imitation of body language to communicate with autistic people. It is known that those along the spectrum tend to protect themselves from sensory overload by using repetitive behaviors. Caldwell has studied these and instead of attempting to intervene, she uses them to gain their attention. \"Contrary to what is normally understood, children on the autistic spectrum do recognise when we use their own body language to communicate, provided we respond using the repertoire of their personal behaviours. We are shifting their attention from solitary self-stimulation to shared activity\" It is important to pay attention to how they do this and the feelings behind it, just mimicking tends to only catch their attention for a short period of time; we need to answer. By echoing them, this will interact with their brain in a positive way and reducing stress, \"Aloneness becomes a shared interest.\"",
            "score": 98.98571443557739
        },
        {
            "docid": "1781678_17",
            "document": "Cocktail party effect . Diana Deutsch, best known for her work in music perception and auditory illusions, has also made important contributions to models of attention. In order to explain in more detail how words can be attended to on the basis of semantic importance, Deutsch & Deutsch and Norman proposed a model of attention which includes a second selection mechanism based on meaning. In what came to be known as the Deutsch-Norman model, information in the unattended stream is not processed all the way into working memory, as Treisman's model would imply. Instead, information on the unattended stream is passed through a secondary filter after pattern recognition. If the unattended information is recognized and deemed unimportant by the secondary filter, it is prevented from entering working memory. In this way, only immediately important information from the unattended channel can come to awareness.  Daniel Kahneman also proposed a model of attention, but it differs from previous models in that he describes attention not in terms of selection, but in terms of capacity. For Kahneman, attention is a resource to be distributed among various stimuli, a proposition which has received some support. This model describes not \"when\" attention is focused, but \"how\" it is focused. According to Kahneman, attention is generally determined by arousal; a general state of physiological activity. The Yerkes-Dodson law predicts that arousal will be optimal at moderate levels - performance will be poor when one is over- or under-aroused. Of particular relevance, Narayan et al. discovered a sharp decline in the ability to discriminate between auditory stimuli when background noises were too numerous and complex - this is evidence of the negative effect of overarousal on attention. Thus, arousal determines our available capacity for attention. Then, an \"allocation policy\" acts to distribute our available attention among a variety of possible activities. Those deemed most important by the allocation policy will have the most attention given to them. The allocation policy is affected by \"enduring dispositions\" (automatic influences on attention) and \"momentary intentions\" (a conscious decision to attend to something). \"Momentary intentions\" requiring a focused direction of attention rely on substantially more attention resources than \"enduring dispositions\". Additionally, there is an ongoing evaluation of the particular demands of certain activities on attention capacity. That is to say, activities that are particularly taxing on attention resources will lower attention capacity and will influence the allocation policy - in this case, if an activity is too draining on capacity, the allocation policy will likely cease directing resources to it and instead focus on less taxing tasks. Kahneman's model explains the cocktail party phenomenon in that \"momentary intentions\" might allow one to expressly focus on a particular auditory stimulus, but that \"enduring dispositions\" (which can include new events, and perhaps words of particular semantic importance) can capture our attention. It is important to note that Kahneman's model doesn't necessarily contradict selection models, and thus can be used to supplement them.",
            "score": 122.9784779548645
        },
        {
            "docid": "422247_33",
            "document": "Self-awareness . Autism spectrum disorder (ASD) is a range of neurodevelopmental disabilities that can adversely impact social communication and create behavioral challenges (Understanding Autism, 2003). \"Autism spectrum disorder (ASD) and autism are both general terms for a group of complex disorders of brain development. These disorders are characterized, in varying degrees, by difficulties in social interaction, verbal and nonverbal communication and repetitive behaviors.\" ASDs can also cause imaginative abnormalities and can range from mild to severe, especially in sensory-motor, perceptual and affective dimensions. Children with ASD may struggle with self-awareness and self acceptance. Their different thinking patterns and brain processing functions in the area of social thinking and actions may compromise their ability to understand themselves and social connections to others. About 75% diagnosed autistics are mentally handicapped in some general way and the other 25% diagnosed with Asperger's Syndrome show average to good cognitive functioning. When we compare our own behavior to the morals and values that we were taught, we can focus more attention on ourselves which increases self-awareness. To understand the many effects of autism spectrum disorders on those afflicted have led many scientists to theorize what level of self-awareness occurs and in what degree. Research found that ASD can be associated with intellectual disability and difficulties in motor coordination and attention. It can also result in physical health issues as well, such as sleep and gastrointestinal disturbances. As a result of all those problems, individuals are literally unaware of themselves. It is well known that children suffering from varying degrees of autism struggle in social situations. Scientists at the University of Cambridge have produced evidence that self-awareness is a main problem for people with ASD. Researchers used functional magnetic resonance scans (FMRI) to measure brain activity in volunteers being asked to make judgments about their own thoughts, opinions, preferences, as well as about someone else's. One area of the brain closely examined was the ventromedial pre-frontal cortex (vMPFC) which is known to be active when people think about themselves. A study out of Stanford University has tried to map out brain circuits with understanding self-awareness in Autism Spectrum Disorders. This study suggests that self-awareness is primarily lacking in social situations but when in private they are more self-aware and present. It is in the company of others while engaging in interpersonal interaction that the self-awareness mechanism seems to fail. Higher functioning individuals on the ASD scale have reported that they are more self-aware when alone unless they are in sensory overload or immediately following social exposure. Self-awareness dissipates when an autistic is faced with a demanding social situation. This theory suggests that this happens due to the behavioral inhibitory system which is responsible for self-preservation. This is the system that prevents human from self-harm like jumping out of a speeding bus or putting our hand on a hot stove. Once a dangerous situation is perceived then the behavioral inhibitory system kicks in and restrains our activities. \"For individuals with ASD, this inhibitory mechanism is so powerful, it operates on the least possible trigger and shows an over sensitivity to impending danger and possible threats. Some of these dangers may be perceived as being in the presence of strangers, or a loud noise from a radio. In these situations self-awareness can be compromised due to the desire of self preservation, which trumps social composure and proper interaction. The Hobson hypothesis reports that autism begins in infancy due to the lack of cognitive and linguistic engagement which in turn results in impaired reflective self-awareness. In this study ten children with Asperger's Syndrome were examined using the Self-understanding Interview. This interview was created by Damon and Hart and focuses on seven core areas or schemas that measure the capacity to think in increasingly difficult levels. This interview will estimate the level of self understanding present. \"The study showed that the Asperger group demonstrated impairment in the 'self-as-object' and 'self-as-subject' domains of the Self-understanding Interview, which supported Hobson's concept of an impaired capacity for self-awareness and self-reflection in people with ASD.\". Self-understanding is a self description in an individual's past, present and future. Without self-understanding it is reported that self-awareness is lacking in people with ASD. Joint attention (JA) was developed as a teaching strategy to help increase positive self-awareness in those with autism spectrum disorder. JA strategies were first used to directly teach about reflected mirror images and how they relate to their reflected image. Mirror Self Awareness Development (MSAD) activities were used as a four-step framework to measure increases in self-awareness in those with ASD. Self-awareness and knowledge is not something that can simply be taught through direct instruction. Instead, students acquire this knowledge by interacting with their environment. Mirror understanding and its relation to the development of self leads to measurable increases in self-awareness in those with ASD. It also proves to be a highly engaging and highly preferred tool in understanding the developmental stages of self- awareness. There have been many different theories and studies done on what degree of self-awareness is displayed among people with autism spectrum disorder. Scientists have done research about the various parts of the brain associated with understanding self and self-awareness. Studies have shown evidence of areas of the brain that are impacted by ASD. Other theories suggest that helping an individual learn more about themselves through Joint Activities, such as the Mirror Self Awareness Development may help teach positive self-awareness and growth. In helping to build self-awareness it is also possible to build self-esteem and self acceptance. This in turn can help to allow the individual with ASD to relate better to their environment and have better social interactions with others.",
            "score": 133.9518859386444
        },
        {
            "docid": "31329046_2",
            "document": "Pre-attentive processing . Pre-attentive processing is the subconscious accumulation of information from the environment. All available information is pre-attentively processed. Then, the brain filters and processes what is important. Information that has the highest salience (a stimulus that stands out the most) or relevance to what a person is thinking about is selected for further and more complete analysis by conscious (attentive) processing. Understanding how pre-attentive processing works is useful in advertising, in education, and for prediction of cognitive ability.",
            "score": 89.39656019210815
        },
        {
            "docid": "31329046_5",
            "document": "Pre-attentive processing . The \"contingent-capture\" model emphasizes the idea that a person\u2019s current intentions and/or goals affect the speed and efficiency of pre-attentive processing. The brain directs an individual\u2019s attention towards stimuli with features that fit in with their goals. Consequently, these stimuli will be processed faster at the pre-attentive stage and will be more likely to be selected for attentive processing. Since this model focuses on the importance of conscious processes (rather than properties of the stimulus itself) in selecting information for attentive processing, it is sometimes called \"top-down\" selection. In support of this model, it has been shown that a target stimulus can be located faster if it is preceded by the presentation of a similar, priming stimulus. For example, if an individual is shown the color green and then required to find a green circle among distractors, the initial exposure to the color will make it easier to find the green circle. This is because they are already thinking about and envisioning the color green, so when it shows up again as the green circle, their brain readily directs its attention towards it. This suggests that processing an initial stimulus speeds up a person\u2019s ability to select a similar target from pre-attentive processing. However, it could be that the speed of pre-attentive processing itself is not affected by the first stimulus, but rather that people are simply able to quickly abandon dissimilar stimuli, enabling them to re-engage to the correct target more quickly. This would mean that the difference in reaction time occurs at the attentive level, after pre-attentive processing and stimulus selection has already taken place.",
            "score": 93.16236400604248
        },
        {
            "docid": "21312312_25",
            "document": "Neuroanatomy of memory . The parietal lobe has many functions and duties in the brain and its main functioning can be divided down into two main areas: (1) sensation and perception (2) constructing a spatial coordinate system to represent the world around us. The parietal lobe helps us to mediate attention when necessary and provides spatial awareness and navigational skills. Also, it integrates all of our sensory information (touch, sight, pain etc.) to form a single perception. Parietal lobe gives the ability to focus our attention on different stimuli at the same time, PET scans show high activity in the parietal lobe when participates being studied were asked to focus their attention at two separate areas of attention. Parietal lobe also assists with verbal short term memory and damage to the supramarginal gyrus cause short term memory loss.",
            "score": 126.67409563064575
        },
        {
            "docid": "16150918_11",
            "document": "Broaden-and-build . The creative process is often discussed in two stages. The first stage is defocused attention which is followed by focused attention. Fredrickson alludes to defocused attention in her Broaden-and-Build model. Defocused attention occurs when a person is able to see a wide range of possibilities and take in as much information as possible. The second stage, focused attention, takes place when more negative emotions are felt. During focused attention, a person analyzes the possibilities that they found during defocused attention. Without this process, concrete ideas do not form. This theory lends itself to the inclusion of negative, narrowing emotions in this model. Another theory verifying this inclusion is the whole-brain hypothesis of creativity. The theory states that the defocused process uses a greater portion of the right side of the brain, whereas the focused process uses more of the left side of the brain. Creativity necessitates the communication between the two hemispheres allowing these processes to work together to form coherent theories and develop personal skills. This theory provides support for a more integrated model that includes narrowing as well as broadening in order to build.",
            "score": 88.87138414382935
        },
        {
            "docid": "33431597_16",
            "document": "Attentional control . According to fMRI studies of the brain and behavioral observations, visual attention can be moved independently of moving eye position. Studies have had participants fixate their eyes on a central point and measured brain activity as stimuli were presented outside the visual fixation point. fMRI findings show changes in brain activity correlated with the shift in spatial attention to the various stimuli. Behavioral studies have also shown that when a person knows where a stimulus is likely to appear, their attention can shift to it more rapidly and process it better.",
            "score": 117.3520188331604
        },
        {
            "docid": "33980253_4",
            "document": "Attenuation theory . Early research came from an era primarily focused upon audition and explaining phenomena such as the cocktail party effect. From this stemmed interest about how we can pick and choose to attend to certain sounds in our surroundings, and at a deeper level, how the processing of attended speech signals differ from those not attended to. Auditory attention is often described as the selection of a channel, message, ear, stimulus, or in the more general phrasing used by Treisman, the \"selection between inputs\". As audition became the preferred way of examining selective attention, so too did the testing procedures of \"dichotic listening\" and \"shadowing\".",
            "score": 119.37025427818298
        },
        {
            "docid": "26945761_8",
            "document": "Cross modal plasticity . Deaf individuals lack auditory input, so the auditory cortex is instead used to assist with visual and language processing. Auditory activations also appear to be attention-dependent in the deaf. However, the process of visual attention in the deaf is not significantly different from that of hearing subjects. Stronger activations of the auditory cortex during visual observation occur when deaf individuals pay attention to a visual cue, and the activations are weaker if the cue is not in the direct line of sight. One study found that deaf participants process peripheral visual stimuli more quickly than hearing subjects. Deafness appears to heighten spatial attention to the peripheral visual field, but not the central one. The brain thus seems to compensate for the auditory loss within its visual system by enhancing peripheral field attention resources; however, central visual resources may suffer.",
            "score": 95.31887173652649
        },
        {
            "docid": "33937822_4",
            "document": "Information processing technology and aging . Cognitive capabilities refer our mental abilities by which we pay attention to the world, interpret the information around us, learn and remember, solve problems and make decisions. Age-related differences in cognitive functioning have been known to stem from the reduction of cognitive resources available, thus impairing older adults\u2019 ability to carry out cognitively demanding tasks. Cognitive aging causes a change in mechanism related to information processing and working memory function. According to Craik, these mechanisms are responsible for age-related speed of decline in performance for mental processing along with a reduction of online cognitive resources available at any given time to process, store, retrieve, and transform information (working memory), focusing on a target, paying attention, and sensory processing of information. This is important since the inherent relationship between cognitive abilities and technology adoption points to the importance of ensuring that system interfaces are well designed and easy to use. The use of information processing theory in cognition looks at the role of the three stages of memory related to retrieving information, transferring and recalling. Cognitive information processing focuses on different aspects of instruction and how those aspects can either facilitate or hinder learning and memory. It emphasizes using strategies that focus the learner's attention, promotes encoding and retrieval, and provide for meaningful, effective practice across learning environments and curriculum.",
            "score": 89.2996438741684
        },
        {
            "docid": "31329046_12",
            "document": "Pre-attentive processing . Vision, sound, smell, touch, and taste are processed together pre-attentively when more than one sensory stimuli are present. This multisensory integration increases activity in the superior temporal sulcus (STS), thalamus, and superior colliculus. Specifically, the pre-attentive process of multisensory integration works jointly with attention to activate brain regions such as the STS. Multisensory integration seems to give a person the advantage of greater comprehension if both auditory and visual stimuli are being processed together. But it is important to note that multisensory integration is affected by what a person pays attention to and their current goals.",
            "score": 111.02991390228271
        },
        {
            "docid": "26622141_22",
            "document": "Emotional branding . The two types of processing that a person can use to comprehend branding are Active Processing, which is learning that happens when deep, attentive processing is being applied, or, Implicit processing, which is when meaning can be processed without awareness. Emotional branding is quite complex, in that a person can interpret a brand image through attentive processing, but once their emotions are provoked, the meaning that they take from the brand image can be implicitly processed, or in other words, subconsciously created. Author Antonio Damasio notes, \u201cWe are more vulnerable when we are only vagely aware that our emotions are being influenced, and most vulnerable when we have no idea at all that our emotions are being influenced.\u201d An example of this could be music playing in a store to create a subconscious mood.",
            "score": 113.71897745132446
        },
        {
            "docid": "31329046_4",
            "document": "Pre-attentive processing . The \"pure-capture\" model focuses on stimulus salience. If certain properties of a stimulus stand out from its background, the stimulus has a higher chance of being selected for attentive processing. This is sometimes referred to as \"bottom-up\" processing, as it is the properties of the stimuli which affect selection. Since things that affect pre-attentive processing do not necessarily correlate with things that affect attention, stimulus salience may be more important than conscious goals. For example, pre-attentive processing is slowed by sleep deprivation while attention, although less focused, is not slowed. Furthermore, when searching for a particular visual stimulus among a variety of visual distractions, people often have more trouble finding what they are looking for if one or more of the distractions is particularly salient. For example, it is easier to locate a bright, green circle (which is salient) among distractor circles if they are all grey (a bland color) than it is to locate a green circle among distractor circles if some are red (also salient colour). This is thought to occur because the salient red circles attract our attention away from the target green circle. However, this is difficult to prove because when given a target (like the green circle) to search for in a laboratory experiment, participants may generalize the task to searching for anything that stands out, rather than solely searching for the target. If this happens, the conscious goal becomes finding anything that stands out, which would direct the person\u2019s attention towards red distractor circles as well as the green target. This means that a person\u2019s goal, rather than the salience of the stimuli, could be causing the delayed ability to find the target.",
            "score": 112.86321341991425
        }
    ],
    "r": [
        {
            "docid": "21161742_21",
            "document": "Dream speech . Words like 'carapace', 'krapkea', and 'crap' constitute the 'Kraepelin' code, a set of words that sound like parts of the proper name Kraepelin and influence/direct associational processes. The key role of the proper name can be explained by referring to the so-called cocktail party effect, which states that during a cocktail party we tune in on our discussion partner, neglecting background noise. However, we notice when someone in the background pronounces our name. This cocktail party effect has been replicated in an experimental set up using the dichotic listening technique. It has been shown that only our proper name tends to break through the attentional barrier, i.e. breaks through amidst other, neglected, sounds offered to the unattended ear. Thus it follows that our proper name is detected even under conditions of low attention. What happens within outer speech during a cocktail-party, likewise occurs within inner speech in dreams. Code words - linked in sound to our proper name - will be detected in the set of potential associations during thinking. The ongoing thinking process will then deviate because code words will act as priming-words, influencing the direction in which associations will go (Engels, 2005, p.\u00a0187).",
            "score": 183.76498413085938
        },
        {
            "docid": "32116125_4",
            "document": "Amblyaudia . Amblyaudia is a deficit in binaural integration of environmental information entering the auditory system. It is a disorder related to brain organization and function rather than what is typically considered a \u201chearing loss\u201d (damage to the cochlea). It may be genetic or developmentally acquired or both. When animals are temporarily deprived of hearing from an early age, profound changes occur in the brain. Specifically, cell sizes in brainstem nuclei are reduced, the configuration of brainstem dendrites are altered and neurons respond in different ways to sounds presented to both the deprived and non-deprived ears (in cases of asymmetric deprivation). This last point is particularly important for listening tasks that require inputs from two ears to perform well. There are multiple auditory functions that rely on the computation of well calibrated inputs from the two ears. Chief among these is the ability to localize sound sources and separate what we want to hear from a background of noise. In the brainstem, the auditory system compares the timing and levels of sounds between the two ears to encode the location of sound sources (sounds that originate from our right as opposed to left side are louder and arrive earlier in our right ear). This ability to separate sound sources not only helps us locate the trajectories of moving objects, but also to separate different sound sources in noisy environments.",
            "score": 181.6329345703125
        },
        {
            "docid": "4220231_8",
            "document": "Evolutionary musicology . The evolutionary switch to bipedalism may have influenced the origins of music. The background is that noise of locomotion and ventilation may mask critical auditory information. Human locomotion is likely to produce more predictable sounds than those of non-human primates. Predictable locomotion sounds may have improved our capacity of entrainment to external rhythms and to feel the beat in music. A sense of rhythm could aid the brain in distinguishing among sounds arising from discrete sources and also help individuals to synchronize their movements with one another. Synchronization of group movement may improve perception by providing periods of relative silence and by facilitating auditory processing. The adaptive value of such skills to early human ancestors may have been keener detection of prey or stalkers and enhanced communication. Thus, bipedal walking may have influenced the development of entrainment in humans and thereby the evolution of rhythmic abilities. Primitive hominids lived and moved around in small groups. The noise generated by the locomotion of two or more individuals can result in a complicated mix of footsteps, breathing, movements against vegetation, echoes, etc. The ability to perceive differences in pitch, rhythm, and harmonies, i.e. \u201cmusicality,\u201d could help the brain to distinguish among sounds arising from discrete sources, and also help the individual to synchronize movements with the group. Endurance and an interest in listening might, for the same reasons, have been associated with survival advantages eventually resulting in adaptive selection for rhythmic and musical abilities and reinforcement of such abilities. Listening to music seems to stimulate release of dopamine. Rhythmic group locomotion combined with attentive listening in nature may have resulted in reinforcement through dopamine release. A primarily survival-based behavior may eventually have attained similarities to dance and music, due to such reinforcement mechanisms . Since music may facilitate social cohesion, improve group effort, reduce conflict, facilitate perceptual and motor skill development, and improve trans-generational communication, music-like behavior may at some stage have become incorporated into human culture.",
            "score": 178.20513916015625
        },
        {
            "docid": "36449834_3",
            "document": "Voxeet . During a real-life conversation, sounds follow a complex journey before reaching the listener's ears for decoding by the brain. The human brain analyses the sounds and all their alterations to determine the source's position in the room. This enables the brain to know instantly who the speaker is, even without recognizing his voice or seeing the speaker. In a crowded room with lots of background noise, the brain can isolate specific sounds and can focus on decoding the information or voice that matters while disregarding the others, a phenomenon also called the cocktail party effect.",
            "score": 161.26898193359375
        },
        {
            "docid": "34898033_6",
            "document": "John Philip Newell . New science speaks of being able to detect the sound of the beginning in the universe. It vibrates within the matter of everything that has being. New science is echoing the ancient wisdom of spiritual insight. In the twelfth century Hildegard of Bingen taught that the sound of God resonates \u2018in every creature\u2019. It is \u2018the holy sound\u2019, she says, \u2018which echoes through the whole creation.\u2019 If we are to listen for the One from whom we have come, it is not away from creation that we are to turn our ears, it is not away from the true depths of our being that we are to listen. It is rather to the very heart of all life that we are to turn our inner attention. For then we will hear that the deepest sound within us is the deepest sound within one another and within everything that has being. We will hear that the true harmony of our being belongs to the universe and that the true harmony of the universe belongs to us. \u2026 Everything arises from that sacred sound.\"",
            "score": 158.1063232421875
        },
        {
            "docid": "6894544_2",
            "document": "Noise-induced hearing loss . Noise-induced hearing loss (NIHL) is hearing impairment resulting from exposure to loud sound. People may have a loss of perception of a narrow range of frequencies, impaired cognitive perception of sound including sensitivity to sound or ringing in the ears. When exposure to hazards such as noise occur at work and is associated with hearing loss, it is referred to as occupational hearing loss.  Hearing may deteriorate gradually from chronic and repeated noise exposure, such as to loud music or background noise, or suddenly, from exposure to impulse noise (a short high intensity noise), such as a gunshot or airhorn. In both types, loud sound overstimulates delicate hearing cells, leading to the permanent injury or death of the cells. Once lost this way, hearing cannot be restored in humans.  There are a variety of prevention strategies available to avoid or reduce hearing loss. Lowering the volume of sound at its source, limiting the time of exposure and physical protection can reduce the impact of excessive noise. If not prevented, hearing loss can be managed through assistive devices and cognitive therapies. The largest burden of NIHL has been through occupational exposures; however, noise-induced hearing loss can also be due to unsafe recreational, residential, social and military service-related noise exposures. It is estimated that 15% of young people are exposed to sufficient leisure noises (i.e. concerts, sporting events, daily activities, personal listening devices, etc.) to cause NIHL. There is not a limited list of noise sources that can cause hearing loss; rather, it is important to understand that exposure to excessively high decibel (dB) levels from any sound source over time, can cause hearing loss. The first symptom of NIHL may be difficulty hearing a conversation against a noisy background. The effect of hearing loss on speech perception has two components. The first component is the loss of audibility, which may be perceived as an overall decrease in volume. Modern hearing aids compensate this loss with amplification. The second component is known as \u201cdistortion\" or \u201cclarity loss\u201d due to selective frequency loss.\u201d Consonants, due to their higher frequency, are typically affected first. For example, the sounds \u201cs\u201d and \u201ct\u201d are often difficult to hear for those with hearing loss, affecting clarity of speech. NIHL can affect either one or both ears. Monaural hearing loss causes problems with directional hearing, affecting the ability to localize sound.",
            "score": 157.62449645996094
        },
        {
            "docid": "35988494_3",
            "document": "Selective auditory attention . The cocktail party problem was first brought up in 1953 by Colin Cherry. This common problem is how our minds solves the issue of knowing what in the auditory scene is important and combining those in a coherent whole, such as the problem of how we can perceive our friend talking in the midst of a crowded cocktail party. He suggested that the auditory system can filter sounds being heard. Physical characteristics of the auditory information such as speaker's voice or location can improve a person's ability to focus on certain stimuli even if there is other auditory stimuli present. Cherry also did work with shadowing which involves different information being played into both ears and only one ear's information can be processed and remembered (Eysneck, 2012, p.\u00a084). Another psychologist, Albert Bregman, came up with the auditory scene analysis model. The model has three main characteristics: segmentation, integration, and segregation. Segmentation involves the division of auditory messages into segments of importance. The process of combining parts of an auditory message to form a whole is associated with integration. Segregation is the separation of important auditory messages and the unwanted information in the brain. It is important to note that Bregman also makes a link back to the idea of perception. He states that it is essential for one to make a useful representation of the world from sensory inputs around us. Without perception, an individual will not recognize or have the knowledge of what is going on around them. While Begman's seminal work is critical to understanding selective auditory attention, his studies did not focus on the way in which an auditory message is selected, if and when it was correctly segregated from other sounds in a mixture, which is a critical stage of selective auditory attention. Inspired in part by Bregman's work, a number of researchers then set out to link directly work on auditory scene analysis to the processes governing attention, including Maria Chait, Mounya Elhilali, Shihab Shamma, and Barbara Shinn-Cunningham.",
            "score": 155.35223388671875
        },
        {
            "docid": "37691878_3",
            "document": "Phonemic restoration effect . This effect is more important to humans than what was initially thought. Linguists have pointed out that at least the English language has many false starts and extraneous sounds. The phonemic restoration effect is the brain's way of resolving those imperfections in our speech. Without this effect interfering with our language processing, there would be a greater need for much more accurate speech signals and human speech could require much more precision. For experiments, white noise is necessary because it takes the place of these imperfections in speech. One of the most important factors in language is continuity and in turn intelligibility. The phonemic restoration effect was first documented in a 1970 paper by Richard M. Warren entitled \"Perceptual Restoration of Missing Speech Sounds\". The purpose of the experiment was to give a reason to why in background of extraneous sounds, masked individual phonemes were still comprehensible.",
            "score": 155.25445556640625
        },
        {
            "docid": "1781678_9",
            "document": "Cocktail party effect . Selective attention shows up across all ages. Starting with infancy, babies begin to turn their heads toward a sound that is familiar to them, such as their parents' voices. This shows that infants selectively attend to specific stimuli in their environment. Furthermore, reviews of selective attention indicate that infants favor \"baby\" talk over speech with an adult tone. This preference indicates that infants can recognize physical changes in the tone of speech. However, the accuracy in noticing these physical differences, like tone, amid background noise improves over time. Infants may simply ignore stimuli because something like their name, while familiar, holds no higher meaning to them at such a young age. However, research suggests that the more likely scenario is that infants do not understand that the noise being presented to them amidst distracting noise is their own name, and thus do not respond. The ability to filter out unattended stimuli reaches its prime in young adulthood. In reference to the cocktail party phenomenon, older adults have a harder time than younger adults focusing in on one conversation if competing stimuli, like \"subjectively\" important messages, make up the background noise.",
            "score": 154.7631378173828
        },
        {
            "docid": "37759941_5",
            "document": "Crossmodal attention . While research on cross-modal attention has found that deficits in attending often occur, this research has led to a better understanding of attentional processing. Some studies have used positron emission tomography (PET) to examine the neurological basis for how we selectively attend to information using different sensory modalities. Event related potentials (ERPs). have also been used to help researchers measure how humans encode and process attended information in the brain. By increasing our understanding of modality-specific and cross-modal attention, we are better able to understand how we think and direct our attention.",
            "score": 153.82357788085938
        },
        {
            "docid": "35988494_2",
            "document": "Selective auditory attention . Selective auditory attention or selective hearing is a type of selective attention and involves the auditory system of the nervous system. Selective hearing is characterized as the action in which people focus their attention on a specific source of a sound or spoken words. The sounds and noise in the surrounding environment is heard by the auditory system but only certain parts of the auditory information are processed in the brain. Most often, auditory attention is directed at things people are most interested in hearing. In an article by Krans, Isbell, Giuliano, and Neville (2013), selective auditory attention is defined as the ability to acknowledge some stimuli while ignoring other stimuli that is occurring at the same time. An example of this is a student focusing on a teacher giving a lesson and ignoring the sounds of classmates in a rowdy classroom (p.\u00a053). This is an example of bottlenecking which means that information cannot be processed simultaneously so only some sensory information gets through the \"bottleneck\" and is processed. A brain simply cannot process all sensory information that is occurring in an environment so only that which is most important is thoroughly processed. Selective hearing is not a physiological disorder but rather it is the capability of humans to block out sounds and noise. It is the notion of ignoring certain things in the surrounding environment. Over the years, there has been increased research in the selectivity of auditory attention, namely selective hearing.",
            "score": 153.69248962402344
        },
        {
            "docid": "37691878_2",
            "document": "Phonemic restoration effect . Phonemic restoration effect is a perceptual phenomenon where under certain conditions, sounds actually missing from a speech signal can be restored by the brain and may appear to be heard. The effect occurs when missing phonemes in an auditory signal are replaced with a noise that would have the physical properties to mask those phonemes, creating an ambiguity. In such ambiguity, the brain tends towards filling in absent phonemes. The effect can be so strong that some listeners may not even notice that there are phonemes missing. This effect is commonly observed in a conversation with heavy background noise, making it difficult to properly hear every phoneme being spoken. Different factors can change the strength of the effect, including how rich the context or linguistic cues are in speech, as well as the listener's state, such as their hearing status or age.",
            "score": 151.87289428710938
        },
        {
            "docid": "101970_2",
            "document": "Tinnitus . Tinnitus is the hearing of sound when no external sound is present. While often described as a ringing, it may also sound like a clicking, hiss or roaring. Rarely, unclear voices or music are heard. The sound may be soft or loud, low pitched or high pitched and appear to be coming from one ear or both. Most of the time, it comes on gradually. In some people, the sound causes depression or anxiety and can interfere with concentration. Tinnitus is not a disease but a symptom that can result from a number of underlying causes. One of the most common causes is noise-induced hearing loss. Other causes include ear infections, disease of the heart or blood vessels, M\u00e9ni\u00e8re's disease, brain tumors, emotional stress, exposure to certain medications, a previous head injury, and earwax. It is more common in those with depression. The diagnosis of tinnitus is usually based on the person's description. A number of questionnaires exist that may help to assess how much tinnitus is interfering with a person's life. The diagnosis is commonly supported by an audiogram and a neurological examination. If certain problems are found, medical imaging, such as with MRI, may be performed. Other tests are suitable when tinnitus occurs with the same rhythm as the heartbeat. Rarely, the sound may be heard by someone else using a stethoscope, in which case it is known as objective tinnitus. Spontaneous otoacoustic emissions, which are sounds produced normally by the inner ear, may also occasionally result in tinnitus. Prevention involves avoiding loud noise. If there is an underlying cause, treating it may lead to improvements. Otherwise, typically, management involves talk therapy. Sound generators or hearing aids may help some. As of 2013, there were no effective medications. It is common, affecting about 10\u201315% of people. Most, however, tolerate it well, and it is a significant problem in only 1\u20132% of people. The word tinnitus is from the Latin \"tinn\u012bre\" which means \"to ring\". Tinnitus can be perceived in one or both ears or in the head. It is the description of a noise inside a person\u2019s head in the absence of auditory stimulation. The noise can be described in many different ways. It is usually described as a ringing noise but, in some patients, it takes the form of a high-pitched whining, electric buzzing, hissing, humming, tinging or whistling sound or as ticking, clicking, roaring, \"crickets\" or \"tree frogs\" or \"locusts (cicadas)\", tunes, songs, beeping, sizzling, sounds that slightly resemble human voices or even a pure steady tone like that heard during a hearing test. It has also been described as a \"whooshing\" sound because of acute muscle spasms, as of wind or waves. Tinnitus can be intermittent or continuous: in the latter case, it can be the cause of great distress. In some individuals, the intensity can be changed by shoulder, head, tongue, jaw or eye movements. Most people with tinnitus have some degree of hearing loss.",
            "score": 147.482666015625
        },
        {
            "docid": "41045246_11",
            "document": "Sound map . Sound and space are closely linked. Our ears help define our surroundings by picking up on spatial clues in reflected sound waves. This innate ability to situate ourselves in our soundscape was probably more overtly useful in the days before electricity, when we had to rely on our ears to alert us to danger our eyes could not detect. There is, however, a movement in the visually impaired community to cultivate this ability to help them navigate in the world and participate in sports, and artists such as Janet Cardiff use sound and spatiality as integral parts of their work (see The Forty Part Motet).",
            "score": 146.08551025390625
        },
        {
            "docid": "318648_4",
            "document": "Musica universalis . Aristotle criticised the notion that celestial bodies make a sound in moving in the context of his own cosmological model. From all this it is clear that the theory that the movement of the stars produces a harmony, i.e. that the sounds they make are concordant, in spite of the grace and originality with which it has been stated, is nevertheless untrue. Some thinkers suppose that the motion of bodies of that size must produce a noise, since on our earth the motion of bodies far inferior in size and in speed of movement has that effect. Also, when the sun and the moon, they say, and all the stars, so great in number and in size, are moving with so rapid a motion, how should they not produce a sound immensely great? Starting from this argument and from the observation that their speeds, as measured by their distances, are in the same ratios as musical concordances, they assert that the sound given forth by the circular movement of the stars is a harmony. Since, however, it appears unaccountable that we should not hear this music, they explain this by saying that the sound is in our ears from the very moment of birth and is thus indistinguishable from its contrary silence, since sound and silence are discriminated by mutual contrast. What happens to men, then, is just what happens to coppersmiths, who are so accustomed to the noise of the smithy that it makes no difference to them. But, as we said before, melodious and poetical as the theory is, it cannot be a true account of the facts. There is not only the absurdity of our hearing nothing, the ground of which they try to remove, but also the fact that no effect other than sensitive is produced upon us. Excessive noises, we know, shatter the solid bodies even of inanimate things: the noise of thunder, for instance, splits rocks and the strongest of bodies. But if the moving bodies are so great, and the sound which penetrates to us is proportionate to their size, that sound must needs reach us in an intensity many times that of thunder, and the force of its action must be immense.",
            "score": 145.60166931152344
        },
        {
            "docid": "57411023_4",
            "document": "Andrew King (neurophysiologist) . King discovered that the mammalian brain contains a spatial map of the auditory world and showed that its development is shaped by sensory experience. His work has also demonstrated that the adult brain represents sound features in a remarkably flexible way, continually adjusting to variations in the statistical distribution of sounds associated with different acoustic environments as well to longer term changes in input resulting from hearing loss. In addition to furthering our understanding of the neural basis for auditory perception, his research is helping to inform better treatment strategies for the hearing impaired.",
            "score": 144.82192993164062
        },
        {
            "docid": "34100130_5",
            "document": "Distraction-conflict . This model more broadly predicts that any attentional conflict will produce drive. Distraction-conflict has been supported by several studies which have produced results showing that \"distractions, such as noise or flashing lights, have the same drivelike effects on task performance that audiences do\". This is because \"our attention is divided between the task at hand and observing the reactions of the people in the audience\" in much the same way how one is distracted from the task at hand by sounds or flashing lights. The effects of distraction-conflict are also shown to be the strongest when there is a sense of urgency.",
            "score": 142.96875
        },
        {
            "docid": "8149603_8",
            "document": "Sound masking . The biggest problem with sound masking is that when people are annoyed by the activity sounds around them (noise), they search for \"quiet.\" They believe that \"quiet\" is a desirable condition of low background sound level, but what they are really searching for is the freedom from the acoustical distractions that ultimately cause annoyance. The only way to achieve true quiet would be to maintain a low background sound level with no transient sounds; a condition that requires complete isolation from all activity sounds. A better definition of \"quiet\" would be the absence of distracting sounds, not the absence of all sound. This is the definition used in sound masking.",
            "score": 142.0768280029297
        },
        {
            "docid": "1046687_14",
            "document": "Equal-loudness contour . The A-weighting curve\u2014in widespread use for noise measurement\u2014is said to have been based on the 40-phon Fletcher\u2013Munson curve. However, research in the 1960s demonstrated that determinations of equal-loudness made using pure tones are not directly relevant to our perception of noise. This is because the cochlea in our inner ear analyzes sounds in terms of spectral content, each \"hair-cell\" responding to a narrow band of frequencies known as a critical band. The high-frequency bands are wider in absolute terms than the low frequency bands, and therefore \"collect\" proportionately more power from a noise source. However, when more than one critical band is stimulated, the signals to the brain add the various bands to produce the impressions of loudness. For these reasons Equal-loudness curves derived using noise bands show an upwards tilt above 1\u00a0kHz and a downward tilt below 1\u00a0kHz when compared to the curves derived using pure tones.",
            "score": 141.67645263671875
        },
        {
            "docid": "11920671_6",
            "document": "Machine perception . Machine hearing, also known as machine listening or computer audition, is the ability of a computer or machine to take in and process sound data such as music or speech. This area has a wide range of application including music recording and compression, speech synthesis, and speech recognition. Moreover, this technology allows the machine to replicate the human brain\u2019s ability to selectively focus in a specific sound against many other competing sounds and background noise. This particular ability is called \u201cauditory scene analysis\u201d. The technology enables the machine to segment several streams occurring at the same time. Many commonly used devices such as a smartphones, voice translators, and cars make use of some form of machine hearing.",
            "score": 141.4239501953125
        },
        {
            "docid": "3233755_8",
            "document": "Directed attention fatigue . The onset of directed attention fatigue can be triggered by a number of activities, all of which involve use of the brain\u2019s inhibitory system. Activities that engage this system include multitasking, working in an environment with disruptive background noise or after a lack of sleep, and rapidly changing focus during a prolonged period of attention. DAF can also be brought about by performing concentration-intensive tasks such as puzzle solving or learning unfamiliar ideas. External factors such as stress resulting from emergencies, exams or work deadlines can also induce DAF. Any illness or injury to the brain that interrupts the brain circuits involved in maintaining attention and inhibiting external stimuli may also contribute to the development of directed attention fatigue.",
            "score": 141.41453552246094
        },
        {
            "docid": "8149603_9",
            "document": "Sound masking . Steady sounds are the background sounds in any environment that are reasonably continuous and long term. If a steady sound persists for a long time without change, and the level is relatively low, persons generally accept it as normal. People are seldom aware that an outdoor background sound exists. Steady sound can be tonal or random. If the sound is tonal it will create more annoyance than a random sound of the same level since the latter conveys no information to the listener.  Transient sounds are conversation, paging, machine sounds as well as exterior sounds such as passing aircraft and road traffic. They are short term, can vary considerably in level, and generally distract a person's attention if the level is high relative to the steady sound level (a rise of about 10\u00a0dB is a common criterion). The distraction is further strengthened if the sound has high information content, such as conversation. At relatively low levels, the major concern is the psychological effect of distraction and annoyance. The primary use of sound masking is to reduce the distraction associated with transient sounds, and in some cases reduce the intelligibility of those transient sounds (closed offices, secure facilities).",
            "score": 140.86163330078125
        },
        {
            "docid": "11217018_16",
            "document": "A-weighting . Although the A-weighting curve, in widespread use for noise measurement, is said to have been based on the 40-phon Fletcher-Munson curve, research in the 1960s demonstrated that determinations of equal-loudness made using pure tones are not directly relevant to our perception of noise. This is because the cochlea in our inner ear analyses sounds in terms of spectral content, each 'hair-cell' responding to a narrow band of frequencies known as a critical band. The high-frequency bands are wider in absolute terms than the low frequency bands, and therefore 'collect' proportionately more power from a noise source. However, when more than one critical band is stimulated, the outputs of the various bands are summed by the brain to produce an impression of loudness. For these reasons equal-loudness curves derived using noise bands show an upwards tilt above 1\u00a0kHz and a downward tilt below 1\u00a0kHz when compared to the curves derived using pure tones.",
            "score": 140.0364990234375
        },
        {
            "docid": "24034128_2",
            "document": "Assistive listening device . An Assistive listening device (ALD) is used to improve hearing ability for people in a variety of situations where they are unable to distinguish speech in noise. Often in a noisy or crowded room it is almost impossible for an individual who is hard of hearing to distinguish one voice among many. The hard of hearing listener has to distinguish between background noise, noise between them and the speaker and then there will be the effect of room acoustics on the quality of sound reaching their ears. Hearing aids are able to amplify and process these sounds and improve the speech to noise ratio but if the sound is too distorted by the time it reaches the listener even the best hearing aids will struggle to unscramble the signal.",
            "score": 139.07504272460938
        },
        {
            "docid": "1781678_7",
            "document": "Cocktail party effect . In the early 1950s much of the early attention research can be traced to problems faced by air traffic controllers. At that time, controllers received messages from pilots over loudspeakers in the control tower. Hearing the intermixed voices of many pilots over a single loudspeaker made the controller's task very difficult. The effect was first defined and named \"the cocktail party problem\" by Colin Cherry in 1953. Cherry conducted attention experiments in which participants listened to two different messages from a single loudspeaker at the same time and tried to separate them; this was later termed a dichotic listening task. (See Broadbent section below for more details). His work reveals that the ability to separate sounds from background noise is affected by many variables, such as the sex of the speaker, the direction from which the sound is coming, the pitch, and the rate of speech.",
            "score": 138.8814239501953
        },
        {
            "docid": "32001777_12",
            "document": "The Ending Is Just the Beginning Repeating . For the first time, with the new album to promote, the band has hired a second guitarist to play live with them. When asked about this, Cheney said, \"the songs on the new album aren't more complex but we felt there were some sounds and elements missing from our live show that are on our records. We plan to use him for some of the songs but not all, the idea is that it creates a fuller sound and you will hear parts of our record that have not been executed on stage. It will free me up to play some parts that have been missing from our gigs.\"",
            "score": 138.53118896484375
        },
        {
            "docid": "41415_22",
            "document": "Noise . Roland Barthes distinguishes between physiological noise, which is merely heard, and psychological noise, which is actively listened to. Physiological noise is felt subconsciously as the vibrations of the noise (sound) waves physically interact with the body while psychological noise is perceived as our conscious awareness shifts its attention to that noise.",
            "score": 137.47682189941406
        },
        {
            "docid": "29329_18",
            "document": "Spectrum . A source of sound can have many different frequencies mixed. A Musical tone's timbre is characterized by its harmonic spectrum. Sound in our environment that we refer to as \"noise\" includes many different frequencies. When a sound signal contains a mixture of all audible frequencies, distributed equally over the audio spectrum, it is called white noise.",
            "score": 137.25636291503906
        },
        {
            "docid": "52287299_2",
            "document": "3D sound synthesis . 3D sound simply refers to the way we experience sound in our everyday lives. In real life, we're surrounded by sounds all the time. Sounds arrive at our ears from every direction and from varying distances. These factors and many more contribute to the three-dimensional aural image we hear. Scientists and engineers have worked to accurately synthesize the complexity of real-world sounds. This is the science of 3D Sound Synthesis.",
            "score": 136.8984832763672
        },
        {
            "docid": "3398345_11",
            "document": "Sound studies . Part of this shift in the dynamics of recorded sound has to do with a desire for noise reduction. This desire is representative of a mode of recording referred to by scholar James Lastra as \"telephonic:\" a mode in which sound is regarded as having hierarchically important qualities, with clarity and intelligibility being the most important aspects. This contrasts with phonographic recording, which generates a \"point of audition\" from which a sense of space can be derived, sacrificing quality for uniqueness and fidelity. This technique is often used in movies to demonstrate how a character hears something (such as muffled voices through a closed door). Through various forms of media, recorded music affects our perceptions and consumptive practices more often than we realize.",
            "score": 134.94119262695312
        },
        {
            "docid": "5292823_7",
            "document": "Coming Home (New Found Glory album) . The band entered Jackson Browne's private recording studio named Groovemasters in January 2006, after Panunzio had suggested it would be a suitable recording location. New Found Glory strove to achieve a \"clean kind of classic guitar sound\" when recording, using a Vox AC30 amp on almost the entire record. The amp, known for its \"jangly\" high-end sound, was used with several classic guitars in the studio including a Fender Tele, Les Paul, Gibson 335-S and a Rickenbacker. Gilbert enthused that, \"It sounds huge. When you put our old records on and our new record, there's actually less guitars on our new album, but it sounds bigger.\" Jordan Pundik likewise accounted; \"he [Panunzio] brought this classic vibe to it, especially with the tones he got. We learned we don't have to double-up 15 Mesa cabinets and make it all distorted to make it sound big.\" Pundik also spoke of the band's desire to challenge themselves musically; \"Usually with every record we think, 'We\u2019ve got to put the fast punk song on it or people won't like it', but this wasn't anything like that.\" He did admit that around thirty songs were written, including some fast-paced songs, but were excluded as, \"(they) didn't really fit.\" Steve Klein, the band's principal lyricist and rhythm guitarist, also praised Panunzio for helping the band bring new elements to their sound. Describing the sessions as \"best recording experience ever\", he added, \"It's this empty mansion where we were able to set up all our equipment, we just woke up and wrote songs. We were really relaxed and able to set our own pace. Everything about the record is way more classic rock sounding because Thom has done a bunch of classic rock records like Tom Petty and Bruce Springsteen and Ozzy, and the list goes on and on. He kind of brought this different element to our band. This disc is less guitar driven and more melody driven, more than any other of our records.\"",
            "score": 134.7858428955078
        },
        {
            "docid": "49426058_5",
            "document": "Deep &amp; Chilled Euphoria . Further noting how \"humans have remained enthralled by the effects of rhythmic sounds and aware of the mind-altering and brain wave entertainment effects of rhythmic noises and lights,\" he said that \"for thousands of years, musicians and composers have consciously influenced the brain states of listeners by manipulating the frequency of the rhythms and tones of their music. Ancient rituals for entering trance states often involved both rhythmic sounds and flickering lights produced by candles or bonfires.\" He commented how British neurologist William Grey Walter discovered that rhythmic flashing lights quickly altered brain wave activity of the whole cortex instead of just the areas associated with vision. Finding familiarity with Walter's conclusion that \"the rhythmic series of flashes appear to be breaking down some of the psychological barriers between different regions of the brain,\" Izbac said that \"rapidly produced states of deep relaxation increase suggestibility, receptivity to new information and enhance access to subconscious material. This in turn may help you move away from habitual patterns of behaviour and become more flexible, creative and at ease with each other.\"",
            "score": 134.63076782226562
        }
    ]
}