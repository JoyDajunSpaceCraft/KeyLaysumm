{
    "q": [
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 139.42177760601044
        },
        {
            "docid": "33826069_3",
            "document": "Viral neuronal tracing . Most neuroanatomists would agree that understanding how the brain is connected to itself and the body is of paramount importance. As such, it is of equal importance to have a way to visualize and study the connections among neurons. Neuronal tracing methods offer an unprecedented view into the morphology and connectivity of neural networks. Depending on the tracer used, this can be limited to a single neuron or can progress trans-synaptically to adjacent neurons. After the tracer has spread sufficiently, the extent may be measured either by fluorescence (for dyes) or by immunohistochemistry (for biological tracers). An important innovation in this field is the use of neurotropic viruses as tracers. These not only spread throughout the initial site of infection, but can jump across synapses. The use of a virus provides a self-replicating tracer. This can allow for the elucidation of neural microcircuitry to an extent that was previously unobtainable.  This has significant implications for the real world. If we can better understand what parts of the brain are intimately connected, we can predict the effect of localized brain injury. For example, if a patient has a stroke in the amygdala, primarily responsible for emotion, the patient might also have trouble learning to perform certain tasks because the amygdala is highly interconnected with the orbitofrontal cortex, responsible for reward learning. As always, the first step to solving a problem is fully understanding it, so if we are to have any hope of fixing brain injury, we must first understand its extent and complexity.",
            "score": 206.35003924369812
        },
        {
            "docid": "21523_2",
            "document": "Artificial neural network . Artificial neural networks (ANNs) or connectionist systems are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the results to identify cats in other images. They do this without any prior knowledge about cats, e.g., that they have fur, tails, whiskers and cat-like faces. Instead, they automatically generate identifying characteristics from the learning material that they process.",
            "score": 231.41946959495544
        },
        {
            "docid": "8402086_16",
            "document": "Computational neurogenetic modeling . Artificial Neural Networks designed to simulate of the human brain require an ability to learn a variety of tasks that is not required by those designed to accomplish a specific task. Supervised learning is a mechanism by which an artificial neural network can learn by receiving a number of inputs with a correct output already known. An example of an artificial neural network that uses supervised learning is a multilayer perceptron (MLP). In unsupervised learning, an artificial neural network is trained using only inputs. Unsupervised learning is the learning mechanism by which a type of artificial neural network known as a self-organizing map (SOM) learns. Some types of artificial neural network, such as evolving connectionist systems, can learn in both a supervised and unsupervised manner.",
            "score": 262.68170261383057
        },
        {
            "docid": "3691953_4",
            "document": "NETtalk (artificial neural network) . NETtalk was created to explore the mechanisms of learning to correctly pronounce English text. The authors note that learning to read involves a complex mechanism involving many parts of the human brain. NETtalk does not specifically model the image processing stages and letter recognition of the visual cortex. Rather, it assumes that the letters have been pre-classified and recognized, and these letter sequences comprising words are then shown to the neural network during training and during performance testing. It is NETtalk's task to learn proper associations between the correct pronunciation with a given sequence of letters based on the context in which the letters appear. In other words, NETtalk learns to use the letters around the currently pronounced phoneme that provide cues as to its intended phonemic mapping.",
            "score": 202.3933914899826
        },
        {
            "docid": "938663_8",
            "document": "Multi-task learning . Related to multi-task learning is the concept of knowledge transfer. Whereas traditional multi-task learning implies that a shared representation is developed concurrently across tasks, transfer of knowledge implies a sequentially shared representation. Large scale machine learning projects such as the deep convolutional neural network GoogLeNet, an image-based object classifier, can develop robust representations which may be useful to further algorithms learning related tasks. For example, the pre-trained model can be used as a feature extractor to perform pre-processing for another learning algorithm. Or the pre-trained model can be used to initialize a model with similar architecture which is then fine-tuned to learn a different classification task.",
            "score": 144.90941643714905
        },
        {
            "docid": "32168948_6",
            "document": "Sepp Hochreiter . Neural networks are different types of simplified mathematical models of biological neural networks like those in human brains.  In feedforward neural networks (NNs) the information moves forward in only one direction,  from the input layer that receives information from the environment,  through the hidden layers to the output layer that supplies the information to the environment. Unlike NNs, recurrent neural networks (RNNs)  can use their internal memory to process arbitrary sequences of inputs.  If data mining is based on neural networks, overfitting reduces the network's capability to correctly process future data. To avoid overfitting, Sepp Hochreiter developed algorithms for finding low complexity neural networks like \"Flat Minimum Search\" (FMS), which searches for a \"flat\" minimum \u2014 a large connected region in the parameter space where the network function is constant. Thus, the network parameters can be given with low precision which means a low complex network that avoids overfitting. Low complexity neural networks are well suited for deep learning because they control the complexity in each network layer and, therefore, learn hierarchical representations of the input. Sepp Hochreiter's group introduced \"exponential linear units\" (ELUs) which speed up learning in deep neural networks and lead to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs), and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to ReLUs, due to negative values which push mean unit activations closer to zero. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect.",
            "score": 187.68384194374084
        },
        {
            "docid": "35591037_7",
            "document": "Marketing and artificial intelligence . From a marketing perspective, neural networks are a form of software tool used to assist in decision making. Neural networks are effective in gathering and extracting information from large data sources and have the ability to identify the cause and effect within data. These neural nets through the process of learning, identify relationships and connections between data bases. Once knowledge has been accumulated, neural networks can be relied on to provide generalisations and can apply past knowledge and learning to a variety of situations.",
            "score": 185.5281538963318
        },
        {
            "docid": "30525054_7",
            "document": "Anders Dale . In a 2003 interview, Dale explained that he had \u201calways been interested in using quantitative modeling methods and simulations to answer biological questions,\u201d and that as a Harvard student he had been \u201cinterested in approaching connectionist neural networks from a more biological angle.\u201d When he went to UCSD to continue his graduate work his interest \u201cshifted to learning how to test models of how the brain works. Ideally you'd like to test your models not in anesthetized animals and brain slices, but by measuring brain activity in humans non-invasively. I wanted to study normal people doing normal tasks. That was what brought me to imaging. My goal was to see what kind of things we can measure non-invasively that can be quantitatively related to the models we want to build...I wanted to know what exactly we are measuring, how can you model it, and how can you relate the signal to what is going on in the brain physiologically...at a level that say you could measure invasively and that you could relate to parameters of quantitative models.\u201d His thesis work at UCSD, he said, \u201cwas on the EEG and MEG forward and inverse problems, and how to use anatomical information to constrain the solutions. It is clear that if you only use EEG or MEG measures, the spatial precision is not good enough to make inferences at a scale that's most useful to neuroscience. That led us into trying to use information with higher spatial resolution to constrain or bias our estimations of the signal sources in the brain.\u201d",
            "score": 166.7703560590744
        },
        {
            "docid": "40158142_9",
            "document": "Nonlinear system identification . Artificial neural networks try loosely to imitate the network of neurons in the brain where computation takes place through a large number of simple processing elements. A typical neural network consists of a number of simple processing units interconnected to form a complex network. Layers of such units are arranged so that data is entered at the input layer and passes through either one or several intermediate layers before reaching the output layer. In supervised learning the network is trained by operating on the difference between the actual output and the desired output of the network, the prediction error, to change the connection strengths between the nodes. By iterating the weights are modified until the output error reaches an acceptable level. This process is called machine learning because the network adjusts the weights so that the output pattern is reproduced. Neural networks have been extensively studied and there are many excellent textbooks devoted to this topic in general, and more focussed textbooks which emphasise control and systems applications. There are two main problem types that can be studied using neural networks: static problems, and dynamic problems. Static problems include pattern recognition, classification, and approximation. Dynamic problems involve lagged variables and are more appropriate for system identification and related applications. Depending on the architecture of the network the training problem can be either nonlinear-in-the-parameters which involves optimisation or linear-in-the-parameters which can be solved using classical approaches. The training algorithms can be categorised into supervised, unsupervised, or reinforcement learning. Neural networks have excellent approximation properties but these are usually based on standard function approximation results using for example the Weierstrass Theorem that applies equally well to polynomials, rational functions, and other well-known models.  Neural networks have been applied extensively to system identification problems which involve nonlinear and dynamic relationships. However, classical neural networks are purely gross static approximating machines. There is no dynamics within the network. Hence when fitting dynamic models all the dynamics arise by allocating lagged inputs and outputs to the input layer of the network. The training procedure then produces the best static approximation that relates the lagged variables assigned to the input nodes to the output. There are more complex network architectures, including recurrent networks, that produce dynamics by introducing increasing orders of lagged variables to the input nodes. But in these cases it is very easy to over specify the lags and this can lead to over fitting and poor generalisation properties.  Neural networks have several advantages; they are conceptually simple, easy to train and to use, have excellent approximation properties, the concept of local and parallel processing is important and this provides integrity and fault tolerant behaviour. The biggest criticism of the classical neural network models is that the models produced are completely opaque and usually cannot be written down or analysed. It is therefore very difficult to know what is causing what, to analyse the model, or to compute dynamic characteristics from the model. Some of these points will not be relevant to all applications but they are for dynamic modelling.",
            "score": 222.8129688501358
        },
        {
            "docid": "902940_8",
            "document": "Recognition heuristic . The recognition heuristic can also be depicted using neuroimaging techniques. A number of studies have shown that people do not automatically use the recognition heuristic when it can be applied, but evaluate its ecological validity. It is less clear, however, how this evaluation process can be modeled. A functional magnetic resonance imaging study tested whether the two processes, recognition and evaluation, can be separated on a neural basis. Participants were given two tasks; the first involved only a recognition judgment (\"Have you ever heard of Modena? Milan?\"), while the second involved an inference in which participants could rely on the recognition heuristic (\"Which city has the larger population: Milan or Modena?\"). For mere recognition judgments, activation in the precuneus, an area that is known from independent studies to respond to recognition confidence, was reported. In the inference task, precuneus activation was also observed, as predicted, and activation was detected in the anterior frontomedian cortex (aFMC), which has been linked in earlier studies to evaluative judgments and self-referential processing. The aFMC activation could represent the neural basis of this evaluation of ecological rationality.",
            "score": 102.43577027320862
        },
        {
            "docid": "22072718_15",
            "document": "Biological network . Network analysis provides the ability to quantify associations between individuals, which makes it possible to infer details about the network as a whole at the species and/or population level. Researchers interested in animal behavior across a multitude of taxa, from insects to primates, are starting to incorporate network analysis into their research. Researchers interested in social insects (e.g., ants and bees) have used network analyses to better understand division of labor, task allocation, and foraging optimization within colonies; Other researchers are interested in how certain network properties at the group and/or population level can explain individual level behaviors. For instance, a study on wire-tailed manakins (a small passerine bird) found that a male\u2019s degree in the network largely predicted the ability of the male to rise in the social hierarchy (i.e. eventually obtain a territory and matings). In bottlenose dolphin groups, an individual\u2019s degree and betweenness centrality values may predict whether or not that individual will exhibit certain behaviors, like the use of side flopping and upside-down lobtailing to lead group traveling efforts; individuals with high betweenness values are more connected and can obtain more information, and thus are better suited to lead group travel and therefore tend to exhibit these signaling behaviors more than other group members. Network analysis can also be used to describe the social organization within a species more generally, which frequently reveals important proximate mechanisms promoting the use of certain behavioral strategies. These descriptions are frequently linked to ecological properties (e.g., resource distribution). For example, network analyses revealed subtle differences in the group dynamics of two related equid fission-fusion species, Grevy\u2019s zebra and onagers, living in variable environments; Grevy\u2019s zebras show distinct preferences in their association choices when they fission into smaller groups, whereas onagers do not. Similarly, researchers interested in primates have also utilized network analyses to compare social organizations across the diverse primate order, suggesting that using network measures (such as centrality, assortativity, modularity, and betweenness) may be useful in terms of explaining the types of social behaviors we see within certain groups and not others. Finally, social network analysis can also reveal important fluctuations in animal behaviors across changing environments. For example, network analyses in female chacma baboons (\"Papio hamadryas ursinus\") revealed important dynamic changes across seasons which were previously unknown; instead of creating stable, long-lasting social bonds with friends, baboons were found to exhibit more variable relationships which were dependent on short-term contingencies related to group level dynamics as well as environmental variability. This is a very small set of broad examples of how researchers can use network analysis to study animal behavior. Research in this area is currently expanding very rapidly. Social network analysis is a valuable tool for studying animal behavior across all animal species, and has the potential to uncover new information about animal behavior and social ecology that was previously poorly understood.",
            "score": 154.56961929798126
        },
        {
            "docid": "52036598_4",
            "document": "Differentiable neural computer . DNC can be trained to navigate a variety of rapid transit systems, and then what the DNC learns can be applied, for example, to get around on the London Underground. A neural network without memory would typically have to learn about each different transit system from scratch. On graph traversal and sequence-processing tasks with supervised learning, DNCs performed better than alternatives such as long short-term memory or a neural turing machine. With a reinforcement learning approach to a block puzzle problem inspired by SHRDLU, DNC was trained via curriculum learning, and learned to make a plan. It performed better than a traditional recurrent neural network.",
            "score": 170.0811574459076
        },
        {
            "docid": "21312313_20",
            "document": "Procedural memory . Specifically, this task uses experimental analysis of weather prediction. As a probability learning task, the participant is required to indicate what strategy they are using to solve the task. It is a cognitively-oriented task that is learned in a procedural manner. It's designed using multidimensional stimuli, so participants are given a set of cards with shapes and then asked to predict the outcome. After the prediction is made participants receive feedback and make a classification based on that feedback. For example, the participant can be shown one pattern and then asked to predict whether the pattern indicates good or bad weather. The actual weather outcome will be determined by a probabilistic rule based on each individual card. Amnesic participants learn this task in training but are impaired in later training control.",
            "score": 78.07655930519104
        },
        {
            "docid": "579390_21",
            "document": "Gene prediction . Artificial neural networks are computational models that excel at machine learning and pattern recognition. Neural networks must be trained with example data before being able to generalise for experimental data, and tested against benchmark data. Neural networks are able to come up with approximate solutions to problems that are hard to solve algorithmically, provided there is sufficient training data. When applied to gene prediction, neural networks can be used alongside other \"ab initio\" methods to predict or identify biological features such as splice sites. One approach involves using a sliding window, which traverses the sequence data in an overlapping manner. The output at each position is a score based on whether the network thinks the window contains a donor splice site or an acceptor splice site. Larger windows offer more accuracy but also require more computational power. A neural network is an example of a signal sensor as its goal is to identify a functional site in the genome.",
            "score": 193.68931555747986
        },
        {
            "docid": "39619438_3",
            "document": "AnimatLab . Neuromechanical simulation enables investigators to explore the dynamical relationships between the brain, the body, and the world in ways that are difficult or impossible through experiment alone. This is done by producing biologically realistic models of the neural networks that control behavior, while also simulating the physics that controls the environment in which an animal is situated. Interactions with the simulated world can then be fed back to the virtual nervous system using models of sensory systems. This provides feedback similar to what the real animal would encounter, and makes it possible to close the sensory-motor feedback loop to study the dynamic relationship between nervous function and behavior. This relationship is crucial to understanding how nervous systems work.",
            "score": 195.51008653640747
        },
        {
            "docid": "39182554_23",
            "document": "Catastrophic interference . Following the same basic idea contributed by Robins, Ans and Rousset (1997) have also proposed a two-network artificial neural architecture with \"memory self-refreshing\" that overcomes catastrophic interference when sequential learning tasks are carried out in distributed networks trained by backpropagation. The principle is to interleave, at the time when new external patterns are learned, those to-be-learned new external patterns with internally generated pseudopatterns, or 'pseudo-memories', that reflect the previously learned information. What mainly distinguishes this model from those that use classical pseudorehearsal in feedforward multilayer networks is a \"reverberating\" process that is used for generating pseudopatterns. This process which, after a number of activity re-injections from a single random seed, tends to go up to nonlinear network \"attractors\", is more suitable for optimally capturing the deep structure of previously learned knowledge than a single feedforward pass of random activation. Ans and Rousset (2000) have shown that the learning mechanism they proposed avoiding catastrophic forgetting, provides a more appropriate way to deal with knowledge transfer as measured by learning speed, ability to generalize and vulnerability to network damages. Musca, Rousset and Ans (2009) have also shown that pseudopatterns originating from an artificial reverberating neural network could induce familiarity in humans with never seen items in the way predicted by simulations conducted with a two-network artificial neural architecture. Furthermore, Ans (2004) has implemented a version of the self-refreshing mechanism using only one network trained by the Contrastive Hebbian Learning rule, a training rule considered as more realistic than the largely used backpropagation algorithm, but fortunately equivalent to the latter.",
            "score": 214.54800271987915
        },
        {
            "docid": "21245_17",
            "document": "Neuroscience . At the systems level, the questions addressed in systems neuroscience include how biological neural networks or neural circuits are formed and used anatomically and physiologically to produce functions such as reflexes, multisensory integration, motor coordination, circadian rhythms, emotional responses, learning, and memory. In other words, they address how these neural circuits function and the mechanisms through which behaviors are generated. For example, systems level analysis addresses questions concerning specific sensory and motor modalities: how does vision work? How do songbirds learn new songs and bats localize with ultrasound? How does the somatosensory system process tactile information? The related fields of neuroethology and neuropsychology address the question of how neural substrates underlie specific animal and human behaviors. Neuroendocrinology and psychoneuroimmunology examine interactions between the nervous system and the endocrine and immune systems, respectively. Despite many advancements, the way that networks of neurons perform complex cognitive processes and behaviors is still poorly understood.",
            "score": 201.64814221858978
        },
        {
            "docid": "32472154_35",
            "document": "Deep learning . Artificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using rule-based programming.",
            "score": 213.5100338459015
        },
        {
            "docid": "2534964_17",
            "document": "Sensory processing . In the future, research on sensory integration will be used to better understand how different sensory modalities are incorporated within the brain to help us perform even the simplest of tasks. For example, we do not currently have the understanding needed to comprehend how neural circuits transform sensory cues into changes in motor activities. More research done on the sensorimotor system can help understand how these movements are controlled. This understanding can potentially be used to learn more about how to make better prosthetics, and eventually help patients who have lost the use of a limb. Also, by learning more about how different sensory inputs can combine can have profound effects on new engineering approaches using robotics. The robot's sensory devices may take in inputs of different modalities, but if we understand multisensory integration better, we might be able to program these robots to convey these data into a useful output to better serve our purposes.",
            "score": 140.24763333797455
        },
        {
            "docid": "25_24",
            "document": "Autism . The mirror neuron system (MNS) theory of autism hypothesizes that distortion in the development of the MNS interferes with imitation and leads to autism's core features of social impairment and communication difficulties. The MNS operates when an animal performs an action or observes another animal perform the same action. The MNS may contribute to an individual's understanding of other people by enabling the modeling of their behavior via embodied simulation of their actions, intentions, and emotions. Several studies have tested this hypothesis by demonstrating structural abnormalities in MNS regions of individuals with ASD, delay in the activation in the core circuit for imitation in individuals with Asperger syndrome, and a correlation between reduced MNS activity and severity of the syndrome in children with ASD. However, individuals with autism also have abnormal brain activation in many circuits outside the MNS and the MNS theory does not explain the normal performance of children with autism on imitation tasks that involve a goal or object. ASD-related patterns of low function and aberrant activation in the brain differ depending on whether the brain is doing social or nonsocial tasks. In autism there is evidence for reduced functional connectivity of the default network, a large-scale brain network involved in social and emotional processing, with intact connectivity of the task-positive network, used in sustained attention and goal-directed thinking. In people with autism the two networks are not negatively correlated in time, suggesting an imbalance in toggling between the two networks, possibly reflecting a disturbance of self-referential thought.",
            "score": 205.7591049671173
        },
        {
            "docid": "53686950_20",
            "document": "Bi-directional hypothesis of language and action . Many studies that have demonstrated a role of the motor system in semantic processing of action language have been used as evidence for a shared neural network between action and language comprehension processes. For example, facilitated activity in language comprehension areas, evidence of semantic priming, with movement of a body part that is associated with the action word has also been used as evidence for this shared neural network. A more specific method for identifying whether certain areas of the brain are necessary for a cognitive task is to demonstrate impaired performance of said task following a functional change to the brain area of interest. A functional change may involve a lesion, or altered excitability through stimulation, or utilization of the area for another task. According to this theory, there is only a finite amount of neural real-estate available for each task. If two tasks share a neural network, there will be competition for the associated neural substrates, and the performance of each task will be inhibited when performed simultaneously. Using this theory, proponents of the bi-directional hypothesis have postulated that performance of verbal working memory of action words would be impaired by movement of the concordant body part. This has been demonstrated with the selective impairment of memorization of arm and leg words when coupled with arm and leg movements, respectively. This implies that the neural network for verbal working memory is specifically tied to the motor systems associated with the body part implied with the word. This semantic topography has been suggested to provide evidence that action language shares a neural network with sensorimotor systems, thereby supporting the bi-directional hypothesis of language and action.",
            "score": 200.39514422416687
        },
        {
            "docid": "33318990_12",
            "document": "Text and conversation theory . Individuals who understand the structure and inner working of their organizations can leverage knowledge toward achieving communication goals. Likewise, organizations can also leverage their hierarchical structures to achieve targeted outcomes. Two types of structures exist within an organization. Goldsmith and Katzenback (2008) explained organizations must understand the informal organization. For example, of being a part of an informal or formal structure, it is important for managers to learn to recognize signs of trouble in order to shape context as they attempt to coordinate meaning and solve day-to-day problems. Specific implications for organizational learning include enhanced performance, coordinated activity and structure, division of labor and collective goal setting  While a formal organization is visually represented by a typical hierarchical structure, it visually shows how formal responsibilities are spread, as well as job dispersal and the flow of information In contrast, the informal organization embodies how people network to accomplish the job, via social relationships and connections or subject-matter experts that are not represented on the organizational chart By leveraging this informal organization, people within the organization are able to use their social network to access and shape the decision-making processes quicker, as well as establish cross-structural collaboration amongst themselves. Additionally, by understanding and using both structures, leaders and managers are able to learn more about their people. Interpreting all forms of communication, verbal and visual, whether you are a supervisor or a subordinate is invaluable. The hierarchical and network structures can allow an organization to recognize signs of trouble from people, accomplish core framing tasks, and to be able to communicate with mindfulness and meaning. By unlocking the value of an organization's structure, leaders and managers can use this knowledge to boost performance or achieve specific goals. Signs of trouble can be emotional, hidden, physical, or in plain sight.",
            "score": 113.89245784282684
        },
        {
            "docid": "1729542_23",
            "document": "Neural network . The utility of artificial neural network models lies in the fact that they can be used to infer a function from observations and also to use it. Unsupervised neural networks can also be used to learn representations of the input that capture the salient characteristics of the input distribution, e.g., see the Boltzmann machine (1983), and more recently, deep learning algorithms, which can implicitly learn the distribution function of the observed data. Learning in neural networks is particularly useful in applications where the complexity of the data or task makes the design of such functions by hand impractical.",
            "score": 185.28921043872833
        },
        {
            "docid": "17651946_6",
            "document": "Ron Sun . Throughout the past two decades, he has been conducting research in the fields of psychology of learning and hybrid neural network (in particular, applying these models to research on human skill acquisition). Specifically, he has worked on the integrated effect of \"top-down\" and \"bottom-up\" learning in human skill acquisition, in a variety of task domains, for example, navigation tasks, reasoning tasks, and implicit learning tasks. This inclusion of bottom-up learning processes has been revolutionary in cognitive psychology, because most previous models of learning had focused exclusively on top-down learning (whereas human learning clearly happens in both directions). This research has culminated with the development of an integrated cognitive architecture that can be used to provide a qualitative and quantitative explanation of empirical psychological learning data. The model, CLARION, is a hybrid neural network that can be used to simulate problem solving and social interactions as well. More importantly, CLARION was the first psychological model that proposed an explanation for the \u201cbottom-up learning\u201d mechanisms present in human skill acquisition: His numerous papers on the subject have brought attention to this neglected area in cognitive psychology.",
            "score": 140.8114275932312
        },
        {
            "docid": "179092_7",
            "document": "Neurolinguistics . Much work in neurolinguistics involves testing and evaluating theories put forth by psycholinguists and theoretical linguists. In general, theoretical linguists propose models to explain the structure of language and how language information is organized, psycholinguists propose models and algorithms to explain how language information is processed in the mind, and neurolinguists analyze brain activity to infer how biological structures (populations and networks of neurons) carry out those psycholinguistic processing algorithms. For example, experiments in sentence processing have used the ELAN, N400, and P600 brain responses to examine how physiological brain responses reflect the different predictions of sentence processing models put forth by psycholinguists, such as Janet Fodor and Lyn Frazier's \"serial\" model, and Theo Vosse and Gerard Kempen's \"unification model\". Neurolinguists can also make new predictions about the structure and organization of language based on insights about the physiology of the brain, by \"generalizing from the knowledge of neurological structures to language structure\".",
            "score": 127.83865642547607
        },
        {
            "docid": "52036598_5",
            "document": "Differentiable neural computer . DNC networks were introduced as an extension of the Neural Turing Machine (NTM), with the addition of memory attention mechanisms that control where the memory is stored, and temporal attention that records the order of events. This structure allows DNCs to be more robust and abstract than a NTM, and still perform tasks that have longer-term dependencies than some of its predecessors such as the LSTM network. The memory, which is simply a matrix, can be allocated dynamically and accessed indefinitely. The DNC is differentiable end-to-end (each subcomponent of the model is differentiable, therefore so is the whole model). This makes it possible to optimize them efficiently using gradient descent. It learns how to store and retrieve the information such that it satisfies the task execution.",
            "score": 143.45250749588013
        },
        {
            "docid": "25391053_2",
            "document": "Regulatory feedback network . Regulatory feedback networks are neural networks that perform inference using Negative feedback. The feedback is not used to find optimal learning or training weights but to find the optimal activation of nodes. In effect this approach is most similar to a non-parametric method but is different from K-nearest neighbors in that it can be shown to mathematically emulate feedforward neural networks.",
            "score": 159.84290957450867
        },
        {
            "docid": "56775942_7",
            "document": "Mathematical models of social learning . The statistician George E. P. Box once said, \"All models are wrong; however, some of them are useful.\" Along the same lines, the DeGroot model is a fairly simple model but it can provide us with useful insights about the learning process in social networks. Indeed, the simplicity of this model makes it tractable for theoretical studies. Specifically, we can analyze different network structure to see for which structures these naive agents can successfully aggregate decentralized information. Since the DeGroot model can be considered a Markov chain, provided that a network is strongly connected (so there is a direct path from any agent to any other) and satisfies a weak aperiodicity condition, beliefs will converge to a consensus. When consensus is reached, the belief of each agent is a weighted average of agents' initial beliefs. These weights provide a measure of social influence.",
            "score": 100.00572168827057
        },
        {
            "docid": "356382_31",
            "document": "Gene regulatory network . Other work has focused on predicting the gene expression levels in a gene regulatory network. The approaches used to model gene regulatory networks have been constrained to be interpretable and, as a result, are generally simplified versions of the network. For example, Boolean networks have been used due to their simplicity and ability to handle noisy data but lose data information by having a binary representation of the genes. Also, artificial neural networks omit using a hidden layer so that they can be interpreted, losing the ability to model higher order correlations in the data. Using a model that is not constrained to be interpretable, a more accurate model can be produced. Being able to predict gene expressions more accurately provides a way to explore how drugs affect a system of genes as well as for finding which genes are interrelated in a process. This has been encouraged by the DREAM competition which promotes a competition for the best prediction algorithms. Some other recent work has used artificial neural networks with a hidden layer.",
            "score": 177.27527451515198
        },
        {
            "docid": "21523_5",
            "document": "Artificial neural network . The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. ANNs have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis. Warren McCulloch and Walter Pitts (1943) created a computational model for neural networks based on mathematics and algorithms called threshold logic. This model paved the way for neural network research to split into two approaches. One approach focused on biological processes in the brain while the other focused on the application of neural networks to artificial intelligence. This work led to work on nerve networks and their link to finite automata.",
            "score": 244.97976350784302
        },
        {
            "docid": "33937822_4",
            "document": "Information processing technology and aging . Cognitive capabilities refer our mental abilities by which we pay attention to the world, interpret the information around us, learn and remember, solve problems and make decisions. Age-related differences in cognitive functioning have been known to stem from the reduction of cognitive resources available, thus impairing older adults\u2019 ability to carry out cognitively demanding tasks. Cognitive aging causes a change in mechanism related to information processing and working memory function. According to Craik, these mechanisms are responsible for age-related speed of decline in performance for mental processing along with a reduction of online cognitive resources available at any given time to process, store, retrieve, and transform information (working memory), focusing on a target, paying attention, and sensory processing of information. This is important since the inherent relationship between cognitive abilities and technology adoption points to the importance of ensuring that system interfaces are well designed and easy to use. The use of information processing theory in cognition looks at the role of the three stages of memory related to retrieving information, transferring and recalling. Cognitive information processing focuses on different aspects of instruction and how those aspects can either facilitate or hinder learning and memory. It emphasizes using strategies that focus the learner's attention, promotes encoding and retrieval, and provide for meaningful, effective practice across learning environments and curriculum.",
            "score": 79.25857472419739
        }
    ],
    "r": [
        {
            "docid": "8402086_16",
            "document": "Computational neurogenetic modeling . Artificial Neural Networks designed to simulate of the human brain require an ability to learn a variety of tasks that is not required by those designed to accomplish a specific task. Supervised learning is a mechanism by which an artificial neural network can learn by receiving a number of inputs with a correct output already known. An example of an artificial neural network that uses supervised learning is a multilayer perceptron (MLP). In unsupervised learning, an artificial neural network is trained using only inputs. Unsupervised learning is the learning mechanism by which a type of artificial neural network known as a self-organizing map (SOM) learns. Some types of artificial neural network, such as evolving connectionist systems, can learn in both a supervised and unsupervised manner.",
            "score": 262.68170166015625
        },
        {
            "docid": "28016652_3",
            "document": "Types of artificial neural networks . Artificial neural networks are computational models inspired by biological neural networks, and are used to approximate functions that are generally unknown. Particularly, they are inspired by the behaviour of neurons and the electrical signals they convey between input (such as from the eyes or nerve endings in the hand), processing, and output from the brain (such as reacting to light, touch, or heat). The way neurons semantically communicate is an area of ongoing research. Most artificial neural networks bear only some resemblance to their more complex biological counterparts, but are very effective at their intended tasks (e.g. classification or segmentation).",
            "score": 245.74974060058594
        },
        {
            "docid": "21523_5",
            "document": "Artificial neural network . The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. ANNs have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis. Warren McCulloch and Walter Pitts (1943) created a computational model for neural networks based on mathematics and algorithms called threshold logic. This model paved the way for neural network research to split into two approaches. One approach focused on biological processes in the brain while the other focused on the application of neural networks to artificial intelligence. This work led to work on nerve networks and their link to finite automata.",
            "score": 244.97976684570312
        },
        {
            "docid": "33818014_15",
            "document": "Nervous system network models . The concept of artificial neural network (ANN) was introduced by McColloch, W. S. & Pitts, W. (1943) for models based on behavior of biological neurons. Norbert Wiener (1961) gave this new field the popular name of cybernetics, whose principle is the interdisciplinary relationship among engineering, biology, control systems, brain functions, and computer science. With the computer science field advancing, the von Neumann-type computer was introduced early in the neuroscience study. But it was not suitable for symbolic processing, nondeterministic computations, dynamic executions, parallel distributed processing, and management of extensive knowledge bases, which are needed for biological neural network applications; and the direction of mind-like machine development changed to a learning machine. Computing technology has since advanced extensively and computational neuroscience is now able to handle mathematical models developed for biological neural network. Research and development are progressing in both artificial and biological neural networks including efforts to merge the two.",
            "score": 234.51515197753906
        },
        {
            "docid": "21523_2",
            "document": "Artificial neural network . Artificial neural networks (ANNs) or connectionist systems are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the results to identify cats in other images. They do this without any prior knowledge about cats, e.g., that they have fur, tails, whiskers and cat-like faces. Instead, they automatically generate identifying characteristics from the learning material that they process.",
            "score": 231.41946411132812
        },
        {
            "docid": "288292_16",
            "document": "Neuropsychology . Connectionism is the use of artificial neural networks to model specific cognitive processes using what are considered to be simplified but plausible models of how neurons operate. Once trained to perform a specific cognitive task these networks are often damaged or 'lesioned' to simulate brain injury or impairment in an attempt to understand and compare the results to the effects of brain injury in humans.",
            "score": 227.9208526611328
        },
        {
            "docid": "40158142_9",
            "document": "Nonlinear system identification . Artificial neural networks try loosely to imitate the network of neurons in the brain where computation takes place through a large number of simple processing elements. A typical neural network consists of a number of simple processing units interconnected to form a complex network. Layers of such units are arranged so that data is entered at the input layer and passes through either one or several intermediate layers before reaching the output layer. In supervised learning the network is trained by operating on the difference between the actual output and the desired output of the network, the prediction error, to change the connection strengths between the nodes. By iterating the weights are modified until the output error reaches an acceptable level. This process is called machine learning because the network adjusts the weights so that the output pattern is reproduced. Neural networks have been extensively studied and there are many excellent textbooks devoted to this topic in general, and more focussed textbooks which emphasise control and systems applications. There are two main problem types that can be studied using neural networks: static problems, and dynamic problems. Static problems include pattern recognition, classification, and approximation. Dynamic problems involve lagged variables and are more appropriate for system identification and related applications. Depending on the architecture of the network the training problem can be either nonlinear-in-the-parameters which involves optimisation or linear-in-the-parameters which can be solved using classical approaches. The training algorithms can be categorised into supervised, unsupervised, or reinforcement learning. Neural networks have excellent approximation properties but these are usually based on standard function approximation results using for example the Weierstrass Theorem that applies equally well to polynomials, rational functions, and other well-known models.  Neural networks have been applied extensively to system identification problems which involve nonlinear and dynamic relationships. However, classical neural networks are purely gross static approximating machines. There is no dynamics within the network. Hence when fitting dynamic models all the dynamics arise by allocating lagged inputs and outputs to the input layer of the network. The training procedure then produces the best static approximation that relates the lagged variables assigned to the input nodes to the output. There are more complex network architectures, including recurrent networks, that produce dynamics by introducing increasing orders of lagged variables to the input nodes. But in these cases it is very easy to over specify the lags and this can lead to over fitting and poor generalisation properties.  Neural networks have several advantages; they are conceptually simple, easy to train and to use, have excellent approximation properties, the concept of local and parallel processing is important and this provides integrity and fault tolerant behaviour. The biggest criticism of the classical neural network models is that the models produced are completely opaque and usually cannot be written down or analysed. It is therefore very difficult to know what is causing what, to analyse the model, or to compute dynamic characteristics from the model. Some of these points will not be relevant to all applications but they are for dynamic modelling.",
            "score": 222.81297302246094
        },
        {
            "docid": "349771_2",
            "document": "Artificial neuron . An artificial neuron is a mathematical function conceived as a model of biological neurons, a neural network. Artificial neurons are elementary units in an artificial neural network. The artificial neuron receives one or more inputs (representing excitatory postsynaptic potentials and inhibitory postsynaptic potentials at neural dendrites) and sums them to produce an output (or , representing a neuron's action potential which is transmitted along its axon). Usually each input is separately weighted, and the sum is passed through a non-linear function known as an activation function or transfer function. The transfer functions usually have a sigmoid shape, but they may also take the form of other non-linear functions, piecewise linear functions, or step functions. They are also often monotonically increasing, continuous, differentiable and bounded. The thresholding function has inspired building logic gates referred to as threshold logic; applicable to building logic circuits resembling brain processing. For example, new devices such as memristors have been extensively used to develop such logic in recent times.",
            "score": 221.47625732421875
        },
        {
            "docid": "1729542_17",
            "document": "Neural network . Neural networks, as used in artificial intelligence, have traditionally been viewed as simplified models of neural processing in the brain, even though the relation between this model and brain biological architecture is debated, as it is not clear to what degree artificial neural networks mirror brain function.",
            "score": 220.54449462890625
        },
        {
            "docid": "1729542_2",
            "document": "Neural network . The term neural network was traditionally used to refer to a network or circuit of neurons. The modern usage of the term often refers to artificial neural networks, which are composed of artificial neurons or nodes. Thus the term may refer to either biological neural networks, made up of real biological neurons, or artificial neural networks, for solving artificial intelligence (AI) problems.The connections of the biological neuron are modeled as weights. A positive weight reflects an excitatory connection, while negative values mean inhibitory connections. All inputs are modified by a weight and summed. This activity is referred as a linear combination. Finally, an activation function controls the amplitude of the output. For example, an acceptable range of output is usually between 0 and 1, or it could be -1 and 1.",
            "score": 219.1932373046875
        },
        {
            "docid": "35591037_6",
            "document": "Marketing and artificial intelligence . An artificial neural network is a form of computer program modelled on the brain and nervous system of humans. Neural networks are composed of a series of interconnected processing neurons functioning in unison to achieve certain outcomes.  Using \u201chuman-like trial and error learning methods neural networks detect patterns existing within a data set ignoring data that is not significant, while emphasising the data which is most influential\u201d.",
            "score": 217.88214111328125
        },
        {
            "docid": "1164_53",
            "document": "Artificial intelligence . Neural networks, or neural nets, were inspired by the architecture of neurons in the human brain. A simple \"neuron\" \"N\" accepts input from multiple other neurons, each of which, when activated (or \"fired\"), cast a weighted \"vote\" for or against whether neuron \"N\" should itself activate. Learning requires an algorithm to adjust these weights based on the training data; one simple algorithm (dubbed \"fire together, wire together\") is to increase the weight between two connected neurons when the activation of one triggers the successful activation of another. The net forms \"concepts\" that are distributed among a subnetwork of shared neurons that tend to fire together; a concept meaning \"leg\" might be coupled with a subnetwork meaning \"foot\" that includes the sound for \"foot\". Neurons have a continuous spectrum of activation; in addition, neurons can process inputs in a nonlinear way rather than weighing straightforward votes. Modern neural nets can learn both continuous functions and, surprisingly, digital logical operations. Neural networks' early successes included predicting the stock market and (in 1995) a mostly self-driving car. In the 2010s, advances in neural networks using deep learning thrust AI into widespread public consciousness and contributed to an enormous upshift in corporate AI spending; for example, AI-related M&A in 2017 was over 25 times as large as in 2015.",
            "score": 216.6985626220703
        },
        {
            "docid": "3737445_11",
            "document": "Quantum neural network . Most learning algorithms follow the classical model of training an artificial neural network to learn the input-output function of a given training set and use classical feedback loops to update parameters of the quantum system until they converge to an optimal configuration. Learning as a parameter optimisation problem has also been approached by adiabatic models of quantum computing. Recently there has been proposed a new post-learning strategy to allow the search for improved set of weights based on analogy with quantum effects occurring in nature. The technique, proposed in is based on the analogy of modeling a biological neuron as a semiconductor heterostructure consisting of one energetic barrier sandwiched between two energetically lower areas. The activation function of the neuron is therefore considered as a particle entering the heterostructure and interacting with the barrier. In this way auxiliary reinforcement to the classical learning process of neural networks is achieved with minimal additional computational costs.",
            "score": 215.888916015625
        },
        {
            "docid": "233488_23",
            "document": "Machine learning . An artificial neural network (ANN) learning algorithm, usually called \"neural network\" (NN), is a learning algorithm that is vaguely inspired by biological neural networks. Computations are structured in terms of an interconnected group of artificial neurons, processing information using a connectionist approach to computation. Modern neural networks are non-linear statistical data modeling tools. They are usually used to model complex relationships between inputs and outputs, to find patterns in data, or to capture the statistical structure in an unknown joint probability distribution between observed variables.",
            "score": 215.8715362548828
        },
        {
            "docid": "2567511_17",
            "document": "Neural engineering . Scientists can use experimental observations of neuronal systems and theoretical and computational models of these systems to create Neural networks with the hopes of modeling neural systems in as realistic a manner as possible. Neural networks can be used for analyses to help design further neurotechnological devices. Specifically, researchers handle analytical or finite element modeling to determine nervous system control of movements and apply these techniques to help patients with brain injuries or disorders. Artificial neural networks can be built from theoretical and computational models and implemented on computers from theoretically devices equations or experimental results of observed behavior of neuronal systems. Models might represent ion concentration dynamics, channel kinetics, synaptic transmission, single neuron computation, oxygen metabolism, or application of dynamic system theory (LaPlaca et al. 2005). Liquid-based template assembly was used to engineer 3D neural networks from neuron-seeded microcarrier beads.",
            "score": 215.30349731445312
        },
        {
            "docid": "162435_22",
            "document": "Mind uploading . Since the function of the human mind and how it might arise from the working of the brain's neural network, are poorly understood issues, mind uploading relies on the idea of neural network emulation. Rather than having to understand the high-level psychological processes and large-scale structures of the brain, and model them using classical artificial intelligence methods and cognitive psychology models, the low-level structure of the underlying neural network is captured, mapped and emulated with a computer system. In computer science terminology, rather than analyzing and reverse engineering the behavior of the algorithms and data structures that resides in the brain, a blueprint of its source code is translated to another programming language. The human mind and the personal identity then, theoretically, is generated by the emulated neural network in an identical fashion to it being generated by the biological neural network.",
            "score": 214.8357696533203
        },
        {
            "docid": "39182554_23",
            "document": "Catastrophic interference . Following the same basic idea contributed by Robins, Ans and Rousset (1997) have also proposed a two-network artificial neural architecture with \"memory self-refreshing\" that overcomes catastrophic interference when sequential learning tasks are carried out in distributed networks trained by backpropagation. The principle is to interleave, at the time when new external patterns are learned, those to-be-learned new external patterns with internally generated pseudopatterns, or 'pseudo-memories', that reflect the previously learned information. What mainly distinguishes this model from those that use classical pseudorehearsal in feedforward multilayer networks is a \"reverberating\" process that is used for generating pseudopatterns. This process which, after a number of activity re-injections from a single random seed, tends to go up to nonlinear network \"attractors\", is more suitable for optimally capturing the deep structure of previously learned knowledge than a single feedforward pass of random activation. Ans and Rousset (2000) have shown that the learning mechanism they proposed avoiding catastrophic forgetting, provides a more appropriate way to deal with knowledge transfer as measured by learning speed, ability to generalize and vulnerability to network damages. Musca, Rousset and Ans (2009) have also shown that pseudopatterns originating from an artificial reverberating neural network could induce familiarity in humans with never seen items in the way predicted by simulations conducted with a two-network artificial neural architecture. Furthermore, Ans (2004) has implemented a version of the self-refreshing mechanism using only one network trained by the Contrastive Hebbian Learning rule, a training rule considered as more realistic than the largely used backpropagation algorithm, but fortunately equivalent to the latter.",
            "score": 214.54800415039062
        },
        {
            "docid": "941909_26",
            "document": "Receptive field . The term receptive field is also used in the context of artificial neural networks, most often in relation to convolutional neural networks (CNNs). When used in this sense, the term adopts a meaning reminiscent of receptive fields in actual biological nervous systems. CNNs have a distinct architecture, designed to mimic the way in which real animal brains are understood to function; instead of having every neuron in each layer connect to all neurons in the next layer (Multilayer perceptron), the neurons are arranged in a 3-dimensional structure in such a way as to take into account the spatial relationships between different neurons with respect to the original data. Since CNNs are used primarily in the field of computer vision, the data that the neurons represent is typically an image; each input neuron represents one pixel from the original image. The first layer of neurons is composed of all the input neurons; neurons in the next layer will receive connections from some of the input neurons (pixels), but not all, as would be the case in a MLP and in other traditional neural networks. Hence, instead of having each neuron receive connections from all neurons in the previous layer, CNNs use a receptive field-like layout in which each neuron receives connections only from a subset of neurons in the previous (lower) layer. The receptive field of a neuron in one of the lower layers encompasses only a small area of the image, while the receptive field of a neuron in subsequent (higher) layers involves a combination of receptive fields from several (but not all) neurons in the layer before (i. e. a neuron in a higher layer \"looks\" at a larger portion of the image than does a neuron in a lower layer). In this way, each successive layer is capable of learning increasingly abstract features of the original image. The use of receptive fields in this fashion is thought to give CNNs an advantage in recognizing visual patterns when compared to other types of neural networks.",
            "score": 213.6934051513672
        },
        {
            "docid": "17319790_3",
            "document": "Modular neural network . As artificial neural network research progresses, it is appropriate that artificial neural networks continue to draw on their biological inspiration and emulate the segmentation and modularization found in the brain. The brain, for example, divides the complex task of visual perception into many subtasks. Within a part of the brain, called the thalamus, lies the lateral geniculate nucleus (LGN), which is divided into layers that separately process color and contrast: both major components of vision. After the LGN processes each component in parallel, it passes the result to another region to compile the results.",
            "score": 213.61764526367188
        },
        {
            "docid": "32472154_35",
            "document": "Deep learning . Artificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using rule-based programming.",
            "score": 213.51004028320312
        },
        {
            "docid": "21523_3",
            "document": "Artificial neural network . An ANN is based on a collection of connected units or nodes called artificial neurons which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it.",
            "score": 213.27760314941406
        },
        {
            "docid": "12994741_14",
            "document": "Neurorobotics . Biological robots are not officially neurorobots in that they are not neurologically inspired AI systems, but actual neuron tissue wired to a robot. This employs the use of cultured neural networks to study brain development or neural interactions. These typically consist of a neural culture raised on a multielectrode array (MEA), which is capable of both recording the neural activity and stimulating the tissue. In some cases, the MEA is connected to a computer which presents a simulated environment to the brain tissue and translates brain activity into actions in the simulation, as well as providing sensory feedback. The ability to record neural activity gives researchers a window into a brain, albeit simple, which they can use to learn about a number of the same issues neurorobots are used for.",
            "score": 213.145751953125
        },
        {
            "docid": "21855574_5",
            "document": "Brain simulation . The connectivity of the neural circuit for touch sensitivity of the simple C. elegans nematode (roundworm) was mapped in 1985 and partly simulated in 1993. Since 2004, many software simulations of the complete neural and muscular system have been developed, including simulation of the worm's physical environment. Some of these models have been made available for download. However, there is still a lack of understanding of how the neurons and the connections between them generate the surprisingly complex range of behaviors that are observed in the relatively simple organism. This contrast between the apparent simplicity of how the mapped neurons interact with their neighbours, and exceeding complexity of the overall brain function, is an example of an emergent property. Interestingly, this kind of emergent property is paralleled within artificial neural networks, the neurons of which are exceedingly simple compared to their often complex, abstract outputs.",
            "score": 212.1595458984375
        },
        {
            "docid": "1726672_2",
            "document": "Neural circuit . A neural circuit, is a population of neurons interconnected by synapses to carry out a specific function when activated. Neural circuits interconnect to one another to form large scale brain networks. Biological neural networks have inspired the design of artificial neural networks.",
            "score": 212.1115264892578
        },
        {
            "docid": "1164_60",
            "document": "Artificial intelligence . According to one overview, the expression \"Deep Learning\" was introduced to the Machine Learning community by Rina Dechter in 1986 and gained traction after Igor Aizenberg and colleagues introduced it to Artificial Neural Networks in 2000. The first functional Deep Learning networks were published by Alexey Grigorevich Ivakhnenko and V. G. Lapa in 1965. These networks are trained one layer at a time. Ivakhnenko's 1971 paper describes the learning of a deep feedforward multilayer perceptron with eight layers, already much deeper than many later networks. In 2006, a publication by Geoffrey Hinton and Ruslan Salakhutdinov introduced another way of pre-training many-layered feedforward neural networks (FNNs) one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then using supervised backpropagation for fine-tuning. Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships. Over the last few years, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.",
            "score": 211.61375427246094
        },
        {
            "docid": "10159567_6",
            "document": "Spiking neural network . This kind of neural network can in principle be used for information processing applications the same way as traditional artificial neural networks. In addition, spiking neural networks can model the central nervous system of a virtual insect for seeking food without the prior knowledge of the environment. However, due to their more realistic properties, they can also be used to study the operation of biological neural circuits. Starting with a hypothesis about the topology of a biological neuronal circuit and its function, the electrophysiological recordings of this circuit can be compared to the output of the corresponding spiking artificial neural network simulated on computer, determining the plausibility of the starting hypothesis.",
            "score": 210.41868591308594
        },
        {
            "docid": "49706798_9",
            "document": "Cortical implant . A Brain-computer interface (BCI) is a type of implant that allows for a direct connection between a patient's brain and some form of external hardware. Since the mid-1990s, the amount of research done on BCI's in both animal and human models has grown exponentially. Most brain-computer interfaces are used for some form of neural signal extraction, while some attempt to return sensation through an implanted signal. As an example of signal extraction, a BCI may take a signal from a paraplegic patient's brain and use it to move a robotic prosthetic. Paralyzed patients get a great amount of utility from these devices because they allow for a return of control to the patient. Current research for brain-computer interfaces is focused on determining which regions of the brain can be manipulated by an individual. A majority of research focuses on the sensorimotor region of the brain, using imagined motor actions to drive the devices, while some studies have sought to determine if the cognitive control network would be a suitable location for implantations. This region is a \"neuronal network that coordinates mental processes in the service of explicit intentions or tasks,\" driving the device by intent, rather than imagined motion An example of returning sensation through an implanted signal would be developing a tactile response for a prosthetic limb. Amputees have no touch response in artificial limbs, but through an implant in their somatosensory cortex could potentially give them an artificial sense of touch.",
            "score": 210.1850128173828
        },
        {
            "docid": "8402086_9",
            "document": "Computational neurogenetic modeling . For the parameters in the gene regulatory network to affect the neurons in the artificial neural network as intended there must be some connection between them. In an organizational context, each node (neuron) in the artificial neural network has its own gene regulatory network associated with it. The weights (and in some networks, frequencies of synaptic transmission to the node), and the resulting membrane potential of the node (including whether an action potential is produced or not), affect the expression of different genes in the gene regulatory network. Factors affecting connections between neurons, such as synaptic plasticity, can be modeled by inputting the values of synaptic activity-associated genes and proteins to a function that re-evaluates the weight of an input from a particular neuron in the artificial neural network.",
            "score": 209.47232055664062
        },
        {
            "docid": "762064_2",
            "document": "Systems neuroscience . Systems neuroscience is a subdiscipline of neuroscience and systems biology that studies the function of neural circuits and systems. It is an umbrella term, encompassing a number of areas of study concerned with how nerve cells behave when connected together to form neural pathways, neural circuits, and larger brain networks. At this level of analysis, neuroscientists study how different neural circuits analyze sensory information, form perceptions of the external world, make decisions, and execute movements. Researchers in systems neuroscience are concerned with the relation between molecular and cellular approaches to understanding brain structure and function, as well as with the study of high-level mental functions such as language, memory, and self-awareness (which are the purview of behavioral and cognitive neuroscience). Systems neuroscientists typically employ techniques for understanding networks of neurons as they are seen to function, by way of electrophysiology using either single-unit recording or multi-electrode recording, functional magnetic resonance imaging (fMRI), and PET scans. The term is commonly used in an educational framework: a common sequence of graduate school neuroscience courses consists of cellular/molecular neuroscience for the first semester, then systems neuroscience for the second semester. It is also sometimes used to distinguish a subdivision within a neuroscience department at an academic institution.",
            "score": 208.89498901367188
        },
        {
            "docid": "21523_136",
            "document": "Artificial neural network . A fundamental objection is that they do not reflect how real neurons function. Back propagation is a critical part of most artificial neural networks, although no such mechanism exists in biological neural networks. How information is coded by real neurons is not known. Sensor neurons fire action potentials more frequently with sensor activation and muscle cells pull more strongly when their associated motor neurons receive action potentials more frequently. Other than the case of relaying information from a sensor neuron to a motor neuron, almost nothing of the principles of how information is handled by biological neural networks is known.",
            "score": 208.45269775390625
        },
        {
            "docid": "21523_30",
            "document": "Artificial neural network . An \"artificial neural network\" is a network of simple elements called \"artificial neurons\", which receive input, change their internal state (\"activation\") according to that input, and produce output depending on the input and activation. The \"network\" forms by connecting the output of certain neurons to the input of other neurons forming a directed, weighted graph. The weights as well as the functions that compute the activation can be modified by a process called \"learning\" which is governed by a \"learning rule\".",
            "score": 207.71096801757812
        },
        {
            "docid": "33818014_21",
            "document": "Nervous system network models . As mentioned in Section 2.4, development of artificial neural network (ANN), or neural network as it is now called, started as simulation of biological neuron network and ended up using artificial neurons. Major development work has gone into industrial applications with learning process. Complex problems were addressed by simplifying the assumptions. Algorithms were developed to achieve a neurological related performance, such as learning from experience. Since the background and overview have been covered in the other internal references, the discussion here is limited to the types of models. The models are at the system or network level.",
            "score": 207.41610717773438
        }
    ]
}