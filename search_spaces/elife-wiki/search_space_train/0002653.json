{
    "q": [
        {
            "docid": "17258308_3",
            "document": "Two-alternative forced choice . There are various manipulations in the design of the task, engineered to test specific behavioral dynamics of choice. In one well known experiment of attention that examines the attentional shift, the Posner Cueing Task uses a 2AFC design to present two stimuli representing two given locations. In this design there is an arrow that cues which stimulus (location) to attend to. The person then has to make a response between the two stimuli (locations) when prompted. In animals, the 2AFC task has been used to test reinforcement probability learning, for example such as choices in pigeons after reinforcement of trials. A 2AFC task has also been designed to test decision making and the interaction of reward and probability learning in monkeys. Monkeys were trained to look at a center stimulus and were then presented with two salient stimuli side by side. A response can then be made in the form of a saccade to the left or to the right stimulus. A juice reward is then administered after each response. The amount of juice reward is then varied to modulate choice.",
            "score": 126.2210556268692
        },
        {
            "docid": "169305_62",
            "document": "Cognitive dissonance . The results reported in \"The Origins of Cognitive Dissonance: Evidence from Children and Monkeys\" (2007) indicated that there might be evolutionary force behind the reduction of cognitive dissonance in the actions of pre-school-age children and Capuchin monkeys when offered a choice between two like options, decals and candies. The groups then were offered a new choice, between the choice-object not chosen and a novel choice-object that was as attractive as the first object. The resulting choices of the human and simian subjects concorded with the theory of cognitive dissonance when the children and the monkeys each chose the novel choice-object in stead of the choice-object not chosen in the first selection, despite every object having the same value.",
            "score": 94.90643167495728
        },
        {
            "docid": "2733733_38",
            "document": "Delayed gratification . When animals are faced with a choice to either wait for a reward, or receive a reward right away, the discounting of the reward is hyperbolic. As the length of time of waiting for a reward increases, the reward is discounted at a gradual rate. Empirical data have suggested that exponential discounting, rewards discounting at a constant rate per unit of waiting time, only occurs when there are random interruptions in foraging. Discounting can also be related to the risk sensitivity of animals. Rather than relating risk to delay, risk sensitivity acts as a function of delay discounting. In a study conducted by Haden and Platt, macaque monkeys were given the choice of a medium reward that they knew they would receive, versus a more risky choice. The riskier choice would reward the monkey with a large reward fifty percent of the time, and a small reward the other fifty percent. The ultimate payoff was the same, but the monkeys preferred the riskier choice. They speculated that the monkeys did not see their action as risky, but rather as a large, delayed reward. They reasoned that the monkeys viewed the large reward as certain: if they did not get the large reward the first time around, they would eventually get it, but at a longer delay. To test for this theory, they gave the same test while varying the time between the opportunities to choose a reward. They found that as the interval increased, the number of times that the monkeys chose the more risky reward decreased. While this occurred in macaque monkeys, the varying interval time did not affect pigeons' choices in another study. This suggests that research looking into varying risk sensitivity of different species is needed. When provided a choice between a small, short delay reward, and a large, long delay reward, there is an impulsive preference for the former. Additionally, as the delay time for the small/short and large/long reward increases, there is a shift in preference toward the larger, delayed reward. This evidence only supports hyperbolic discounting, not exponential.",
            "score": 106.49903309345245
        },
        {
            "docid": "2999259_23",
            "document": "Choice-supportive bias . Henkel and Mather tested the role of beliefs at the time of retrieval about which option was chosen by giving participants several hypothetical choices like deciding between two used cars. After making several choices, participants left and were asked to return a week later. At that point, Henkel and Mather reminded them which option they had chosen for each choice and gave them a list of the features of the two options; some new positive and negative features were mixed in with the old features. Next, participants were asked to indicate whether each option was new, had been associated with the option they chose, or had been associated with the option they rejected. Participants favored whichever option Henkel and Mather had told them they had chosen in their memories. These findings show that beliefs at the time of retrieval about which option was chosen shape both which features are attributed to the options and how vividly they are remembered.",
            "score": 66.2269606590271
        },
        {
            "docid": "515094_7",
            "document": "Neuroeconomics . For example, Padoa-Schioppa & Assad tracked the firing rates of individual neurons in the monkey orbitofrontal cortex while the animals chose between two kinds of juice. The firing rate of the neurons was directly correlated with the utility of the food items and did not differ when other types of food were offered. This suggests that, in accordance with the economic theory of decision making, neurons are directly comparing some form of utility across different options and choosing the one with the higher value. Similarly, a common measure of prefrontal cortex dysfunction, the FrSBe, is correlated with multiple different measures of economic attitudes and behavior, supporting the idea that brain activation can display important aspects of the decision process.",
            "score": 112.8354263305664
        },
        {
            "docid": "57272974_8",
            "document": "Inequity aversion in animals . Brosnan subsequently tested five female capuchins in different conditions. As before, the rewards were either equal or inferior to what the other monkey received. Brosnan also tested if it matters if the other monkey receives the reward for effort or for not doing anything at all. The task the capuchins had to perform was a common exchange task: the experimenter handed the monkey a stone which simply had to be handed back. If done so, the experimenter would give the food reward. In the side-by-side setting the capuchins could see each others actions and, crucially, each other's rewards. A further control condition was to ascertain if the presence of the higher value reward mattered or the presence of another monkey. In this condition there was only one capuchin and the experimenter first placed a grape in front of the empty place where the other monkey would have been, before starting the exchange task with the test subject.",
            "score": 122.07104563713074
        },
        {
            "docid": "26685721_33",
            "document": "Methods used to study memory . The textbook \"Fundamentals of Human Neuropsychology\" by Kolb and Whishaw describes some designs used to study memory in the macaque monkey. Elizabeth Murray and her colleagues trained monkeys to reach through the bars of their cage after a brief delay in order to displace objects under which a reward may be located. During the brief delay the monkey had to use either object recognition memory, or contextual memory to remember where the reward was located. Object recognition is tested with a matching-to-sample task where the monkey had to remember visual characteristics of the object in order to obtain the reward. Alternatively, in the non-matching-to-sample design the monkey must remember the location of the previously seen object. The monkey must then use context and spatial memory in order to correctly displace an object in the same location as previous, in order to obtain the food reward. These two tasks can be used to differentiate between object recognition memory and contextual memory. Murray and her colleagues were able to show that hippocampal lesions impaired contextual memory whereas rhinal cortex lesions impaired object recognition memory. This experimental design allowed for the dissociation of two mutually exclusive brain regions devoted to specific types of memory.",
            "score": 90.866690158844
        },
        {
            "docid": "55377516_30",
            "document": "Dual systems model . Reward decision-making tasks involve participants being asked to choose among different options of reward. Sometimes the rewards differ on probability, magnitude, or type of reward (e.g., social versus monetary). These tasks are typically conceived to not have a correct or incorrect response, but rather to have decision-making based on the participants' preference. Examples of decision making tasks include delay discounting tasks and the Driving Game. During feedback on decision-making tasks, greater striatal activation to rewarding outcomes has been observed in adolescents compared to adults.",
            "score": 135.86482095718384
        },
        {
            "docid": "425938_63",
            "document": "Animal cognition . Western lowland gorillas given the choice between two food trays demonstrated the ability to choose the tray with more food items at a rate higher than chance after training. In a similar task, chimpanzees chose the option with the larger amount of food. Salamanders given a choice between two displays with differing amounts of fruit flies, used as a food reward, reliably choose the display with more flies, as shown in a particular experiment.",
            "score": 60.436758518218994
        },
        {
            "docid": "2060392_5",
            "document": "Pair by association . Paired association learning can be defined as a system of learning in which items (such as words, letters, numbers, symbols etc.) are matched so that presentation of one member of the pair will cue the recall of the other member. It is this learning which constitutes the basics in a paired-associate task. These tasks can be divided into the following: visual-visual, verbal-verbal, and visual-verbal. In visual-visual both members of the pair are in a visual form (e.g. the picture of a blue circle paired with that of a picture of a yellow triangle). The verbal-verbal is when the members of the pair are both verbally presented (e.g. listening to the word cat followed by the word hat spoken to a participant). The last form, visual-verbal is when one member of the pair is spoken out loud while the other member is presented in a visual form (e.g. listening to the word box and seeing a picture of a house). It should be noted that visual associative learning has a positive association with age. In school age children, their visual association ability grows in conjunction with their age; younger children made more errors while older children made less. The paired association task broken down to its basics is: a stimuli, response, and the consequence of the cue association. This is best seen in a study where Naya, Sakai, & Miyashita performed one version of the task on monkeys. In the study a primate was given a visual-visual paired-associate task where they were shown all the pairs in the set. Then after a long delay they displayed one picture of a pair to the primate. When the correct picture was paired by the monkey, showing that the pictures were cueing the response, they were given rewards in the form of food. What this study shows is that it is possible for associations to occur for two previously unrelated items. The monkeys showed they had actually remembered what was shown to them. In visual associative learning, the efficiency of the participant/subject in making these connections actually will decrease as the \u201cmemory load\u201d increases. The more items/the higher the complexity that one has to keep in their memory leads to poorer performance on paired associative learning tasks. Gluck, Mercado, and Myers explain how paired-association is possibly tied to encoding rather than retrieval. In the study presented by Gluck et al., there was a paired associates test where after studying word pairs the participants were presented with one word from the pair and required to recall the match there was a noticeable difference in accuracy between the young adult and older adults. At the start of the study each pair was shown for 15 seconds, in this the older adults had much worse performance; their recall abilities paled in comparison to the younger adults. This however did change when the time was doubled to that of 30 seconds; here the elderly were able to have a much improved performance level. It is an accepted understanding that in associative learning there is a negative regression, as one ages their performance levels decrease. The regression remains even after addressing the possible interfering variables such as attention or spatial memory.",
            "score": 98.08108115196228
        },
        {
            "docid": "8297063_10",
            "document": "Spatial view cells . Current Research shows that the maximum firing rate of spatial view cells is obtained when the test agent is allowed to explore the environment freely. Tests in which the monkey was not allowed to have active locomotion provided very few results of spatial view cells being detected in the hippocampus. Majority of the experiments conducted for spatial view cells involved the use of macaque monkeys as test subjects. These types of cells are identified by monitoring the hippocampus of the monkeys while the brains are stimulated by presenting various images and objects in the monkey's vision. Various researchers use different methodologies in sync with the experiment being conducted in order to identify these spatial view cells. For example, in a delayed spatial response task, the monkey is shown a stimulus on one side of a screen and then the stimulus is taken away. After a short while, the stimulus is again presented to the monkey in the same location and the firing of the cell in the hippocampus that is specifically associated with the location at which the monkey is looking and is independent of the location of the monkey helps identify the spatial view cell. The monkeys in this of experiment are encouraged by rewarding them with fruit juice when they correctly identify the same object in the same location twice in a row and if they get it incorrect, the monkeys receive a saline taste.",
            "score": 85.38974416255951
        },
        {
            "docid": "14554121_3",
            "document": "Social inequity aversion . To better understand and breakdown the concept of social inequity aversion would be to use the study done by Sarah Brosnan (as well as with Frans B. M. de Waal), who specializes in social behavior and social cognition. In their experiment, \"Monkeys Reject Unequal Pay\" five female capuchin monkeys were used and given an unequal distribution of rewards by the human experimenter. The female monkeys alternated in pairs under four different conditions with the experimenter. Of the female monkeys, two received the same reward, one female received a superior reward, one female received a superior reward without exchange (for example without work), and a single female observed a superior reward in the absence of a partner. The females were much less likely to complete a trade with the human experimenter when their corresponding partner received a food item of higher value item (a grape; the lower item was a cucumber), and when that partner received the higher food item with no exchange of work of any kind, the likelihood of not completing a trade intensified. All of these refusals of exchange included both passive and active rejections ranging from refusing to take the awards to throwing the reward, respectively. These negative responses of situation made with the monkeys support the early evolutionary origin of inequity aversion and thus helps (in combination with the definitions of inequity and aversion) give an overall idea of what social inequity aversion is: the tendency to reject or avoid situations in which there is social inequality, unfairness, or injustice.",
            "score": 92.63214993476868
        },
        {
            "docid": "40629843_12",
            "document": "Mirror-touch synesthesia . In most people, several parts of the brain are activated when observing touch, particularly in the motor system. Mirror neurons, discovered recently in monkeys, play a role in helping perceive action. Studies in monkeys have shown that mirror neurons in the ventral premotor cortex fire both when monkeys perform tasks and when monkeys see other monkeys performing the same task. Although the discovery of mirror neurons was made in monkeys recent studies have suggested that a similar mirror system functions in humans. Furthermore, it has been shown that the mirror system is selective only for biological actions. When observing another human grasping an object, there is an increase in premotor cortex activation. However, when seeing a robot grasping an object, there is no such increase.",
            "score": 112.44043302536011
        },
        {
            "docid": "2999259_3",
            "document": "Choice-supportive bias . What is remembered about a decision can be as important as the decision itself, especially in determining how much regret or satisfaction one experiences. Research indicates that the process of making and remembering choices yields memories that tend to be distorted in predictable ways. In cognitive science, one predictable way that memories of choice options are distorted is that positive aspects tend to be remembered as part of the chosen option, whether or not they originally were part of that option, and negative aspects tend to be remembered as part of rejected options. Once an action has been taken, the ways in which we evaluate the effectiveness of what we did may be biased. It is believed this may influence our future decision-making. These biases may be stored as memories, which are attributions that we make about our mental experiences based on their subjective qualities, our prior knowledge and beliefs, our motives and goals, and the social context. True and false memories arise by the same mechanism because when the brain processes and stores information, it cannot tell the difference from where they came from.",
            "score": 128.27530336380005
        },
        {
            "docid": "690278_2",
            "document": "Choice . Choice involves decision making. It can include judging the merits of multiple options and selecting one or more of them. One can make a choice between imagined options (\"What would I do if...?\") or between real options followed by the corresponding action. For example, a traveller might choose a route for a journey based on the preference of arriving at a given destination as soon as possible. The preferred (and therefore chosen) route can then follow from information such as the length of each of the possible routes, traffic conditions, etc. The arrival at a choice can include more complex motivators such as cognition, instinct, and feeling.",
            "score": 133.50137567520142
        },
        {
            "docid": "7214278_10",
            "document": "Decision field theory . Many classic probabilistic models of choice satisfy two rational types of choice principles. One principle is called independence of irrelevant alternatives, and according to this principle, if the probability of choosing option X is greater than option Y when only X,Y are available, then option X should remain more likely to be chosen over Y even when a new option Z is added to the choice set. In other words, adding an option should not change the preference relation between the original pair of options. A second principle is called regularity, and according to this principle, the probability of choosing option X from a set containing only X and Y should be greater than or equal to the probability of choosing option X from a larger set containing options X, Y, and a new option Z. In other words, adding an option should only decrease the probability of choosing one of the original pair of options. However, empirical findings obtained by consumer researchers studying human choice behavior have found systematic context effects that systematically violate both of these principles.",
            "score": 82.32463145256042
        },
        {
            "docid": "4833512_4",
            "document": "Mu wave . The mirror neuron system consists of a class of neurons that was first studied in the 1990s in macaque monkeys. Studies have found sets of neurons that fire when these monkeys perform simple tasks and also when the monkeys view others performing the same simple tasks. This suggests they play a role in mapping others' movements into the brain without actually physically performing the movements. These sets of neurons are called mirror neurons and together make up the mirror neuron system. Mu waves are suppressed when these neurons fire, a phenomenon which allows researchers to study mirror neuron activity in humans. There is evidence that mirror neurons exist in humans as well as in non-human animals. The right fusiform gyrus, left inferior parietal lobule, right anterior parietal cortex, and left inferior frontal gyrus are of particular interest. Some researchers believe that mu wave suppression can be a consequence of mirror neuron activity throughout the brain, and represents a higher-level integrative processing of mirror neuron activity. Tests in both monkeys (using invasive measuring techniques) and humans (using EEG and fMRI) have found that these mirror neurons not only fire during basic motor tasks, but also have components that deal with intention. There is evidence of an important role for mirror neurons in humans, and mu waves may represent a high level coordination of those mirror neurons.",
            "score": 106.79562568664551
        },
        {
            "docid": "57091071_33",
            "document": "Intuitive statistics . Experiments found that when reasoning about preferred vs. non-preferred food proportions, capuchin monkeys were able to make inferences about proportions inferred by sequentially sampled data. Rhesus monkeys were similarly capable of using probabilistic and sequentially sampled data to make inferences about rewarding outcomes, and neural activity in the parietal cortex appeared to be involved in the decision-making process when they made inferences. In a series of 7 experiments using a variety of relative frequency differences between banana pellets and carrots, orangutans, bonobos, chimpanzees, and gorillas also appeared to guide their decisions based on the ratios favoring the banana pellets after this was established as their preferred food item.",
            "score": 123.21191668510437
        },
        {
            "docid": "13064673_19",
            "document": "Emotions in decision-making . Research done by Isen and Patrick put forth the theory of \"mood maintenance\" which states that happy decision-makers are reluctant to gamble. In other words, happy people decide against gambling, since they would not want to undermine the happy feeling. Alternatively, the influence of negative feelings at the time of decision-making was studied by Raghunathan and Tuan Pham (1999). They conducted three experiments in gambling decisions and job selection decisions, where unhappy subjects were found to prefer high-risk/high-reward options unlike anxious subjects who preferred low-risk/low-reward options. They stated that \"anxiety and sadness convey distinct types of information to the decision-maker and prime different goals.\" It was found that \"while anxiety primes an implicit goal of uncertainty reduction, sadness primes an implicit goal of reward replacement\". Thus emotions cannot simply be classified as positive or negative as we need to consider the consequences of the emotions in ultimate decision-making.",
            "score": 98.62979209423065
        },
        {
            "docid": "56279481_27",
            "document": "Cooperative pulling paradigm . The first test with evidence of cooperation in capuchins happened when de Waal and Brosnan adopted Crawford's pulling paradigm. Two captive monkeys were situated in adjacent sections of a test chamber, with a mesh partition between them. In front of them was an apparatus consisting of a counter-weighted tray with two pull bars and two food cups. Each monkey had access to only one bar and one food cup, but could see both, and only one cup was filled with food. The tray was too heavy for one monkey to pull it in, with weights established over trials lasting three years. Only when they worked together and both pulled could they move the tray, enabling one of them to grab the food. Trained monkeys were much more successful if they both obtained rewards after pulling than if only one of them received rewards. The pull rate dropped significantly when monkeys were alone at the apparatus, suggesting an understanding of the need for a partner. In later tests, researchers replaced the mesh partition with an opaque barrier with a small hole, so that the monkeys could see the other one was there but not their actions. This dramatically reduced success in cooperation. De Waal and Berger used the cooperative pulling paradigm to investigate animal economics. They compared the behavior when both transparent bowls were loaded with food to when just one was loaded, and with a solo task where the partner was only an observer and unable to help. They found that captive capuchin monkeys were willing to pull even if their bowl was empty and it was uncertain if their partner would share food. In 90% of cases the owner of the food did indeed share the food. Food was shared more often if the partner actually worked for it than just being an observer.",
            "score": 96.21885442733765
        },
        {
            "docid": "690278_12",
            "document": "Choice . When choosing between options one must make judgments about the quality of each option's attributes. For example, if one is choosing between candidates for a job, the quality of relevant attributes such as previous work experience, college or high school GPA, and letters of recommendation will be judged for each option and the decision will likely be based on these attribute judgments. However, each attribute has a different level of \"evaluability\", that is, the extent to which one can use information from that attribute to make a judgment.",
            "score": 83.72534203529358
        },
        {
            "docid": "903376_7",
            "document": "Hyperbolic discounting . The most important consequence of hyperbolic discounting is that it creates temporary preferences for small rewards that occur sooner over larger, later ones. Individuals using hyperbolic discounting reveal a strong tendency to make choices that are inconsistent over time \u2013 they make choices today that their future self would prefer not to have made, despite knowing the same information. This dynamic inconsistency happens because hyperbolas distort the relative value of options with a fixed difference in delays in proportion to how far the choice-maker is from those options.",
            "score": 72.01366448402405
        },
        {
            "docid": "55377516_27",
            "document": "Dual systems model . Three primary experimental paradigms are used to study reward behavior in adolescents (1) passive receipt of reward, (2) reward conditional on task performance, and (3) decision-making selecting different types of reward options.",
            "score": 101.53127312660217
        },
        {
            "docid": "9425_26",
            "document": "Ethology . Imitation is an advanced behaviour whereby an animal observes and exactly replicates the behaviour of another. The National Institutes of Health reported that capuchin monkeys preferred the company of researchers who imitated them to that of researchers who did not. The monkeys not only spent more time with their imitators but also preferred to engage in a simple task with them even when provided with the option of performing the same task with a non-imitator. Imitation has been observed in recent research on chimpanzees; not only did these chimps copy the actions of another individual, when given a choice, the chimps preferred to imitate the actions of the higher-ranking elder chimpanzee as opposed to the lower-ranking young chimpanzee.",
            "score": 78.40684747695923
        },
        {
            "docid": "4698768_6",
            "document": "Naturalistic decision-making . The recognition-primed decision (RPD) model is the main protocol derived from the NDM framework. RPD describes how people use their experience in the form of patterns. These patterns highlight the relevant cues, provide expected outcomes, identify plausible goals, and suggest typical types of reactions in that type of situation. When people need to make a decision, they can quickly match the situation to the patterns they have learned and experienced in the past. Doing this, people can successfully make rapid decisions. The RPD model explains how people can make good decisions without comparing options. However, there is more to the RPD model than pattern matching. How can a person evaluate an option without comparing it with others? It has been found that fireground commanders evaluate a course of action by using mental simulation to imagine how a situation would play out within the context of the current situation. If it would work, then the commanders could initiate the action. If it almost worked, they could try to adapt it or else consider other actions that were somewhat less typical, continuing until they found an option that felt comfortable. This process exemplifies Herbert Simon's (1957) notion of satisficing \u2013 looking for the first workable option rather than trying to find the best possible option. Because fires grow exponentially, the faster the commanders could react, the easier their job. Therefore, the RPD model is a blend of intuition and analysis. The pattern matching is the intuitive part, and the mental simulation is the conscious, deliberate, and analytical part. Intuitive strategy relying only on pattern matching would be too risky because sometimes the pattern matching generates flawed options. Also, a completely deliberative and analytical strategy would be too slow; the fires would be out of control by the time the commanders finished deliberating. In-depth interviews with fireground commanders who recently experienced challenging incidents show that the percentage of RPD strategies used in those situations generally ranged from 80% to 90% (Klein, 1989). Other researchers have replicated these findings (see Klein, 1998). The first moves that occurred to them were much better than would be expected by chance. These findings support the RPD hypothesis that the first option considered is usually satisfactory. These results were later replicated by Johnson and Raab (2003).",
            "score": 145.1091947555542
        },
        {
            "docid": "25225295_15",
            "document": "Consumer neuroscience . A study by McClure et al. investigated the difference in branding between Coca-Cola and Pepsi. The study found that when the two drinks were tasted blind there was no difference in consumer preference between the brands. Both drinks produced equal activation in the ventromedial prefrontal cortex, which is thought to be activated because the taste is rewarding. When the subjects were informed of the brand names the consumers preferred Coke, and only Coke activated the ventromedial prefrontal cortex, suggesting that drinking the Coke brand is rewarding beyond simply the taste itself. More subjects preferred Coke when they knew it was Coke than when the taste testing was anonymous, which demonstrates the power of branding to influence consumer behavior. There was also significant activation in the hippocampus and dorsolateral prefrontal cortex when subjects knew they were drinking Coke. These brain structures are known to play a role in memory and recollection, which indicates they are helping the subjects to connect their present drinking experience to previous brand associations. The study proposes that there are two separate processes contributing to consumer decision making: the ventromedial prefrontal cortex responds to sensory inputs and the hippocampus and dorsolateral prefrontal cortex recall previous associations to cultural information. According to the results of this study, the Coke brand has much more firmly established itself as a rewarding experience.",
            "score": 90.23780131340027
        },
        {
            "docid": "33639698_5",
            "document": "Zero Escape: Virtue's Last Reward . The gameplay of \"Virtue's Last Reward\" is divided into two types of sections: Novel and Escape. In Novel sections, the player advances through the storyline and converses with non-playable characters through visual novel segments. These sections require little interaction from the player other than reading the dialogue and text that appear on the screen. During Novel sections, the player may be presented with decision options that affect the course of the game. One recurring decision option is a prisoner's dilemma-type choice where the player must choose to \"ally\" or \"betray\" the characters they are pitted against, with different results depending on what choices the two parties picked.",
            "score": 77.93648266792297
        },
        {
            "docid": "6989597_15",
            "document": "Premovement neuronal activity . Approximately 65% of the neurons in the pre-motor cortex are responsible for conditional \"closed-loop\" motor tasks. In experimentation using monkeys, when they were trained to reach in different directions, depending on the specified visual cue, the approximately coordinated lateral pre-motor neurons began to fire at the appearance of that specified cue, but before the actual signal to perform the movement. As learning takes place, to associate a new visual cue with a particular movement, the approximately coordinated neurons increase their rate of fire during the time between the initial specified cue and the actual signal for the initiation of the movement. It now seems that these specific neurons do not command the initiation of the movements but the intention to perform the movements. Thus these pre-motor neurons are especially involved in the selection of movements based on external events.",
            "score": 85.47360706329346
        },
        {
            "docid": "515094_15",
            "document": "Neuroeconomics . In 2017 March, Laurence T. Hunt and Benjamin Y. Hayden argued an alternative viewpoint of the mechanistic model to explain how we evaluate options and choose the best course of action. Many accounts of reward-based choice argue for distinct component processes that are serial and functionally localized. The component processes typically include the evaluation of options, the comparison of option values in the absence of any other factors, the selection of an appropriate action plan and the monitoring of the outcome of the choice. They emphasized how several features of neuroanatomy may support the implementation of choice, including mutual inhibition in recurrent neural networks and the hierarchical organization of timescales for information processing across the cortex.",
            "score": 136.5191216468811
        },
        {
            "docid": "14511650_50",
            "document": "Impulsivity . Economic theory suggests that optimal discounting involves the exponential discounting of value over time. This model assumes that people and institutions should discount the value of rewards and punishments at a constant rate according to how delayed they are in time. While economically rational, recent evidence suggests that people and animals do not discount exponentially. Many studies suggest that humans and animals discount future values according to a hyperbolic discounting curve where the discount factor decreases with the length of the delay (for example, waiting from today to tomorrow involves more loss of value than waiting from twenty days to twenty-one days). Further evidence for non-constant delay discounting is suggested by the differential involvement of various brain regions in evaluating immediate versus delayed consequences. Specifically, the prefrontal cortex is activated when choosing between rewards at a short delay or a long delay, but regions associated with the dopamine system are additionally activated when the option of an immediate reinforcer is added. Additionally, intertemporal choices differ from economic models because they involve anticipation (which may involve a neurological \"reward\" even if the reinforcer is delayed), self-control (and the breakdown of it when faced with temptations), and representation (how the choice is framed may influence desirability of the reinforcer), none of which are accounted for by a model that assumes economic rationality.",
            "score": 99.63808858394623
        },
        {
            "docid": "40941597_6",
            "document": "Ecological rationality . To illustrate, consider the take-the-best heuristic, which can be used for finding the best options from a set of two according to some criterion. Rather than considering information about all attributes of each option, the heuristic uses only information on the most valid attribute (i.e., the attribute correlating the highest with the criterion) that discriminates between different options and chooses the option favored by this one attribute. Thus, it does not form expectations integrating all available information, as required by RCT. Nonetheless, it was found that the take-the-best heuristic can yield better choices than other models of decision-making including multiple regression that considers all available information. The success of this strategy, however, depends on specific characteristics of the choice environment: When information is scarce, validities of the attributes vary highly, and a large portion of attributes is redundant, the take-the-best heuristic is preferred.",
            "score": 98.88480925559998
        },
        {
            "docid": "515094_21",
            "document": "Neuroeconomics . Neuroeconomic research in intertemporal choice is largely aimed at understanding what mediates observed behaviors such as future discounting and impulsively choosing smaller sooner rather than larger later rewards. The process of choosing between immediate and delayed rewards seems to be mediated by an interaction between two brain areas. In choices involving both primary (fruit juice) and secondary rewards (money), the limbic system is highly active when choosing the immediate reward while the lateral prefrontal cortex was equally active when making either choice. Furthermore, the ratio of limbic to cortex activity decreased as a function of the amount of time until reward. This suggests that the limbic system, which forms part of the dopamine reward pathway, is most involved in making impulsive decisions while the cortex is responsible for the more general aspects of the intertemporal decision process.",
            "score": 118.49757993221283
        }
    ],
    "r": [
        {
            "docid": "25225295_12",
            "document": "Consumer neuroscience . Brand loyalty has been shown to be the result of changes in neural activity in the striatum, which is part of the human action reward system. In order to become brand loyal the brain must make a decision of brand A over brand B, a process which relies on the brain to make predictions based upon expected reward and then evaluate the results to learn loyalty. The brain is required to remember both positive and negative outcomes of previous brand choices in order to accurately be able to make predictions regarding the expected outcome of future brand decisions. For example, a helpful salesman or a discount in price may serve as a reward to encourage future customer loyalty. It is thought that the amygdala and striatum are the two most prominent structures for predicting the outcomes of decisions, and that the brain learns to better predict in part by establishing a larger neural network in these structures.",
            "score": 180.2811737060547
        },
        {
            "docid": "3844076_12",
            "document": "Harold Kelley . The theory is set up with a rewards and costs model similar to those used in game theory. The balance of rewards and costs between partners within a relationship as well as how well rewards and costs compare to what would be expected in another relationship predict relationship quality. Kelley used the economic terminology to defend the idea that people are maximizers of good outcomes (high rewards, low costs) in relationships just as they are with finances or other decision-making. These reward and cost outcomes are often presented in matrices closely resembling the payoff matrices used in game theory, which had also been adapted in psychological research previously but not as comprehensively utilized. In the matrix, person A\u2019s possible actions in the interaction would be listed on the horizontal, and person B\u2019s on the vertical. Each cell within the matrix then represents the reward and cost outcomes for both individuals given the particular combination of A\u2019s and B\u2019s actions. Kelley\u2019s use of the matrices provided an objective visual representation of all possible outcomes in a given interaction.",
            "score": 170.08322143554688
        },
        {
            "docid": "33246145_4",
            "document": "Neural decoding . When looking at a picture, people's brains are constantly making decisions about what object they are looking at, where they need to move their eyes next, and what they find to be the most salient aspects of the input stimulus. As these images hit the back of the retina, these stimuli are converted from varying wavelengths to a series of neural spikes called action potentials. These pattern of action potentials are different for different objects and different colors; we therefore say that the neurons are encoding objects and colors by varying their spike rates or temporal pattern. Now, if someone were to probe the brain by placing electrodes in the primary visual cortex, they may find what appears to be random electrical activity. These neurons are actually firing in response to the lower level features of visual input, possibly the edges of a picture frame. This highlights the crux of the neural decoding hypothesis: that it is possible to reconstruct a stimulus from the response of the ensemble of neurons that represent it. In other words, it is possible to look at spike train data and say that the person or animal being recorded is looking at a red ball.",
            "score": 155.7014617919922
        },
        {
            "docid": "52876404_7",
            "document": "Cortico-basal ganglia-thalamo-cortical loop . Two models have been proposed to explain how actions are selected in the basal ganglia. The actor-critic modal suggests that actions are generated and evaluated by a \"critic\" in the ventral striatum, while the actions are carried out by an \"actor\" in the dorsal striatum. Another model proposes the basal ganglia acts as a selection mechanism, where actions are generated in the cortex and are selected based on context by the basal ganglia. The CBGTC loop is also involved in reward discounting, with firing increasing with an unexpected or greater than expected reward. One review supported the idea that the cortex was involved in learning actions regardless of their outcome, while the basal ganglia was involved in selecting appropriate actions based on associative reward based trial and error learning.",
            "score": 153.2519989013672
        },
        {
            "docid": "673153_6",
            "document": "Dopaminergic pathways . The dopaminergic pathways that project from the substantia nigra pars compacta and ventral tegmental area into the striatum (i.e., the nigrostriatal and mesolimbic pathways, respectively) form one component of a sequence of pathways known as the cortico-basal ganglia-thalamo-cortical loop. This method of classification is used in the study of many psychiatric illness. The nigrostriatal component of the loop consists of the SNc, giving rise to both inhibitory and excitatory pathways that run from the striatum into the globus pallidus, before carrying on to the thalamus, or into the subthalamic nucleus before heading into the thalamus. The dopaminergic neurons in this circuit increase the magnitude of phasic firing in response to positive reward error, that is when the reward exceeds the expected reward. These neurons do not decrease phasic firing during a negative reward prediction (less reward than expected), leading to hypothesis that serotonergic, rather than dopaminergic neurons encode reward loss. Dopamine phasic activity also increases during cues that signal negative events, however dopaminergic neuron stimulation still induces place preference, indicating its main role in evaluating a positive stimulus. From these findings, two hypotheses have developed, as to the role of the basal ganglia and nigrostiatal dopamine circuits in action selection. The first model suggests a \"critic\" which encodes value, and an actor which encodes responses to stimuli based on perceived value. However, the second model proposes that the actions do not originate in the basal ganglia, and instead originate in the cortex and are selected by the basal ganglia. This model proposes that the direct pathway controls appropriate behavior and the indirect suppresses actions not suitable for the situation. This model proposes that tonic dopaminergic firing increases the activity of the direct pathway, causing a bias towards executing actions faster.",
            "score": 152.89125061035156
        },
        {
            "docid": "99026_25",
            "document": "Basal ganglia . Two models have been proposed for the basal ganglia, one being that actions are generated by a \"critic\" in the ventral striatum and estimates value, and the actions are carried out by an \"actor\" in the dorsal striatum. Another model proposes the basal ganglia acts as a selection mechanism, where actions are generated in the cortex and are selected based on context by the basal ganglia. The CBGTC loop is also involved in reward discounting, with firing increasing with an unexpected or greater than expected reward. One review supported the idea that the cortex was involved in learning actions regardless of their outcome, while the basal ganglia was involved in selecting appropriate actions based on associative reward based trial and error learning.",
            "score": 152.11280822753906
        },
        {
            "docid": "26317569_8",
            "document": "Maturity (psychological) . The pre-frontal cortex, which is responsible for higher cognitive functions such as planning, decision-making, judgment and reasoning, develops and matures most rapidly during early adolescence and into the early 20s. Accompanying the growth of the pre-frontal cortex is continued synaptic pruning (the trimming of rarely used synapses) as well as increased myelination of nerve fibers in the brain, which serves to insulate and speed up signal transmission between neurons. The incomplete development of this process contributes to the finding that adolescents use their brain less broadly than do adults when asked to inhibit a response and show less cross-talk (communication across diverse regions of the brain). The brain's \"cross-talk\" may be related to decision-making concerning risk-taking, with one study of American adolescents finding delayed reaction time and decreased spread across brain regions in a task asking them to determine whether a dangerous action is a good idea or not. Steinberg observes that there is close overlap in the activated brain regions for socioemotional and reward information, which may pose a challenge when making decisions in the most high-risk peer contexts. One study found that preference for small immediate rewards over larger long-term rewards was associated with increased activation with regions primarily responsible for socioemotional decision-making.",
            "score": 149.947265625
        },
        {
            "docid": "41578765_18",
            "document": "Paul Glimcher . Glimcher\u2019s research aims to describe the neural events that underlie behavioral decision-making using tools from neuroscience, psychology, and economics. His research merges psychological and economic models with computational neuroscience, including pioneering uses of fMRI (function magnetic resonance imaging) for behavioral science, to understand how value is encoded in the brain and how the brain uses those neural representations of value to guide decision-making; for example, how the brain carries out delay discounting or action-selection in the face of both risk and ambiguity. His laboratory in NYU\u2019s Center for Neural Science uses a wide range of methods including cohort studies in experimental economics, brain imaging, and single-neuron studies in non-human animals.",
            "score": 149.24192810058594
        },
        {
            "docid": "4562875_22",
            "document": "Motion planning . Reward-based algorithms assume that the robot in each state (position and internal state, including direction) can choose between different actions (motion). However, the result of each action is not definite. In other words, outcomes (displacement) are partly random and partly under the control of the robot. The robot gets positive reward when it reaches the target and gets negative reward if it collides with an obstacle. These algorithms try to find a path which maximizes cumulative future rewards. The Markov decision process (MDP) is a popular mathematical framework that is used in many reward-based algorithms. The advantage of MDPs over other reward-based algorithms is that they generate the optimal path. The disadvantage of MDPs is that they limit the robot to choose from a finite set of actions. Therefore, the path is not smooth (similar to grid-based approaches). Fuzzy Markov decision processes (FDMPs) are an extension of MDPs which generate smooth paths using a fuzzy inference system.",
            "score": 147.70716857910156
        },
        {
            "docid": "33827415_20",
            "document": "Unconscious cognition . Axel Cleeremans, a professor of cognitive science with the Department of Psychology of the Universit\u00e9 Libre de Bruxelles, Brussels, in his paper \"The radical plasticity thesis: how the brain learns to be conscious\", proposed the idea that conscious brain is a product of unconscious brain's attempts at predicting the consequences of its actions on the external world. The paper also states that the activity of one cerebral region and its effect on the other regions of the brain. According to \"radical plasticity\" thesis, thinking and reasoning are the products of the unconscious mind's ability to decipher and process countless possibilities and predict the consequences of taking a certain course of action. In contrast, the conscious mind is only able to process the outcomes of no more than a couple of courses of action during decision making.",
            "score": 147.47146606445312
        },
        {
            "docid": "25400_12",
            "document": "Rational choice theory . The theory applies to more general settings than those identified by costs and benefit. In general, rational decision making entails choosing among all available alternatives the alternative that the individual most prefers. The \"alternatives\" can be a set of actions (\"what to do?\") or a set of objects (\"what to choose/buy\"). In the case of actions, what the individual really cares about are the outcomes that results from each possible action. Actions, in this case, are only an instrument for obtaining a particular outcome.",
            "score": 146.97601318359375
        },
        {
            "docid": "515094_8",
            "document": "Neuroeconomics . Neuroeconomics studies the neurobiological along with the computational bases of decision-making. A framework of basic computations which may be applied to Neuroeconomics studies is proposed by A. Rangel, C. Camerer, and P. R. Montague. It divides the process of decision making into five stages implemented by a subject. First, the representation of the problem is computed. This includes analysis of internal states, external states and potential course of action. Second, values are assigned to potential actions. Third, based on the valuations, one of the actions is selected. Fourth, the subject evaluates how desirable the outcome is. Final stage, learning, includes updating all of the above processes in order to improve future decisions.",
            "score": 145.7709197998047
        },
        {
            "docid": "2029298_11",
            "document": "Benjamin Libet . Researchers also analyzed EEG recordings for each trial with respect to the timing of the action. It was noted that brain activity involved in the initiation of the action, primarily centered in the secondary motor cortex, occurred, on average, approximately five hundred milliseconds \"before\" the trial ended with the pushing of the button. That is to say, researchers recorded mounting brain activity related to the resultant action as many as three hundred milliseconds \"before\" subjects reported the first awareness of conscious will to act. In other words, apparently conscious decisions to act were \"preceded\" by an unconscious buildup of electrical activity within the brain - the change in EEG signals reflecting this buildup came to be called Bereitschaftspotential or readiness potential. As of 2008, the upcoming outcome of a decision could be found in study of the brain activity in the prefrontal and parietal cortex up to 7 seconds before the subject was aware of their decision.",
            "score": 145.70272827148438
        },
        {
            "docid": "4698768_6",
            "document": "Naturalistic decision-making . The recognition-primed decision (RPD) model is the main protocol derived from the NDM framework. RPD describes how people use their experience in the form of patterns. These patterns highlight the relevant cues, provide expected outcomes, identify plausible goals, and suggest typical types of reactions in that type of situation. When people need to make a decision, they can quickly match the situation to the patterns they have learned and experienced in the past. Doing this, people can successfully make rapid decisions. The RPD model explains how people can make good decisions without comparing options. However, there is more to the RPD model than pattern matching. How can a person evaluate an option without comparing it with others? It has been found that fireground commanders evaluate a course of action by using mental simulation to imagine how a situation would play out within the context of the current situation. If it would work, then the commanders could initiate the action. If it almost worked, they could try to adapt it or else consider other actions that were somewhat less typical, continuing until they found an option that felt comfortable. This process exemplifies Herbert Simon's (1957) notion of satisficing \u2013 looking for the first workable option rather than trying to find the best possible option. Because fires grow exponentially, the faster the commanders could react, the easier their job. Therefore, the RPD model is a blend of intuition and analysis. The pattern matching is the intuitive part, and the mental simulation is the conscious, deliberate, and analytical part. Intuitive strategy relying only on pattern matching would be too risky because sometimes the pattern matching generates flawed options. Also, a completely deliberative and analytical strategy would be too slow; the fires would be out of control by the time the commanders finished deliberating. In-depth interviews with fireground commanders who recently experienced challenging incidents show that the percentage of RPD strategies used in those situations generally ranged from 80% to 90% (Klein, 1989). Other researchers have replicated these findings (see Klein, 1998). The first moves that occurred to them were much better than would be expected by chance. These findings support the RPD hypothesis that the first option considered is usually satisfactory. These results were later replicated by Johnson and Raab (2003).",
            "score": 145.10919189453125
        },
        {
            "docid": "9496_13",
            "document": "Epiphenomenalism . The scientific data seem to support the idea that conscious experience is created by non-conscious processes in the brain (i.e., there is subliminal processing that becomes conscious experience). These results have been interpreted to suggest that people are capable of action before conscious experience of the decision to act occurs. Some argue that this supports epiphenomenalism, since it shows that the feeling of making a decision to act is actually an epiphenomenon; the action happens before the decision, so the decision did not cause the action to occur. The most powerful argument against epiphenomenalism is that it is self-contradictory: If we have knowledge about epiphenomenalism, then our brains know about the existence of the mind, but if epiphenomenalism were correct, then our brains should not have any knowledge about the mind, because the mind does not affect anything physical.",
            "score": 141.26026916503906
        },
        {
            "docid": "35597124_16",
            "document": "Bayesian inference in marketing . The three principle strengths of Bayes' theorem that have been identified by scholars are that it is prescriptive, complete and coherent. Prescriptive in that it is the theorem that is the simple prescription to the conclusions reached on the basis of evidence and reasoning for the consistent decision maker. It is complete because (for a given choice of model and prior distribution) the solution is often clear and unambiguous. It allows for the incorporation of prior information when available to increase the robustness of the solutions, as well as taking into consideration the costs and risks that are associated with choosing alternate decisions. Lastly Bayes theorem is coherent. It is considered the most appropriate way to update beliefs by welcoming the incorporation of new information, as is seen through the probability distributions (see Savage and De Finetti). This is further complemented by the fact that Bayes inference satisfies the likelihood principle, which states that models or inferences for datasets leading to the same likelihood function should generate the same statistical information. Bayes methods are more cost effective than the traditional frequentist take on marketing research and subsequent decision making. The probability can be assessed from a degree of belief before and after accounting for evidence, instead of calculating the probabilities of a certain decision by carrying out a large number of trials with each one producing an outcome from a set of possible outcomes. The planning and implementation of trials to see how a decision impacts in the \u2018field\u2019 e.g. observing consumers reaction to a relabeling of a product, is time consuming and costly, a method many firms cannot afford. In place of taking the frequentist route in aiming for a universally acceptable conclusion through iteration, it is sometimes more effective to take advantage of all the information available to the firm to work out the \u2018best\u2019 decision at the time, and then subsequently when new knowledge is obtained, revise the posterior distribution to be then used as the prior, thus the inferences continue to logically contribute to one another based on Bayes theorem.",
            "score": 138.72528076171875
        },
        {
            "docid": "2843988_23",
            "document": "Motor control . Some of the earliest and most influential work on the study of motor redundancy came from the Russian physiologist Nikolai Bernstein. Bernstein's research was primarily concerned with understanding how coordination was developed for skilled actions. He observed that the redundancy of the motor system made it possible to execute actions and movements in a multitude of different ways while achieving equivalent outcomes. This equivalency in motor action means that there is no one-to-one correspondence between the desired movements and the coordination of the motor system needed to execute those movements. Any desired movement or action does not have a particular coordination of neurons, muscles, and kinematics that make it possible. This motor equivalency problem became known as the degrees of freedom problem because it is a product of having redundant degrees of freedom available in the motor system.",
            "score": 138.28224182128906
        },
        {
            "docid": "189018_14",
            "document": "Elbow Room (book) . Some complaints about \"Elbow Room\" relate to our intuitions about free will. Some say that Dennett's theory does not satisfactorily deal with the issue of why we feel so strongly that we do have behavioral choice. One answer to this question is the result of selection on individuals to live harmoniously in society. But one doesn't have to be free to achieve that goal. Another answer is that it tells us (our brains) whether we're doing something or someone else is doing something to us (e.g. shaking arm). But, again one does not have to be free to make such a distinction. A final answer to this question is that our sensation of having behavioral choice has been carefully selected by evolution. The well-developed human sensation of having free will and being able to select among possible behaviors has strong survival value. People who lose the feeling that they can plan alternative behaviors and execute their choice of possible behaviors tend to become fatalistic and stop struggling for survival. According to Dennett, belief in free will is a necessary condition for having free will. When we are planning for the future and thinking about possible actions to take in the future, we are utilizing considerable amounts of biologically expensive resources (brain power). Evolution has designed us to feel strongly that all of our effort of planning pays off, that we control what we do. If this connection between our brains' efforts to model reality and predict the future and so make possible good outcomes is disconnected from our sense of self and our will, then fatalism and self-destructive behaviors are close at hand. However, the same effect is attainted if, despite not believing in the control free will gives, we believe that does not prevent us to live as fully as our bodies allow us to and to try harder to achieve things if we think we have agency.",
            "score": 138.08554077148438
        },
        {
            "docid": "26565579_51",
            "document": "Neuroscience of free will . Contemporary voluntary decision prediction tasks have been criticised based on the possibility the neuronal signatures for pre-conscious decisions could actually correspond to lower conscious processing rather than unconscious processing. People may be aware of their decisions before making their report yet need to wait several seconds to be certain. Such a model does not however explain what is left unconscious if everything can be conscious at some level (and the purpose of defining separate systems). Yet limitations remain in free will prediction research to date. In particular, the prediction of considered judgements from brain activity involving thought processes beginning minutes rather than seconds before a conscious will to act, including the rejection of a conflicting desire. Such are generally seen to be the product of sequences of evidence accumulating judgements.",
            "score": 137.7972869873047
        },
        {
            "docid": "515094_15",
            "document": "Neuroeconomics . In 2017 March, Laurence T. Hunt and Benjamin Y. Hayden argued an alternative viewpoint of the mechanistic model to explain how we evaluate options and choose the best course of action. Many accounts of reward-based choice argue for distinct component processes that are serial and functionally localized. The component processes typically include the evaluation of options, the comparison of option values in the absence of any other factors, the selection of an appropriate action plan and the monitoring of the outcome of the choice. They emphasized how several features of neuroanatomy may support the implementation of choice, including mutual inhibition in recurrent neural networks and the hierarchical organization of timescales for information processing across the cortex.",
            "score": 136.5191192626953
        },
        {
            "docid": "55377516_30",
            "document": "Dual systems model . Reward decision-making tasks involve participants being asked to choose among different options of reward. Sometimes the rewards differ on probability, magnitude, or type of reward (e.g., social versus monetary). These tasks are typically conceived to not have a correct or incorrect response, but rather to have decision-making based on the participants' preference. Examples of decision making tasks include delay discounting tasks and the Driving Game. During feedback on decision-making tasks, greater striatal activation to rewarding outcomes has been observed in adolescents compared to adults.",
            "score": 135.8648223876953
        },
        {
            "docid": "47921_92",
            "document": "Free will . These studies of the timing between actions and the conscious decision bear upon the role of the brain in understanding free will. A subject's declaration of intention to move a finger appears \"after\" the brain has begun to implement the action, suggesting to some that unconsciously the brain has made the decision \"before\" the conscious mental act to do so. Some believe the implication is that free will was not involved in the decision and is an illusion. The first of these experiments reported the brain registered activity related to the move about 0.2 s before movement onset. However, these authors also found that awareness of action was \"anticipatory\" to activity in the muscle underlying the movement; the entire process resulting in action involves more steps than just the \"onset\" of brain activity. The bearing of these results upon notions of free will appears complex.",
            "score": 135.45626831054688
        },
        {
            "docid": "4136417_10",
            "document": "Supplementary eye field . In other words, the SEF does not immediately or directly contribute to saccade initiation. But, the SEF is thought to improve saccade production by using prior knowledge of anticipated task requirements to influence saccadic eye movements. It does so by balancing gaze holding and gaze shifting actions, yielding a modest improvement in performance in stop signal tasks by delaying saccade initiation when necessary. It can be thought that the FEF does the driving part of saccade initiation, while the SEF acts as a backseat passenger, advising the driver as to what to do based on past insights. The SEF has recently been found to encode reward prediction error, suggesting that the SEF may actively evaluate decisions based on a value system on an occulomotor basis, independent of other brain regions.",
            "score": 135.30612182617188
        },
        {
            "docid": "8582684_19",
            "document": "Reward system . Rewarding stimuli can drive learning in both the form of classical conditioning (Pavlovian conditioning) and operant conditioning (instrumental conditioning). In classical conditioning, a reward can act as an unconditioned stimulus that, when associated with the conditioned stimulus, causes the conditioned stimulus to elicit both musculoskeletal (in the form of simple approach and avoidance behaviors) and vegetative responses. In operant conditioning, a reward may act as a reinforcing stimulus in that it increases or supports actions that lead to itself. Learned behaviors may or may not be sensitive to the value of the outcomes they lead to; behaviors that are sensitive to the contingency of an outcome on the performance of an action as well as the outcome value are goal-directed, while elicited actions that are insensitive to contingency or value are called habits. This distinction is thought to reflected two forms of learning, model free and model based. Model free learning involves the simple caching and updating of values. In contrast, model based learning involves the storage and construction of an internal model of events that allows inference and flexible prediction. Although pavlovian conditioning is generally assumed to be model free, the incentive salience assigned to a conditioned stimulus is flexible with regard to changes in internal motivational states.",
            "score": 134.75193786621094
        },
        {
            "docid": "18345642_14",
            "document": "Behavioral addiction . One of the most important discoveries of addictions has been the drug based reinforcement and, even more important, reward based learning processes. Several structures of the brain are important in the conditioning process of behavioral addiction; these subcortical structures form the brain regions known as the reward system. One of the major areas of study is the amygdala, a brain structure which involves emotional significance and associated learning. Research shows that dopaminergic projections from the ventral tegmental area facilitate a motivational or learned association to a specific behavior.  Dopamine neurons take a role in the learning and sustaining of many acquired behaviors. Research specific to Parkinson\u2019s disease has led to identifying the intracellular signaling pathways that underlie the immediate actions of dopamine. The most common mechanism of dopamine is to create addictive properties along with certain behaviors. There are three stages to the dopamine reward system: bursts of dopamine, triggering of behavior, and further impact to the behavior. Once electronically signaled, possibly through the behavior, dopamine neurons let out a \u2018burst-fire\u2019 of elements to stimulate areas along fast transmitting pathways. The behavior response then perpetuates the striated neurons to further send stimuli. The fast firing of dopamine neurons can be monitored over time by evaluating the amount of extracellular concentrations of dopamine through micro dialysis and brain imaging. This monitoring can lead to a model in which one can see the multiplicity of triggering over a period of time. Once the behavior is triggered, it is hard to work away from the dopamine reward system.",
            "score": 134.50062561035156
        },
        {
            "docid": "3197853_56",
            "document": "Dialog manager . Instead of letting a human expert write a complex set of decision rules, it is more common to use reinforcement learning. The dialog is represented as a Markov Decision Process (MDP) - a process where, in each state, the DM has to select an action, based on the state and the possible rewards from each action. In this setting, the dialog author should only define the reward function, for example: in tutorial dialogs, the reward is the increase in the student grade; in information seeking dialogs, the reward is positive if the human receives the information, but there is also a negative reward for each dialog step.",
            "score": 134.34051513671875
        },
        {
            "docid": "690278_2",
            "document": "Choice . Choice involves decision making. It can include judging the merits of multiple options and selecting one or more of them. One can make a choice between imagined options (\"What would I do if...?\") or between real options followed by the corresponding action. For example, a traveller might choose a route for a journey based on the preference of arriving at a given destination as soon as possible. The preferred (and therefore chosen) route can then follow from information such as the length of each of the possible routes, traffic conditions, etc. The arrival at a choice can include more complex motivators such as cognition, instinct, and feeling.",
            "score": 133.50137329101562
        },
        {
            "docid": "26565579_50",
            "document": "Neuroscience of free will . Multivariate pattern analysis using EEG has suggested that an evidence based perceptual decision model may be applicable to free will decisions. It was found that decisions could be predicted by neural activity immediately after stimulus perception. Furthermore, when the participant was unable to determine the nature of the stimulus the recent decision history predicted the neural activity (decision). The starting point of evidence accumulation was in effect shifted towards a previous choice (suggesting a priming bias). Another study has found that subliminally priming a participant for a particular decision outcome (showing a cue for 13ms) could be used to influence free decision outcomes. Likewise, it has been found that decision history alone can be used to predict future decisions. The prediction capacities of the Soon et al. (2008) experiment were successfully replicated using a linear SVM model based on participant decision history alone (without any brain activity data). Despite this, a recent study has sought to confirm the applicability of a perceptual decision model to free will decisions. When shown a masked and therefore invisible stimulus, participants were asked to either guess between a category or make a free decision for a particular category. Multivariate pattern analysis using fMRI could be trained on \"free decision\" data to successfully predict \"guess decisions\", and trained on \"guess data\" in order to predict \"free decisions\" (in the precuneus and cuneus region).",
            "score": 133.3958740234375
        },
        {
            "docid": "1613899_8",
            "document": "Herbert Blumer . According to Blumer's theory, interaction between individuals is based on autonomous action, which in turn is based on the subjective meaning actors attribute to social objects and/or symbols. Thus individual actors regulate their behavior based on the meaning they attribute to objects and symbols in their relevant situation. Blumer theorized that assigning objects meaning is an ongoing, two-fold process. First, is the identification of the objects that have situational meaning. Second, is the process of internal communication to decide which meaningful object to respond to. Acknowledging that others are equally autonomous, individuals use their subjectively derived interpretations of others (as social objects) to predict the outcome of certain behaviors, and use such predictive insight to make decisions about their own behavior in the hopes of reaching their goal. Thus, when there is consensus among individual actors about the meaning of the objects that make up their situation, social coordination ensues. Social structures are determined as much by the action of individual actors as they determine the action of those individuals. Based on this, Blumer believed that society exists only as a set of potentials, or ideas that people could possibly use in the future.",
            "score": 133.28001403808594
        },
        {
            "docid": "446216_8",
            "document": "Decision theory . The area of choice under uncertainty represents the heart of decision theory. Known from the 17th century (Blaise Pascal invoked it in his famous wager, which is contained in his \"Pens\u00e9es\", published in 1670), the idea of expected value is that, when faced with a number of actions, each of which could give rise to more than one possible outcome with different probabilities, the rational procedure is to identify all possible outcomes, determine their values (positive or negative) and the probabilities that will result from each course of action, and multiply the two to give an \"expected value\", or the average expectation for an outcome; the action to be chosen should be the one that gives rise to the highest total expected value. In 1738, Daniel Bernoulli published an influential paper entitled \"Exposition of a New Theory on the Measurement of Risk\", in which he uses the St. Petersburg paradox to show that expected value theory must be normatively wrong. He gives an example in which a Dutch merchant is trying to decide whether to insure a cargo being sent from Amsterdam to St Petersburg in winter. In his solution, he defines a utility function and computes expected utility rather than expected financial value (see for a review).",
            "score": 133.09841918945312
        },
        {
            "docid": "2893529_5",
            "document": "Everything Bad Is Good for You . He argues that the appeal of video games is not through their (possibly violent or sexual) content, but rather through the fact that the \"structure\" of the video games uniquely invites exploration and stimulates the reward centers of the brain. In pointing out arguments for the support of video games, Johnson sheds light on how kids can be more involved in games than in class, but this involvement can teach them that which could be taught in class. To substantiate this argument, he discusses how games and other virtual worlds have immediate rewards, whereas in reality, rewards can take a while to obtain. Johnson states \u201cif you create a system where rewards are both clearly defined and achieved by exploring an environment, you\u2019ll find human brains drawn to those systems, even if they\u2019re made up of virtual characters and simulated sidewalks. It\u2019s not the subject matter of these games that attracts\u2026it\u2019s the reward system\u201d. Finally, he argues for the support of video games because they also require one to make decisions, whereas books and other forms of art may conjure up imagination and emotions but don\u2019t require decision-making.",
            "score": 132.94017028808594
        },
        {
            "docid": "38442646_13",
            "document": "Gain-field encoding . This multiplicative property is an effect of recurrent neural circuitry. A target neuron that takes only two types of direct input can only combine them additively. However mathematical models show that when also receiving recursive input from neighboring neurons, the resulting transformation to the target neurons firing rate is multiplicative. In this model, neurons with overlapping receptive fields excite each other, multiplying the strength. Likewise, neurons with non-overlapping receptive fields are inhibitory. The result is a response curve that is a scaled representation of the simple additive model. Observation of human developmental patterns also lend evidence toward this theory of gain-field encoding and gain modulation. Since arm movements are based on both intrinsic and extrinsic models, in order to build these connections one has to learn by self-generating movements and watching. By moving the arms to different parts of space and following with the eyes, the neurons form connections based on mechanical body movements as well as their positioning in an external space. Ideally this is done from every possible gaze angle and position available. This provides your brain with the proper translations by aligning the retinal (extrinsic) and body-centered (intrinsic) representations of space. It is not surprising that before babies develop motor control of their limbs, they tend to flail and watch their own limbs move.",
            "score": 132.9010772705078
        }
    ]
}