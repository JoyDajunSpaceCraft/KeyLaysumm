{
    "q": [
        {
            "docid": "32168948_6",
            "document": "Sepp Hochreiter . Neural networks are different types of simplified mathematical models of biological neural networks like those in human brains.  In feedforward neural networks (NNs) the information moves forward in only one direction,  from the input layer that receives information from the environment,  through the hidden layers to the output layer that supplies the information to the environment. Unlike NNs, recurrent neural networks (RNNs)  can use their internal memory to process arbitrary sequences of inputs.  If data mining is based on neural networks, overfitting reduces the network's capability to correctly process future data. To avoid overfitting, Sepp Hochreiter developed algorithms for finding low complexity neural networks like \"Flat Minimum Search\" (FMS), which searches for a \"flat\" minimum \u2014 a large connected region in the parameter space where the network function is constant. Thus, the network parameters can be given with low precision which means a low complex network that avoids overfitting. Low complexity neural networks are well suited for deep learning because they control the complexity in each network layer and, therefore, learn hierarchical representations of the input. Sepp Hochreiter's group introduced \"exponential linear units\" (ELUs) which speed up learning in deep neural networks and lead to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs), and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to ReLUs, due to negative values which push mean unit activations closer to zero. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect.",
            "score": 166.60222327709198
        },
        {
            "docid": "941909_26",
            "document": "Receptive field . The term receptive field is also used in the context of artificial neural networks, most often in relation to convolutional neural networks (CNNs). When used in this sense, the term adopts a meaning reminiscent of receptive fields in actual biological nervous systems. CNNs have a distinct architecture, designed to mimic the way in which real animal brains are understood to function; instead of having every neuron in each layer connect to all neurons in the next layer (Multilayer perceptron), the neurons are arranged in a 3-dimensional structure in such a way as to take into account the spatial relationships between different neurons with respect to the original data. Since CNNs are used primarily in the field of computer vision, the data that the neurons represent is typically an image; each input neuron represents one pixel from the original image. The first layer of neurons is composed of all the input neurons; neurons in the next layer will receive connections from some of the input neurons (pixels), but not all, as would be the case in a MLP and in other traditional neural networks. Hence, instead of having each neuron receive connections from all neurons in the previous layer, CNNs use a receptive field-like layout in which each neuron receives connections only from a subset of neurons in the previous (lower) layer. The receptive field of a neuron in one of the lower layers encompasses only a small area of the image, while the receptive field of a neuron in subsequent (higher) layers involves a combination of receptive fields from several (but not all) neurons in the layer before (i. e. a neuron in a higher layer \"looks\" at a larger portion of the image than does a neuron in a lower layer). In this way, each successive layer is capable of learning increasingly abstract features of the original image. The use of receptive fields in this fashion is thought to give CNNs an advantage in recognizing visual patterns when compared to other types of neural networks.",
            "score": 192.1504727602005
        },
        {
            "docid": "38870173_8",
            "document": "Feature learning . Neural networks are a family of learning algorithms that use a \"network\" consisting of multiple layers of inter-connected nodes. It is inspired by the animal nervous system, where the nodes are viewed as neurons and edges are viewed as synapses. Each edge has an associated weight, and the network defines computational rules for passing input data from the network's input layer to the output layer. A network function associated with a neural network characterizes the relationship between input and output layers, which is parameterized by the weights. With appropriately defined network functions, various learning tasks can be performed by minimizing a cost function over the network function (weights).",
            "score": 142.64844393730164
        },
        {
            "docid": "31217535_44",
            "document": "Memory . One question that is crucial in cognitive neuroscience is how information and mental experiences are coded and represented in the brain. Scientists have gained much knowledge about the neuronal codes from the studies of plasticity, but most of such research has been focused on simple learning in simple neuronal circuits; it is considerably less clear about the neuronal changes involved in more complex examples of memory, particularly declarative memory that requires the storage of facts and events (Byrne 2007). Convergence-divergence zones might be the neural networks where memories are stored and retrieved. Considering that there are several kinds of memory, depending on types of represented knowledge, underlying mechanisms, processes functions and modes of acquisition, it is likely that different brain areas support different memory systems and that they are in mutual relationships in neuronal networks: \"components of memory representation are distributed widely across different parts of the brain as mediated by multiple neocortical circuits\".",
            "score": 172.8629513978958
        },
        {
            "docid": "40158142_9",
            "document": "Nonlinear system identification . Artificial neural networks try loosely to imitate the network of neurons in the brain where computation takes place through a large number of simple processing elements. A typical neural network consists of a number of simple processing units interconnected to form a complex network. Layers of such units are arranged so that data is entered at the input layer and passes through either one or several intermediate layers before reaching the output layer. In supervised learning the network is trained by operating on the difference between the actual output and the desired output of the network, the prediction error, to change the connection strengths between the nodes. By iterating the weights are modified until the output error reaches an acceptable level. This process is called machine learning because the network adjusts the weights so that the output pattern is reproduced. Neural networks have been extensively studied and there are many excellent textbooks devoted to this topic in general, and more focussed textbooks which emphasise control and systems applications. There are two main problem types that can be studied using neural networks: static problems, and dynamic problems. Static problems include pattern recognition, classification, and approximation. Dynamic problems involve lagged variables and are more appropriate for system identification and related applications. Depending on the architecture of the network the training problem can be either nonlinear-in-the-parameters which involves optimisation or linear-in-the-parameters which can be solved using classical approaches. The training algorithms can be categorised into supervised, unsupervised, or reinforcement learning. Neural networks have excellent approximation properties but these are usually based on standard function approximation results using for example the Weierstrass Theorem that applies equally well to polynomials, rational functions, and other well-known models.  Neural networks have been applied extensively to system identification problems which involve nonlinear and dynamic relationships. However, classical neural networks are purely gross static approximating machines. There is no dynamics within the network. Hence when fitting dynamic models all the dynamics arise by allocating lagged inputs and outputs to the input layer of the network. The training procedure then produces the best static approximation that relates the lagged variables assigned to the input nodes to the output. There are more complex network architectures, including recurrent networks, that produce dynamics by introducing increasing orders of lagged variables to the input nodes. But in these cases it is very easy to over specify the lags and this can lead to over fitting and poor generalisation properties.  Neural networks have several advantages; they are conceptually simple, easy to train and to use, have excellent approximation properties, the concept of local and parallel processing is important and this provides integrity and fault tolerant behaviour. The biggest criticism of the classical neural network models is that the models produced are completely opaque and usually cannot be written down or analysed. It is therefore very difficult to know what is causing what, to analyse the model, or to compute dynamic characteristics from the model. Some of these points will not be relevant to all applications but they are for dynamic modelling.",
            "score": 149.8148021697998
        },
        {
            "docid": "32472154_70",
            "document": "Deep learning . Deep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, \"...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature.\"",
            "score": 201.61330604553223
        },
        {
            "docid": "1164_53",
            "document": "Artificial intelligence . Neural networks, or neural nets, were inspired by the architecture of neurons in the human brain. A simple \"neuron\" \"N\" accepts input from multiple other neurons, each of which, when activated (or \"fired\"), cast a weighted \"vote\" for or against whether neuron \"N\" should itself activate. Learning requires an algorithm to adjust these weights based on the training data; one simple algorithm (dubbed \"fire together, wire together\") is to increase the weight between two connected neurons when the activation of one triggers the successful activation of another. The net forms \"concepts\" that are distributed among a subnetwork of shared neurons that tend to fire together; a concept meaning \"leg\" might be coupled with a subnetwork meaning \"foot\" that includes the sound for \"foot\". Neurons have a continuous spectrum of activation; in addition, neurons can process inputs in a nonlinear way rather than weighing straightforward votes. Modern neural nets can learn both continuous functions and, surprisingly, digital logical operations. Neural networks' early successes included predicting the stock market and (in 1995) a mostly self-driving car. In the 2010s, advances in neural networks using deep learning thrust AI into widespread public consciousness and contributed to an enormous upshift in corporate AI spending; for example, AI-related M&A in 2017 was over 25 times as large as in 2015.",
            "score": 220.68296658992767
        },
        {
            "docid": "55867424_2",
            "document": "Residual neural network . A residual neural network is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex. Residual neural networks do this by utilizing \"skip connections\" or \"short-cuts\" to jump over some layers. In its limit as \"ResNets\" it will only skip over a single layer. With an additional weight matrix to learn the skip weights it is referred to as \"HighwayNets\". With several parallel skips it is referred to as \"DenseNets\". In comparison, a non-residual neural network is described as a \"plain network\" in the context of residual neural networks. The brain has structures similar to residual nets, as layer VI neurons gets input from layer I, skipping over all intermediary layers. In the figure this compares to signals from the (3) Apical dendrite skipping over layers while the (2) Basal dendrite collecting signals from the previous and/or same layer. Similar structures exists for other layers. How many layers in the cerebral cortex compare to layers in an artificial neural network is not clear, neither if every area in cerebral cortex exhibits the same structure, but over large areas they look quite similar.",
            "score": 147.07914173603058
        },
        {
            "docid": "27075922_9",
            "document": "Natural computing . An artificial neural network is a network of artificial neurons.  An artificial neuron \"A\" is equipped with a function formula_1, receives \"n\" real-valued inputs formula_2 with respective weights formula_3, and it outputs formula_4. Some neurons are selected to be the output neurons, and the network function is the vectorial function that associates to the \"n\" input values, the outputs of the \"m\" selected output neurons. Note that different choices of weights produce different network functions for the same inputs. Back-propagation is a supervised learning method by which the weights of the connections in the network are repeatedly adjusted so as to minimize the difference between the vector of actual outputs and that of desired outputs. Learning algorithms based on backwards propagation of errors can be used to find optimal weights for given topology of the network and input-output pairs.",
            "score": 171.9115639925003
        },
        {
            "docid": "30138821_4",
            "document": "Quantum cognition . The brain is definitely a macroscopic physical system operating on the scales (of time, space, temperature) which differ crucially from the corresponding quantum scales. (The macroscopic quantum physical phenomena such as e.g. the Bose-Einstein condensate are also characterized by the special conditions which are definitely not fulfilled in the brain.) In particular, the brain is simply too hot to be able perform the real quantum information processing, i.e., to use the quantum carriers of information such as photons, ions, electrons. As is commonly accepted in brain science, the basic unit of information processing is a neuron. It is clear that a neuron cannot be in the superposition of two states: firing and non-firing. Hence, it cannot produce superposition playing the basic role in the quantum information processing. Superpositions of mental states are created by complex networks of neurons (and these are classical neural networks). Quantum cognition community states that the activity of such neural networks can produce effects which are formally described as interference (of probabilities) and entanglement. In principle, the community does not try to create the concrete models of quantum (-like) representation of information in the brain.",
            "score": 137.4711229801178
        },
        {
            "docid": "33818014_7",
            "document": "Nervous system network models . The basic structural unit of the neural network is connectivity of one neuron to another via an active junction, called synapse. Neurons of widely divergent characteristics are connected to each other via synapses, whose characteristics are also of diverse chemical and electrical properties. In presenting a comprehensive view of all possible modeling of the brain and neural network, an approach is to organize the material based on the characteristics of the networks and the goals that need to be accomplished. The latter could be either for understanding the brain and the nervous system better or to apply the knowledge gained from the total or partial nervous system to real world applications such as artificial intelligence, Neuroethics or improvements in medical science for society.",
            "score": 147.67017817497253
        },
        {
            "docid": "233488_23",
            "document": "Machine learning . An artificial neural network (ANN) learning algorithm, usually called \"neural network\" (NN), is a learning algorithm that is vaguely inspired by biological neural networks. Computations are structured in terms of an interconnected group of artificial neurons, processing information using a connectionist approach to computation. Modern neural networks are non-linear statistical data modeling tools. They are usually used to model complex relationships between inputs and outputs, to find patterns in data, or to capture the statistical structure in an unknown joint probability distribution between observed variables.",
            "score": 176.2709310054779
        },
        {
            "docid": "21523_4",
            "document": "Artificial neural network . In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called 'edges'. Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times.",
            "score": 172.459002494812
        },
        {
            "docid": "12142270_4",
            "document": "GENESIS (software) . Neural networks like the ones simulated with GENESIS software can quickly become highly complex and difficult to understand. \"Just a few interconnected neurons (a microcircuit) can perform sophisticated tasks such as mediate reflexes, process sensory information, generate locomotion and mediate learning and memory. Even more complex networks, macrocircuits, consist of multiple embedded microcircuits. Macrocircuits mediate higher brain functions such as object recognition and cognition\". GENESIS endeavors to simulate neural systems as they are found in nature. Often, \"a neuron can receive contacts from up to 10,000 presynaptic neurons, and, in turn, any one neuron can contact up to 10,000 postsynaptic neurons. The combinatorial possibility could give rise to enormously complex neuronal circuits or network topologies, which might be very difficult to understand\".",
            "score": 186.6209362745285
        },
        {
            "docid": "8402086_16",
            "document": "Computational neurogenetic modeling . Artificial Neural Networks designed to simulate of the human brain require an ability to learn a variety of tasks that is not required by those designed to accomplish a specific task. Supervised learning is a mechanism by which an artificial neural network can learn by receiving a number of inputs with a correct output already known. An example of an artificial neural network that uses supervised learning is a multilayer perceptron (MLP). In unsupervised learning, an artificial neural network is trained using only inputs. Unsupervised learning is the learning mechanism by which a type of artificial neural network known as a self-organizing map (SOM) learns. Some types of artificial neural network, such as evolving connectionist systems, can learn in both a supervised and unsupervised manner.",
            "score": 190.55700135231018
        },
        {
            "docid": "1164_60",
            "document": "Artificial intelligence . According to one overview, the expression \"Deep Learning\" was introduced to the Machine Learning community by Rina Dechter in 1986 and gained traction after Igor Aizenberg and colleagues introduced it to Artificial Neural Networks in 2000. The first functional Deep Learning networks were published by Alexey Grigorevich Ivakhnenko and V. G. Lapa in 1965. These networks are trained one layer at a time. Ivakhnenko's 1971 paper describes the learning of a deep feedforward multilayer perceptron with eight layers, already much deeper than many later networks. In 2006, a publication by Geoffrey Hinton and Ruslan Salakhutdinov introduced another way of pre-training many-layered feedforward neural networks (FNNs) one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then using supervised backpropagation for fine-tuning. Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships. Over the last few years, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.",
            "score": 194.02856302261353
        },
        {
            "docid": "33244792_14",
            "document": "Non-spiking neuron . Very little is known about the application of these networks to memory and learning. There are indications that spiking and nonspiking networks both play a vital role in memory and learning. Research has been conducted with the use of learning algorithms, microelectrode arrays, and hybrots. By studying how neurons transfer information, it becomes more possible to enhance those model neural networks and better define what clear information streams could be presented. Perhaps, by conjoining this study with the many neurotrophic factors present, neural networks could be manipulated for optimal routing, and consequently optimal learning.",
            "score": 160.8658504486084
        },
        {
            "docid": "8402086_7",
            "document": "Computational neurogenetic modeling . An artificial neural network generally refers to any computational model that mimics the central nervous system, with capabilities such as learning and pattern recognition. With regards to computational neurogenetic modeling, however, it is often used to refer to those specifically designed for biological accuracy rather than computational efficiency. Individual neurons are the basic unit of an artificial neural network, with each neuron acting as a node. Each node receives weighted signals from other nodes that are either excitatory or inhibitory. To determine the output, a transfer function (or activation function) evaluates the sum of the weighted signals and, in some artificial neural networks, their input rate. Signal weights are strengthened (long-term potentiation) or weakened (long-term depression) depending on how synchronous the presynaptic and postsynaptic activation rates are (Hebbian theory).",
            "score": 170.92326426506042
        },
        {
            "docid": "8402086_18",
            "document": "Computational neurogenetic modeling . Because the amount of data on the interplay of genes and neurons and their effects is not enough to construct a rigorous model,  evolutionary computation is used to optimize artificial neural networks and gene regulatory networks, a common technique being the genetic algorithm. A genetic algorithm is a process that can be used to refine models by mimicking the process of natural selection observed in biological ecosystems. The primary advantages are that, due to not requiring derivative information, it can be applied to black box problems and multimodal optimization. The typical process for using genetic algorithms to refine a gene  regulatory network is: first, create a population; next, to create offspring via a crossover operation and  evaluate their fitness; then, on a group chosen for high fitness, simulate mutation via a mutation operator;  finally, taking the now mutated group, repeat this process until a desired level of fitness is demonstrated. Methods by which artificial neural networks may alter their structure without simulated mutation and fitness selection have been developed. A dynamically evolving neural network is one approach, as the creation of new connections and new neurons can  be modeled as the system adapts to new data. This enables the network to evolve in modeling accuracy without simulated natural selection. One method by which dynamically evolving networks may be optimized, called evolving layer neuron aggregation, combines neurons with sufficiently similar input weights into one neuron. This can take place during the training of the network, referred to as online aggregation, or between periods of training, referred to as offline aggregation. Experiments have suggested that offline aggregation is more efficient.",
            "score": 173.20256757736206
        },
        {
            "docid": "54186633_3",
            "document": "Aika (software) . The Aika algorithm is based on various ideas and approaches from the field of AI such as artificial neural networks, frequent pattern mining and logic based expert systems. It can be applied to a broad spectrum of text analysis tasks and combines these concepts in a single algorithm.  Aika is based on non-monotonic logic, meaning that it first draws tentative conclusions only. In other words, Aika is able to generate multiple mutually exclusive interpretations of a word, phrase, or sentence, and select the most likely interpretation. It does so by propagating activations through a neural network. These activations can be seen as a kind of text annotation since they refer to a specific text segment and a given interpretation.  Aika consists of two layers. The neural layer, containing all the neurons and continuously weighted synapses and underneath that the discrete logic layer, containing a boolean representation of all the neurons. The logic layer uses a frequent pattern lattice to efficiently store the individual logic nodes.",
            "score": 107.71699690818787
        },
        {
            "docid": "21523_30",
            "document": "Artificial neural network . An \"artificial neural network\" is a network of simple elements called \"artificial neurons\", which receive input, change their internal state (\"activation\") according to that input, and produce output depending on the input and activation. The \"network\" forms by connecting the output of certain neurons to the input of other neurons forming a directed, weighted graph. The weights as well as the functions that compute the activation can be modified by a process called \"learning\" which is governed by a \"learning rule\".",
            "score": 178.38934087753296
        },
        {
            "docid": "39182554_16",
            "document": "Catastrophic interference . Kortge (1990) proposed a learning rule for training neural networks, called the 'novelty rule', to help alleviate catastrophic interference. As its name suggests, this rule helps the neural network to learn only the components of a new input that differ from an old input. Consequently, the novelty rule changes only the weights that were not previously dedicated to storing information, thereby reducing the overlap in representations at the hidden units. Thus, even when inputs are somewhat similar to another, dissimilar representations can be made at the hidden layer. In order to apply the novelty rule, during learning the input pattern is replaced by a novelty vector that represents the components that differ. The novelty vector for the first layer (input units to hidden units) is determined by taking the target pattern away from the current output of the network (the delta rule). For the second layer (hidden units to output units) the novelty vector is simply the activation of the hidden units that resulted from using the novelty vector as an input through the first layer. Weight changes in the network are computed by using a modified delta rule with the novelty vector replacing the activation value (sum of the inputs):",
            "score": 114.69233655929565
        },
        {
            "docid": "40409788_11",
            "document": "Convolutional neural network . Although fully connected feedforward neural networks can be used to learn features as well as classify data, it is not practical to apply this architecture to images. A very high number of neurons would be necessary, even in a shallow (opposite of deep) architecture, due to the very large input sizes associated with images, where each pixel is a relevant variable. For instance, a fully connected layer for a (small) image of size 100 x 100 has 10000 weights for \"each\" neuron in the second layer. The convolution operation brings a solution to this problem as it reduces the number of free parameters, allowing the network to be deeper with fewer parameters. For instance, regardless of image size, tiling regions of size 5 x 5, each with the same shared weights, requires only 25 learnable parameters. In this way, it resolves the vanishing or exploding gradients problem in training traditional multi-layer neural networks with many layers by using backpropagation.",
            "score": 154.85060107707977
        },
        {
            "docid": "8278198_4",
            "document": "Random neural network . RNNs are also related to artificial neural networks, which (like the random neural network) have gradient-based learning algorithms. The learning algorithm for an n-node random neural network that includes feedback loops (it is also a recurrent neural network) is of computational complexity O(n^3) (the number of computations is proportional to the cube of n, the number of neurons). The random neural network can also be used with other learning algorithms such as reinforcement learning. The RNN has been shown to be a universal approximator for bounded and continuous functions.",
            "score": 167.2563933134079
        },
        {
            "docid": "33818014_21",
            "document": "Nervous system network models . As mentioned in Section 2.4, development of artificial neural network (ANN), or neural network as it is now called, started as simulation of biological neuron network and ended up using artificial neurons. Major development work has gone into industrial applications with learning process. Complex problems were addressed by simplifying the assumptions. Algorithms were developed to achieve a neurological related performance, such as learning from experience. Since the background and overview have been covered in the other internal references, the discussion here is limited to the types of models. The models are at the system or network level.",
            "score": 181.40142059326172
        },
        {
            "docid": "43502368_6",
            "document": "Vanishing gradient problem . Similar ideas have been used in feed-forward neural network for unsupervised pre-training to structure a neural network, making it first learn generally useful feature detectors. Then the network is trained further by supervised back-propagation to classify labeled data. The deep belief network model by Hinton et al. (2006) involves learning the distribution of a high level representation using successive layers of binary or real-valued latent variables. It uses a restricted Boltzmann machine to model each new layer of higher level features. Each new layer guarantees an increase on the lower-bound of the log likelihood of the data, thus improving the model, if trained properly. Once sufficiently many layers have been learned the deep architecture may be used as a generative model by reproducing the data when sampling down the model (an \"ancestral pass\") from the top level feature activations. Hinton reports that his models are effective feature extractors over high-dimensional, structured data. This work plays a key role in reintroducing the interests in deep neural network research and consequently leads to the developments of Deep learning, although deep belief network is no longer the main deep learning technique.",
            "score": 168.08612728118896
        },
        {
            "docid": "1729542_23",
            "document": "Neural network . The utility of artificial neural network models lies in the fact that they can be used to infer a function from observations and also to use it. Unsupervised neural networks can also be used to learn representations of the input that capture the salient characteristics of the input distribution, e.g., see the Boltzmann machine (1983), and more recently, deep learning algorithms, which can implicitly learn the distribution function of the observed data. Learning in neural networks is particularly useful in applications where the complexity of the data or task makes the design of such functions by hand impractical.",
            "score": 146.3141347169876
        },
        {
            "docid": "39120_26",
            "document": "Nvidia . Nvidia GPUs are used in deep learning, artificial intelligence, and accelerated analytics. The company developed GPU-based deep learning in order to use artificial intelligence to approach problems like cancer detection, weather prediction, and self-driving vehicles. They are included in all Tesla vehicles. The purpose is to help networks learn to \u201cthink\u201d. According to \"TechRepublic\", Nvidia GPUs \"work well for deep learning tasks because they are designed for parallel computing and do well to handle the vector and matrix operations that are prevalent in deep learning\". These GPUs are used by researchers, laboratories, tech companies and enterprise companies. In 2009, Nvidia was involved in what was called the \"big bang\" of deep learning, \"as deep-learning neural networks were combined with Nvidia graphics processing units (GPUs)\". That year, the Google Brain used Nvidia GPUs to create Deep Neural Networks capable of machine learning, where Andrew Ng determined that GPUs could increase the speed of deep-learning systems by about 100 times.",
            "score": 224.60311019420624
        },
        {
            "docid": "3717_69",
            "document": "Brain . Theorists have worked to understand these response patterns by constructing mathematical models of neurons and neural networks, which can be simulated using computers. Some useful models are abstract, focusing on the conceptual structure of neural algorithms rather than the details of how they are implemented in the brain; other models attempt to incorporate data about the biophysical properties of real neurons. No model on any level is yet considered to be a fully valid description of brain function, though. The essential difficulty is that sophisticated computation by neural networks requires distributed processing in which hundreds or thousands of neurons work cooperatively\u2014current methods of brain activity recording are only capable of isolating action potentials from a few dozen neurons at a time.",
            "score": 195.2776780128479
        },
        {
            "docid": "21523_136",
            "document": "Artificial neural network . A fundamental objection is that they do not reflect how real neurons function. Back propagation is a critical part of most artificial neural networks, although no such mechanism exists in biological neural networks. How information is coded by real neurons is not known. Sensor neurons fire action potentials more frequently with sensor activation and muscle cells pull more strongly when their associated motor neurons receive action potentials more frequently. Other than the case of relaying information from a sensor neuron to a motor neuron, almost nothing of the principles of how information is handled by biological neural networks is known.",
            "score": 147.7284173965454
        },
        {
            "docid": "505717_72",
            "document": "Image segmentation . Pulse-coupled neural networks (PCNNs) are neural models proposed by modeling a cat\u2019s visual cortex and developed for high-performance biomimetic image processing. In 1989, Eckhorn introduced a neural model to emulate the mechanism of a cat\u2019s visual cortex. The Eckhorn model provided a simple and effective tool for studying the visual cortex of small mammals, and was soon recognized as having significant application potential in image processing. In 1994, the Eckhorn model was adapted to be an image processing algorithm by Johnson, who termed this algorithm Pulse-Coupled Neural Network. Over the past decade, PCNNs have been utilized for a variety of image processing applications, including: image segmentation, feature generation, face extraction, motion detection, region growing, noise reduction, and so on. A PCNN is a two-dimensional neural network. Each neuron in the network corresponds to one pixel in an input image, receiving its corresponding pixel\u2019s color information (e.g. intensity) as an external stimulus. Each neuron also connects with its neighboring neurons, receiving local stimuli from them. The external and local stimuli are combined in an internal activation system, which accumulates the stimuli until it exceeds a dynamic threshold, resulting in a pulse output. Through iterative computation, PCNN neurons produce temporal series of pulse outputs. The temporal series of pulse outputs contain information of input images and can be utilized for various image processing applications, such as image segmentation and feature generation. Compared with conventional image processing means, PCNNs have several significant merits, including robustness against noise, independence of geometric variations in input patterns, capability of bridging minor intensity variations in input patterns, etc.",
            "score": 108.24142920970917
        },
        {
            "docid": "1706303_15",
            "document": "Recurrent neural network . Independently recurrent neural network (IndRNN) solves the gradient vanishing and exploding problems in the traditional fully connected RNN. Each neuron in one layer only receives its own past state as context information and thus is independent of each other. The gradient backpropagation can be easily regulated to avoid gradient vanishing and exploding while keeping long-term memory as well as memory of any range. The cross-neuron information is explored in the next layers. IndRNN can be robustly trained together with the popular non-saturated nonlinear functions such as ReLU. It can also learn very long dependencies and construct very deep networks.",
            "score": 144.3177261352539
        }
    ],
    "r": [
        {
            "docid": "32472154_72",
            "document": "Deep learning . Although a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons and neural populations. Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system both at the single-unit and at the population levels.",
            "score": 248.24192810058594
        },
        {
            "docid": "39120_26",
            "document": "Nvidia . Nvidia GPUs are used in deep learning, artificial intelligence, and accelerated analytics. The company developed GPU-based deep learning in order to use artificial intelligence to approach problems like cancer detection, weather prediction, and self-driving vehicles. They are included in all Tesla vehicles. The purpose is to help networks learn to \u201cthink\u201d. According to \"TechRepublic\", Nvidia GPUs \"work well for deep learning tasks because they are designed for parallel computing and do well to handle the vector and matrix operations that are prevalent in deep learning\". These GPUs are used by researchers, laboratories, tech companies and enterprise companies. In 2009, Nvidia was involved in what was called the \"big bang\" of deep learning, \"as deep-learning neural networks were combined with Nvidia graphics processing units (GPUs)\". That year, the Google Brain used Nvidia GPUs to create Deep Neural Networks capable of machine learning, where Andrew Ng determined that GPUs could increase the speed of deep-learning systems by about 100 times.",
            "score": 224.6031036376953
        },
        {
            "docid": "1164_53",
            "document": "Artificial intelligence . Neural networks, or neural nets, were inspired by the architecture of neurons in the human brain. A simple \"neuron\" \"N\" accepts input from multiple other neurons, each of which, when activated (or \"fired\"), cast a weighted \"vote\" for or against whether neuron \"N\" should itself activate. Learning requires an algorithm to adjust these weights based on the training data; one simple algorithm (dubbed \"fire together, wire together\") is to increase the weight between two connected neurons when the activation of one triggers the successful activation of another. The net forms \"concepts\" that are distributed among a subnetwork of shared neurons that tend to fire together; a concept meaning \"leg\" might be coupled with a subnetwork meaning \"foot\" that includes the sound for \"foot\". Neurons have a continuous spectrum of activation; in addition, neurons can process inputs in a nonlinear way rather than weighing straightforward votes. Modern neural nets can learn both continuous functions and, surprisingly, digital logical operations. Neural networks' early successes included predicting the stock market and (in 1995) a mostly self-driving car. In the 2010s, advances in neural networks using deep learning thrust AI into widespread public consciousness and contributed to an enormous upshift in corporate AI spending; for example, AI-related M&A in 2017 was over 25 times as large as in 2015.",
            "score": 220.68296813964844
        },
        {
            "docid": "233488_24",
            "document": "Machine learning . Falling hardware prices and the development of GPUs for personal use in the last few years have contributed to the development of the concept of deep learning which consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.",
            "score": 216.3554229736328
        },
        {
            "docid": "6596_14",
            "document": "Computer vision . A third field which plays an important role is neurobiology, specifically the study of the biological vision system. Over the last century, there has been an extensive study of eyes, neurons, and the brain structures devoted to processing of visual stimuli in both humans and various animals. This has led to a coarse, yet complicated, description of how \"real\" vision systems operate in order to solve certain vision related tasks. These results have led to a subfield within computer vision where artificial systems are designed to mimic the processing and behavior of biological systems, at different levels of complexity. Also, some of the learning-based methods developed within computer vision (\"e.g.\" neural net and deep learning based image and feature analysis and classification) have their background in biology.",
            "score": 209.39903259277344
        },
        {
            "docid": "623686_84",
            "document": "Brain\u2013computer interface . In 2004 Thomas DeMarse at the University of Florida used a culture of 25,000 neurons taken from a rat's brain to fly a F-22 fighter jet aircraft simulator. After collection, the cortical neurons were cultured in a petri dish and rapidly began to reconnect themselves to form a living neural network. The cells were arranged over a grid of 60 electrodes and used to control the pitch and yaw functions of the simulator. The study's focus was on understanding how the human brain performs and learns computational tasks at a cellular level.",
            "score": 207.93975830078125
        },
        {
            "docid": "32472154_36",
            "document": "Deep learning . An ANN is based on a collection of connected units called artificial neurons, (analogous to axons in a biological brain). Each connection (synapse) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it. Neurons may have state, generally represented by real numbers, typically between 0 and 1. Neurons and synapses may also have a weight that varies as learning proceeds, which can increase or decrease the strength of the signal that it sends downstream.",
            "score": 207.249267578125
        },
        {
            "docid": "35591037_6",
            "document": "Marketing and artificial intelligence . An artificial neural network is a form of computer program modelled on the brain and nervous system of humans. Neural networks are composed of a series of interconnected processing neurons functioning in unison to achieve certain outcomes.  Using \u201chuman-like trial and error learning methods neural networks detect patterns existing within a data set ignoring data that is not significant, while emphasising the data which is most influential\u201d.",
            "score": 204.14576721191406
        },
        {
            "docid": "1164_59",
            "document": "Artificial intelligence . Deep learning is any artificial neural network that can learn a long chain of causal links. For example, a feedforward network with six hidden layers can learn a seven-link causal chain (six hidden layers + output layer) and has a \"credit assignment path\" (CAP) depth of seven. Many deep learning systems need to be able to learn chains ten or more causal links in length. Deep learning has transformed many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing and others.",
            "score": 202.3617706298828
        },
        {
            "docid": "32472154_40",
            "document": "Deep learning . As of 2017, neural networks typically have a few thousand to a few million units and millions of connections. Despite this number being several order of magnitude less than the number of neurons on a human brain, these networks can perform many tasks at a level beyond that of humans (e.g., recognizing faces, playing \"Go\" ).",
            "score": 201.6287384033203
        },
        {
            "docid": "32472154_70",
            "document": "Deep learning . Deep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s. These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, \"...the infant's brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature.\"",
            "score": 201.61331176757812
        },
        {
            "docid": "3717_60",
            "document": "Brain . Computational neuroscience encompasses two approaches: first, the use of computers to study the brain; second, the study of how brains perform computation. On one hand, it is possible to write a computer program to simulate the operation of a group of neurons by making use of systems of equations that describe their electrochemical activity; such simulations are known as \"biologically realistic neural networks\". On the other hand, it is possible to study algorithms for neural computation by simulating, or mathematically analyzing, the operations of simplified \"units\" that have some of the properties of neurons but abstract out much of their biological complexity. The computational functions of the brain are studied both by computer scientists and neuroscientists.",
            "score": 200.5349884033203
        },
        {
            "docid": "48423216_21",
            "document": "List of Ship of Theseus examples . In Hans Moravec's \"Mind Children\", an example of mind uploading is given - a human brain is replaced a single neuron at a time by a nanorobot and computer that perfectly simulates the behaviour of the neuron and its neurotransmitters. The end result is a completely digital copy of brain in simulation. However, there are other factors such as the fact that the intricate structure of the brain is changing as the brain learns, so a simulated brain may not learn the same way.",
            "score": 195.8111572265625
        },
        {
            "docid": "3717_69",
            "document": "Brain . Theorists have worked to understand these response patterns by constructing mathematical models of neurons and neural networks, which can be simulated using computers. Some useful models are abstract, focusing on the conceptual structure of neural algorithms rather than the details of how they are implemented in the brain; other models attempt to incorporate data about the biophysical properties of real neurons. No model on any level is yet considered to be a fully valid description of brain function, though. The essential difficulty is that sophisticated computation by neural networks requires distributed processing in which hundreds or thousands of neurons work cooperatively\u2014current methods of brain activity recording are only capable of isolating action potentials from a few dozen neurons at a time.",
            "score": 195.27767944335938
        },
        {
            "docid": "586357_19",
            "document": "Artificial general intelligence . There are some research projects that are investigating brain simulation using more sophisticated neural models, implemented on conventional computing architectures. The Artificial Intelligence System project implemented non-real time simulations of a \"brain\" (with 10 neurons) in 2005. It took 50 days on a cluster of 27 processors to simulate 1 second of a model. The Blue Brain project used one of the fastest supercomputer architectures in the world, IBM's Blue Gene platform, to create a real time simulation of a single rat neocortical column consisting of approximately 10,000 neurons and 10 synapses in 2006. A longer term goal is to build a detailed, functional simulation of the physiological processes in the human brain: \"It is not impossible to build a human brain and we can do it in 10 years,\" Henry Markram, director of the Blue Brain Project said in 2009 at the TED conference in Oxford. There have also been controversial claims to have simulated a cat brain. Neuro-silicon interfaces have been proposed as an alternative implementation strategy that may scale better.",
            "score": 195.02130126953125
        },
        {
            "docid": "33818014_29",
            "document": "Nervous system network models . The challenge involved in developing models for small, medium, and large networks is one of reducing the complexity by making valid simplifying assumptions in and extending the Hodgkin-Huxley neuronal model appropriately to design those models ( see Chapter 9 of Sterratt, D., Graham, B., Gillies, A., & Willshaw, D. (2011), Kotter, R., Nielson, P., Dyhrfjeld-Johnson, J., Sommer, F. T., & Northoff, G. (2002), and Chapter 9 of Gerstner, W., & Kistler, W. (2002)). Network models can be classified as either network of neurons propagating through different levels of cortex or neuron populations interconnected as multilevel neurons. The spatial positioning of neuron could be 1-, 2- or 3-dimensional; the latter ones are called small-world networks as they are related to local region. The neuron could be either excitatory or inhibitory, but not both. Modeling design depends on whether it is artificial neuron or biological neuron of neuronal model. Type I or Type II choice needs to be made for the firing mode. Signaling in neurons could be rate-based neurons, spiking response neurons, or deep-brain stimulated. The network can be designed as feedforward or recurrent type. The network needs to be scaled for the computational resource capabilities. Large-scale thalamocortical systems are handled in the manner of the Blue Brain project (Markam, H. (2006)).",
            "score": 194.71817016601562
        },
        {
            "docid": "586357_18",
            "document": "Artificial general intelligence . The artificial neuron model assumed by Kurzweil and used in many current artificial neural network implementations is simple compared with biological neurons. A brain simulation would likely have to capture the detailed cellular behaviour of biological neurons, presently only understood in the broadest of outlines. The overhead introduced by full modeling of the biological, chemical, and physical details of neural behaviour (especially on a molecular scale) would require computational powers several orders of magnitude larger than Kurzweil's estimate. In addition the estimates do not account for glial cells, which are at least as numerous as neurons, and which may outnumber neurons by as much as 10:1, and are now known to play a role in cognitive processes.",
            "score": 194.55133056640625
        },
        {
            "docid": "1164_60",
            "document": "Artificial intelligence . According to one overview, the expression \"Deep Learning\" was introduced to the Machine Learning community by Rina Dechter in 1986 and gained traction after Igor Aizenberg and colleagues introduced it to Artificial Neural Networks in 2000. The first functional Deep Learning networks were published by Alexey Grigorevich Ivakhnenko and V. G. Lapa in 1965. These networks are trained one layer at a time. Ivakhnenko's 1971 paper describes the learning of a deep feedforward multilayer perceptron with eight layers, already much deeper than many later networks. In 2006, a publication by Geoffrey Hinton and Ruslan Salakhutdinov introduced another way of pre-training many-layered feedforward neural networks (FNNs) one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then using supervised backpropagation for fine-tuning. Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships. Over the last few years, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.",
            "score": 194.028564453125
        },
        {
            "docid": "2894560_85",
            "document": "History of artificial intelligence . Deep learning is a branch of machine learning that models high level abstractions in data by using a deep graph with many processing layers. According to the Universal approximation theorem, deep-ness isn't necessary for a neural network to be able to approximate arbitrary continuous functions. Even so, there are many problems that are common to shallow networks (such as overfitting) that deep networks help avoid. As such, deep neural networks are able to realistically generate much more complex models as compared to their shallow counterparts.",
            "score": 193.42001342773438
        },
        {
            "docid": "941909_26",
            "document": "Receptive field . The term receptive field is also used in the context of artificial neural networks, most often in relation to convolutional neural networks (CNNs). When used in this sense, the term adopts a meaning reminiscent of receptive fields in actual biological nervous systems. CNNs have a distinct architecture, designed to mimic the way in which real animal brains are understood to function; instead of having every neuron in each layer connect to all neurons in the next layer (Multilayer perceptron), the neurons are arranged in a 3-dimensional structure in such a way as to take into account the spatial relationships between different neurons with respect to the original data. Since CNNs are used primarily in the field of computer vision, the data that the neurons represent is typically an image; each input neuron represents one pixel from the original image. The first layer of neurons is composed of all the input neurons; neurons in the next layer will receive connections from some of the input neurons (pixels), but not all, as would be the case in a MLP and in other traditional neural networks. Hence, instead of having each neuron receive connections from all neurons in the previous layer, CNNs use a receptive field-like layout in which each neuron receives connections only from a subset of neurons in the previous (lower) layer. The receptive field of a neuron in one of the lower layers encompasses only a small area of the image, while the receptive field of a neuron in subsequent (higher) layers involves a combination of receptive fields from several (but not all) neurons in the layer before (i. e. a neuron in a higher layer \"looks\" at a larger portion of the image than does a neuron in a lower layer). In this way, each successive layer is capable of learning increasingly abstract features of the original image. The use of receptive fields in this fashion is thought to give CNNs an advantage in recognizing visual patterns when compared to other types of neural networks.",
            "score": 192.15048217773438
        },
        {
            "docid": "620396_42",
            "document": "Origin of language . In humans, functional MRI studies have reported finding areas homologous to the monkey mirror neuron system in the inferior frontal cortex, close to Broca's area, one of the language regions of the brain. This has led to suggestions that human language evolved from a gesture performance/understanding system implemented in mirror neurons. Mirror neurons have been said to have the potential to provide a mechanism for action-understanding, imitation-learning, and the simulation of other people's behavior. This hypothesis is supported by some cytoarchitectonic homologies between monkey premotor area F5 and human Broca's area. Rates of vocabulary expansion link to the ability of children to vocally mirror non-words and so to acquire the new word pronunciations. Such speech repetition occurs automatically, quickly and separately in the brain to speech perception. Moreover, such vocal imitation can occur without comprehension such as in speech shadowing and echolalia. Further evidence for this link comes from a recent study in which the brain activity of two participants was measured using fMRI while they were gesturing words to each other using hand gestures with a game of charades\u2014a modality that some have suggested might represent the evolutionary precursor of human language. Analysis of the data using Granger Causality revealed that the mirror-neuron system of the observer indeed reflects the pattern of activity of in the motor system of the sender, supporting the idea that the motor concept associated with the words is indeed transmitted from one brain to another using the mirror system.",
            "score": 191.59996032714844
        },
        {
            "docid": "8402086_16",
            "document": "Computational neurogenetic modeling . Artificial Neural Networks designed to simulate of the human brain require an ability to learn a variety of tasks that is not required by those designed to accomplish a specific task. Supervised learning is a mechanism by which an artificial neural network can learn by receiving a number of inputs with a correct output already known. An example of an artificial neural network that uses supervised learning is a multilayer perceptron (MLP). In unsupervised learning, an artificial neural network is trained using only inputs. Unsupervised learning is the learning mechanism by which a type of artificial neural network known as a self-organizing map (SOM) learns. Some types of artificial neural network, such as evolving connectionist systems, can learn in both a supervised and unsupervised manner.",
            "score": 190.55699157714844
        },
        {
            "docid": "9617564_2",
            "document": "Oja's rule . Oja's learning rule, or simply Oja's rule, named after Finnish computer scientist Erkki Oja, is a model of how neurons in the brain or in artificial neural networks change connection strength, or learn, over time. It is a modification of the standard Hebb's Rule (see Hebbian learning) that, through multiplicative normalization, solves all stability problems and generates an algorithm for principal components analysis. This is a computational form of an effect which is believed to happen in biological neurons.",
            "score": 190.0382843017578
        },
        {
            "docid": "245926_18",
            "document": "Autonomous car . Driverless vehicles require some form of machine vision for the purpose of visual object recognition. Autonomous cars are being developed with deep neural networks, a type of deep learning architecture with many computational stages, or levels, in which neurons are simulated from the environment that activate the network. The neural network depends on an extensive amount of data extracted from real-life driving scenarios, enabling the neural network to \"learn\" how to execute the best course of action.",
            "score": 189.9790802001953
        },
        {
            "docid": "49706798_9",
            "document": "Cortical implant . A Brain-computer interface (BCI) is a type of implant that allows for a direct connection between a patient's brain and some form of external hardware. Since the mid-1990s, the amount of research done on BCI's in both animal and human models has grown exponentially. Most brain-computer interfaces are used for some form of neural signal extraction, while some attempt to return sensation through an implanted signal. As an example of signal extraction, a BCI may take a signal from a paraplegic patient's brain and use it to move a robotic prosthetic. Paralyzed patients get a great amount of utility from these devices because they allow for a return of control to the patient. Current research for brain-computer interfaces is focused on determining which regions of the brain can be manipulated by an individual. A majority of research focuses on the sensorimotor region of the brain, using imagined motor actions to drive the devices, while some studies have sought to determine if the cognitive control network would be a suitable location for implantations. This region is a \"neuronal network that coordinates mental processes in the service of explicit intentions or tasks,\" driving the device by intent, rather than imagined motion An example of returning sensation through an implanted signal would be developing a tactile response for a prosthetic limb. Amputees have no touch response in artificial limbs, but through an implant in their somatosensory cortex could potentially give them an artificial sense of touch.",
            "score": 189.4231719970703
        },
        {
            "docid": "39151518_12",
            "document": "Neuronal recycling hypothesis . The visual word form area (VWFA) is located in the left lateral occipitotemporal sulcus. This area overlaps with the part of the ventral visual cortex that detects the presence of line junctions, and thus is thought to have provided the VWFA with its neuronal niche. Biederman (1987) found that line vertices are more essential to object recognition than line segments. Cross-culturally, letters/symbols used in written language are all made up of a small number of lines which meet at vertices. This suggests that cerebral constraints have influenced the development of writing systems and that there are limits on what kind of cultural inventions we can accommodate. Furthermore, computer simulations have shown that letter perception in deep neural networks is facilitated by recycling low-level visual features learned from natural images, thereby supporting the hypothesis that the structure of letter shapes has been culturally selected to match the structure of human natural environments.",
            "score": 188.43438720703125
        },
        {
            "docid": "39182554_23",
            "document": "Catastrophic interference . Following the same basic idea contributed by Robins, Ans and Rousset (1997) have also proposed a two-network artificial neural architecture with \"memory self-refreshing\" that overcomes catastrophic interference when sequential learning tasks are carried out in distributed networks trained by backpropagation. The principle is to interleave, at the time when new external patterns are learned, those to-be-learned new external patterns with internally generated pseudopatterns, or 'pseudo-memories', that reflect the previously learned information. What mainly distinguishes this model from those that use classical pseudorehearsal in feedforward multilayer networks is a \"reverberating\" process that is used for generating pseudopatterns. This process which, after a number of activity re-injections from a single random seed, tends to go up to nonlinear network \"attractors\", is more suitable for optimally capturing the deep structure of previously learned knowledge than a single feedforward pass of random activation. Ans and Rousset (2000) have shown that the learning mechanism they proposed avoiding catastrophic forgetting, provides a more appropriate way to deal with knowledge transfer as measured by learning speed, ability to generalize and vulnerability to network damages. Musca, Rousset and Ans (2009) have also shown that pseudopatterns originating from an artificial reverberating neural network could induce familiarity in humans with never seen items in the way predicted by simulations conducted with a two-network artificial neural architecture. Furthermore, Ans (2004) has implemented a version of the self-refreshing mechanism using only one network trained by the Contrastive Hebbian Learning rule, a training rule considered as more realistic than the largely used backpropagation algorithm, but fortunately equivalent to the latter.",
            "score": 187.20257568359375
        },
        {
            "docid": "520602_21",
            "document": "Sialic acid . It has been demonstrated that the human brain has more sialic acid than the brains of other mammals (2 \u2013 4 times more). Neural membranes have 20 times more sialic acid than other cellular membranes. It is believed that sialic acid has a decisive role in enabling neurotransmission between neurons. The effects of sialic acid supplementation on learning and memory behaviour has been studied in rodents, as well as in piglets (whose brain structure and function more closely resemble those of humans). A diet rich in sialic acid was given to newborn piglets for five weeks. Then learning and memory were evaluated using a visual cue in a maze. A relationship between dietary sialic acid supplementation and cognitive function was seen: the piglets that had been fed high doses of sialic acid learned more quickly and made fewer mistakes. This suggests that sialic acid has an influence upon brain development and learning.",
            "score": 186.77676391601562
        },
        {
            "docid": "12142270_4",
            "document": "GENESIS (software) . Neural networks like the ones simulated with GENESIS software can quickly become highly complex and difficult to understand. \"Just a few interconnected neurons (a microcircuit) can perform sophisticated tasks such as mediate reflexes, process sensory information, generate locomotion and mediate learning and memory. Even more complex networks, macrocircuits, consist of multiple embedded microcircuits. Macrocircuits mediate higher brain functions such as object recognition and cognition\". GENESIS endeavors to simulate neural systems as they are found in nature. Often, \"a neuron can receive contacts from up to 10,000 presynaptic neurons, and, in turn, any one neuron can contact up to 10,000 postsynaptic neurons. The combinatorial possibility could give rise to enormously complex neuronal circuits or network topologies, which might be very difficult to understand\".",
            "score": 186.62094116210938
        },
        {
            "docid": "33826069_3",
            "document": "Viral neuronal tracing . Most neuroanatomists would agree that understanding how the brain is connected to itself and the body is of paramount importance. As such, it is of equal importance to have a way to visualize and study the connections among neurons. Neuronal tracing methods offer an unprecedented view into the morphology and connectivity of neural networks. Depending on the tracer used, this can be limited to a single neuron or can progress trans-synaptically to adjacent neurons. After the tracer has spread sufficiently, the extent may be measured either by fluorescence (for dyes) or by immunohistochemistry (for biological tracers). An important innovation in this field is the use of neurotropic viruses as tracers. These not only spread throughout the initial site of infection, but can jump across synapses. The use of a virus provides a self-replicating tracer. This can allow for the elucidation of neural microcircuitry to an extent that was previously unobtainable.  This has significant implications for the real world. If we can better understand what parts of the brain are intimately connected, we can predict the effect of localized brain injury. For example, if a patient has a stroke in the amygdala, primarily responsible for emotion, the patient might also have trouble learning to perform certain tasks because the amygdala is highly interconnected with the orbitofrontal cortex, responsible for reward learning. As always, the first step to solving a problem is fully understanding it, so if we are to have any hope of fixing brain injury, we must first understand its extent and complexity.",
            "score": 186.61415100097656
        },
        {
            "docid": "586357_20",
            "document": "Artificial general intelligence . Hans Moravec addressed the above arguments (\"brains are more complicated\", \"neurons have to be modeled in more detail\") in his 1997 paper \"When will computer hardware match the human brain?\". He measured the ability of existing software to simulate the functionality of neural tissue, specifically the retina. His results do not depend on the number of glial cells, nor on what kinds of processing neurons perform where.",
            "score": 185.0191192626953
        },
        {
            "docid": "10839226_23",
            "document": "Cultured neuronal network . In order to establish learning in a cultured network, researchers have attempted to re-embody the dissociated neuronal networks in either simulated or real environments (see MEART and animat). Through this method the networks are able to interact with their environment and, therefore, have the opportunity to learn in a more realistic setting. Other studies have attempted to imprint signal patterns onto the networks via artificial stimulation. This can be done by inducing network bursts or by inputing specific patterns to the neurons, from which the network is expected to derive some meaning (as in experiments with animats, where an arbitrary signal to the network indicates that the simulated animal has run into a wall or is moving in a direction, etc.). The latter technique attempts to take advantage of the inherent ability of neuronal networks to make sense of patterns. However, experiments have had limited success in demonstrating a definition of learning that is widely agreed upon. Nevertheless, plasticity in neuronal networks is a phenomenon that is well-established in the neuroscience community, and one that is thought to play a very large role in learning.",
            "score": 184.7814178466797
        }
    ]
}