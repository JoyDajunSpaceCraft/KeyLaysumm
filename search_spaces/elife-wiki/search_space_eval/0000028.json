{
    "q": [
        {
            "docid": "15774067_27",
            "document": "Synaptic noise . To understand the future of synaptic noise research, it would be essential to discuss the work of Alain Destexhe, a Belgian doctor who has greatly studied the importance of synaptic noise in neuronal connections. He uses the dynamic-clamp technique to understand the presence and characteristics of noise. While voltage-gated clamps record configurations, dynamic-clamp allows for the control of conductance by way of computer. A computational model of synaptic noise is created and is then implemented into the neuron, simulating synaptic noise. This can be used to compare with in-vivo conditions. Destexhe states that future research can be directed towards four possible ways, in reflection of his research with dynamic-clamp. First, it could be beneficial to understand the control of synaptic noise so that the modulation of noise can be used on humans to turn unresponsive networks into a responsive state. Next, it would be necessary to understand how external noise interacts with internal neuronal properties more fully to coincide models with experimental facts. There also exists the need to further investigate experimentally the methods of dendritic integration and the role of synaptic noise when it is present. Finally, he found support that synaptic noise enhances temporal resolution in neurons, yet experimental proof has not been done to further elaborate on past modeling studies. By use of dynamic-clamp, these pieces of information clarify the role of synaptic noise in the brain and how it can be harnessed for specific therapies.",
            "score": 152.00522708892822
        },
        {
            "docid": "3717_69",
            "document": "Brain . Theorists have worked to understand these response patterns by constructing mathematical models of neurons and neural networks, which can be simulated using computers. Some useful models are abstract, focusing on the conceptual structure of neural algorithms rather than the details of how they are implemented in the brain; other models attempt to incorporate data about the biophysical properties of real neurons. No model on any level is yet considered to be a fully valid description of brain function, though. The essential difficulty is that sophisticated computation by neural networks requires distributed processing in which hundreds or thousands of neurons work cooperatively\u2014current methods of brain activity recording are only capable of isolating action potentials from a few dozen neurons at a time.",
            "score": 190.9309732913971
        },
        {
            "docid": "33818014_29",
            "document": "Nervous system network models . The challenge involved in developing models for small, medium, and large networks is one of reducing the complexity by making valid simplifying assumptions in and extending the Hodgkin-Huxley neuronal model appropriately to design those models ( see Chapter 9 of Sterratt, D., Graham, B., Gillies, A., & Willshaw, D. (2011), Kotter, R., Nielson, P., Dyhrfjeld-Johnson, J., Sommer, F. T., & Northoff, G. (2002), and Chapter 9 of Gerstner, W., & Kistler, W. (2002)). Network models can be classified as either network of neurons propagating through different levels of cortex or neuron populations interconnected as multilevel neurons. The spatial positioning of neuron could be 1-, 2- or 3-dimensional; the latter ones are called small-world networks as they are related to local region. The neuron could be either excitatory or inhibitory, but not both. Modeling design depends on whether it is artificial neuron or biological neuron of neuronal model. Type I or Type II choice needs to be made for the firing mode. Signaling in neurons could be rate-based neurons, spiking response neurons, or deep-brain stimulated. The network can be designed as feedforward or recurrent type. The network needs to be scaled for the computational resource capabilities. Large-scale thalamocortical systems are handled in the manner of the Blue Brain project (Markam, H. (2006)).",
            "score": 135.26757335662842
        },
        {
            "docid": "33818014_8",
            "document": "Nervous system network models . On a high level representation, the neurons can be viewed as connected to other neurons to form a neural network in one of three ways. A specific network can be represented as a physiologically (or anatomically) connected network and modeled that way. There are several approaches to this (see Ascoli, G.A. (2002) Sporns, O. (2007), Connectionism, Rumelhart, J. L., McClelland, J. L., and PDP Research Group (1986), Arbib, M. A. (2007)). Or, it can form a functional network that serves a certain function and modeled accordingly (Honey, C. J., Kotter, R., Breakspear, R., & Sporns, O. (2007), Arbib, M. A. (2007)). A third way is to hypothesize a theory of the functioning of the biological components of the neural system by a mathematical model, in the form of a set of mathematical equations. The variables of the equation are some or all of the neurobiological properties of the entity being modeled, such as the dimensions of the dendrite or the stimulation rate of action potential along the axon in a neuron. The mathematical equations are solved using computational techniques and the results are validated with either simulation or experimental processes. This approach to modeling is called computational neuroscience. This methodology is used to model components from the ionic level to system level of the brain. This method is applicable for modeling integrated system of biological components that carry information signal from one neuron to another via intermediate active neurons that can pass the signal through or create new or additional signals. The computational neuroscience approach is extensively used and is based on two generic models, one of cell membrane potential Goldman (1943) and Hodgkin and Katz (1949), and the other based on Hodgkin-Huxley model of action potential (information signal).",
            "score": 154.32175052165985
        },
        {
            "docid": "39199253_2",
            "document": "Percolation (cognitive psychology) . Percolation (from the Latin word \"percolatio\", meaning filtration) is a theoretical model used to understand the way activation and diffusion of neural activity occur within neural networks. Percolation is a model used to explain how neural activity is transmitted across the various connections within the brain. Often it is easiest to understand percolation theory by explaining its use in epidemiology. Individuals that are infected with a disease can spread the disease through contact with others in their social network. Those who are more social and come into contact with more people will help to propagate the disease quicker than those who are less social. Therefore factors such as occupation and sociability influence the rate of infection. Now, if one were to think of \"neurons\" as the \"individuals\" and \"synaptic connections\" as the \"social bonds\" between people, then one can determine how easily messages between neurons will spread. When a neuron fires, the message is transmitted along all synaptic connections to other neurons until it can no longer continue. Synaptic connections are considered either open or closed (like a social or unsocial person) and messages will flow along any and all open connections until they can go no further. Just like occupation and sociability play a key role in the spread of disease, so too do the number of neurons, synaptic plasticity and long-term potentiation when talking about neural percolation.",
            "score": 137.91591620445251
        },
        {
            "docid": "20512936_21",
            "document": "Dendritic spike . Computational modeling of neurons, artificial neural networking, has become a very popular tool in investigating the properties of neuronal signaling. These models are based on biological neural networks. Computational modeling can be used to study single neurons, groups of neurons, or even networks of neurons. This field has generated much interest and serves as a tool for all branches of neuroscience research including dendritic spike initiation.",
            "score": 110.54085063934326
        },
        {
            "docid": "2567511_17",
            "document": "Neural engineering . Scientists can use experimental observations of neuronal systems and theoretical and computational models of these systems to create Neural networks with the hopes of modeling neural systems in as realistic a manner as possible. Neural networks can be used for analyses to help design further neurotechnological devices. Specifically, researchers handle analytical or finite element modeling to determine nervous system control of movements and apply these techniques to help patients with brain injuries or disorders. Artificial neural networks can be built from theoretical and computational models and implemented on computers from theoretically devices equations or experimental results of observed behavior of neuronal systems. Models might represent ion concentration dynamics, channel kinetics, synaptic transmission, single neuron computation, oxygen metabolism, or application of dynamic system theory (LaPlaca et al. 2005). Liquid-based template assembly was used to engineer 3D neural networks from neuron-seeded microcarrier beads.",
            "score": 146.2109067440033
        },
        {
            "docid": "10839226_2",
            "document": "Cultured neuronal network . A cultured neuronal network is a cell culture of neurons that is used as a model to study the central nervous system, especially the brain. Often, cultured neuronal networks are connected to an input/output device such as a multi-electrode array (MEA), thus allowing two-way communication between the researcher and the network. This model has proved to be an invaluable tool to scientists studying the underlying principles behind neuronal learning, memory, plasticity, connectivity, and information processing.",
            "score": 129.8154797554016
        },
        {
            "docid": "8402086_18",
            "document": "Computational neurogenetic modeling . Because the amount of data on the interplay of genes and neurons and their effects is not enough to construct a rigorous model,  evolutionary computation is used to optimize artificial neural networks and gene regulatory networks, a common technique being the genetic algorithm. A genetic algorithm is a process that can be used to refine models by mimicking the process of natural selection observed in biological ecosystems. The primary advantages are that, due to not requiring derivative information, it can be applied to black box problems and multimodal optimization. The typical process for using genetic algorithms to refine a gene  regulatory network is: first, create a population; next, to create offspring via a crossover operation and  evaluate their fitness; then, on a group chosen for high fitness, simulate mutation via a mutation operator;  finally, taking the now mutated group, repeat this process until a desired level of fitness is demonstrated. Methods by which artificial neural networks may alter their structure without simulated mutation and fitness selection have been developed. A dynamically evolving neural network is one approach, as the creation of new connections and new neurons can  be modeled as the system adapts to new data. This enables the network to evolve in modeling accuracy without simulated natural selection. One method by which dynamically evolving networks may be optimized, called evolving layer neuron aggregation, combines neurons with sufficiently similar input weights into one neuron. This can take place during the training of the network, referred to as online aggregation, or between periods of training, referred to as offline aggregation. Experiments have suggested that offline aggregation is more efficient.",
            "score": 140.58349335193634
        },
        {
            "docid": "10459803_6",
            "document": "Neuron (software) . Neuron features a graphical user interace (GUI), for use by individuals with minimal programming experience. The GUI comes equipped with a builder for single and multiple compartment cells, networks, network cells, channels and linear electric circuits. Single and multiple compartment cells differ in that multiple compartment cells features several \"sections\", each with potentially distinct parameters for dimensions and kinetics. Tutorials are available on the Neuron website, including for getting basic models out of the cell, channel and network builders. With these builders, the user can form the basis of all simulations and models.",
            "score": 137.13864183425903
        },
        {
            "docid": "21523_125",
            "document": "Artificial neural network . Many types of models are used, defined at different levels of abstraction and modeling different aspects of neural systems. They range from models of the short-term behavior of individual neurons, models of how the dynamics of neural circuitry arise from interactions between individual neurons and finally to models of how behavior can arise from abstract neural modules that represent complete subsystems. These include models of the long-term, and short-term plasticity, of neural systems and their relations to learning and memory from the individual neuron to the system level.",
            "score": 122.54525327682495
        },
        {
            "docid": "33818014_23",
            "document": "Nervous system network models . Computational science is an interdisciplinary field that combines engineering, biology, control systems, brain functions, physical sciences, and computer science. It has fundamental development models done at the lower levels of ions, neurons, and synapses, as well as information propagation between neurons. These models have established the enabling technology for higher-level models to be developed. They are based on chemical and electrical activities in the neurons for which electrical equivalent circuits are generated. A simple model for the neuron with predominantly potassium ions inside the cell and sodium ions outside establishes an electric potential on the membrane under equilibrium, i.e., no external activity, condition. This is called the resting membrane potential, which can be determined by Nernst Equation (Nernst, W. (1888)). An equivalent electrical circuit for a patch of membrane, for example an axon or dendrite, is shown in Figure 5. E and E are the potentials associated with the potassium and sodium channels respectively and R and R are the resistances associated with them. C is the capacitance of the membrane and I is the source current, which could be the test source or the signal source (action potential). The resting potential for potassium-sodium channels in a neuron is about -65 millivolts. The membrane model is for a small section of the cell membrane; for larger sections it can be extended by adding similar sections, called compartments, with the parameter values being the same or different. The compartments are cascaded by a resistance, called axial resistance. Figure 6 shows a compartmental model of a neuron that is developed over the membrane model. Dendrites are the postsynaptic receptors receiving inputs from other neurons; and the axon with one or more axon terminals transmits neurotransmitters to other neurons. The second building block is the Hodgkin-Huxley (HH) model of the action potential. When the membrane potential from the dendrites exceeds the resting membrane potential, a pulse is generated by the neuron cell and propagated along the axon. This pulse is called the action potential and HH model is a set of equations that is made to fit the experimental data by the design of the model and the choice of the parameter values.",
            "score": 155.63709032535553
        },
        {
            "docid": "292744_215",
            "document": "Ising model . The activity of neurons in the brain can be modelled statistically. Each neuron at any time is either active + or inactive\u00a0\u2212. The active neurons are those that send an action potential down the axon in any given time window, and the inactive ones are those that do not. Because the neural activity at any one time is modelled by independent bits, Hopfield suggested that a dynamical Ising model would provide a first approximation to a neural network which is capable of learning.",
            "score": 128.75744485855103
        },
        {
            "docid": "53757504_6",
            "document": "Viktor K. Jirsa . The Virtual Brain is a free open source neuroinformatics tool designed to aid in the exploration of network mechanisms of brain function and associated pathologies. TVB provides the possibility to feed computational neuronal network models with information about structural and functional imaging data including population (sEEG/EEG/MEG) activity, spatially highly resolved whole brain metabolic/vascular signals (fMRI) and global measures of neuronal connections (DTI) \u2013 for intact as well as pathologically altered connectivity. TVB is model agnostic and offers a wide range of neural population models to be used as network nodes. The software infrastructure of the Virtual Brain is composed of a functional core running the large-scale brain simulations independently or in batch mode, a web based interface to access the simulator, as well as a command line interface to develop more extensive applications. All simulations may be performed on workstations and labtops, as well as on high-performance clusters (HPCs). Manipulations of network parameters within the Virtual Brain allow researchers and clinicians to test the effects of experimental paradigms, interventions (such as stimulation and surgery) and therapeutic strategies (such as pharmaceutical interventions targeting local areas). The computational environment allows the user to visualise the simulated data in 2D and 3D and perform data analyses in the same way as commonly performed with empirical data.",
            "score": 187.13125610351562
        },
        {
            "docid": "271430_14",
            "document": "Computational neuroscience . Modeling the richness of biophysical properties on the single-neuron scale can supply mechanisms that serve as the building blocks for network dynamics. However, detailed neuron descriptions are computationally expensive and this can handicap the pursuit of realistic network investigations, where many neurons need to be simulated. As a result, researchers that study large neural circuits typically represent each neuron and synapse with an artificially simple model, ignoring much of the biological detail. Hence there is a drive to produce simplified neuron models that can retain significant biological fidelity at a low computational overhead. Algorithms have been developed to produce faithful, faster running, simplified surrogate neuron models from computationally expensive, detailed neuron models.",
            "score": 131.60714435577393
        },
        {
            "docid": "1896271_17",
            "document": "Holonomic brain theory . In 1969 scientists D. Wilshaw, O. P. Buneman and H. Longuet-Higgins proposed an alternative, non-holographic model that fulfilled many of the same requirements as Gabor's original holographic model. The Gabor model did not explain how the brain could use Fourier analysis on incoming signals or how it would deal with the low signal-noise ratio in reconstructed memories. Longuet-Higgin's correlograph model built on the idea that any system could perform the same functions as a Fourier holograph if it could correlate pairs of patterns. It uses minute pinholes that do not produce diffraction patterns to create a similar reconstruction as that in Fourier holography. Like a hologram, a discrete correlograph can recognize displaced patterns and store information in a parallel and non-local way so it usually will not be destroyed by localized damage. They then expanded the model beyond the correlograph to an associative net where the points become parallel lines arranged in a grid. Horizontal lines represent axons of input neurons while vertical lines represent output neurons. Each intersection represents a modifiable synapse. Though this cannot recognize displaced patterns, it has a greater potential storage capacity. This was not necessarily meant to show how the brain is organized, but instead to show the possibility of improving on Gabor's original model. P. Van Heerden countered this model by demonstrating mathematically that the signal-noise ratio of a hologram could reach 50% of ideal. He also used a model with a 2D neural hologram network for fast searching imposed upon a 3D network for large storage capacity. A key quality of this model was its flexibility to change the orientation and fix distortions of stored information, which is important for our ability to recognize an object as the same entity from different angles and positions, something the correlograph and association network models lack.",
            "score": 140.37840855121613
        },
        {
            "docid": "12142270_3",
            "document": "GENESIS (software) . GENESIS works by creating simulation environments for constructing models of neurons or neural systems. \"Nerve cells are capable of communicating with each other in such a highly structured manner as to form neuronal networks. To understand neural networks, it is necessary to understand the ways in which one neuron communicates with another through synaptic connections and the process called synaptic transmission\". Neurons have a specialized structure for their function, they \"are different from most other cells in the body in that they are polarized and have distinct morphological regions, each with specific functions\". The two important regions of a neuron are the dendrite and the axon. \"Dendrites are the region where one neuron receives connections from other neurons. The cell body or soma contains the nucleus and the other organelles necessary for cellular function. The axon is a key component of nerve cells over which information is transmitted from one part of the neuron (e.g., the cell body) to the terminal regions of the neuron\". The third important piece of a neuron is the synapse. \"The synapse is the terminal region of the axon this is where one neuron forms a connection with another and conveys information through the process of synaptic transmission\".",
            "score": 111.42158007621765
        },
        {
            "docid": "33818014_2",
            "document": "Nervous system network models . Network of human nervous system comprises nodes (for example, neurons) that are connected by links (for example, synapses). The connectivity may be viewed anatomically, functionally, or electrophysiologically. These are presented in several Wikipedia articles that include Connectionism (a.k.a. Parallel Distributed Processing (PDP)), Biological neural network, Artificial neural network (a.k.a. Neural network), Computational neuroscience, as well as in several books by Ascoli, G. A. (2002), Sterratt, D., Graham, B., Gillies, A., & Willshaw, D. (2011), Gerstner, W., & Kistler, W. (2002), and Rumelhart, J. L., McClelland, J. L., and PDP Research Group (1986) among others. The focus of this article is a comprehensive view of modeling a neural network (technically neuronal network based on neuron model). Once an approach based on the perspective and connectivity is chosen, the models are developed at microscopic (ion and neuron), mesoscopic (functional or population), or macroscopic (system) levels. Computational modeling refers to models that are developed using computing tools.",
            "score": 95.64245295524597
        },
        {
            "docid": "41121515_4",
            "document": "Traumatic brain injury modeling . In order to better understand what is happening during TBI, models are used to approximate the damage. Models bring both advantages and disadvantages to TBI research; on one hand brain models are very good at representing one aspect that can be observed, while on the other, aspects of the whole system must be ignored. For example, when studying blunt impacts, a neuronal cell culture model can be created that is the depth of the cortical layer. This is then subjected to different impact sizes, shapes, and forces in order to see how the cells react and what cytokines are released. This model works very well for the cortical layer, but deeper cell layers must be ignored due to the inability to oxygenate a deeper cell culture effectively. In this experiment, the disadvantage and limitation of this model is cell depth; any interactions that might occur below the cortical layer are ignored in order to gather accurate information within the cortical layer itself.",
            "score": 146.5840814113617
        },
        {
            "docid": "2860430_20",
            "document": "Neural oscillation . Computational models adopt a variety of abstractions in order to describe complex oscillatory dynamics observed in brain activity. Many models are used in the field, each defined at a different level of abstraction and trying to model different aspects of neural systems. They range from models of the short-term behaviour of individual neurons, through models of how the dynamics of neural circuitry arise from interactions between individual neurons, to models of how behaviour can arise from abstract neural modules that represent complete subsystems.",
            "score": 156.8341727256775
        },
        {
            "docid": "33818014_7",
            "document": "Nervous system network models . The basic structural unit of the neural network is connectivity of one neuron to another via an active junction, called synapse. Neurons of widely divergent characteristics are connected to each other via synapses, whose characteristics are also of diverse chemical and electrical properties. In presenting a comprehensive view of all possible modeling of the brain and neural network, an approach is to organize the material based on the characteristics of the networks and the goals that need to be accomplished. The latter could be either for understanding the brain and the nervous system better or to apply the knowledge gained from the total or partial nervous system to real world applications such as artificial intelligence, Neuroethics or improvements in medical science for society.",
            "score": 129.7408105134964
        },
        {
            "docid": "24882534_3",
            "document": "Brian (software) . Brian is aimed at researchers developing models based on networks of spiking neurons. The general design is aimed at maximising flexibility, simplicity and users' development time. Users specify neuron models by giving their differential equations in standard mathematical form as strings, create groups of neurons and connect them via synapses. This is in contrast to the approach taken by many neural simulators in which users select from a predefined set of neuron models.",
            "score": 110.84977269172668
        },
        {
            "docid": "2860430_23",
            "document": "Neural oscillation . A neural network model describes a population of physically interconnected neurons or a group of disparate neurons whose inputs or signalling targets define a recognizable circuit. These models aim to describe how the dynamics of neural circuitry arise from interactions between individual neurons. Local interactions between neurons can result in the synchronization of spiking activity and form the basis of oscillatory activity. In particular, models of interacting pyramidal cells and inhibitory interneurons have been shown to generate brain rhythms such as gamma activity.",
            "score": 162.40314555168152
        },
        {
            "docid": "33818014_18",
            "document": "Nervous system network models . There are three types of brain connectivity models of a network (Sporns, O. (2007)). \u201cAnatomical (or structural) connectivity\u201d describes a network with anatomical links having specified relationship between connected \u201cunits.\u201d If the dependent properties are stochastic, it is defined as \u201cfunctional connectivity.\u201d \u201cEffective connectivity\u201d has causal interactions between distinct units in the system. As stated earlier, brain connectivity can be described at three levels. At microlevel, it connects neurons through electrical or chemical synapses. A column of neurons can be considered as a unit in the mesolevel and regions of the brain comprising a large number of neurons and neuron populations as units in the macrolevel. The links in the latter case are the inter-regional pathways, forming large-scale connectivity. Figure 2 shows the three types of connectivity. The analysis is done using the directed graphs (see Sporns, O. (2007) and Hilgetag, C. C. (2002)). In the structural brain connectivity type, the connectivity is a sparse and directed graph. The functional brain connectivity has bidirectional graphs. The effective brain connectivity is bidirectional with interactive cause and effect relationships. Another representation of the connectivity is by matrix representation (See Sporns, O. (2007)). Hilgetag, C. C. (2002) describes the computational analysis of brain connectivity.",
            "score": 138.86607456207275
        },
        {
            "docid": "43956835_21",
            "document": "Binding neuron . The above-mentioned and other neuronal models and nets made of them can be  implemented in microchips. Among different chips it is worth mentioning the FPGA ones. The FPGA chips can be used for implementation of any neuronal model,  but the BN model can be programmed most naturally because it can use only integers and do not need solving  differential equations. Those features are used, e.g. in",
            "score": 95.21677041053772
        },
        {
            "docid": "14408479_3",
            "document": "Biological neuron model . Neuron models can be divided into two categories according to the physical units of the interface of the model. Each category could be further divided according to the abstraction/detail level:  Although it is not unusual in science and engineering to have several descriptive models for different abstraction/detail levels, the number of different, sometimes contradicting, biological neuron models is exceptionally high. This situation is partly the result of the many different experimental settings, and the difficulty to separate the intrinsic properties of a single neuron from measurements effects and interactions of many cells (network effects). To accelerate the convergence to a unified theory, we list several models in each category, and where applicable, also references to supporting experiments.",
            "score": 124.08893871307373
        },
        {
            "docid": "33827219_2",
            "document": "Compartmental modelling of dendrites . Compartmental modelling of dendrites deals with multi-compartment modelling of the dendrites, to make the understanding of the electrical behavior of complex dendrites easier. Basically, compartmental modelling of dendrites is a very helpful tool to develop new biological neuron models. Dendrites are very important because they occupy the most membrane area in many of the neurons and give the neuron an ability to connect to thousands of other cells. Originally the dendrites were thought to have constant conductance and current but now it has been understood that they may have active Voltage-gated ion channels, which influences the firing properties of the neuron and also the response of neuron to synaptic inputs. Many mathematical models have been developed to understand the electric behavior of the dendrites. Dendrites tend to be very branchy and complex, so the compartmental approach to understand the electrical behavior of the dendrites makes it very useful.",
            "score": 124.58484041690826
        },
        {
            "docid": "10459803_12",
            "document": "Neuron (software) . Neuron allows for the generation of mixed models, populated with both artificial cells and neurons. Artificial cells essentially function as point processes, implemented into the network. Artificial cells require only a point process, with defined parameters. The user can create the structure and dynamics of network cells. The user can create synapses, using simulated synapse point processes as archetypes. Parameters on these point processes can be manipulated to simulate both inhibitory and excitatory responses. Synapses can be placed on specific segments of the constructed cell, wherein, again, they will behave as point processes, except that they are sensitive to the activity of a pre-synaptic element. Cells can be managed. The user creates the basic grid of network cells, taking previously completed network cells as archetypes. Connections can be defined between source cells and target synapses on other cells. The cell containing the target synapse becomes the post-synaptic element, whereas the source cells function as pre-synaptic elements. Weights can be added to define strength of activation of a synapse by the pre-synaptic cell. A plot option can be activated to open a graph of spikes across time for individual neurons.",
            "score": 115.64140915870667
        },
        {
            "docid": "39619438_5",
            "document": "AnimatLab . AnimatLab allows users to develop models of varied levels of detail due to the types of models available. Neurons may be simple firing rate models, integrate-and-fire models, or Hodgkin\u2013Huxley models. Plugins for other neuron models can be written and used. Hill-type muscles, motors, or servos can be used to actuate joints. Adapters between neurons and actuators are used to generate forces. Adapters between mechanical components (joints, body segments, muscles, etc.) provide feedback to the control system. Stimuli, such as voltage clamps, current clamps, and velocity clamps (for joints) can be added to design experiments. Data can be recorded from virtually every component of the system, and viewed in graphs or exported as a comma separated values file, making analysis easy. In addition, the user interface is entirely graphical, making it easy for beginners to use.",
            "score": 135.61520743370056
        },
        {
            "docid": "349771_14",
            "document": "Artificial neuron . The first artificial neuron was the Threshold Logic Unit (TLU), or Linear Threshold Unit, first proposed by Warren McCulloch and Walter Pitts in 1943. The model was specifically targeted as a computational model of the \"nerve net\" in the brain. As a transfer function, it employed a threshold, equivalent to using the Heaviside step function. Initially, only a simple model was considered, with binary inputs and outputs, some restrictions on the possible weights, and a more flexible threshold value. Since the beginning it was already noticed that any boolean function could be implemented by networks of such devices, what is easily seen from the fact that one can implement the AND and OR functions, and use them in the disjunctive or the conjunctive normal form. Researchers also soon realized that cyclic networks, with feedbacks through neurons, could define dynamical systems with memory, but most of the research concentrated (and still does) on strictly feed-forward networks because of the smaller difficulty they present.",
            "score": 114.49954211711884
        },
        {
            "docid": "41121858_9",
            "document": "Binocular neurons . An energy model, a kind of stimulus-response model, of binocular neurons allows for investigation behind the computational function these disparity tuned cells play in the creation of depth perception. Energy models of binocular neurons involve the combination of monocular receptive fields that are either shifted in position or phase. These shifts in either position or phase allow for the simulated binocular neurons to be sensitive to disparity. The relative contributions of phase and position shifts in simple and complex cells combine together in order to create depth perception of an object in 3-dimensional space. Binocular simple cells are modeled as linear neurons. Due to the linear nature of these neurons, positive and negative values are encoded by two neurons where one neuron encodes the positive part and the other the negative part. This results in the neurons being complements of each other where the excitatory region of one binocular simple cell overlaps with the inhibitory region of another. Each neuron's response is limited such that only one may have a non-zero response for any time. This kind of limitation is called halfwave-rectifing. Binocular complex cells are modeled as energy neurons since they do not have discrete on and off regions in their receptive fields. Energy neurons sum the squared responses of two pairs of linear neurons which must be 90 degrees out of phase. Alternatively, they can also be the sum the squared responses of four halfwave-rectified linear neurons.",
            "score": 105.24126291275024
        },
        {
            "docid": "17033211_2",
            "document": "Quantitative models of the action potential . In neurophysiology, several mathematical models of the action potential have been developed, which fall into two basic types. The first type seeks to model the experimental data quantitatively, i.e., to reproduce the measurements of current and voltage exactly. The renowned Hodgkin\u2013Huxley model of the axon from the \"Loligo\" squid exemplifies such models. Although qualitatively correct, the H-H model does not describe every type of excitable membrane accurately, since it considers only two ions (sodium and potassium), each with only one type of voltage-sensitive channel. However, other ions such as calcium may be important and there is a great diversity of channels for all ions. As an example, the cardiac action potential illustrates how differently shaped action potentials can be generated on membranes with voltage-sensitive calcium channels and different types of sodium/potassium channels. The second type of mathematical model is a simplification of the first type; the goal is not to reproduce the experimental data, but to understand qualitatively the role of action potentials in neural circuits. For such a purpose, detailed physiological models may be unnecessarily complicated and may obscure the \"forest for the trees\". The Fitzhugh-Nagumo model is typical of this class, which is often studied for its entrainment behavior. Entrainment is commonly observed in nature, for example in the synchronized lighting of fireflies, which is coordinated by a burst of action potentials; entrainment can also be observed in individual neurons. Both types of models may be used to understand the behavior of small biological neural networks, such as the central pattern generators responsible for some automatic reflex actions. Such networks can generate a complex temporal pattern of action potentials that is used to coordinate muscular contractions, such as those involved in breathing or fast swimming to escape a predator.",
            "score": 137.45409870147705
        }
    ],
    "r": [
        {
            "docid": "3717_69",
            "document": "Brain . Theorists have worked to understand these response patterns by constructing mathematical models of neurons and neural networks, which can be simulated using computers. Some useful models are abstract, focusing on the conceptual structure of neural algorithms rather than the details of how they are implemented in the brain; other models attempt to incorporate data about the biophysical properties of real neurons. No model on any level is yet considered to be a fully valid description of brain function, though. The essential difficulty is that sophisticated computation by neural networks requires distributed processing in which hundreds or thousands of neurons work cooperatively\u2014current methods of brain activity recording are only capable of isolating action potentials from a few dozen neurons at a time.",
            "score": 190.9309844970703
        },
        {
            "docid": "53757504_6",
            "document": "Viktor K. Jirsa . The Virtual Brain is a free open source neuroinformatics tool designed to aid in the exploration of network mechanisms of brain function and associated pathologies. TVB provides the possibility to feed computational neuronal network models with information about structural and functional imaging data including population (sEEG/EEG/MEG) activity, spatially highly resolved whole brain metabolic/vascular signals (fMRI) and global measures of neuronal connections (DTI) \u2013 for intact as well as pathologically altered connectivity. TVB is model agnostic and offers a wide range of neural population models to be used as network nodes. The software infrastructure of the Virtual Brain is composed of a functional core running the large-scale brain simulations independently or in batch mode, a web based interface to access the simulator, as well as a command line interface to develop more extensive applications. All simulations may be performed on workstations and labtops, as well as on high-performance clusters (HPCs). Manipulations of network parameters within the Virtual Brain allow researchers and clinicians to test the effects of experimental paradigms, interventions (such as stimulation and surgery) and therapeutic strategies (such as pharmaceutical interventions targeting local areas). The computational environment allows the user to visualise the simulated data in 2D and 3D and perform data analyses in the same way as commonly performed with empirical data.",
            "score": 187.13125610351562
        },
        {
            "docid": "3062721_16",
            "document": "Neuroinformatics . Biology is concerned with molecular data (from genes to cell specific expression); medicine and anatomy with the structure of synapses and systems level anatomy; engineering \u2013 electrophysiology (from single channels to scalp surface EEG), brain imaging; computer science \u2013 databases, software tools, mathematical sciences \u2013 models, chemistry \u2013 neurotransmitters, etc. Neuroscience uses all aforementioned experimental and theoretical studies to learn about the brain through its various levels. Medical and biological specialists help to identify the unique cell types, and their elements and anatomical connections. Functions of complex organic molecules and structures, including a myriad of biochemical, molecular, and genetic mechanisms which regulate and control brain function, are determined by specialists in chemistry and cell biology. Brain imaging determines structural and functional information during mental and behavioral activity. Specialists in biophysics and physiology study physical processes within neural cells neuronal networks. The data from these fields of research is analyzed and arranged in databases and neural models in order to integrate various elements into a sophisticated system; this is the point where neuroinformatics meets other disciplines.",
            "score": 169.15274047851562
        },
        {
            "docid": "33548913_9",
            "document": "Dehaene\u2013Changeux model . Furthermore, exploring the neural dynamics of cognitive efforts after, \"inter alia\", the Dehaene-Changeux Model, Kitzbichler et al. (2011b) demonstrated how cognitive effort breaks the modularity of mind to make human brain functional networks transiently adopt a more efficient but less economical configuration. Werner (2007a) used the Dehaene-Changeux Global Neuronal Workspace to defend the use of statistical physics approaches for exploring phase transitions, scaling and universality properties of the so-called \"Dynamic Core\" of the brain, with relevance to the macroscopic electrical activity in EEG and EMG. Furthermore, building from the Dehaene-Changeux Model, Werner (2007b) proposed that the application of the twin concepts of scaling and universality of the theory of non-equilibrium phase transitions can serve as an informative approach for elucidating the nature of underlying neural-mechanisms, with emphasis on the dynamics of recursively reentrant activity flow in intracortical and cortico-subcortical neuronal loops. Friston (2000) also claimed that \"\"the nonlinear nature of asynchronous coupling enables the rich, context-sensitive interactions that characterize real brain dynamics, suggesting that it plays a role in functional integration that may be as important as synchronous interactions\"\".",
            "score": 167.74510192871094
        },
        {
            "docid": "29020457_3",
            "document": "Gordon M. Shepherd . His electrophysiological studies of the olfactory bulb in 1963 produced one of the first examples of a brain microcircuit. Building on this work he collaborated with Wilfrid Rall at NIH to construct the first computational models of brain neurons. This predicted dendrodendritic interactions in the olfactory bulb, subsequently confirmed by electronmicroscopy, hypothesized to mediate lateral inhibition of the sensory input. A collaboration in 1975, using new methods of brain imaging, revealed that odors are encoded by different spatial activity patterns in the olfactory glomeruli of the olfactory bulb. This showed that the neural basis of smell in virtually all vertebrates involves odor representation by glomerular activity patterns (\"odor images\") which are then processed by lateral inhibition mediated by the dendrodendritic circuits. Shepherd's lab continued to use the olfactory bulb as a general model for the integrative actions of neuronal dendrites. This showed that dendrites contain multiple computational units; backpropagating action potentials in dendrites carry out specific functional operations; and dendritic spines can function as semi-independent input-output units. The lab also provided a basic circuit for olfactory cortex. New concepts to replace the classical \"neuron doctrine\" were suggested, and the term \"microcircuit\" for characterizing specific patterns of synaptic interactions in the nervous system.",
            "score": 166.3592987060547
        },
        {
            "docid": "179092_7",
            "document": "Neurolinguistics . Much work in neurolinguistics involves testing and evaluating theories put forth by psycholinguists and theoretical linguists. In general, theoretical linguists propose models to explain the structure of language and how language information is organized, psycholinguists propose models and algorithms to explain how language information is processed in the mind, and neurolinguists analyze brain activity to infer how biological structures (populations and networks of neurons) carry out those psycholinguistic processing algorithms. For example, experiments in sentence processing have used the ELAN, N400, and P600 brain responses to examine how physiological brain responses reflect the different predictions of sentence processing models put forth by psycholinguists, such as Janet Fodor and Lyn Frazier's \"serial\" model, and Theo Vosse and Gerard Kempen's \"unification model\". Neurolinguists can also make new predictions about the structure and organization of language based on insights about the physiology of the brain, by \"generalizing from the knowledge of neurological structures to language structure\".",
            "score": 165.1131591796875
        },
        {
            "docid": "2567511_11",
            "document": "Neural engineering . Engineers employ quantitative tools that can be used for understanding and interacting with complex neural systems. Methods of studying and generating chemical, electrical, magnetic, and optical signals responsible for extracellular field potentials and synaptic transmission in neural tissue aid researchers in the modulation of neural system activity (Babb et al. 2008).  To understand properties of neural system activity, engineers use signal processing techniques and computational modeling (Eliasmith & Anderson 2003). To process these signals, neural engineers must translate the voltages across neural membranes into corresponding code, a process known as neural coding. Neural coding uses studies on how the brain encodes simple commands in the form of central pattern generators (CPGs), movement vectors, the cerebellar internal model, and somatotopic maps to understand movement and sensory phenomena. Decoding of these signals in the realm of neuroscience is the process by which neurons understand the voltages that have been transmitted to them. Transformations involve the mechanisms that signals of a certain form get interpreted and then translated into another form. Engineers look to mathematically model these transformations (Eliasmith & Anderson 2003).  There are a variety of methods being used to record these voltage signals. These can be intracellular or extracellular. Extracellular methods involve single-unit recordings, extracellular field potentials, and amperometry; more recently, multielectrode arrays have been used to record and mimic signals.",
            "score": 164.141845703125
        },
        {
            "docid": "30525054_7",
            "document": "Anders Dale . In a 2003 interview, Dale explained that he had \u201calways been interested in using quantitative modeling methods and simulations to answer biological questions,\u201d and that as a Harvard student he had been \u201cinterested in approaching connectionist neural networks from a more biological angle.\u201d When he went to UCSD to continue his graduate work his interest \u201cshifted to learning how to test models of how the brain works. Ideally you'd like to test your models not in anesthetized animals and brain slices, but by measuring brain activity in humans non-invasively. I wanted to study normal people doing normal tasks. That was what brought me to imaging. My goal was to see what kind of things we can measure non-invasively that can be quantitatively related to the models we want to build...I wanted to know what exactly we are measuring, how can you model it, and how can you relate the signal to what is going on in the brain physiologically...at a level that say you could measure invasively and that you could relate to parameters of quantitative models.\u201d His thesis work at UCSD, he said, \u201cwas on the EEG and MEG forward and inverse problems, and how to use anatomical information to constrain the solutions. It is clear that if you only use EEG or MEG measures, the spatial precision is not good enough to make inferences at a scale that's most useful to neuroscience. That led us into trying to use information with higher spatial resolution to constrain or bias our estimations of the signal sources in the brain.\u201d",
            "score": 163.79295349121094
        },
        {
            "docid": "2860430_23",
            "document": "Neural oscillation . A neural network model describes a population of physically interconnected neurons or a group of disparate neurons whose inputs or signalling targets define a recognizable circuit. These models aim to describe how the dynamics of neural circuitry arise from interactions between individual neurons. Local interactions between neurons can result in the synchronization of spiking activity and form the basis of oscillatory activity. In particular, models of interacting pyramidal cells and inhibitory interneurons have been shown to generate brain rhythms such as gamma activity.",
            "score": 162.4031524658203
        },
        {
            "docid": "4537268_11",
            "document": "Neuroepithelial cell . Researchers have been able to create neural chimeras by combining neurons that developed from embryonic stem cells with glial cells that were also derived from embryonic stem cells. These neural chimeras give researchers a comprehensive way of studying the molecular mechanisms behind cell repair and regeneration via neuroepithelial precursor cells and will hopefully shed light on possible nervous system repair in a clinical setting. In an attempt to identify the key features that differentiate neuroepithelial cells from their progenitor cells, researchers identified an intermediate filament that was expressed by 98% of the neuroepithelial cells of the neural tube, but none of their progenitor cells. After this discovery it became clear that all three cell types in the nervous system resulted from a homogenous population of stem cells. In order make clinical neural repair possible researchers needed to further characterize regional determination of stem cells during brain development by determining what factors commit a precursor to becoming one or the other. While the exact factors that lead to differentiation are unknown, researchers have taken advantage of human-rat neural chimeras to explore the development of human neurons and glial cells in an animal model. These neural chimeras have permitted researchers to look at neurological diseases in an animal model where traumatic and reactive changes can be controlled. Eventually researchers hope to be able to use the information taken from these neural chimera experiments to repair regions of the brain affected by central nervous system disorders. The problem of delivery, however, has still not been resolved as neural chimeras have been shown to circulate throughout the ventricles and incorporate into all parts of the CNS. By finding environmental cues of differentiation, neuroepithelial precursor transplantation could be used in the treatment of many diseases including multiple sclerosis, Huntington\u2019s disease, and Parkinson\u2019s disease. Further exploration of neural chimera cells and chimeric brains will provide evidence for manipulating the correct genes and increasing the efficacy of neural transplant repair.",
            "score": 161.8502197265625
        },
        {
            "docid": "53757504_8",
            "document": "Viktor K. Jirsa . Full brain modelling of the last century was limited to either a few regions of interest modelling or to (mostly unrealistic) approximations of brain connectivity. However, full brain models have always been the interface between human brain imaging and theorising on brain function and dysfunction. In 2002 Jirsa and colleagues demonstrated that the approximations of brain connectivity will never be able to capture most behaviour of brain imaging data (in particular the spatiotemporal symmetries in the data) and thus proposed to use DTI data as a proxy of network connectivity in brain models. Characteristic challenges for this type of large-scale models would be 1) the detailed connection topology and 2) time delays via signal transmission, which do not play a role for modelling on all other levels of organisation. In 2006 Jirsa introduced connectome-based connectivity (from the Cocamac data base with the help of Rolf K\u00f6tter) and presented a large-scale brain network model of resting state brain dynamics in Sendai, Japan, at the Brain Connectivity workshop. Connectome-based brain modelling became an active field of research in the years that followed (Honey et al. 2007; Ghosh et al. 2008; Deco et al. 2009), with many applications devoted to resting state dynamics in healthy subjects, ageing and diseases such as schizophrenia, lesions and epilepsy. Various reviews summarise the findings (Deco et al. 2011, 2013; Kringelbach et al. 2015) and highlight the impact of this new approach. Jirsa and his group have contributed to the conception and development of connectome-based modelling and developed a range of technical tools since the early 2000s (Jirsa & Kelso 2000; Jirsa et al. 2002; Jirsa 2009). Of particular importance are Jirsa\u2019s contributions to a better understanding and treatment of signal transmission time delays in brain networks. The presence of many time delays, which are systematically distributed across the network, is a key characteristic of connectome-based brain models and not encountered in any other system of spatiotemporal pattern formation.",
            "score": 160.5056610107422
        },
        {
            "docid": "8953842_15",
            "document": "Computational auditory scene analysis . While many models consider the audio signal as a complex combination of different frequencies, modeling the auditory system can also require consideration for the neural components. By taking a holistic process, where a stream (of feature-based sounds) correspond to neuronal activity distributed in many brain areas, the perception of the sound could be mapped and modeled. Two different solutions have been proposed to the binding of the audio perception and the area in the brain. Hierarchical coding models many cells to encode all possible combinations of features and objects in the auditory scene. Temporal or oscillatory correlation addressing the binding problem by focusing on the synchrony and desynchrony between neural oscillations to encode the state of binding among the auditory features. These two solutions are very similar to the debacle between place coding and temporal coding. While drawing from modeling neural components, another phenomenon of ASA comes into play with CASA systems: the extent of modeling neural mechanisms. The studies of CASA systems have involved modeling some known mechanisms, such as the bandpass nature of cochlear filtering and random auditory nerve firing patterns, however, these models may not lead to finding new mechanisms, but rather give an understanding of purpose to the known mechanisms.",
            "score": 159.7691650390625
        },
        {
            "docid": "40466325_3",
            "document": "Cerebral organoid . Using human pluripotent stem cells to create \"in vitro\" cerebral organoids allows researchers to  summarize current developmental mechanisms for human neural tissue as well as study the roots of  human neurological diseases. Cerebral organoids are an investigative tool, used to understand how disease  pathology works. These organoids can be used in experiments that current \"in vitro\" methods are too simple for, while also being more human applicable than rodent or other mammalian models. Historically, major  breakthroughs in how the brain works have resulted from injury or disorder in human brain function, leading to understanding of how regions of the brain work. An \"in vitro\" human brain model would allow  for the next wave in understanding of the human brain.",
            "score": 159.0543212890625
        },
        {
            "docid": "2860430_25",
            "document": "Neural oscillation . The Kuramoto model of coupled phase oscillators is one of the most abstract and fundamental models used to investigate neural oscillations and synchronization. It captures the activity of a local system (e.g., a single neuron or neural ensemble) by its circular phase alone and hence ignores the amplitude of oscillations (amplitude is constant). Interactions amongst these oscillators are introduced by a simple algebraic form (such as a sine function) and collectively generate a dynamical pattern at the global scale. The Kuramoto model is widely used to study oscillatory brain activity and several extensions have been proposed that increase its neurobiological plausibility, for instance by incorporating topological properties of local cortical connectivity. In particular, it describes how the activity of a group of interacting neurons can become synchronized and generate large-scale oscillations. Simulations using the Kuramoto model with realistic long-range cortical connectivity and time-delayed interactions reveal the emergence of slow patterned fluctuations that reproduce resting-state BOLD functional maps, which can be measured using fMRI.",
            "score": 158.5787811279297
        },
        {
            "docid": "586357_19",
            "document": "Artificial general intelligence . There are some research projects that are investigating brain simulation using more sophisticated neural models, implemented on conventional computing architectures. The Artificial Intelligence System project implemented non-real time simulations of a \"brain\" (with 10 neurons) in 2005. It took 50 days on a cluster of 27 processors to simulate 1 second of a model. The Blue Brain project used one of the fastest supercomputer architectures in the world, IBM's Blue Gene platform, to create a real time simulation of a single rat neocortical column consisting of approximately 10,000 neurons and 10 synapses in 2006. A longer term goal is to build a detailed, functional simulation of the physiological processes in the human brain: \"It is not impossible to build a human brain and we can do it in 10 years,\" Henry Markram, director of the Blue Brain Project said in 2009 at the TED conference in Oxford. There have also been controversial claims to have simulated a cat brain. Neuro-silicon interfaces have been proposed as an alternative implementation strategy that may scale better.",
            "score": 158.36264038085938
        },
        {
            "docid": "1171552_12",
            "document": "Terry Sejnowski . The long-range goal of Sejnowski's research is to understand the computational resources of brains and to build linking principles from brain to behavior using computational models. This goal is being pursued with a combination of theoretical and experimental approaches at several levels of investigation ranging from the biophysical level to the systems level. Hippocampal and cortical slice preparations are being used to explore the properties of single neurons and synapses, including the precision of spike firing and the influence of neuromodulators. Biophysical models of electrical and chemical signal processing within neurons are used as an adjunct to physiological experiments. New techniques have been developed for modeling cell signaling using Monte Carlo methods (MCell).",
            "score": 156.9864044189453
        },
        {
            "docid": "2860430_20",
            "document": "Neural oscillation . Computational models adopt a variety of abstractions in order to describe complex oscillatory dynamics observed in brain activity. Many models are used in the field, each defined at a different level of abstraction and trying to model different aspects of neural systems. They range from models of the short-term behaviour of individual neurons, through models of how the dynamics of neural circuitry arise from interactions between individual neurons, to models of how behaviour can arise from abstract neural modules that represent complete subsystems.",
            "score": 156.83416748046875
        },
        {
            "docid": "1935504_2",
            "document": "Functional integration (neurobiology) . Functional integration is the study of how brain regions work together to process information and effect responses. Though functional integration frequently relies on anatomic knowledge of the connections between brain areas, the emphasis is on how large clusters of neurons \u2013 numbering in the thousands or millions \u2013 fire together under various stimuli. The large datasets required for such a whole-scale picture of brain function have motivated the development of several novel and general methods for the statistical analysis of interdependence, such as dynamic causal modelling and statistical linear parametric mapping. These datasets are typically gathered in human subjects by non-invasive methods such as EEG/MEG, fMRI, or PET. The results can be of clinical value by helping to identify the regions responsible for psychiatric disorders, as well as to assess how different activities or lifestyles affect the functioning of the brain.",
            "score": 155.6870574951172
        },
        {
            "docid": "33818014_23",
            "document": "Nervous system network models . Computational science is an interdisciplinary field that combines engineering, biology, control systems, brain functions, physical sciences, and computer science. It has fundamental development models done at the lower levels of ions, neurons, and synapses, as well as information propagation between neurons. These models have established the enabling technology for higher-level models to be developed. They are based on chemical and electrical activities in the neurons for which electrical equivalent circuits are generated. A simple model for the neuron with predominantly potassium ions inside the cell and sodium ions outside establishes an electric potential on the membrane under equilibrium, i.e., no external activity, condition. This is called the resting membrane potential, which can be determined by Nernst Equation (Nernst, W. (1888)). An equivalent electrical circuit for a patch of membrane, for example an axon or dendrite, is shown in Figure 5. E and E are the potentials associated with the potassium and sodium channels respectively and R and R are the resistances associated with them. C is the capacitance of the membrane and I is the source current, which could be the test source or the signal source (action potential). The resting potential for potassium-sodium channels in a neuron is about -65 millivolts. The membrane model is for a small section of the cell membrane; for larger sections it can be extended by adding similar sections, called compartments, with the parameter values being the same or different. The compartments are cascaded by a resistance, called axial resistance. Figure 6 shows a compartmental model of a neuron that is developed over the membrane model. Dendrites are the postsynaptic receptors receiving inputs from other neurons; and the axon with one or more axon terminals transmits neurotransmitters to other neurons. The second building block is the Hodgkin-Huxley (HH) model of the action potential. When the membrane potential from the dendrites exceeds the resting membrane potential, a pulse is generated by the neuron cell and propagated along the axon. This pulse is called the action potential and HH model is a set of equations that is made to fit the experimental data by the design of the model and the choice of the parameter values.",
            "score": 155.6370849609375
        },
        {
            "docid": "22000_10",
            "document": "Neural Darwinism . Criticism of Neural \"Darwinism\" was made by Francis Crick on the basis that neuronal groups are instructed by the environment rather than undergoing blind variation. A recent review by Fernando, Szathmary and Husbands explains why Edelman's Neural Darwinism is not Darwinian because it does not contain units of evolution as defined by John Maynard Smith. It is selectionist in that it satisfies the Price equation, but there is no mechanism in Edelman's theory that explains how information can be transferred between neuronal groups. A recent theory called Evolutionary Neurodynamics being developed by Eors Szathmary and Chrisantha Fernando has proposed several means by which true replication may take place in the brain. These neuronal models have been extended by Fernando in a later paper . In the most recent model, three plasticity mechanisms i) multiplicative STDP, ii) LTD, and iii) Heterosynaptic competition, are responsible for copying of connectivity patterns from one part of the brain to another. Exactly the same plasticity rules can explain experimental data for how infants do causal learning in the experiments conducted by Alison Gopnik. It has also been shown that by adding Hebbian learning to neuronal replicators the power of neuronal evolutionary computation may actually be greater than natural selection in organisms.",
            "score": 155.12571716308594
        },
        {
            "docid": "33818014_8",
            "document": "Nervous system network models . On a high level representation, the neurons can be viewed as connected to other neurons to form a neural network in one of three ways. A specific network can be represented as a physiologically (or anatomically) connected network and modeled that way. There are several approaches to this (see Ascoli, G.A. (2002) Sporns, O. (2007), Connectionism, Rumelhart, J. L., McClelland, J. L., and PDP Research Group (1986), Arbib, M. A. (2007)). Or, it can form a functional network that serves a certain function and modeled accordingly (Honey, C. J., Kotter, R., Breakspear, R., & Sporns, O. (2007), Arbib, M. A. (2007)). A third way is to hypothesize a theory of the functioning of the biological components of the neural system by a mathematical model, in the form of a set of mathematical equations. The variables of the equation are some or all of the neurobiological properties of the entity being modeled, such as the dimensions of the dendrite or the stimulation rate of action potential along the axon in a neuron. The mathematical equations are solved using computational techniques and the results are validated with either simulation or experimental processes. This approach to modeling is called computational neuroscience. This methodology is used to model components from the ionic level to system level of the brain. This method is applicable for modeling integrated system of biological components that carry information signal from one neuron to another via intermediate active neurons that can pass the signal through or create new or additional signals. The computational neuroscience approach is extensively used and is based on two generic models, one of cell membrane potential Goldman (1943) and Hodgkin and Katz (1949), and the other based on Hodgkin-Huxley model of action potential (information signal).",
            "score": 154.32174682617188
        },
        {
            "docid": "31075772_15",
            "document": "Thought identification . On 31 January 2012 Brian Pasley and colleagues of University of California Berkeley published their paper in PLoS Biology wherein subjects' internal neural processing of auditory information was decoded and reconstructed as sound on computer by gathering and analyzing electrical signals directly from subjects' brains. The research team conducted their studies on the superior temporal gyrus, a region of the brain that is involved in higher order neural processing to make semantic sense from auditory information. The research team used a computer model to analyze various parts of the brain that might be involved in neural firing while processing auditory signals. Using the computational model, scientists were able to identify the brain activity involved in processing auditory information when subjects were presented with recording of individual words. Later, the computer model of auditory information processing was used to reconstruct some of the words back into sound based on the neural processing of the subjects. However the reconstructed sounds were not of good quality and could be recognized only when the audio wave patterns of the reconstructed sound were visually matched with the audio wave patterns of the original sound that was presented to the subjects. However this research marks a direction towards more precise identification of neural activity in cognition.",
            "score": 153.86778259277344
        },
        {
            "docid": "34004373_4",
            "document": "Sensory maps and brain development . The computational map is the \u201ckey building block in the infrastructure of information processing by the nervous system.\u201d Computation defined as the transformation in the representation of information is the essence of brain function. Computational maps are involved in processing sensory information and motor programming, and they contain derived information that is accessible to higher-order processing regions. The first computational map to be proposed was the Jeffress model (1948) which stated that the computation of sound localization was dependent upon timing differences of sensory input. Since the introduction of the Jeffress model, more general guiding principles for relating brain maps to the properties of the computations they perform have been proposed. One of the proposed models is that computations are distributed across parallel processors like computers; with this model, computer processing is a model for computations performed by the brain. More recently, the \u201celastic net\u201d model has been proposed after studying how the primary visual cortex overlaps multiple visual maps, such as visual field position, orientation, direction, ocular dominance, and spatial frequency. The elastic net uses parallel algorithms to analyze the visual field and allows for optimized trade-off between coverage and continuity.",
            "score": 153.85670471191406
        },
        {
            "docid": "2534964_17",
            "document": "Sensory processing . In the future, research on sensory integration will be used to better understand how different sensory modalities are incorporated within the brain to help us perform even the simplest of tasks. For example, we do not currently have the understanding needed to comprehend how neural circuits transform sensory cues into changes in motor activities. More research done on the sensorimotor system can help understand how these movements are controlled. This understanding can potentially be used to learn more about how to make better prosthetics, and eventually help patients who have lost the use of a limb. Also, by learning more about how different sensory inputs can combine can have profound effects on new engineering approaches using robotics. The robot's sensory devices may take in inputs of different modalities, but if we understand multisensory integration better, we might be able to program these robots to convey these data into a useful output to better serve our purposes.",
            "score": 153.13803100585938
        },
        {
            "docid": "10974486_2",
            "document": "Storage (memory) . Memory is the ability of the mind to store and recall information that was previously acquired. Memory is processed through three fundamental processing stages: storage, encoding, and retrieval. Storing refers to the process of placing newly acquired information into memory, which is modified in the brain for easier storage. Encoding this information makes the process of retrieval easier for the brain where it can be recalled and brought into conscious thinking. Modern memory psychology differentiates between the two distinct types of memory storage: short-term memory and long-term memory. In addition, different memory models have suggested variations of existing short- and long-term memory to account for different ways of storing memory. The memory it can be defined as the circuit or a device which can store the information like programs data and results. Memory is generally used for the faster form and store for the slower form",
            "score": 152.46694946289062
        },
        {
            "docid": "41578765_18",
            "document": "Paul Glimcher . Glimcher\u2019s research aims to describe the neural events that underlie behavioral decision-making using tools from neuroscience, psychology, and economics. His research merges psychological and economic models with computational neuroscience, including pioneering uses of fMRI (function magnetic resonance imaging) for behavioral science, to understand how value is encoded in the brain and how the brain uses those neural representations of value to guide decision-making; for example, how the brain carries out delay discounting or action-selection in the face of both risk and ambiguity. His laboratory in NYU\u2019s Center for Neural Science uses a wide range of methods including cohort studies in experimental economics, brain imaging, and single-neuron studies in non-human animals.",
            "score": 152.11463928222656
        },
        {
            "docid": "43278016_12",
            "document": "Joe Z. Tsien . In 2015, Tsien developed the \"Theory of Connectivity\" to explain the design principle upon which evolution and development may construct the brain to be capable of generating intelligence. This theory has made six predictions which have received supportive evidence by a recent set of experiments on both the mouse brain and hamster brain. At its core, the \"Theory of Connectivity\" predicts that the cell assemblies in the brain are not random, rather they should conform to the power-of-two-based equation, N = 2 - 1, to form the pre-configured building block termed as the functional connectivity motif (FCM). Instead of using a single neuron as the computational unit in some extremely simple brains, the theory denotes that in most brains, a group of neurons exhibiting similar tuning properties, termed as a neural clique, should serve as the basic computing processing unit (CPU). Defined by the power-of-two-based equation, N = 2 - 1, each FCM consists of principal-projection neuron cliques (N), ranging from those specific cliques receiving specific information inputs (i) to those general and sub-general cliques receiving various combinatorial convergent inputs. As the evolutionarily conserved logic, its validation requires experimental demonstrations of the following three major properties: 1) Anatomical prevalence - FCMs are prevalent across neural circuits, regardless of gross anatomical shapes; 2) Species conservancy - FCMs are conserved across different animal species; and 3) Cognitive universality - FCMs serve as a universal computational logic at the cell-assembly level for processing a variety of cognitive experiences and flexible behaviors. More importantly, this \"Theory of Connectivity\" further predicts that the specific-to-general combinatorial connectivity pattern within FCMs should be pre-configured by evolution, and emerge innately from development as the brain's computational primitives. This proposed design principle can also explain the general purpose and computational algorithm of the neocortex. This proposed design principle of intelligence can be examined via various experiments and also be modeled by neuromorphic engineers and computer scientists. However, Dr. Joe Tsien cautions that artificial general intelligence based on the brain's principles can come with great benefits and, potentially, even greater risks.",
            "score": 152.05209350585938
        },
        {
            "docid": "15774067_27",
            "document": "Synaptic noise . To understand the future of synaptic noise research, it would be essential to discuss the work of Alain Destexhe, a Belgian doctor who has greatly studied the importance of synaptic noise in neuronal connections. He uses the dynamic-clamp technique to understand the presence and characteristics of noise. While voltage-gated clamps record configurations, dynamic-clamp allows for the control of conductance by way of computer. A computational model of synaptic noise is created and is then implemented into the neuron, simulating synaptic noise. This can be used to compare with in-vivo conditions. Destexhe states that future research can be directed towards four possible ways, in reflection of his research with dynamic-clamp. First, it could be beneficial to understand the control of synaptic noise so that the modulation of noise can be used on humans to turn unresponsive networks into a responsive state. Next, it would be necessary to understand how external noise interacts with internal neuronal properties more fully to coincide models with experimental facts. There also exists the need to further investigate experimentally the methods of dendritic integration and the role of synaptic noise when it is present. Finally, he found support that synaptic noise enhances temporal resolution in neurons, yet experimental proof has not been done to further elaborate on past modeling studies. By use of dynamic-clamp, these pieces of information clarify the role of synaptic noise in the brain and how it can be harnessed for specific therapies.",
            "score": 152.00523376464844
        },
        {
            "docid": "33818014_20",
            "document": "Nervous system network models . There are three views of modules for modeling. They are (1) modules for brain structures, (2) modules as schemas, and (3) modules as interfaces. Figure 3 presents the modular design of a model for reflex control of saccades (Arbib, M. A. (2007)). It involves two main modules, one for superior colliculus (SC), and one for brainstem. Each of these is decomposed into submodules, with each submodule defining an array of physiologically defined neurons. In Figure 3(b) the model of Figure 3(a) is embedded into a far larger model which embraces various regions of cerebral cortex (represented by the modules Pre-LIP Vis, Ctx., LIP, PFC, and FEF), thalamus, and basal ganglia. While the model may indeed be analyzed at this top level of modular decomposition, we need to further decompose basal ganglia, BG, as shown in Figure 3(c) if we are to tease apart the role of dopamine in differentially modulating (the 2 arrows shown arising from SNc) the direct and indirect pathways within the basal ganglia (Crowley, M. (1997)). Neural Simulation Language (NSL) has been developed to provide a simulation system for large-scale general neural networks. It provides an environment to develop an object-oriented approach to brain modeling. NSL supports neural models having as basic data structure neural layers with similar properties and similar connection patterns. Models developed using NSL are documented in Brain Operation Database (BODB) as hierarchically organized modules that can be decomposed into lower levels.",
            "score": 151.8507080078125
        },
        {
            "docid": "21855574_5",
            "document": "Brain simulation . The connectivity of the neural circuit for touch sensitivity of the simple C. elegans nematode (roundworm) was mapped in 1985 and partly simulated in 1993. Since 2004, many software simulations of the complete neural and muscular system have been developed, including simulation of the worm's physical environment. Some of these models have been made available for download. However, there is still a lack of understanding of how the neurons and the connections between them generate the surprisingly complex range of behaviors that are observed in the relatively simple organism. This contrast between the apparent simplicity of how the mapped neurons interact with their neighbours, and exceeding complexity of the overall brain function, is an example of an emergent property. Interestingly, this kind of emergent property is paralleled within artificial neural networks, the neurons of which are exceedingly simple compared to their often complex, abstract outputs.",
            "score": 151.77027893066406
        },
        {
            "docid": "26277390_7",
            "document": "Virtual geographic environments . VGEs were created to provide virtual environments that correspond to the real world to allow the conduct of open CAGEs, in which human\u2013environment interactions can be represented, simulated, and analyzed. Furthermore, VGEs can help researchers to reproduce the past, replicate the current world, and predict the future (Batty 1997; Lin and Gong 2001; Lin, Huang, and Lu 2009). With a VGE, researchers from different areas and fields can collaboratively perform CAGEs. First, they can build virtual geographic scenes of different scales with integrated geographic data derived from various resources. Second, the distribution and dynamics of geographic features not only involve statistical relationships but also mechanisms driving the phenomenon in question (Goodchild, Yuan, and Cova 2007). A VGE allows researchers to simulate and explore those dynamic geographic phenomena and processes using geographic analysis models (e.g., the Fifth- Generation Pennsylvania State University/National Center for Atmospheric Research Mesoscale Model or Gaussian Plume Model). Third, social factors can be subsequently incorporated into the virtual environment for geographic analysis and decision making. For example, emissions of polluted air caused by economic development and population expansion can be taken into account as negative impacts for experiments related to air quality management in the workspace. Public users can observe interactions between their activities and the resultant air quality change or directly participate in this virtual environment as avatars through multidimensional and multisense interactive interfaces, especially in microscenes, to experience and interact with the \u201creal polluted world.\u201d They can improve or worsen the situation through their virtual activities. In this way, users not only feel the environments \u201cin person,\u201d but they also \u201cbring\u201d their spatial knowledge and virtual spatial behaviors into the VGE. Fourth, based on the combined studies described earlier, multidisciplinary researchers can communicate and collaborate with corresponding tools to visually and interactively conduct and repeat comprehensive geographic experiments in a VGE. They can also verify the results, perform geographic analyses, and solve geographic issues.",
            "score": 150.49266052246094
        },
        {
            "docid": "54462558_3",
            "document": "Wei Ji Ma . Ma researches how the human brain represents and processes uncertainty. A large portion of his academic work is devoted to the construction Bayesian inference models which describe how an observer arrives at beliefs about things in the world from noisy information. This modeling spans the range of describing the behavior of an observer, for example how an observer might infer two sensory inputs arise from a common source, to the activity of a population of neurons implementing the Bayesian operations. A complimentary line of inquiry is studying encoding strategies in working memory, specifically highlighting the relationships between the role of noisy representations of objects in the brain and the number that can be recalled correctly. Broadly, his modeling focuses can be described as examining encoding models, decision rules, and probabilistic computations.",
            "score": 150.35809326171875
        }
    ]
}