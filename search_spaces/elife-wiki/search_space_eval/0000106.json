{
    "q": [
        {
            "docid": "4833512_4",
            "document": "Mu wave . The mirror neuron system consists of a class of neurons that was first studied in the 1990s in macaque monkeys. Studies have found sets of neurons that fire when these monkeys perform simple tasks and also when the monkeys view others performing the same simple tasks. This suggests they play a role in mapping others' movements into the brain without actually physically performing the movements. These sets of neurons are called mirror neurons and together make up the mirror neuron system. Mu waves are suppressed when these neurons fire, a phenomenon which allows researchers to study mirror neuron activity in humans. There is evidence that mirror neurons exist in humans as well as in non-human animals. The right fusiform gyrus, left inferior parietal lobule, right anterior parietal cortex, and left inferior frontal gyrus are of particular interest. Some researchers believe that mu wave suppression can be a consequence of mirror neuron activity throughout the brain, and represents a higher-level integrative processing of mirror neuron activity. Tests in both monkeys (using invasive measuring techniques) and humans (using EEG and fMRI) have found that these mirror neurons not only fire during basic motor tasks, but also have components that deal with intention. There is evidence of an important role for mirror neurons in humans, and mu waves may represent a high level coordination of those mirror neurons.",
            "score": 130.05217099189758
        },
        {
            "docid": "6989597_15",
            "document": "Premovement neuronal activity . Approximately 65% of the neurons in the pre-motor cortex are responsible for conditional \"closed-loop\" motor tasks. In experimentation using monkeys, when they were trained to reach in different directions, depending on the specified visual cue, the approximately coordinated lateral pre-motor neurons began to fire at the appearance of that specified cue, but before the actual signal to perform the movement. As learning takes place, to associate a new visual cue with a particular movement, the approximately coordinated neurons increase their rate of fire during the time between the initial specified cue and the actual signal for the initiation of the movement. It now seems that these specific neurons do not command the initiation of the movements but the intention to perform the movements. Thus these pre-motor neurons are especially involved in the selection of movements based on external events.",
            "score": 77.63908433914185
        },
        {
            "docid": "1287722_9",
            "document": "Barrel cortex . As well as combinations of which whiskers have been stimulated, neurons may also respond to specific types of whisker stimulation. The simplest response, seen in neurons within the layer IV barrel cortex, directly code for whisker displacement. That is to say, that the neuron within a given barrel will fire when the whisker that barrel represents is moved at a rate that is roughly proportional to the angular displacement of the neuron. These neurons also show directional sensitivity; certain neurons will only fire when the whisker is moved in a specific direction. Deflection-based firing neurons can sustain their response throughout the deflection of the whisker. Other neurons respond to the initial deflection, but then quickly return to their previous level of activity. Much of this activity is also modulated by the behaviour of the animal - rats and mice actively move their whiskers to explore their environment, and the response of a neuron to a particular stimulus can vary depending on what the animal is doing.",
            "score": 92.37356925010681
        },
        {
            "docid": "48776333_14",
            "document": "Sun compass in animals . For some animals, the sun is a form of visual stimulus used as a tool for navigation. As seen in birds and bees, the animal will orient their body at a certain angle in relation to the sun and the time of day. This external stimuli activates a portion of the brain (in necessary for navigation and allows the organism to adjust their orientation in relation to the sun). That is to say, if the animal leaves its nest in the morning when the sun is low in the sky and plans to head in a known direction, the animal will travel in a certain direction with the sun in a position related to its body (e.g. to travel West, the sun could be on the animal's right side during navigation). This form of navigation is not as simple as observing a stimulus and acting accordingly. Studies have shown that animals may use other \"tricks\" like the length and direction of shadows to determine where the sun is during time shifts and then calculate the direction they should travel. For example, above the Tropic of Cancer, the sun will always be South at its zenith (highest point) so short shadows will point North. Animals tend to incorporate several types of navigation techniques, like magnetic orientation and landmarks, to their repertoire in order to perform normal navigation or to migrate.",
            "score": 79.57190299034119
        },
        {
            "docid": "31715062_3",
            "document": "Leo M. Chalupa . His research involves trying to understand how humans and other animals are able to perceive our surroundings and translate that into brain function which in turn leads to some action. For example, an animal identifying a predator and fleeing. Consequently, his research involves studying the retina, the visual system, and the development of visual perception. Using a combination of physiological, anatomical and molecular techniques his research has helped redefine the way we think about the visual system, by demonstrating how genetic and environmental factors play complementary roles in shaping the proper wiring of the visual system.  Specifically, his work has shown that neuronal activity does not instruct the formation of specific connections in the developing visual system, a view widely held in the field of developmental neurobiology. This involved performing the first ever recordings from the primate fetal retina and the manufacture of a novel neurotoxin that selectively depletes cholinergic neurons from the developing retina. He is a co-editor of Development and Organization of the Retina: From Molecules to Function (1998) , The Visual Neurosciences Vol. 1&2 (2004) , Eye, Retina, and Visual System of the Mouse (2008) , and Cerebral Plasticity: New Perspectives (2011)",
            "score": 95.88638365268707
        },
        {
            "docid": "28354637_6",
            "document": "Richard A. Andersen . Early work centered on the discovery and elucidation of cortical gain fields, a general rule of multiplicative computation used by many areas of the cortex. Andersen and Zipser of UCSD developed one of the first neural network models of cortical function, which generated a mathematical basis for testing hypotheses based on laboratory findings. His research established that the posterior parietal cortex (PPC) is involved in forming movement intentions\u2014the early and abstract plans for movement. Previously this part of the brain was thought only to function for spatial awareness and attention. His laboratory discovered the lateral intraparietal area (LIP) in the PPC and established its role in eye movements. He also discovered the parietal reach region, an area involved in forming early reach plans. His lab has also made a number of discoveries related to visual motion perception. He established that the middle temporal area processes the perception of form from motion. He found that the perception of the direction of heading, important for navigation, is computed in the brain using both visual stimuli and eye movement signals. His lab has also determined how eye position and limb position signals are combined for eye-hand coordination.",
            "score": 131.85958683490753
        },
        {
            "docid": "2898964_2",
            "document": "Head direction cells . Head direction (HD) cells are neurons found in a number of brain regions that increase their firing rates above baseline levels only when the animal's head points in a specific direction. They have been reported in rats, monkeys, mice, chinchillas and bats, but are thought to be common to all mammals, perhaps all vertebrates and perhaps even some invertebrates, and to underlie the \"sense of direction\". When the animal's head is facing in the cell's \"preferred firing direction\" these neurons fire at a steady rate (i.e., they do not show adaptation), but firing decreases back to baseline rates as the animal's head turns away from the preferred direction (usually about 45\u00b0 away from this direction).",
            "score": 66.32393527030945
        },
        {
            "docid": "4833512_9",
            "document": "Mu wave . Brain-computer interfaces (BCIs) are a developing technology that clinicians hope will one day bring more independence and agency to the severely physically disabled. Those the technology has the potential to help include people with near-total or total paralysis, such as those with tetraplegia (quadriplegia) or advanced amyotrophic lateral sclerosis (ALS); BCIs are intended to help them to communicate or even move objects such as motorized wheelchairs, neuroprostheses, or robotic grasping tools. Few of these technologies are currently in regular use by people with disabilities, but a diverse array are in development at an experimental level. One type of BCI uses event-related desynchronization (ERD) of the mu wave in order to control the computer. This method of monitoring brain activity takes advantage of the fact that when a group of neurons is at rest they tend to fire in synchrony with each other. When a participant is cued to imagine movement (an \"event\"), the resulting desynchronization (the group of neurons that was firing in synchronous waves now firing in complex and individualized patterns) can be reliably detected and analyzed by a computer. Users of such an interface are trained in visualizing movements, typically of the foot, hand, and/or tongue, which are each in different locations on the cortical homunculus and thus distinguishable by an electroencephalograph (EEG) or electrocorticograph (ECoG) recording of electrical activity over the motor cortex. In this method, computers monitor for a typical pattern of mu wave ERD contralateral to the visualized movement combined with event-related synchronization (ERS) in the surrounding tissue. This paired pattern intensifies with training, and the training increasingly takes the form of games, some of which utilize virtual reality. Some researchers have found that the feedback from virtual reality games is particularly effective in giving the user tools to improve control of his or her mu wave patterns. The ERD method can be combined with one or more other methods of monitoring the brain's electrical activity to create hybrid BCIs, which often offer more flexibility than a BCI that uses any single monitoring method.",
            "score": 98.24144661426544
        },
        {
            "docid": "9627698_46",
            "document": "Child development . According to a study showing the different relationships between limbs of the body and coordination in infants, genetic components have a huge impact on motor development( Piek, Gasson, Barrett, & Case (2002)). Intra-limb correlations, like the strong relationship and distance between hip and knee joints, were studied and proved to affect the way an infant will walk. There are also bigger genetic factors like the tendency to use the left or right side of the body more, predicting the dominant hand early. Sample t-tests proved that there was a significant difference between both sides at 18 weeks for girls and the right side was considered to be more dominant( Piek et al. (2002)). Some factors, like the fact that boys tend to have larger and longer arms are biological constraints that we cannot control, yet have an influence for example, on when an infant will reach  sufficiently. Overall, there are sociological factors and genetic factors that influence motor development.  Nutrition and exercise also determine strength and therefore the ease and accuracy with which a body part can be moved. Flexibility is also affected by nutrition and exercise as well. It has also been shown that the frontal lobe develops posterio-anteriorally (from back to front). This is significant in motor development because the hind portion of the frontal lobe is known to control motor functions. This form of development is known as \"Portional Development\" and explains why motor functions develop relatively quickly during typical childhood development, while logic, which is controlled by the middle and front portions of the frontal lobe, usually will not develop until late childhood and early adolescence. Opportunities to carry out movements help establish the abilities to flex (move toward the trunk) and extend body parts, both capacities are necessary for good motor ability. Skilled voluntary movements such as passing objects from hand to hand develop as a result of practice and learning. Mastery Climate is a suggested successful learning environment for children to promote motor skills by their own motivation. This promotes participation and active learning in children, which according to Piaget's theory of cognitive development is extremely important in early childhood rule.",
            "score": 58.20339894294739
        },
        {
            "docid": "31209304_13",
            "document": "Righting reflex . These automatic postural adjustments can be explained in terms of two reflexes similar to the righting reflex: the vestibulo-ocular reflex (VOR) and the vestibulocollic reflex (VCR). The VOR involves movement of the eyes while the head turns to remain fixated on a stationary image, and the VCR involves control of neck muscles for correction of the head's orientation. During the VOR, the semicircular canals send information to the brain and correct eye movements in the direction opposite head movement by sending excitatory signals to motor neurons on the side opposite to the head rotation. Neurons in the otoliths control not only these signals for control of eye movements, but also signals for head movement correction through the neck muscles. The righting reflex utilizes the VOR and VCR as it brings the body back into position. Visual information under the control of these reflexes creates greater stability for more accurate postural correction.",
            "score": 74.85561347007751
        },
        {
            "docid": "6147487_39",
            "document": "Neural coding . From the theoretical point of view, population coding is one of a few mathematically well-formulated problems in neuroscience. It grasps the essential features of neural coding and yet is simple enough for theoretic analysis. Experimental studies have revealed that this coding paradigm is widely used in the sensor and motor areas of the brain. For example, in the visual area medial temporal (MT), neurons are tuned to the moving direction. In response to an object moving in a particular direction, many neurons in MT fire with a noise-corrupted and bell-shaped activity pattern across the population. The moving direction of the object is retrieved from the population activity, to be immune from the fluctuation existing in a single neuron\u2019s signal. In one classic example in the primary motor cortex, Apostolos Georgopoulos and colleagues trained monkeys to move a joystick towards a lit target. They found that a single neuron would fire for multiple target directions. However it would fire fastest for one direction and more slowly depending on how close the target was to the neuron's 'preferred' direction.",
            "score": 100.18177247047424
        },
        {
            "docid": "14530184_16",
            "document": "Vision in toads . Electrical stimulation experiments demonstrated that the tectum initiates orienting and snapping behaviors. It contains many different visually sensitive neurons, among these Type I and Type II neurons (later named T5.1 and T5.2, respectively). Type I neurons are activated when an object traversing the toad's visual field is extended in the direction of movement; Type II neurons, too, but they will fire less when the object is extended in a direction that is perpendicular to the direction of movement. Those T5.2 neurons display prey-selective properties; see prey feature detectors. The discharge patterns of these neurons \u2013 recorded in freely moving toads \u2013 \"predict\" prey-catching reactions, e.g. the tongue flip of snapping. Their axons project down to the bulbar/spinal motor systems, such as the hypoglossal nucleus which harbors the motor neurons of the tongue muscles. In combination with additional projection neurons, prey-selective cells contribute to the ability of the tectum to initiate orienting behavior and snapping, respectively.",
            "score": 87.21691226959229
        },
        {
            "docid": "6989597_2",
            "document": "Premovement neuronal activity . Premovement neuronal activity in neurophysiological literature refers to neuronal modulations that alter the rate at which neurons fire before a subject produces movement. Through experimentation with multiple animals, predominantly monkeys, it has been shown that several regions of the brain are particularly active and involved in initiation and preparation of movement. Two specific membrane potentials, the bereitschaftspotential, or the BP, and contingent negative variation, or the CNV, play a pivotal role in premovement neuronal activity. Both have been shown to be directly involved in planning and initiating movement. Multiple factors are involved with premovement neuronal activity including motor preparation, inhibition of motor response, programming of the target of movement, closed-looped and open-looped tasks, instructed delay periods, short-lead and long-lead changes, and mirror motor neurons.",
            "score": 75.19950652122498
        },
        {
            "docid": "11134503_10",
            "document": "Posterior parietal cortex . In a study conducted by neuroscientists at New York University, coherent patterns of firing of neurons in the brain's PPC were associated with coordination of different effectors. The researchers examined neurological activity of macaque monkeys while having them perform a variety of tasks that required them to either reach and to simultaneously employ rapid eye movements (saccades) or to only use saccades. The coherent pattern of the firing of neurons in the PPC were only seen when both the eyes and arms were required to move for the same task, but not for tasks that involved only saccades.",
            "score": 127.35583019256592
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 125.31402623653412
        },
        {
            "docid": "38442646_13",
            "document": "Gain-field encoding . This multiplicative property is an effect of recurrent neural circuitry. A target neuron that takes only two types of direct input can only combine them additively. However mathematical models show that when also receiving recursive input from neighboring neurons, the resulting transformation to the target neurons firing rate is multiplicative. In this model, neurons with overlapping receptive fields excite each other, multiplying the strength. Likewise, neurons with non-overlapping receptive fields are inhibitory. The result is a response curve that is a scaled representation of the simple additive model. Observation of human developmental patterns also lend evidence toward this theory of gain-field encoding and gain modulation. Since arm movements are based on both intrinsic and extrinsic models, in order to build these connections one has to learn by self-generating movements and watching. By moving the arms to different parts of space and following with the eyes, the neurons form connections based on mechanical body movements as well as their positioning in an external space. Ideally this is done from every possible gaze angle and position available. This provides your brain with the proper translations by aligning the retinal (extrinsic) and body-centered (intrinsic) representations of space. It is not surprising that before babies develop motor control of their limbs, they tend to flail and watch their own limbs move.",
            "score": 73.07375657558441
        },
        {
            "docid": "2898964_7",
            "document": "Head direction cells . HD cells continue to fire in an organized manner during sleep, as if animals were awake. However, instead of always pointing toward the same direction\u2014the animals are asleep and thus immobile\u2014the neuronal \"compass needle\" moves constantly. In particular, during rapid eye movement sleep, a brain state rich in dreaming activity in humans and whose electrical activity is virtually indistinguishable from the waking brain, this directional signal moves as if the animal is awake: that is, HD neurons are sequentially activated, and the individual neurons representing a common direction during wake are still active, or silent, at the same time.",
            "score": 83.30599975585938
        },
        {
            "docid": "2640086_28",
            "document": "Affective neuroscience . Instead of investigating specific emotions, Kober, et al. 2008 reviewed 162 neuroimaging studies published between 1990-2005 to determine if groups of brain regions show consistent patterns of activation during emotional experience (that is, actively experiencing an emotion first-hand) and during emotion perception (that is, perceiving a given emotion as experienced by another). This meta-analysis used multilevel kernal density analysis (MKDA) to examine fMRI and PET studies, a technique that prevents single studies from dominating the results (particularly if they report multiple nearby peaks) and that enables studies with large sample sizes (those involving more participants) to exert more influence upon the results. MKDA was used to establish a neural reference space that includes the set of regions showing consistent increases across all studies (for further discussion of MDKA see Wager et al. 2007). Next, this neural reference space was partitioned into functional groups of brain regions showing similar activation patterns across studies by first using multivariate techniques to determine co-activation patterns and then using data-reduction techniques to define the functional groupings (resulting in six groups). Consistent with a psychological construction approach to emotion, the authors discuss each functional group in terms more basic psychological operations. The first \u201cCore Limbic\u201d group included the left amygdala, hypothalamus, periaqueductal gray/thalamus regions, and amygdala/ventral striatum/ventral globus pallidus/thalamus regions, which the authors discuss as an integrative emotional center that plays a general role in evaluating affective significance. The second \u201cLateral Paralimbic\u201d group included the ventral anterior insula/frontal operculum/right temporal pole/ posterior orbitofrontal cortex, the anterior insula/ posterior orbitofrontal cortex, the ventral anterior insula/ temporal cortex/ orbitofrontal cortex junction, the midinsula/ dorsal putamen, and the ventral striatum /mid insula/ left hippocampus, which the authors suggest plays a role in motivation, contributing to the general valuation of stimuli and particularly in reward. The third \u201cMedial Prefrontal Cortex\u201d group included the dorsal medial prefrontal cortex, pregenual anterior cingulate cortex, and rostral dorsal anterior cingulate cortex, which the authors discuss as playing a role in both the generation and regulation of emotion. The fourth \u201cCognitive/ Motor Network\u201d group included right frontal operculum, the right interior frontal gyrus, and the pre-supplementray motor area/ left interior frontal gyrus, regions that are not specific to emotion, but instead appear to play a more general role in information processing and cognitive control. The fifth \u201cOccipital/ Visual Association\u201d group included areas V8 and V4 of the primary visual cortex, the medial temporal lobe, and the lateral occipital cortex, and the sixth \u201cMedial Posterior\u201d group included posterior cingulate cortex and area V1 of the primary visual cortex. The authors suggest that these regions play a joint role in visual processing and attention to emotional stimuli.",
            "score": 113.8134834766388
        },
        {
            "docid": "2905826_3",
            "document": "Path integration . Charles Darwin first postulated an inertially-based navigation system in animals in 1873. Studies beginning in the middle of the 20th century confirmed that animals could return directly to a starting point, such as a nest, in the absence of vision and having taken a circuitous outwards journey. This shows that they can use cues to track distance and direction in order to estimate their position, and hence how to get home. This process was named \"path integration\" to capture the concept of continuous integration of movement cues over the journey. Manipulation of inertial cues confirmed that at least one of these movement (or \"idiothetic\") cues is information from the vestibular organs, which detect movement in the three dimensions. Other cues probably include proprioception (information from muscles and joints about limb position), motor efference (information from the motor system telling the rest of the brain what movements were commanded and executed), and optic flow (information from the visual system signaling how fast the visual world is moving past the eyes). Together, these sources of information can tell the animal which direction it is moving, at what speed, and for how long. In addition, sensitivity to the earth's magnetic field for underground animals (e.g., mole rat) can give path integration.",
            "score": 81.94564723968506
        },
        {
            "docid": "226722_25",
            "document": "Functional magnetic resonance imaging . Researchers have checked the BOLD signal against both signals from implanted electrodes (mostly in monkeys) and signals of field potentials (that is the electric or magnetic field from the brain's activity, measured outside the skull) from EEG and MEG. The local field potential, which includes both post-neuron-synaptic activity and internal neuron processing, better predicts the BOLD signal. So the BOLD contrast reflects mainly the inputs to a neuron and the neuron's integrative processing within its body, and less the output firing of neurons. In humans, electrodes can be implanted only in patients who need surgery as treatment, but evidence suggests a similar relationship at least for the auditory cortex and the primary visual cortex. Activation locations detected by BOLD fMRI in cortical areas (brain surface regions) are known to tally with CBF-based functional maps from PET scans. Some regions just a few millimeters in size, such as the lateral geniculate nucleus (LGN) of the thalamus, which relays visual inputs from the retina to the visual cortex, have been shown to generate the BOLD signal correctly when presented with visual input. Nearby regions such as the pulvinar nucleus were not stimulated for this task, indicating millimeter resolution for the spatial extent of the BOLD response, at least in thalamic nuclei. In the rat brain, single-whisker touch has been shown to elicit BOLD signals from the somatosensory cortex.",
            "score": 128.095738530159
        },
        {
            "docid": "41171338_10",
            "document": "Emulation theory of representation . Visual modal specific emulators have been experimentally shown to exist in an experiment by Ernst Mach in 1896. In his experiment, the subjects\u2019 eyes were prevented from moving and then they were exposed to a stimulus that would trigger a saccade. Most subjects reported experiencing their entire visual scene briefly being shift in the opposite direction of the stimulus. Mach thus inferred that there is a mechanism within the visual system producing an a priori estimate of future visual scenes based upon motor commands and current visual stimuli. In a similar experiment on monkeys, this particular emulator was found to exist within a group of neurons within parietal cortex. Furthermore, it was discovered that these neurons began firing before the eye even moved. They only fired, however, if the motor command would result in a visual saccade. This suggests that visual emulators are modally specific.",
            "score": 67.98855686187744
        },
        {
            "docid": "18345264_14",
            "document": "Neural correlates of consciousness . Logothetis and colleagues recorded a variety of visual cortical areas in awake macaque monkeys performing a binocular rivalry task. Macaque monkeys can be trained to report whether they see the left or the right image. The distribution of the switching times and the way in which changing the contrast in one eye affects these leaves little doubt that monkeys and humans experience the same basic phenomenon. In the primary visual cortex (V1) only a small fraction of cells weakly modulated their response as a function of the percept of the monkey while most cells responded to one or the other retinal stimulus with little regard to what the animal perceived at the time. But in a high-level cortical area such as the inferior temporal cortex along the ventral stream almost all neurons responded only to the perceptually dominant stimulus, so that a \"face\" cell only fired when the animal indicated that it saw the face and not the pattern presented to the other eye. This implies that NCC involve neurons active in the inferior temporal cortex: it is likely that specific reciprocal actions of neurons in the inferior temporal and parts of the prefrontal cortex are necessary.",
            "score": 101.81977486610413
        },
        {
            "docid": "599917_9",
            "document": "Mental image . The biological foundation of the mind's eye is not fully understood. Studies using fMRI have shown that the lateral geniculate nucleus and the V1 area of the visual cortex are activated during mental imagery tasks. Ratey writes: The visual pathway is not a one-way street. Higher areas of the brain can also send visual input back to neurons in lower areas of the visual cortex. [...] As humans, we have the ability to see with the mind's eye \u2013 to have a perceptual experience in the absence of visual input. For example, PET scans have shown that when subjects, seated in a room, imagine they are at their front door starting to walk either to the left or right, activation begins in the visual association cortex, the parietal cortex, and the prefrontal cortex - all higher cognitive processing centers of the brain.",
            "score": 140.91589105129242
        },
        {
            "docid": "404084_27",
            "document": "Hebbian theory . Evidence for that perspective comes from many experiments that show that motor programs can be triggered by novel auditory or visual stimuli after repeated pairing of the stimulus with the execution of the motor program (for a review of the evidence, see Giudice et al., 2009). For instance, people who have never played the piano do not activate brain regions involved in playing the piano when listening to piano music. Five hours of piano lessons, in which the participant is exposed to the sound of the piano each time he presses a key, suffices to later trigger activity in motor regions of the brain upon listening to piano music. Consistent with the fact that spike-timing-dependent plasticity occurs only if the presynaptic neuron's firing predicts the post-synaptic neuron's firing, the link between sensory stimuli and motor programs also only seem to be potentiated if the stimulus is contingent on the motor program.",
            "score": 87.51519072055817
        },
        {
            "docid": "9627698_44",
            "document": "Child development . The speed of motor development is rapid in early life, as many of the reflexes of the newborn alter or disappear within the first year, and slows later. Like physical growth, motor development shows predictable patterns of cephalocaudal (head to foot) and proximodistal (torso to extremities) development, with movements at the head and in the more central areas coming under control before those of the lower part of the body or the hands and feet. Types of movement develop in stage-like sequences; for example, locomotion at 6\u20138 months involves creeping on all fours, then proceeds to pulling to stand, \"cruising\" while holding on to an object, walking while holding an adult's hand, and finally walking independently. Older children continue the sequence by walking sideways or backward, galloping, hopping, skipping with one foot and walking with the other, and finally skipping. By middle childhood and adolescence, new motor skills are acquired by instruction or observation rather than in a predictable sequence. There are executive functions of the brain (working memory, timing measure of inhibition and switching) which are important to motor skills. Critiques to the order of Executive Functioning leads to Motor Skills, suggesting Motor Skills can support Executive Functioning in the brain.",
            "score": 52.134068965911865
        },
        {
            "docid": "14368827_6",
            "document": "Ideomotor apraxia . The prevailing hypothesis for the pathophysiology of ideomotor apraxia is that the various brain lesions associated with the disorder somehow disrupt portions of the praxis system. The praxis system is the brain regions that are involved in taking processed sensory input, accessing of stored information about tools and gestures, and translating these into a motor output. Buxbaum et al. have proposed that the praxis system involves three distinct parts: stored gesture representations, stored tool knowledge, and a \"dynamic body schema.\" The first two store information about the representation of gestures in the brain and the characteristic movements of tools. The body schema is a brain model of the body and its position in space. The praxis system relates the stored information about a movement type to how the dynamic, i.e. changing, body representation varies as the movement progresses. It is still not clear how this system maps out onto the brain itself, although some research has given indications to possible locations for certain portions. The dynamic body schema has been suggested to be localized in the superior posterior parietal cortex. There is also evidence that the inferior parietal lobule may be the locus for storage of the characteristic movements of a tool. This area showed inverse activation to the cerebellum in a study of tool use and tool mime. If the connections between these areas become severed, the praxis system would be disrupted, possibly resulting in the symptoms observed in ideomotor apraxia. There is no one definitive test for ideomotor apraxia; there are several that are used clinically to make an ideomotor apraxia diagnosis. The criteria for a diagnosis are not entirely conserved among clinicians, for apraxia in general or distinguishing subtypes. Almost all the tests laid out here that enable a diagnosis of ideomotor apraxia share a common feature: assessment of the ability to imitate gestures. A test developed by Georg Goldenberg uses imitation assessment of 10 gestures. The tester demonstrates the gesture to the patient and rates him on how whether the gesture was correctly imitated. If the first attempt to imitate the gesture was unsuccessful, the gesture is presented a second time; a higher score is given for correct imitation on the first trial, then for the second, and the lowest score is for not correctly imitating the gesture. The gestures used here are all meaningless, such as placing the hand flat on the top of the head or flat outward with the fingers towards the ear. This test is specifically designed for ideomotor apraxia. The main variation from this is in the type and number of gestures used. One test uses twenty-four movements with three trials for each and a trial-based scoring system similar to the Goldenberg protocol. The gestures here are also copied by the patient from the tester and are divided into finger movements, e.g. making a scissor movement with the forefinger and middle finger, and hand and arm movements, e.g. doing a salute. This protocol combines meaningful and meaningless gestures. Another test uses five meaningful gestures, such as waving goodbye or scratching your head and five meaningless gestures. Additional differences in this test are a verbal command to initiate the movement and it distinguishes between accurate performance and inaccurate but recognizable performance. One test utilizes tools, including a hammer and a key, with both a verbal command to use the tools and the patient copying the tester's demonstrated use of the tools. These tests have been shown to be individually unreliable, with considerable variability between the diagnoses delivered by each. If a battery of tests is used, however, the reliability and validity may be improved. It is also highly advisable to include assessments of how the patient performs activities in daily life. One of the newer tests that has been developed may provide greater reliability without relying on a multitude of tests. It combines three types of tool use with imitation of gestures. The tool use section includes having the patient pantomime use with no tool present, with visual contact with the tool, and finally with tactile contact with the tool. This test screens for ideational and ideomotor apraxia, with the second portion aimed specifically at ideomotor apraxia. One study showed great potential for this test, but further studies are needed to reproduce these results before this can be said with confidence. This disorder often occurs with other degenerative neurological disorders such as Parkinson's disease and Alzheimer's Disease. These comorbidities can make it difficult to pick out the specific features of ideomotor apraxia. The important point in distinguishing ideomotor apraxia is that basic motor control is intact; it is a high level dysfunction involving tool use and gesturing. Additionally, clinicians must be careful to exclude aphasia as a possible diagnosis, as, in the tests involving verbal command, an aphasic patient could fail to perform a task properly because they do not understand what the directions are.",
            "score": 88.60731256008148
        },
        {
            "docid": "14782003_20",
            "document": "Body schema . The most direct of related disorders, deafferentation occurs when sensory input from the body is reduced or absent, without affecting efferent, or motor, neurons. The most famous case of this disorder is \"IW\", who lost all sensory input from below the neck, resulting in temporary paralysis. He was forced to learn to control his movement all over again using only his conscious body image and visual feedback. As a result, when constant visual input is lost during an activity, such as walking, it becomes impossible for him to complete the task, which may result in falling, or simply stopping. IW requires constant attention to tasks to be able to complete them accurately, demonstrating how automatic and subconscious the process of integrating touch and proprioception into the body schema actually is.",
            "score": 71.42579865455627
        },
        {
            "docid": "33998077_15",
            "document": "Preferred walking speed . The rate at which the environment flows past the eyes seems to be a mechanism for regulating walking speed. In virtual environments, the gain in visual flow can be decoupled from a person\u2019s actual walking speed, much as one might experience when walking on a conveyor belt. There, the environment flows past an individual more quickly than their walking speed would predict (higher than normal visual gain). At higher than normal visual gains, individuals prefer to walk more slowly, while at lower than normal visual gains, individuals prefer to walk more quickly. This behavior is consistent with returning the visually observed speed back toward the preferred speed and suggests that vision is used correctively to maintain walking speed at a value that is perceived to be optimal. Moreover, the dynamics of this visual influence on preferred walking speed are rapid\u2014when visual gains are changed suddenly, individuals adjust their speed within a few seconds. The timing and direction of these responses strongly indicate that a rapid predictive process informed by visual feedback helps select preferred speed, perhaps to complement a slower optimization process that directly senses metabolic rate and iteratively adapts gait to minimize it.",
            "score": 72.41076254844666
        },
        {
            "docid": "39199253_5",
            "document": "Percolation (cognitive psychology) . Percolation has been developed outside of the cognitive sciences; however, its application in the field has proven it to be a useful tool for understanding neural processes. Researchers have focused their attention not only studying how neural activity is diffused across networks but also how percolation and its aspect of phase transition can affect decision making and thought processes. Percolation theory has enabled researchers to better understand many psychological conditions, such as epilepsy, disorganized schizophrenia and divergent thinking. These conditions are often indicative of percolating clusters and their involvement in propagating the excess firing of neurons. Seizures occur when neurons in the brain fire simultaneously, and often these seizures can occur in one part of the brain and transfer to other parts. Researchers are able to facilitate a better understanding of these conditions because \"the neurons involved in a seizure are analogous to the sites in a percolating cluster\". Disorganized schizophrenia is more complex as the activity is indicative activity in a percolating cluster; however, some researchers have suggested that the percolation of information occurs not in a small cluster but on a global functional scale. Attention as well as percolation also plays a key role in disorganized and divergent thinking; however, it is more likely that directed percolation, that is a directionally controlled percolation, is more useful to study divergent thinking and creativity.",
            "score": 106.80910432338715
        },
        {
            "docid": "3883287_8",
            "document": "Tranquillity . Within tranquillity studies, much of the emphasis has been placed on understanding the role of vision in the perception of natural environments, which is probably not surprising, considering that upon first viewing a scene its configurational coherence can be established with incredible speed. Indeed, scene information can be captured in a single glance and the gist of a scene determined in as little as 100ms. The speed of processing of complex natural images was tested by Thorpe \"et al.\" using colour photographs of a wide range of animals (mammals, birds, reptiles and fish), in their natural environments, mixed with distracters that included pictures of forests, mountains, lakes, buildings and fruit. During this experiment, subjects were shown an image for 20ms and asked to determine whether it contained an animal or not. The electrophysiological brain responses obtained in this study showed that a decision could be made within 150ms of the image being seen, indicating the speed at which cognitive visual processing occurs. However, audition, and in particular the individual components that collectively comprise the soundscape, a term coined by Schafer to describe the ever-present array of sounds that constitute the sonic environment, also significantly inform the various schemata used to characterise differing landscape types. This interpretation is supported by the auditory reaction times, which are 50 to 60ms faster than that of the visual modality. It is also known that sound can alter visual perception and that under certain conditions areas of the brain involved in processing auditory information can be activated in response to visual stimuli.  Research conducted by Pheasant \"et al.\" has shown that when individuals make tranquillity assessments based on a uni-modal auditory or visual sensory input, they characterise the environment by drawing upon a number of key landscape and soundscape characteristics. For example, when making assessments in response to visual-only stimuli the percentage of water, flora and geological features present within a scene, positively influence how tranquil a location is perceived to be. Likewise when responding to uni-modal auditory stimuli, the perceived loudness of biological sounds positively influences the perception of tranquillity, whilst the perceived loudness of mechanical sounds have a negative effect. However, when presented with bi-modal auditory-visual stimuli the individual soundscape and landscape components alone no longer influenced the perception of tranquillity. Rather configurational coherence was provided by the percentage of natural and contextual features present within the scene and the equivalent continuous sound pressure level (LAeq).",
            "score": 110.28712821006775
        },
        {
            "docid": "4833512_2",
            "document": "Mu wave . Mu waves, also known as mu rhythms, comb or wicket rhythms, arciform rhythms, or sensorimotor rhythms, are synchronized patterns of electrical activity involving large numbers of neurons, probably of the pyramidal type, in the part of the brain that controls voluntary movement. These patterns as measured by electroencephalography (EEG), magnetoencephalography (MEG), or electrocorticography (ECoG), repeat at a frequency of 7.5\u201312.5 (and primarily 9\u201311) Hz, and are most prominent when the body is physically at rest. Unlike the alpha wave, which occurs at a similar frequency over the resting visual cortex at the back of the scalp, the mu wave is found over the motor cortex, in a band approximately from ear to ear. A person suppresses mu wave patterns when he or she performs a motor action or, with practice, when he or she visualizes performing a motor action. This suppression is called desynchronization of the wave because EEG wave forms are caused by large numbers of neurons firing in synchrony. The mu wave is even suppressed when one observes another person performing a motor action or an abstract motion with biological characteristics. Researchers such as V. S. Ramachandran and colleagues have suggested that this is a sign that the mirror neuron system is involved in mu wave suppression, although others disagree.",
            "score": 76.92828333377838
        },
        {
            "docid": "1038052_31",
            "document": "Neuroesthetics . Emotions play a large role in aesthetic processing. Experiments designed specifically to force the subjects to view the artwork subjectively (by inquiring of its aesthetic appeal) rather than simply with the visual systems, revealed a higher activation in the brain's emotional circuitry. Results from these experiments revealed high activation in the bilateral insula which can be attributed to the emotional experience of viewing art. This correlates with other known emotional roles of the insula. However, the correlation between the insula's varying states of activation and positive or negative emotions in this context is unknown. The emotional view of art can be contrasted with perception related to object recognition when pragmatically viewing art. The right fusiform gyrus has been revealed to show activation to visual stimuli such as faces and representational art. This holds importance in the field because as Ramachandran also speculated, object recognition and the search for meaning can evoke a pleasant emotional response. The motor cortex was also shown to be involved in aesthetic perception. However, it displayed opposite trends of activation from the OFC. It may be a common correlate for the perception of emotionally charged stimuli despite its previously known roles. Several other areas of the brain were shown to be slightly activated during certain studies such as the anterior cingulate cortex, previously known for its involvement in the feeling of romance, and the left parietal cortex, whose purpose may be to direct spatial attention.",
            "score": 107.03785192966461
        }
    ],
    "r": [
        {
            "docid": "2363287_6",
            "document": "Visual learning . Various areas of the brain work together in a multitude of ways in order to produce the images that we see with our eyes and that are encoded by our brains. The basis of this work takes place in the visual cortex of the brain. The visual cortex is located in the occipital lobe of the brain and harbors many other structures that aid in visual recognition, categorization, and learning. One of the first things the brain must do when acquiring new visual information is recognize the incoming material. Brain areas involved in recognition are the inferior temporal cortex, the superior parietal cortex, and the cerebellum. During tasks of recognition, there is increased activation in the left inferior temporal cortex and decreased activation in the right superior parietal cortex. Recognition is aided by neural plasticity, or the brain's ability to reshape itself based on new information. Next the brain must categorize the material. The three main areas that are used when categorizing new visual information are the orbitofrontal cortex and two dorsolateral prefrontal regions which begin the process of sorting new information into groups and further assimilating that information into things that you might already know. After recognizing and categorizing new material entered into the visual field, the brain is ready to begin the encoding process \u2013 the process which leads to learning. Multiple brain areas are involved in this process such as the frontal lobe, the right extrastriate cortex, the neocortex, and again, the neostriatum. One area in particular, the limbic-diencephalic region, is essential for transforming perceptions into memories. With the coming together of tasks of recognition, categorization and learning; schemas help make the process of encoding new information and relating it to things you already know much easier. One can remember visual images much better when they can apply it to an already known schema. Schemas actually provide enhancement of visual memory and learning.",
            "score": 154.2578582763672
        },
        {
            "docid": "2438760_26",
            "document": "Change blindness . Other studies using fMRI (functional magnetic resonance imaging) scanners have shown that when change is not consciously detected, there was a significant decrease in the dorsolateral prefrontal and parietal lobe regions. These results further the importance of the dorsolateral prefrontal and parietal cortext in the detection of visual change. In addition to fMRI studies, recent research has used transcranial magnetic stimulation (TMS) in order to inhibit areas of the brain while participants were instructed to try to detect the change between two images. The results show that when the posterior parietal cortex (PPC) is inhibited, individuals are significantly slower at detecting change. The PPC is critical for encoding and maintaining visual images in short term working memory, which demonstrates the importance of the PPC in terms of detecting changes between images. For a change to be detected, the information of the first picture needs to be held in working memory and compared to the second picture. If the PPC is inhibited, the area of the brain responsible for encoding visual images will not function properly. The information will not be encoded and will not be held in working memory and compared to the second picture, thus inducing change blindness.",
            "score": 141.69895935058594
        },
        {
            "docid": "599917_9",
            "document": "Mental image . The biological foundation of the mind's eye is not fully understood. Studies using fMRI have shown that the lateral geniculate nucleus and the V1 area of the visual cortex are activated during mental imagery tasks. Ratey writes: The visual pathway is not a one-way street. Higher areas of the brain can also send visual input back to neurons in lower areas of the visual cortex. [...] As humans, we have the ability to see with the mind's eye \u2013 to have a perceptual experience in the absence of visual input. For example, PET scans have shown that when subjects, seated in a room, imagine they are at their front door starting to walk either to the left or right, activation begins in the visual association cortex, the parietal cortex, and the prefrontal cortex - all higher cognitive processing centers of the brain.",
            "score": 140.9158935546875
        },
        {
            "docid": "32018467_7",
            "document": "Christian Keysers . After finishing his master, Christian Keysers decided to concentrate on a subfield of cognitive neuroscience called social neuroscience that uses neuroscience methods to understand how we process the social world. He therefore performed his doctoral studies at the University of St Andrews with David Ian Perrett, one of the founding father of the field, to understand how the brain processes faces and facial expressions. This thesis work led to new insights into how quickly the brain can process the faces of others. During this period, Keysers became fascinated with the question of how the brain can attach meaning to the faces of others. How is it for instance, that we understand that a certain grimace would signal that another person is happy? How do we understand that a certain bodily movement towards a glass indicates that the other person aims to grasp a glass? In 1999, Keysers was exposed to a visit of Vittorio Gallese, who presented his recent discovery of mirror neurons in the Psychology department lecture series. This deeply influenced Keysers who decided to move to the lab of Giacomo Rizzolatti to undertake further studies on how these fascinating neurons could contribute to social perception. In 2000, after finishing his doctorate, Christian Keysers moved to the University of Parma to study mirror neurons. In early work there demonstrated that mirror neurons in the premotor cortex not only respond to the sight of actions, but also when actions can only be deduced or heard, leading to a publication in the journal \"Science\". This work had tremendous impact on the field, as it suggested that the premotor cortex could play a central, modality independent role in perception and may lay the origin for the evolution of speech in humans.  Together this work indicated that brain regions involved in our own actions play a role in how we process the actions of others. Keysers wondered whether a similar principle may underlie how we process the tactile sensations and emotions of others, and became increasingly independent of the research focus on the motor system in Parma. At the time, Keysers had also met his to be wife, Valeria Gazzola, a biologist in the final phases of her studies, and together they decided to explore if the somatosensory system might be involved in perceiving the sensations of others. Via a fruitful collaboration with the French neuroimaging specialist Bruno Wicker, they used functional magnetic resonance imaging, and showed for the first time, that the secondary somatosensory cortex, previously thought only to represent a persons own experiences of touch, is also activated when seeing someone or something else be touched. They also showed that the insula, thought only to respond to the experience of first-hand emotions, was also activated when we see another individual experience similar emotions. Together this indicated a much more general principle than the original mirror neuron theory, in which people process the actions, sensations and emotions of others by vicariously activating owns own actions, sensations and emotions. Jointly, this work laid the foundation of the neuroscientific investigation of empathy.",
            "score": 134.1487274169922
        },
        {
            "docid": "28354637_6",
            "document": "Richard A. Andersen . Early work centered on the discovery and elucidation of cortical gain fields, a general rule of multiplicative computation used by many areas of the cortex. Andersen and Zipser of UCSD developed one of the first neural network models of cortical function, which generated a mathematical basis for testing hypotheses based on laboratory findings. His research established that the posterior parietal cortex (PPC) is involved in forming movement intentions\u2014the early and abstract plans for movement. Previously this part of the brain was thought only to function for spatial awareness and attention. His laboratory discovered the lateral intraparietal area (LIP) in the PPC and established its role in eye movements. He also discovered the parietal reach region, an area involved in forming early reach plans. His lab has also made a number of discoveries related to visual motion perception. He established that the middle temporal area processes the perception of form from motion. He found that the perception of the direction of heading, important for navigation, is computed in the brain using both visual stimuli and eye movement signals. His lab has also determined how eye position and limb position signals are combined for eye-hand coordination.",
            "score": 131.85958862304688
        },
        {
            "docid": "4833512_4",
            "document": "Mu wave . The mirror neuron system consists of a class of neurons that was first studied in the 1990s in macaque monkeys. Studies have found sets of neurons that fire when these monkeys perform simple tasks and also when the monkeys view others performing the same simple tasks. This suggests they play a role in mapping others' movements into the brain without actually physically performing the movements. These sets of neurons are called mirror neurons and together make up the mirror neuron system. Mu waves are suppressed when these neurons fire, a phenomenon which allows researchers to study mirror neuron activity in humans. There is evidence that mirror neurons exist in humans as well as in non-human animals. The right fusiform gyrus, left inferior parietal lobule, right anterior parietal cortex, and left inferior frontal gyrus are of particular interest. Some researchers believe that mu wave suppression can be a consequence of mirror neuron activity throughout the brain, and represents a higher-level integrative processing of mirror neuron activity. Tests in both monkeys (using invasive measuring techniques) and humans (using EEG and fMRI) have found that these mirror neurons not only fire during basic motor tasks, but also have components that deal with intention. There is evidence of an important role for mirror neurons in humans, and mu waves may represent a high level coordination of those mirror neurons.",
            "score": 130.0521697998047
        },
        {
            "docid": "226722_25",
            "document": "Functional magnetic resonance imaging . Researchers have checked the BOLD signal against both signals from implanted electrodes (mostly in monkeys) and signals of field potentials (that is the electric or magnetic field from the brain's activity, measured outside the skull) from EEG and MEG. The local field potential, which includes both post-neuron-synaptic activity and internal neuron processing, better predicts the BOLD signal. So the BOLD contrast reflects mainly the inputs to a neuron and the neuron's integrative processing within its body, and less the output firing of neurons. In humans, electrodes can be implanted only in patients who need surgery as treatment, but evidence suggests a similar relationship at least for the auditory cortex and the primary visual cortex. Activation locations detected by BOLD fMRI in cortical areas (brain surface regions) are known to tally with CBF-based functional maps from PET scans. Some regions just a few millimeters in size, such as the lateral geniculate nucleus (LGN) of the thalamus, which relays visual inputs from the retina to the visual cortex, have been shown to generate the BOLD signal correctly when presented with visual input. Nearby regions such as the pulvinar nucleus were not stimulated for this task, indicating millimeter resolution for the spatial extent of the BOLD response, at least in thalamic nuclei. In the rat brain, single-whisker touch has been shown to elicit BOLD signals from the somatosensory cortex.",
            "score": 128.09573364257812
        },
        {
            "docid": "11134503_10",
            "document": "Posterior parietal cortex . In a study conducted by neuroscientists at New York University, coherent patterns of firing of neurons in the brain's PPC were associated with coordination of different effectors. The researchers examined neurological activity of macaque monkeys while having them perform a variety of tasks that required them to either reach and to simultaneously employ rapid eye movements (saccades) or to only use saccades. The coherent pattern of the firing of neurons in the PPC were only seen when both the eyes and arms were required to move for the same task, but not for tasks that involved only saccades.",
            "score": 127.35582733154297
        },
        {
            "docid": "10269587_9",
            "document": "Echoic memory . Auditory sensory memory has been found to be stored in the primary auditory cortex contralateral to the ear of presentation. This echoic memory storage involves several different brain areas, due to the different processes it is involved in. The majority of brain regions involved are located in the prefrontal cortex (PFC) as this is where the executive control is located, and is responsible for attentional control. The phonological store and the rehearsal system appear to be a left-hemisphere based memory system as increased brain activity has been observed in these areas. The major regions involved are the left posterior ventrolateral prefrontal cortex (VLPFC), the left premotor cortex (PMC), and the left posterior parietal cortex (PPC). Within the VLPFC, Broca's area is the main location responsible for verbal rehearsal and the articulatory process. The dorsal PMC is used in rhythmic organization and rehearsal, and finally the PPC shows a role in localizing objects in space.",
            "score": 126.04283905029297
        },
        {
            "docid": "38442646_4",
            "document": "Gain-field encoding . Most gain field activity is based in the premotor cortex found in the frontal lobe anterior to the primary motor cortex, however it receives input from a variety of locations in the brain. These incoming signals provide frame of reference information through the individual's senses. Further evidence suggests that the cerebellum and posterior parietal cortex (PPC) also play major functional roles in gain field encoding. The intrinsic and extrinsic properties of the gain field can be shown as products of the PPC. In Brodmann area 7 of the PPC, the positioning of objects with respect to the eyes is represented completely extrinsically with no input from the positioning of the body involved. This opposes the case of other parts of the PPC such as Brodmann area 5 which represents objects in relation to body defined coordinates. Due to the extrinsic and intrinsic properties of motor functioning, it is speculated that these types of signals are both taken multiplicatively to form the gain field. With input from each area, a three-dimensional representation of the objects in space can be arranged for use by the rest of the motor system.",
            "score": 125.9405746459961
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 125.31402587890625
        },
        {
            "docid": "20395179_7",
            "document": "Vittorio Gallese . Observing the world is more complex than the mere activation of the visual brain. Vision is multimodal: it encompasses the activation of motor, somatosensory and emotion-related brain networks. Any intentional relation entertained with the external world has an intrinsic pragmatic nature, hence it always bears a motor content. The same motor circuits that control our motor behavior also map the space around us, the objects at hand in that very same space, thus defining and shaping in motor terms their representational content. The space around us is defined by the motor potentialities of our body. Motor neurons also respond to visual, tactile and auditory stimuli. Indeed, premotor neurons controlling the movements of the upper arm also respond to tactile stimuli applied to it, to visual stimuli moved within the arm's peripersonal space, or to auditory stimuli also coming from the same peri-personal space. The same applies to artifacts, like three-dimensional objects. The manipulable objects we look at are classified by the motor brain as potential targets of the interactions we might entertain with them. Premotor and parietal 'canonical neurons' control the grasping and manipulation of objects and also respond to their mere observation. The functional architecture of embodied simulation seems to constitute a basic characteristic of our brain, making possible our rich and diversified experiences of space, objects and other individuals, being at the basis of our capacity to empathize with them.\"",
            "score": 124.03962707519531
        },
        {
            "docid": "739262_10",
            "document": "Neural correlate . Neurophysiological studies in animals provided some insights on the neural correlates of conscious behavior. Vernon Mountcastle, in the early 1960s, set up to study this set of problems, which he termed \"the Mind/Brain problem\", by studying the neural basis of perception in the somatic sensory system. His labs at Johns Hopkins were among the first, along with Edward V.Evarts at NIH, to record neural activity from behaving monkeys. Struck with the elegance of SS Stevens approach of magnitude estimation, Mountcastle's group discovered three different modalities of somatic sensation shared one cognitive attribute: in all cases the firing rate of peripheral neurons was linearly related to the strength of the percept elicited. More recently, Ken H. Britten, William T. Newsome, and C. Daniel Salzman have shown that in area MT of monkeys, neurons respond with variability that suggests they are the basis of decision making about direction of motion. They first showed that neuronal rates are predictive of decisions using signal detection theory, and then that stimulation of these neurons could predictably bias the decision. Such studies were followed by Ranulfo Romo in the somatic sensory system, to confirm, using a different percept and brain area, that a small number of neurons in one brain area underlie perceptual decisions.",
            "score": 123.71867370605469
        },
        {
            "docid": "1168317_15",
            "document": "Mirror neuron . It is not normally possible to study single neurons in the human brain, so most evidence for mirror neurons in humans is indirect. Brain imaging experiments using functional magnetic resonance imaging (fMRI) have shown that the human inferior frontal cortex and superior parietal lobe are active when the person performs an action and also when the person sees another individual performing an action. It has been suggested that these brain regions contain mirror neurons, and they have been defined as the human mirror neuron system. More recent experiments have shown that even at the level of single participants, scanned using fMRI, large areas containing multiple fMRI voxels increase their activity both during the observation and execution of actions.",
            "score": 121.82951354980469
        },
        {
            "docid": "33246145_4",
            "document": "Neural decoding . When looking at a picture, people's brains are constantly making decisions about what object they are looking at, where they need to move their eyes next, and what they find to be the most salient aspects of the input stimulus. As these images hit the back of the retina, these stimuli are converted from varying wavelengths to a series of neural spikes called action potentials. These pattern of action potentials are different for different objects and different colors; we therefore say that the neurons are encoding objects and colors by varying their spike rates or temporal pattern. Now, if someone were to probe the brain by placing electrodes in the primary visual cortex, they may find what appears to be random electrical activity. These neurons are actually firing in response to the lower level features of visual input, possibly the edges of a picture frame. This highlights the crux of the neural decoding hypothesis: that it is possible to reconstruct a stimulus from the response of the ensemble of neurons that represent it. In other words, it is possible to look at spike train data and say that the person or animal being recorded is looking at a red ball.",
            "score": 118.94751739501953
        },
        {
            "docid": "41848173_2",
            "document": "Surround suppression . Surround suppression is a descriptive term referring to observations that the relative firing rate of a neuron may under certain conditions decrease when a particular stimulus is enlarged. It is has been observed in electrophysiology studies of the brain and has been noted in many sensory neurons, most notably in the early visual system. Surround suppression is defined as a reduction in the activity of a neuron in response to a stimulus outside its classical receptive field. (The classical receptive field refers to a concept of neural behavior that was understood to be invalid virtally from the start. As Spillman et al (2015)) note, quoting Kuffler (1953), \"not only the areas from which responses can actually be set up by retinal illumination may be included in a definition of the receptive field but also all areas which show a functional connection, by an inhibitory or excitatory effect on a ganglion cell.\" The necessary functional connections with other neurons influenced by stimulation outside a particular area and by dynamic processes in general, and the absence of a theoretical description of a system state to be treated as a baseline, deprive the term \"classical receptive field\" of functional meaning. The descriptor \"surround suppression\" suffers from a similar problem, as the activities of neurons in the \"surround\" of the \"classical receptive field are similarly determined by connectivities and processes involving neurons beyond it.) This nonlinear effect is one of many that reveals the complexity of biological sensory systems, and the connections of properties of neurons that may cause this effect (or its opposite) are still being studied. The characteristics, mechanisms, and perceptual consequences of this phenomenon are of interest to many communities, including neurobiology, computational neuroscience, psychology, and computer vision.",
            "score": 118.73995971679688
        },
        {
            "docid": "2860457_6",
            "document": "Neural ensemble . Neuronal ensembles encode information in a way somewhat similar to the principle of Wikipedia operation \u2013 multiple edits by many participants. Neuroscientists have discovered that individual neurons are very noisy. For example, by examining the activity of only a single neuron in the visual cortex, it is very difficult to reconstruct the visual scene that the owner of the brain is looking at. Like a single Wikipedia participant, an individual neuron does not 'know' everything and is likely to make mistakes. This problem is solved by the brain having billions of neurons. Information processing by the brain is population processing, and it is also distributed \u2013 in many cases each neuron knows a little bit about everything, and the more neurons participate in a job, the more precise the information encoding. In the distributed processing scheme, individual neurons may exhibit neuronal noise, but the population as a whole averages this noise out.",
            "score": 117.9312515258789
        },
        {
            "docid": "32172794_15",
            "document": "Visual space . Two major concepts dating back to the middle of the 19th century set the parameters of the discussion here. Johannes M\u00fcller emphasized that what matters in a neural path is the connection it makes, and Hermann Lotze, from psychological considerations, enunciated the principle of local sign. Put together in modern neuroanatomical terms they mean that a nerve fiber from a fixed retinal location instructs its target neurons in the brain about the presence of a stimulus in the location in the eye's visual field that is imaged there. The orderly array of retinal locations is preserved in the passage from the retina to the brain, and provides what is aptly called a \"retinotopic\" mapping in the primary visual cortex. Thus in the first instance brain activity retains the relative spatial ordering of the objects and lays the foundations for a neural substrate of visual space. Unfortunately, as is so common in brain studies, simplicity and transparency ends here. Right at the outset, visual signals are analyzed not only for their position, but also, separately in parallel channels, for many other attributes such as brightness, color, orientation, depth. No single neuron or even neuronal center or circuit represents both the nature of a target feature and its accurate location. The unitary mapping of object space into the coherent visual space without internal contradictions or inconsistencies that we as observer automatically experience, demands concepts of conjoint activity in several parts of the nervous system that is at present beyond the reach of neurophysiological research.",
            "score": 117.78978729248047
        },
        {
            "docid": "156940_17",
            "document": "Electrophysiology . An electrode introduced into the brain of a living animal will detect electrical activity that is generated by the neurons adjacent to the electrode tip. If the electrode is a microelectrode, with a tip size of about 1 micrometre, the electrode will usually detect the activity of at most one neuron. Recording in this way is in general called \"single-unit\" recording. The action potentials recorded are very much like the action potentials that are recorded intracellularly, but the signals are very much smaller (typically about 1 mV). Most recordings of the activity of single neurons in anesthetized and conscious animals are made in this way. Recordings of single neurons in living animals have provided important insights into how the brain processes information. For example, David Hubel and Torsten Wiesel recorded the activity of single neurons in the primary visual cortex of the anesthetized cat, and showed how single neurons in this area respond to very specific features of a visual stimulus. Hubel and Wiesel were awarded the Nobel Prize in Physiology or Medicine in 1981.",
            "score": 117.7774429321289
        },
        {
            "docid": "33702464_5",
            "document": "Extrastriate body area . The experiment had subjects view images of different objects, including faces (as a control group), body parts, animals, parts of the face and intimate objects. While viewing the images, the subjects were scanned with an fMRI to see what area of the brain was activated. Through the trials a compilation of the fMRI\u2019s was made. From this compilation image a specific region was determined to have increased activity when shown visual stimuli of body parts and even more activity when viewing whole bodies. There have been no studies involving brain damage to the EBA. Thus far, only scans of brain activity, as well as transcranial magnetic stimulation, have been used to study the EBA. To find the specific functions of the EBA, Comimo Urgesi, Giovanni Berlucchi and Salvatore M. Aglioti used repetitive transcranial magnetic stimulation (rTMS) to disrupt part of the brain, making the brain less responsive in the target area. The study used event-related rTMS to disrupt the EBA, resulting in inactivation of cortical areas. This inactivation caused a slower response time in discriminating body parts. The study used facial features and motorcycle parts as non human parts for control groups. The facial features and motorcycle body parts did not display any change in response time. The neural activity data shows the EBA handles some of the visual processing of human body and parts but is not related to the processing of the face or other objects.",
            "score": 117.21739196777344
        },
        {
            "docid": "11134503_7",
            "document": "Posterior parietal cortex . In addition to separation based on effector type, some regions are activated during both decision and execution, while other regions are only active during execution. In one study, single cell recordings showed activity in parietal reach region while non-human primates decided whether to reach or make a saccade to a target, and activity persisted during the chosen movement if and only if the monkey chose to make a reaching movement. However, cells in area 5d were only active after the decision was made to reach with the arm. Another study found that neurons in area 5d only encoded the next movement in a sequence of reach movements, and not reach movements later in the sequence.",
            "score": 116.37831115722656
        },
        {
            "docid": "5664_46",
            "document": "Consciousness . A number of studies have shown that activity in primary sensory areas of the brain is not sufficient to produce consciousness: it is possible for subjects to report a lack of awareness even when areas such as the primary visual cortex show clear electrical responses to a stimulus. Higher brain areas are seen as more promising, especially the prefrontal cortex, which is involved in a range of higher cognitive functions collectively known as executive functions. There is substantial evidence that a \"top-down\" flow of neural activity (i.e., activity propagating from the frontal cortex to sensory areas) is more predictive of conscious awareness than a \"bottom-up\" flow of activity. The prefrontal cortex is not the only candidate area, however: studies by Nikos Logothetis and his colleagues have shown, for example, that visually responsive neurons in parts of the temporal lobe reflect the visual perception in the situation when conflicting visual images are presented to different eyes (i.e., bistable percepts during binocular rivalry).",
            "score": 116.23873901367188
        },
        {
            "docid": "33826069_3",
            "document": "Viral neuronal tracing . Most neuroanatomists would agree that understanding how the brain is connected to itself and the body is of paramount importance. As such, it is of equal importance to have a way to visualize and study the connections among neurons. Neuronal tracing methods offer an unprecedented view into the morphology and connectivity of neural networks. Depending on the tracer used, this can be limited to a single neuron or can progress trans-synaptically to adjacent neurons. After the tracer has spread sufficiently, the extent may be measured either by fluorescence (for dyes) or by immunohistochemistry (for biological tracers). An important innovation in this field is the use of neurotropic viruses as tracers. These not only spread throughout the initial site of infection, but can jump across synapses. The use of a virus provides a self-replicating tracer. This can allow for the elucidation of neural microcircuitry to an extent that was previously unobtainable.  This has significant implications for the real world. If we can better understand what parts of the brain are intimately connected, we can predict the effect of localized brain injury. For example, if a patient has a stroke in the amygdala, primarily responsible for emotion, the patient might also have trouble learning to perform certain tasks because the amygdala is highly interconnected with the orbitofrontal cortex, responsible for reward learning. As always, the first step to solving a problem is fully understanding it, so if we are to have any hope of fixing brain injury, we must first understand its extent and complexity.",
            "score": 116.23619842529297
        },
        {
            "docid": "1168317_18",
            "document": "Mirror neuron . The mirror neurons found were located in the supplementary motor area and medial temporal cortex (other brain regions were not sampled). For purely practical reasons, these regions are not the same as those in which mirror neurons had been recorded from in the monkey: researchers in Parma were studying the ventral premotor cortex and the associated inferior parietal lobe, two regions in which epilepsy rarely occurs, and hence, single cell recordings in these regions are not usually done in humans. On the other hand, no one has to date looked for mirror neurons in the supplementary motor area or the medial temporal lobe in the monkey. Together, this therefore does not suggest that humans and monkeys have mirror neurons in different locations, but rather that they may have mirror neurons both in the ventral premotor cortex and inferior parietal lobe, where they have been recorded in the monkey, and in the supplementary motor areas and medial temporal lobe, where they have been recorded from in human \u2013 especially because detailed human fMRI analyses suggest activity compatible with the presence of mirror neurons in all these regions.",
            "score": 115.84312438964844
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 115.26461791992188
        },
        {
            "docid": "1764639_17",
            "document": "Levels-of-processing effect . Several brain imaging studies using positron emission tomography and functional magnetic resonance imaging techniques have shown that higher levels of processing correlate with more brain activity and activity in different parts of the brain than lower levels. For example, in a lexical analysis task, subjects showed activity in the left inferior prefrontal cortex only when identifying whether the word represented a living or nonliving object, and not when identifying whether or not the word contained an \"a\". Similarly, an auditory analysis task showed increased activation in the left inferior prefrontal cortex when subjects performed increasingly semantic word manipulations. Synaptic aspects of word recognition have been correlated with the left frontal operculum and the cortex lining the junction of the inferior frontal and inferior precentral sulcus. The self-reference effect also has neural correlates with a region of the medial prefrontal cortex, which was activated in an experiment where subjects analyzed the relevance of data to themselves. Specificity of processing is explained on a neurological basis by studies that show brain activity in the same location when a visual memory is encoded and retrieved, and lexical memory in a different location. Visual memory areas were mostly located within the bilateral extrastriate visual cortex.",
            "score": 114.82627868652344
        },
        {
            "docid": "21312318_27",
            "document": "Recognition memory . Recognition memory is critically dependent on a hierarchically organized network of brain areas including the visual ventral stream, medial temporal lobe structures, frontal lobe and parietal cortices along with the hippocampus. As mentioned previously, the processes of recollection and familiarity are represented differently in the brain. As such, each of the regions listed above can be further subdivided according to which part is primarily involved in recollection or in familiarity. In the temporal cortex, for instance, the medial region is related to recollection whereas the anterior region is related to familiarity. Similarly, in the parietal cortex, the lateral region is related to recollection whereas the superior region is related to familiarity. An even more specific account divides the medial parietal region, relating the posterior cingulate to recollection and the precuneus to familiarity. The hippocampus plays a prominent role in recollection whereas familiarity depends heavily on the surrounding medial-temporal regions, especially the perirhinal cortex. Finally, it is not yet clear what specific regions of the prefrontal lobes are associated with recollection versus familiarity, although there is evidence that the left prefrontal cortex is correlated more strongly with recollection whereas the right prefrontal cortex is involved more in familiarity. Though left-side activation involved in recollection was originally hypothesized to result from semantic processing of words (many of these earlier studies used written words for stimuli) subsequent studies using nonverbal stimuli produced the same finding\u2014suggesting that prefrontal activation in the left hemisphere results from any kind of detailed remembering.  As previously mentioned, recognition memory is not a stand-alone concept; rather it is a highly interconnected and integrated sub-system of memory. Perhaps misleadingly, the regions of the brain listed above correspond to an abstract and highly generalized understanding of recognition memory, in which the stimuli or items-to-be-recognized are not specified. In reality, however, the location of brain activation involved in recognition is highly dependent on the nature of the stimulus itself. Consider the conceptual differences in recognizing written words compared to recognizing human faces. These are two qualitatively different tasks and as such it is not surprising that they involve additional, distinct regions of the brain. Recognizing words, for example, involves the visual word form area, a region in the left fusiform gyrus, which is believed to specialized in recognizing written words. Similarly, the fusiform face area, located in the right hemisphere, is linked specifically to the recognition of faces.",
            "score": 114.02359771728516
        },
        {
            "docid": "515094_7",
            "document": "Neuroeconomics . For example, Padoa-Schioppa & Assad tracked the firing rates of individual neurons in the monkey orbitofrontal cortex while the animals chose between two kinds of juice. The firing rate of the neurons was directly correlated with the utility of the food items and did not differ when other types of food were offered. This suggests that, in accordance with the economic theory of decision making, neurons are directly comparing some form of utility across different options and choosing the one with the higher value. Similarly, a common measure of prefrontal cortex dysfunction, the FrSBe, is correlated with multiple different measures of economic attitudes and behavior, supporting the idea that brain activation can display important aspects of the decision process.",
            "score": 113.90560913085938
        },
        {
            "docid": "39151518_10",
            "document": "Neuronal recycling hypothesis . As was stated in the neuronal recycling hypothesis, brain circuits bias what we are able to learn. One bias identified involves the preference of central versus peripheral images at different points along the cerebral cortex. It was observed that in all individuals, the visual word form area fell on the region of the cortex with a massive preference for fine-grained, central images. This area is most suitable to accommodate reading ability, due to the high degree of visual precision necessary to perform this function effectively. Another cortical bias relevant to reading comes from the lateralization of cerebral hemispheres. Reading consistently activates the left hemisphere, which is associated with language abilities and discriminating between small shapes, showing a clear bias towards reading functions. There is a preadaptation of the inferior temporal cortex that we use when learning to read. It is the area activated during invariant object recognition, and it's sufficient plasticity allows it to accommodate the new shapes and symbols necessary for reading.",
            "score": 113.82115936279297
        },
        {
            "docid": "2640086_28",
            "document": "Affective neuroscience . Instead of investigating specific emotions, Kober, et al. 2008 reviewed 162 neuroimaging studies published between 1990-2005 to determine if groups of brain regions show consistent patterns of activation during emotional experience (that is, actively experiencing an emotion first-hand) and during emotion perception (that is, perceiving a given emotion as experienced by another). This meta-analysis used multilevel kernal density analysis (MKDA) to examine fMRI and PET studies, a technique that prevents single studies from dominating the results (particularly if they report multiple nearby peaks) and that enables studies with large sample sizes (those involving more participants) to exert more influence upon the results. MKDA was used to establish a neural reference space that includes the set of regions showing consistent increases across all studies (for further discussion of MDKA see Wager et al. 2007). Next, this neural reference space was partitioned into functional groups of brain regions showing similar activation patterns across studies by first using multivariate techniques to determine co-activation patterns and then using data-reduction techniques to define the functional groupings (resulting in six groups). Consistent with a psychological construction approach to emotion, the authors discuss each functional group in terms more basic psychological operations. The first \u201cCore Limbic\u201d group included the left amygdala, hypothalamus, periaqueductal gray/thalamus regions, and amygdala/ventral striatum/ventral globus pallidus/thalamus regions, which the authors discuss as an integrative emotional center that plays a general role in evaluating affective significance. The second \u201cLateral Paralimbic\u201d group included the ventral anterior insula/frontal operculum/right temporal pole/ posterior orbitofrontal cortex, the anterior insula/ posterior orbitofrontal cortex, the ventral anterior insula/ temporal cortex/ orbitofrontal cortex junction, the midinsula/ dorsal putamen, and the ventral striatum /mid insula/ left hippocampus, which the authors suggest plays a role in motivation, contributing to the general valuation of stimuli and particularly in reward. The third \u201cMedial Prefrontal Cortex\u201d group included the dorsal medial prefrontal cortex, pregenual anterior cingulate cortex, and rostral dorsal anterior cingulate cortex, which the authors discuss as playing a role in both the generation and regulation of emotion. The fourth \u201cCognitive/ Motor Network\u201d group included right frontal operculum, the right interior frontal gyrus, and the pre-supplementray motor area/ left interior frontal gyrus, regions that are not specific to emotion, but instead appear to play a more general role in information processing and cognitive control. The fifth \u201cOccipital/ Visual Association\u201d group included areas V8 and V4 of the primary visual cortex, the medial temporal lobe, and the lateral occipital cortex, and the sixth \u201cMedial Posterior\u201d group included posterior cingulate cortex and area V1 of the primary visual cortex. The authors suggest that these regions play a joint role in visual processing and attention to emotional stimuli.",
            "score": 113.81348419189453
        },
        {
            "docid": "2727254_7",
            "document": "Mnemonist . The method of loci is \"the use of an orderly arrangement of locations into which one could place the images of things or people that are to be remembered\". The encoding process happens in three steps. First, an architectural area, such as the houses on a street, must be memorized. Second, each item to be remembered must be associated with a separate image. Finally, this set of images can be distributed in a \"locus,\" or place within the architectural area in a pre-determined order. Then, as one tries to recall the information, the mnemonists simply has to \"walk\" down the street, see each symbol, and recall the associated information. An example of mnemonists who used this is Solomon Shereshevsky; he would use Gorky Street, a street he lived on. When he read, each word would form a graphic image. He would then place this image in a place along the street; later, when he needed to recall the information, he would simply \"stroll\" down the street again to recall the necessary information. Neuroimaging studies have shown results that support the method of loci as the retrieval method in world-class memory performers. An fMRI recorded brain activity in memory experts and a control group as they were memorizing selected data. Previous studies have shown that teaching a control group the method of loci leads to changes in brain activation during memorization. Consistent with their use of the method of loci, memory experts had higher activity in the medial parietal cortex, retrospenial cortex, and right posterior hippocampus; these brain areas have been linked to spatial memory and navigation. These differences were observable even when the memory experts were trying to memorize stimuli, such as snowflakes, where they showed no superior ability to the control group.",
            "score": 113.44187927246094
        },
        {
            "docid": "490620_10",
            "document": "Human brain . The cortex is mapped by divisions into about fifty different functional areas known as Brodmann's areas. These areas are distinctly different when seen under a microscope. The cortex is divided into two main functional areas \u2013 a motor cortex and a sensory cortex. The primary motor cortex, which sends axons down to motor neurons in the brainstem and spinal cord, occupies the rear portion of the frontal lobe, directly in front of the somatosensory area. The primary sensory areas receive signals from the sensory nerves and tracts by way of relay nuclei in the thalamus. Primary sensory areas include the visual cortex of the occipital lobe, the auditory cortex in parts of the temporal lobe and insular cortex, and the somatosensory cortex in the parietal lobe. The remaining parts of the cortex, are called the association areas. These areas receive input from the sensory areas and lower parts of the brain and are involved in the complex cognitive processes of perception, thought, and decision-making. The main functions of the frontal lobe are to control attention, abstract thinking, behaviour, problem solving tasks, and physical reactions and personality. The occipital lobe is the smallest lobe; its main functions are visual reception, visual-spatial processing, movement, and colour recognition. There is a smaller occipital lobule in the lobe known as the cuneus. The temporal lobe controls auditory and visual memories, language, and some hearing and speech.",
            "score": 113.19773864746094
        }
    ]
}