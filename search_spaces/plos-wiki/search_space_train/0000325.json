{
    "q": [
        {
            "docid": "54842715_43",
            "document": "Interoception . The EPIC model proposes a method of understanding the brain\u2019s response to stimuli contrary to the classic \"stimulus-response\" model. The classical view of information processing is that when a peripheral stimulus provided information to the central nervous system, it was processed in the brain, and a response was elicited. The EPIC model deviates from this and proposes that the brain is involved in a process of active inference, that is, assiduously making predictions about situations based on previous experiences. These predictions, when coupled with incoming sensory signals, allow the brain to compute a prediction error. Interoceptive prediction errors signal the occurrence of discrepancies within the body, which the brain attempts to minimize. This can be done by 1) modifying the predictions through brain-related pathways, 2) altering the body position/location in order to better align incoming sensory signals with the prediction, or 3) altering the brain\u2019s method of receiving incoming stimuli. Interoceptive prediction error signals are a key component of many theories of interoceptive dysfunction in physical and mental health.",
            "score": 160.24240338802338
        },
        {
            "docid": "684801_4",
            "document": "Andy Clark . In contrast to traditional models of cognition, which often posit the one-way flow of sensory information from the periphery towards more remote areas of the brain, Clark has suggested a two-way \"cascade of cortical processing\" underlying perception, action, and learning. The concept of predictive processing lies at the heart of this view, wherein top-down predictions attempt to correctly guess or \"explain away\" bottom-up sensory information in an iterative, hierarchical manner. Discrepancies between the expected signal and actual signal, in essence the \"prediction error,\" travel upward to help refine the accuracy of future predictions. Interactions between forward flow of error (conveyed by \"error units\") and backward flow of prediction are dynamic, with attention playing a key role in weighting the relative influence of either at each level of the cascade (dopamine is mentioned as \"one possible mechanism for encoding precision\" with regard to error units). Action (or action-oriented predictive processing) also plays an important role in Clark's account as another means by which the brain can reduce prediction error by directly influencing the environment. To this, he adds that \"personal, affective, and hedonic\" factors would be implicated along with the minimization of prediction error, creating a more nuanced model for the relationship between action and perception.",
            "score": 130.9708114862442
        },
        {
            "docid": "53953041_5",
            "document": "Predictive coding . Most of the research literature in the field has been about sensory perception, particularly vision, which is more easily conceptualized. However, the predictive coding framework could also be applied to different neural systems. Taking the sensory system as an example, the brain solves the seemingly intractable problem of modelling distal causes of sensory input through a version of Bayesian inference. It does this by modelling predictions of lower-level sensory inputs via backward connections from relatively higher levels in a cortical hierarchy (Clark, 2013).  Constrained by the statistical regularities of the outside world (and certain evolutionarily prepared predictions), the brain encodes top-down generative models at various temporal and spatial scales in order to predict and effectively suppress sensory inputs rising up from lower levels. A comparison between predictions (priors) and sensory input (likelihood) yields a difference measure (e.g. prediction error, free energy, or surprise) which, if it is sufficiently large beyond the levels of expected statistical noise, will cause the generative model to update so that it better predicts sensory input in the future.",
            "score": 124.82176184654236
        },
        {
            "docid": "53953041_7",
            "document": "Predictive coding . Expectations about the precision (or inverse variance) of incoming sensory input are crucial for effectively minimizing prediction error in that the expected precision of a given prediction error can inform confidence in that error, which influences the extent to which the error is weighted in updating predictions (Feldman & Friston, 2010). Given that the world we live in is loaded with statistical noise, precision expectations must be represented as part of the brain\u2019s generative models, and they should be able to flexibly adapt to changing contexts. For instance, the expected precision of visual prediction errors likely varies between dawn and dusk, such that greater conditional confidence is assigned to errors in broad daylight than errors in prediction at nightfall (Hohwy, 2012). It has recently been proposed that such weighting of prediction errors in proportion to their estimated precision is, in essence, attention (Friston, 2009), and that the process of devoting attention may be neurobiologically accomplished by ascending reticular activating systems (ARAS) optimizing the \u201cgain\u201d of prediction error units.",
            "score": 142.65520656108856
        },
        {
            "docid": "53953041_15",
            "document": "Predictive coding . The empirical evidence for predictive coding is most robust for perceptual processing. As early as 1999, Rao and Ballard proposed a hierarchical visual processing model in which higher-order visual cortical area sends down predictions and the feedforward connections carry the residual errors between the predictions and the actual lower-level activities (Rao and Ballard, 1999). According to this model, each level in the hierarchical model network (except the lowest level, which represents the image) attempts to predict the responses at the next lower level via feedback connections, and the error signal is used to correct the estimate of the input signal at each level concurrently (Rao and Ballard, 1999). Emberson et al. established the top-down modulation in infants using a cross-modal audiovisual omission paradigm, determining that even infant brains have expectation about future sensory input that is carried downstream from visual cortices and are capable of expectation-based feedback (Emberson et al., 2015). Functional near-infrared spectroscopy (fNIRS) data showed that infant occipital cortex responded to unexpected visual omission (with no visual information input) but not to expected visual omission. These results establish that in a hierarchically organized perception system, higher-order neurons send down predictions to lower-order neurons, which in turn sends back up the prediction error signal.",
            "score": 115.5445909500122
        },
        {
            "docid": "53953041_6",
            "document": "Predictive coding . If, instead, the model accurately predicts driving sensory signals, activity at higher levels cancels out activity at lower levels, and the posterior probability of the model is increased. Thus, predictive coding inverts the conventional view of perception as a mostly bottom-up process, suggesting that it is largely constrained by prior predictions, where signals from the external world only shape perception to the extent that they are propagated up the cortical hierarchy in the form of prediction error.",
            "score": 110.85258364677429
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 127.56697690486908
        },
        {
            "docid": "53953041_13",
            "document": "Predictive coding . \u201c...prediction neurons... in deep layers of agranular cortex drive active inference by sending sensory predictions via projections ...to supragranular layers of dysgranular and granular sensory cortices. Prediction-error neurons \u2026.in the supragranular layers of granular cortex compute the difference between the predicted and received sensory signal, and send prediction-error signals via projections...back to the deep layers of agranular cortical regions. Precision cells \u2026 tune the gain on predictions and prediction error dynamically, thereby giving these signals reduced (or, in some cases, greater) weight depending on the relative confidence in the descending predictions or the reliability of incoming sensory signals.\u201d (Barrett & Simmons, 2015)",
            "score": 115.40073347091675
        },
        {
            "docid": "53953041_3",
            "document": "Predictive coding . Theoretical ancestors to predictive coding date back as early as 1860 with Helmholz\u2019s concept of unconscious inference (Clark, 2013). Unconscious inference refers to the idea that the human brain fills in visual information to make sense of a scene. For example, if something is relatively smaller than another object in the visual field, the brain uses that information as a likely cue of depth, such that the perceiver ultimately (and involuntarily) experiences depth. The understanding of perception as the interaction between sensory stimuli (bottom-up) and conceptual knowledge (top-down) continued to be established by Jerome Bruner (psychologist) who, starting in the 1940s, studied the ways in which needs, motivations and expectations influence perception, research that came to be known as 'New Look' psychology. In 1981, McClelland and Rumelhart in their seminal paper examined the interaction between processing features (lines and contours) which form letters, which in turn form words. While the features suggest the presence of a word, they found that when letters were situated in the context of a word, people were able to identify them faster than when they were situated in a non-word without semantic context. McClelland and Rumelhart\u2019s parallel processing model describes perception as the meeting of top-down (conceptual) and bottom-up (sensory) elements.",
            "score": 100.57911205291748
        },
        {
            "docid": "53953041_19",
            "document": "Predictive coding . As a mechanistic theory, predictive coding has not been mapped out physiologically on the neuronal level. One of the biggest challenges to the theory has been the imprecision of exactly how prediction error minimization works (Kogo & Trengove, 2015). In some studies, the increase in BOLD signal has been interpreted as error signal while in others it indicates changes in the input representation (Kogo & Trengove, 2015). A crucial question that needs to be addressed is what exactly constitutes error signal and how it is computed at each level of information processing (Bastos et al., 2012). Another challenge that has been posed is predictive coding\u2019s computational tractability. According to Kwisthout and Rooij, the subcomputation in each level of the predictive coding framework potentially hides a computationally intractable problem, which amounts to \u201cintractable hurdles\u201d that computational modelers have yet to overcome (Kwisthout & Rooij, 2013). Ransom and Fazelpour (2015) indicate \"Three Problems for the Predictive Coding Theory of Attention\".",
            "score": 107.55566322803497
        },
        {
            "docid": "14639492_9",
            "document": "Erich Schr\u00f6ger . In December 2008, Schr\u00f6ger won a one-million-Euro, five-year Reinhart Koselleck Project Grant by the DFG. The main research issue of this project was the mechanism of predictive modeling in audition. Specifically, Schr\u00f6ger investigated how automatic predictions about upcoming auditory events can be generated on the basis of regular environmental stimulation. Due to this mechanism, for example, incoming acoustic stimuli can be processed with astonishing speed as when comprehending spoken language or localizing moving sounds. Likewise, the specific processing of self-induced auditory stimuli\u2014stimuli that a person creates by means of its own behavior\u2014can be explained by the principles of predictive modeling. In order to optimize a predictive model, the information processing system calculates predictive errors as the difference between the prediction and the actual stimulus signal.",
            "score": 113.74735021591187
        },
        {
            "docid": "1221571_2",
            "document": "Rescorla\u2013Wagner model . The Rescorla\u2013Wagner model (\"R-W\") is a model of classical conditioning, in which learning is conceptualized in terms of associations between conditioned (CS) and unconditioned (US) stimuli. A strong CS-US association means, essentially, that the CS signals or predicts the US. One might say that before conditioning, the subject is surprised by the US, but after conditioning, the subject is no longer surprised, because the CS predicts the coming of the US. The model casts the conditioning processes into discrete trials, during which stimuli may be either present or absent. The strength of prediction of the US on a trial can be represented as the summed associative strengths of all CSs present during the trial. This feature of the model represented a major advance over previous models, and it allowed a straightforward explanation of important experimental phenomena, most notably the blocking effect. Failures of the model have led to modifications, alternative models, and many additional findings. The model has had some impact on neural science in recent years, as studies have suggested that the phasic activity of dopamine neurons in mesostriatal DA projections in the midbrain encodes for the type of prediction error detailed in the model.",
            "score": 100.96927726268768
        },
        {
            "docid": "37527148_20",
            "document": "Psychology of film . According to Event Segmentation Theory (EST), the perception of event boundaries is a side effect of prediction during ongoing perception. Prediction is an adaptive mechanism made up of cognitive event models that represent \u201cwhat is going on now\u201d to create expectations and attentive biases for ongoing processing. Prediction errors occur at situational changes and cause information processing segmentation.",
            "score": 86.59416246414185
        },
        {
            "docid": "29354346_8",
            "document": "Change deafness . Additional studies of change deafness have generated evidence in support of the prediction that undetected changes are successfully encoded at the sensory level in the auditory cortex, but do not trigger later change-related cortical responses that would produce conscious perception of change. EEG analysis during a change-detection task using changes in pitch revealed that responses previously shown to be involved with sensory extraction of pitch information increased during both detected and undetected pitch changes in auditory input, however only in cases where the pitch change was detected were later processing stages triggered, originating from hierarchically higher non-sensory brain regions. These findings suggest that change deafness does not arise from a deficit in initial sensory encoding of changed stimulus features in auditory cortex but occurs at a higher level of stimulus processing in auditory cortex, resulting in a failure to trigger auditory change detection mechanisms.",
            "score": 97.12921059131622
        },
        {
            "docid": "39403556_18",
            "document": "Free energy principle . Usually, the generative models that define free energy are non-linear and hierarchical (like cortical hierarchies in the brain). Special cases of generalised filtering include Kalman filtering, which is formally equivalent to predictive coding \u2013 a popular metaphor for message passing in the brain. Under hierarchical models, predictive coding involves the recurrent exchange of ascending (bottom-up) prediction errors and descending (top-down) predictions that is consistent with the anatomy and physiology of sensory and motor systems.",
            "score": 95.46876382827759
        },
        {
            "docid": "21107290_10",
            "document": "Bayesian approaches to brain function . During the 1990s some researchers such as Geoffrey Hinton and Karl Friston began examining the concept of free energy as a calculably tractable measure of the discrepancy between actual features of the world and representations of those features captured by neural network models. A synthesis has been attempted recently by Karl Friston, in which the Bayesian brain emerges from a general principle of free energy minimisation. In this framework, both action and perception are seen as a consequence of suppressing free-energy, leading to perceptual and active inference and a more embodied (enactive) view of the Bayesian brain. Using variational Bayesian methods, it can be shown how internal models of the world are updated by sensory information to minimize free energy or the discrepancy between sensory input and predictions of that input. This can be cast (in neurobiologically plausible terms) as predictive coding or, more generally, Bayesian filtering.",
            "score": 106.04843783378601
        },
        {
            "docid": "53953041_8",
            "document": "Predictive coding . The same principle of prediction error minimization has been used to provide an account of behavior in which motor actions are not commands but descending proprioceptive predictions. In this scheme of active inference, classical reflex arcs are coordinated so as to selectively sample sensory input in ways that better fulfill predictions, thereby minimizing proprioceptive prediction errors (Friston, 2009). Indeed, Adams et al. (2013) review evidence suggesting that this view of hierarchical predictive coding in the motor system provides a principled and neurally plausible framework for explaining the agranular organization of the motor cortex. This view suggests that \u201cperceptual and motor systems should not be regarded as separate but instead as a single active inference machine that tries to predict its sensory input in all domains: visual, auditory, somatosensory, interoceptive and, in the case of the motor system, proprioceptive\u201d (Adams, Shipp, & Friston, 2013).",
            "score": 104.44320273399353
        },
        {
            "docid": "22509570_15",
            "document": "Lateralized readiness potential . As described above, experiments have used the LRP to generate support for a continuous model of stimulus evaluation and response selection. This model predicts that partial information is continuously available from the environment and information can accumulate to an eventual response or near response that is never actually committed. This is in contrast to a discrete model that predicts full stimulus evaluation must be complete before response initiation can start. Thus results using the LRP suggest that partial information is accumulated in the sensory systems and is sent to the motor system before and during response preparation (Coles et al., 1988).",
            "score": 101.02986407279968
        },
        {
            "docid": "24514_41",
            "document": "Psychosis . NMDA receptor dysfunction has been proposed as a mechanism in psychosis. This theory is reinforced by the fact that dissociative NMDA receptor antagonists such as ketamine, PCP and dextromethorphan (at large overdoses) induce a psychotic state. The symptoms of dissociative intoxication are also considered to mirror the symptoms of schizophrenia, including negative psychotic symptoms. NMDA receptor antagonism, in addition to producing symptoms reminiscent of psychosis, mimics the neurophysiological aspects, such as reduction in the amplitude of P50, P300, and MMN evoked potentials. Hierarchical Bayesian neurocomputational models of sensory feedback, in agreement with neuroimaging literature, link NMDA receptor hypofunction to delusional or hallucinatory symptoms via proposing a failure of NMDA mediated top down predictions to adequately cancel out enhanced bottom up AMPA mediated predictions errors. Excessive prediction errors in response to stimuli that would normally not produce such as response is thought to confer excessive salience to otherwise mundane events. Dsyfunction higher up in the hierarchy, where representation is more abstract, could result in delusions. The common finding of reduced GAD67 expression in psychotic disorders may explain enhanced AMPA mediated signaling, caused by reduced GABAergic inhibition.",
            "score": 87.6134284734726
        },
        {
            "docid": "53953041_17",
            "document": "Predictive coding . In 2013, Anil Seth proposed that our subjective feeling states, otherwise known as emotions, are generated by predictive models that is built actively of causal interoceptive appraisals. In relation to how we attribute internal states of others to causes, Sasha Ondobaka, James Kilner, and Karl Friston (2015) proposed that the free energy principle requires the brain to produce a continuous series of predictions with the goal of reducing the amount of prediction error that manifests as \u201cfree energy\u201d. These errors are then used to model anticipatory information about what the state of the outside world will be and attributions of causes of that world state, including understanding of causes of others\u2019 behavior. This is especially necessary because, to create these attributions, our multimodal sensory systems need interoceptive predictions to organize themselves. Therefore, Ondobaka posits that predictive coding is key to understanding other people\u2019s internal states.",
            "score": 105.81357550621033
        },
        {
            "docid": "8651984_19",
            "document": "Plant perception (physiology) . Plant physiology studies the role of signalling to integrate data obtained at the genetic, biochemical, cellular and physiological levels to understand plant development and behaviour. The neurobiological view sees plants as information-processing organisms with rather complex processes of communication occurring throughout the individual plant organism. It studies how environmental information is gathered, processed, integrated and shared (sensory plant biology) to enable these adaptive and coordinated responses (plant behaviour); and how sensory perceptions and behavioural events are 'remembered' in order to allow predictions of future activities upon the basis of past experiences. Plants, it is claimed by some plant physiologists, are as sophisticated in behaviour as animals but this sophistication has been masked by the time scales of plants' response to stimuli, many orders of magnitude slower than animals'.",
            "score": 93.02350115776062
        },
        {
            "docid": "5664_64",
            "document": "Consciousness . In neuroscience, a great deal of effort has gone into investigating how the perceived world of conscious awareness is constructed inside the brain. The process is generally thought to involve two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals arising from sensory organs are transmitted to the brain and then processed in a series of stages, which extract multiple types of information from the raw input. In the visual system, for example, sensory signals from the eyes are transmitted to the thalamus and then to the primary visual cortex; inside the cerebral cortex they are sent to areas that extract features such as three-dimensional structure, shape, color, and motion. Memory comes into play in at least two ways. First, it allows sensory information to be evaluated in the context of previous experience. Second, and even more importantly, working memory allows information to be integrated over time so that it can generate a stable representation of the world\u2014Gerald Edelman expressed this point vividly by titling one of his books about consciousness \"The Remembered Present\". In computational neuroscience, Bayesian approaches to brain function have been used to understand both the evaluation of sensory information in light of previous experience, and the integration of information over time. Bayesian models of the brain are probabilistic inference models, in which the brain takes advantage of prior knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian models have successfully predicted many perceptual phenomena in vision and the nonvisual senses.",
            "score": 102.17932164669037
        },
        {
            "docid": "188540_48",
            "document": "Classical conditioning . An organism's need to predict future events is central to modern theories of conditioning. Most theories use associations between stimuli to take care of these predictions. For example: In the R\u2013W model, the associative strength of a CS tells us how strongly that CS predicts a US. A different approach to prediction is suggested by models such as that proposed by Gallistel & Gibbon (2000, 2002). Here the response is not determined by associative strengths. Instead, the organism records the times of onset and offset of CSs and USs and uses these to calculate the probability that the US will follow the CS. A number of experiments have shown that humans and animals can learn to time events (see Animal cognition), and the Gallistel & Gibbon model yields very good quantitative fits to a variety of experimental data. However, recent studies have suggested that duration-based models cannot account for some empirical findings as well as associative models.",
            "score": 81.19103288650513
        },
        {
            "docid": "35982062_9",
            "document": "Biased Competition Theory . A Top-down process is characterized by a high level of direction of sensory processing by more cognition; Top-down processing is based on pre-existing knowledge when interpreting sensory information. Top-down guidance of attention refers to when the properties of an object (i.e. color, shape) are activated and held in working memory to facilitate the visual search for that object. This controls visual search by guiding attention only to objects that could be the target and avoiding attention on irrelevant objects. Top-down processes are not a complete representation of the object but are coarse, which is why objects similar in color, shape or meaning are often attended to in the process of discriminating irrelevant objects. There is evidence that observers have Top-down control over the locations that will benefit from biased competition in spatial selection visual tasks. Evidence supports that observers can make voluntary decision about which locations are selected. or features that capture the attention in a stimulus-driven manner. Neurophysiology studies have showed that the neural mechanisms in Top-down processing are also seen in attention and working memory, suggesting Top-down processes play an important role in those functions as well. Additionally, Top-down processes can modulate Bottom-up processes by suppressing the \u201cpop-out\u201d features of Bottom-up processing from distracting from the visual search. fMRI studies have investigated the Top-down and Bottom-up processes involved in biased competition theory. Results of fMRI suggest that both Bottom-up and Top-down processes work in parallel to bias competition. Multiple studies have shown that stimuli in the visual field suppress each other when presented together, but not when each stimulus is presented alone. Kastner and colleagues also found that directing attention to the specific location of a stimulus reduces the suppressive effect. Increased activity in the visual cortex was also observed; this was the result of Top-down biasing due to the favoring of the attended location.",
            "score": 84.22944605350494
        },
        {
            "docid": "179092_7",
            "document": "Neurolinguistics . Much work in neurolinguistics involves testing and evaluating theories put forth by psycholinguists and theoretical linguists. In general, theoretical linguists propose models to explain the structure of language and how language information is organized, psycholinguists propose models and algorithms to explain how language information is processed in the mind, and neurolinguists analyze brain activity to infer how biological structures (populations and networks of neurons) carry out those psycholinguistic processing algorithms. For example, experiments in sentence processing have used the ELAN, N400, and P600 brain responses to examine how physiological brain responses reflect the different predictions of sentence processing models put forth by psycholinguists, such as Janet Fodor and Lyn Frazier's \"serial\" model, and Theo Vosse and Gerard Kempen's \"unification model\". Neurolinguists can also make new predictions about the structure and organization of language based on insights about the physiology of the brain, by \"generalizing from the knowledge of neurological structures to language structure\".",
            "score": 96.86413657665253
        },
        {
            "docid": "53953041_2",
            "document": "Predictive coding . Predictive coding models suggest that the brain is constantly generating and updating hypotheses that predict sensory input at varying levels of abstraction. This framework is in contrast to the view that the brain integrates exteroceptive information through a predominantly feedforward process, with feedback connections playing a more minor role in cortical processing.",
            "score": 103.88420629501343
        },
        {
            "docid": "2843988_27",
            "document": "Motor control . Forward models are a predictive internal model of motor control that takes the available perceptual information, combined with a particular motor program, and tries to predict the outcome of the planned motor movement. Forward models structure action by determining how the forces, velocities, and positions of motor components affect changes in the environment and in the individual. It is proposed that forward models help with the Neural control of limb stiffness when individuals interact with their environment. Forward models are thought to use motor programs as input to predict the outcome of an action. An error signal is generated when the predictions made by a forward model do not match the actual outcome of the movement, prompting an update of an existing model and providing a mechanism for learning. These models explain why it is impossible to tickle yourself. A sensation is experienced as ticklish when it is unpredictable. However, forward models predict the outcome of your motor movements, meaning the motion is predictable, and therefore not ticklish.",
            "score": 98.06395983695984
        },
        {
            "docid": "53953041_9",
            "document": "Predictive coding . Evaluating the empirical evidence that suggests a neurologically plausible basis for predictive coding is a broad and varied task. For one thing, and according to the model, predictive coding occurs at every iterative step in the perceptual and cognitive processes; accordingly, manifestations of predictive coding in the brain include genetics, specific cytoarchitecture of cells, systemic networks of neurons, and whole brain analyses. Due to this range of specificity, different methods of investigating the neural mechanisms of predictive coding have been applied, where available; more generally, however, and at least as it relates to humans, there are significant methodological limitations to investigating the potential evidence and much of the work is based on computational modeling of microcircuits in the brain. Notwithstanding, there has been substantial [theoretical] work that has been applied to understanding predictive coding mechanisms in the brain. This section will focus on specific evidence as it relates to the predictive coding phenomenon, rather than analogues, such as homeostasis (which are, nonetheless, integral to our overall understanding of Bayesian inference but already supported heavily; see Clark, 2012 for a review).",
            "score": 103.13475024700165
        },
        {
            "docid": "1196714_10",
            "document": "Memory-prediction framework . Hawkins has extensive training as an electrical engineer. Another way to describe the theory (hinted at in his book) is as a learning hierarchy of feed forward stochastic state machines. In this view, the brain is analyzed as an encoding problem, not too dissimilar from future-predicting error-correction codes. The hierarchy is a hierarchy of abstraction, with the higher level machines' states representing more abstract conditions or events, and these states predisposing lower-level machines to perform certain transitions. The lower level machines model limited domains of experience, or control or interpret sensors or effectors. The whole system actually controls the organism's behavior. Since the state machine is \"feed forward\", the organism responds to future events predicted from past data. Since it is hierarchical, the system exhibits behavioral flexibility, easily producing new sequences of behavior in response to new sensory data. Since the system learns, the new behavior adapts to changing conditions.",
            "score": 82.84934103488922
        },
        {
            "docid": "53953041_4",
            "document": "Predictive coding . In the late 1990s, the idea of top-down and bottom-up processing was translated into a computational model of vision by Rao and Ballard (1990). Their paper demonstrated that there could be a generative model of a scene (top-down processing), which would receive feedback via error signals (how much the visual input varied from the prediction), which would subsequently lead to updating the prediction. The computational model was able to replicate well-established receptive field effects, as well as less understood extra-classical receptive field effects such as end-stopping. Today, the fields of computer science and cognitive science incorporate these same concepts to create the multilayer generative models that underlie machine learning and neural nets (Hinton, 2010).",
            "score": 87.46422624588013
        },
        {
            "docid": "3766002_15",
            "document": "Orbitofrontal cortex . Neurons in the OFC respond both to primary reinforcers, as well as cues that predict rewards across multiple sensory domains. The evidence for responses to visual, gustatory, somatosensory, and olfactory stimuli is robust, but evidence or auditory responses are weaker. In a subset of OFC neurons, neural responses to rewards or reward cues are modulated by individual preference and by internal motivational states such as hunger. A fraction of neurons that respond to sensory cues predicting a reward are selective for reward, and exhibit reversal behavior when cue outcome relationships are swapped. Neurons in the OFC also exhibit responses to the absence of an expected reward, and punishment. Another population of neurons exhibits responses to novel stimuli and can \u201cremember\u201d familiar stimuli for up to a day.",
            "score": 93.14599680900574
        },
        {
            "docid": "59160_21",
            "document": "Confirmation bias . People may remember evidence selectively to reinforce their expectations, even if they gather and interpret evidence in a neutral manner. This effect is called \"selective recall\", \"confirmatory memory\", or \"access-biased memory\". Psychological theories differ in their predictions about selective recall. Schema theory predicts that information matching prior expectations will be more easily stored and recalled than information that does not match. Some alternative approaches say that surprising information stands out and so is memorable. Predictions from both these theories have been confirmed in different experimental contexts, with no theory winning outright.",
            "score": 82.89705777168274
        }
    ],
    "r": [
        {
            "docid": "54842715_43",
            "document": "Interoception . The EPIC model proposes a method of understanding the brain\u2019s response to stimuli contrary to the classic \"stimulus-response\" model. The classical view of information processing is that when a peripheral stimulus provided information to the central nervous system, it was processed in the brain, and a response was elicited. The EPIC model deviates from this and proposes that the brain is involved in a process of active inference, that is, assiduously making predictions about situations based on previous experiences. These predictions, when coupled with incoming sensory signals, allow the brain to compute a prediction error. Interoceptive prediction errors signal the occurrence of discrepancies within the body, which the brain attempts to minimize. This can be done by 1) modifying the predictions through brain-related pathways, 2) altering the body position/location in order to better align incoming sensory signals with the prediction, or 3) altering the brain\u2019s method of receiving incoming stimuli. Interoceptive prediction error signals are a key component of many theories of interoceptive dysfunction in physical and mental health.",
            "score": 160.24240112304688
        },
        {
            "docid": "53953041_7",
            "document": "Predictive coding . Expectations about the precision (or inverse variance) of incoming sensory input are crucial for effectively minimizing prediction error in that the expected precision of a given prediction error can inform confidence in that error, which influences the extent to which the error is weighted in updating predictions (Feldman & Friston, 2010). Given that the world we live in is loaded with statistical noise, precision expectations must be represented as part of the brain\u2019s generative models, and they should be able to flexibly adapt to changing contexts. For instance, the expected precision of visual prediction errors likely varies between dawn and dusk, such that greater conditional confidence is assigned to errors in broad daylight than errors in prediction at nightfall (Hohwy, 2012). It has recently been proposed that such weighting of prediction errors in proportion to their estimated precision is, in essence, attention (Friston, 2009), and that the process of devoting attention may be neurobiologically accomplished by ascending reticular activating systems (ARAS) optimizing the \u201cgain\u201d of prediction error units.",
            "score": 142.65521240234375
        },
        {
            "docid": "684801_4",
            "document": "Andy Clark . In contrast to traditional models of cognition, which often posit the one-way flow of sensory information from the periphery towards more remote areas of the brain, Clark has suggested a two-way \"cascade of cortical processing\" underlying perception, action, and learning. The concept of predictive processing lies at the heart of this view, wherein top-down predictions attempt to correctly guess or \"explain away\" bottom-up sensory information in an iterative, hierarchical manner. Discrepancies between the expected signal and actual signal, in essence the \"prediction error,\" travel upward to help refine the accuracy of future predictions. Interactions between forward flow of error (conveyed by \"error units\") and backward flow of prediction are dynamic, with attention playing a key role in weighting the relative influence of either at each level of the cascade (dopamine is mentioned as \"one possible mechanism for encoding precision\" with regard to error units). Action (or action-oriented predictive processing) also plays an important role in Clark's account as another means by which the brain can reduce prediction error by directly influencing the environment. To this, he adds that \"personal, affective, and hedonic\" factors would be implicated along with the minimization of prediction error, creating a more nuanced model for the relationship between action and perception.",
            "score": 130.97080993652344
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 127.56697845458984
        },
        {
            "docid": "53953041_5",
            "document": "Predictive coding . Most of the research literature in the field has been about sensory perception, particularly vision, which is more easily conceptualized. However, the predictive coding framework could also be applied to different neural systems. Taking the sensory system as an example, the brain solves the seemingly intractable problem of modelling distal causes of sensory input through a version of Bayesian inference. It does this by modelling predictions of lower-level sensory inputs via backward connections from relatively higher levels in a cortical hierarchy (Clark, 2013).  Constrained by the statistical regularities of the outside world (and certain evolutionarily prepared predictions), the brain encodes top-down generative models at various temporal and spatial scales in order to predict and effectively suppress sensory inputs rising up from lower levels. A comparison between predictions (priors) and sensory input (likelihood) yields a difference measure (e.g. prediction error, free energy, or surprise) which, if it is sufficiently large beyond the levels of expected statistical noise, will cause the generative model to update so that it better predicts sensory input in the future.",
            "score": 124.82176208496094
        },
        {
            "docid": "53953041_15",
            "document": "Predictive coding . The empirical evidence for predictive coding is most robust for perceptual processing. As early as 1999, Rao and Ballard proposed a hierarchical visual processing model in which higher-order visual cortical area sends down predictions and the feedforward connections carry the residual errors between the predictions and the actual lower-level activities (Rao and Ballard, 1999). According to this model, each level in the hierarchical model network (except the lowest level, which represents the image) attempts to predict the responses at the next lower level via feedback connections, and the error signal is used to correct the estimate of the input signal at each level concurrently (Rao and Ballard, 1999). Emberson et al. established the top-down modulation in infants using a cross-modal audiovisual omission paradigm, determining that even infant brains have expectation about future sensory input that is carried downstream from visual cortices and are capable of expectation-based feedback (Emberson et al., 2015). Functional near-infrared spectroscopy (fNIRS) data showed that infant occipital cortex responded to unexpected visual omission (with no visual information input) but not to expected visual omission. These results establish that in a hierarchically organized perception system, higher-order neurons send down predictions to lower-order neurons, which in turn sends back up the prediction error signal.",
            "score": 115.54459381103516
        },
        {
            "docid": "53953041_13",
            "document": "Predictive coding . \u201c...prediction neurons... in deep layers of agranular cortex drive active inference by sending sensory predictions via projections ...to supragranular layers of dysgranular and granular sensory cortices. Prediction-error neurons \u2026.in the supragranular layers of granular cortex compute the difference between the predicted and received sensory signal, and send prediction-error signals via projections...back to the deep layers of agranular cortical regions. Precision cells \u2026 tune the gain on predictions and prediction error dynamically, thereby giving these signals reduced (or, in some cases, greater) weight depending on the relative confidence in the descending predictions or the reliability of incoming sensory signals.\u201d (Barrett & Simmons, 2015)",
            "score": 115.4007339477539
        },
        {
            "docid": "14639492_9",
            "document": "Erich Schr\u00f6ger . In December 2008, Schr\u00f6ger won a one-million-Euro, five-year Reinhart Koselleck Project Grant by the DFG. The main research issue of this project was the mechanism of predictive modeling in audition. Specifically, Schr\u00f6ger investigated how automatic predictions about upcoming auditory events can be generated on the basis of regular environmental stimulation. Due to this mechanism, for example, incoming acoustic stimuli can be processed with astonishing speed as when comprehending spoken language or localizing moving sounds. Likewise, the specific processing of self-induced auditory stimuli\u2014stimuli that a person creates by means of its own behavior\u2014can be explained by the principles of predictive modeling. In order to optimize a predictive model, the information processing system calculates predictive errors as the difference between the prediction and the actual stimulus signal.",
            "score": 113.74735260009766
        },
        {
            "docid": "53953041_6",
            "document": "Predictive coding . If, instead, the model accurately predicts driving sensory signals, activity at higher levels cancels out activity at lower levels, and the posterior probability of the model is increased. Thus, predictive coding inverts the conventional view of perception as a mostly bottom-up process, suggesting that it is largely constrained by prior predictions, where signals from the external world only shape perception to the extent that they are propagated up the cortical hierarchy in the form of prediction error.",
            "score": 110.85258483886719
        },
        {
            "docid": "33912_43",
            "document": "Working memory . There is some evidence that optimal working memory performance links to the neural ability to focus attention on task-relevant information and to ignore distractions, and that practice-related improvement in working memory is due to increasing these abilities. One line of research suggests a link between the working memory capacities of a person and their ability to control the orientation of attention to stimuli in the environment. Such control enables people to attend to information important for their current goals, and to ignore goal-irrelevant stimuli that tend to capture their attention due to their sensory saliency (such as an ambulance siren). The direction of attention according to one's goals is assumed to rely on \"top-down\" signals from the pre-frontal cortex (PFC) that biases processing in posterior cortical areas. Capture of attention by salient stimuli is assumed to be driven by \"bottom-up\" signals from subcortical structures and the primary sensory cortices. The ability to override \"bottom-up\" capture of attention differs between individuals, and this difference has been found to correlate with their performance in a working-memory test for visual information. Another study, however, found no correlation between the ability to override attentional capture and measures of more general working-memory capacity.",
            "score": 108.58429718017578
        },
        {
            "docid": "53953041_19",
            "document": "Predictive coding . As a mechanistic theory, predictive coding has not been mapped out physiologically on the neuronal level. One of the biggest challenges to the theory has been the imprecision of exactly how prediction error minimization works (Kogo & Trengove, 2015). In some studies, the increase in BOLD signal has been interpreted as error signal while in others it indicates changes in the input representation (Kogo & Trengove, 2015). A crucial question that needs to be addressed is what exactly constitutes error signal and how it is computed at each level of information processing (Bastos et al., 2012). Another challenge that has been posed is predictive coding\u2019s computational tractability. According to Kwisthout and Rooij, the subcomputation in each level of the predictive coding framework potentially hides a computationally intractable problem, which amounts to \u201cintractable hurdles\u201d that computational modelers have yet to overcome (Kwisthout & Rooij, 2013). Ransom and Fazelpour (2015) indicate \"Three Problems for the Predictive Coding Theory of Attention\".",
            "score": 107.5556640625
        },
        {
            "docid": "21107290_10",
            "document": "Bayesian approaches to brain function . During the 1990s some researchers such as Geoffrey Hinton and Karl Friston began examining the concept of free energy as a calculably tractable measure of the discrepancy between actual features of the world and representations of those features captured by neural network models. A synthesis has been attempted recently by Karl Friston, in which the Bayesian brain emerges from a general principle of free energy minimisation. In this framework, both action and perception are seen as a consequence of suppressing free-energy, leading to perceptual and active inference and a more embodied (enactive) view of the Bayesian brain. Using variational Bayesian methods, it can be shown how internal models of the world are updated by sensory information to minimize free energy or the discrepancy between sensory input and predictions of that input. This can be cast (in neurobiologically plausible terms) as predictive coding or, more generally, Bayesian filtering.",
            "score": 106.0484390258789
        },
        {
            "docid": "53953041_17",
            "document": "Predictive coding . In 2013, Anil Seth proposed that our subjective feeling states, otherwise known as emotions, are generated by predictive models that is built actively of causal interoceptive appraisals. In relation to how we attribute internal states of others to causes, Sasha Ondobaka, James Kilner, and Karl Friston (2015) proposed that the free energy principle requires the brain to produce a continuous series of predictions with the goal of reducing the amount of prediction error that manifests as \u201cfree energy\u201d. These errors are then used to model anticipatory information about what the state of the outside world will be and attributions of causes of that world state, including understanding of causes of others\u2019 behavior. This is especially necessary because, to create these attributions, our multimodal sensory systems need interoceptive predictions to organize themselves. Therefore, Ondobaka posits that predictive coding is key to understanding other people\u2019s internal states.",
            "score": 105.8135757446289
        },
        {
            "docid": "53953041_8",
            "document": "Predictive coding . The same principle of prediction error minimization has been used to provide an account of behavior in which motor actions are not commands but descending proprioceptive predictions. In this scheme of active inference, classical reflex arcs are coordinated so as to selectively sample sensory input in ways that better fulfill predictions, thereby minimizing proprioceptive prediction errors (Friston, 2009). Indeed, Adams et al. (2013) review evidence suggesting that this view of hierarchical predictive coding in the motor system provides a principled and neurally plausible framework for explaining the agranular organization of the motor cortex. This view suggests that \u201cperceptual and motor systems should not be regarded as separate but instead as a single active inference machine that tries to predict its sensory input in all domains: visual, auditory, somatosensory, interoceptive and, in the case of the motor system, proprioceptive\u201d (Adams, Shipp, & Friston, 2013).",
            "score": 104.44320678710938
        },
        {
            "docid": "33246145_2",
            "document": "Neural decoding . Neural decoding is a neuroscience field concerned with the hypothetical reconstruction of sensory and other stimuli from information that has already been encoded and represented in the brain by networks of neurons. Reconstruction refers to the ability of the researcher to predict what sensory stimuli the subject is receiving based purely on neuron action potentials. Therefore, the main goal of neural decoding is to characterize how the electrical activity of neurons elicit activity and responses in the brain.",
            "score": 104.3139877319336
        },
        {
            "docid": "53953041_2",
            "document": "Predictive coding . Predictive coding models suggest that the brain is constantly generating and updating hypotheses that predict sensory input at varying levels of abstraction. This framework is in contrast to the view that the brain integrates exteroceptive information through a predominantly feedforward process, with feedback connections playing a more minor role in cortical processing.",
            "score": 103.88420867919922
        },
        {
            "docid": "48548_33",
            "document": "Dopamine . Within the brain, dopamine functions partly as a \"global reward signal\", where an initial phasic dopamine response to a rewarding stimulus encodes information about the salience, value, and context of a reward. In the context of reward-related learning, dopamine also functions as a \"reward prediction error\" signal, that is, the degree to which the value of a reward is unexpected. According to this hypothesis of Wolfram Schultz, rewards that are expected do not produce a second phasic dopamine response in certain dopaminergic cells, but rewards that are unexpected, or greater than expected, produce a short-lasting increase in synaptic dopamine, whereas the omission of an expected reward actually causes dopamine release to drop below its background level. The \"prediction error\" hypothesis has drawn particular interest from computational neuroscientists, because an influential computational-learning method known as temporal difference learning makes heavy use of a signal that encodes prediction error. This confluence of theory and data has led to a fertile interaction between neuroscientists and computer scientists interested in machine learning.",
            "score": 103.63402557373047
        },
        {
            "docid": "53953041_9",
            "document": "Predictive coding . Evaluating the empirical evidence that suggests a neurologically plausible basis for predictive coding is a broad and varied task. For one thing, and according to the model, predictive coding occurs at every iterative step in the perceptual and cognitive processes; accordingly, manifestations of predictive coding in the brain include genetics, specific cytoarchitecture of cells, systemic networks of neurons, and whole brain analyses. Due to this range of specificity, different methods of investigating the neural mechanisms of predictive coding have been applied, where available; more generally, however, and at least as it relates to humans, there are significant methodological limitations to investigating the potential evidence and much of the work is based on computational modeling of microcircuits in the brain. Notwithstanding, there has been substantial [theoretical] work that has been applied to understanding predictive coding mechanisms in the brain. This section will focus on specific evidence as it relates to the predictive coding phenomenon, rather than analogues, such as homeostasis (which are, nonetheless, integral to our overall understanding of Bayesian inference but already supported heavily; see Clark, 2012 for a review).",
            "score": 103.13475036621094
        },
        {
            "docid": "6240439_6",
            "document": "Mismatch negativity . The MMN is a response to a deviant within a sequence of otherwise regular stimuli; thus, in an experimental setting, it is produced when stimuli are presented in a many-to-one ratio; for example, in a sequence of sounds \"s s s s s s s d s s s s d s s s...\", the \"d\" is the deviant or oddball stimulus, and will elicit an MMN response. The mismatch negativity occurs even if the subject is not consciously paying attention to the stimuli. Processing of sensory stimulus features is essential for humans in determining their responses and actions. If behaviourally relevant aspects of the environment are not correctly represented in the brain, then the organism's behaviour cannot be appropriate. Without these representations our ability to understand spoken language, for example, would be seriously impaired. Cognitive neuroscience has consequently emphasised the importance of understanding brain mechanisms of sensory information processing, that is, the sensory prerequisites of cognition. Most of the data obtained, unfortunately, do not allow the objective measurement of the accuracy of these stimulus representations (see N\u00e4\u00e4t\u00e4nen, 1992). In addition, recent cognitive neuroscience seems to have succeeded in extracting such a measure, however. This is the mismatch negativity (MMN), a component of the event-related potential (ERP), first reported by N\u00e4\u00e4t\u00e4nen, Gaillard, and M\u00e4ntysalo (1978). An in-depth review of MMN research can be found in N\u00e4\u00e4t\u00e4nen (1992) while other recent reviews also provide information on the generator mechanisms of MMN (Alho 1995), its magnetic counterpart, MMNm (N\u00e4\u00e4t\u00e4nen, Ilmoniemi & Alho, 1994), and its clinical applicability (N\u00e4\u00e4t\u00e4nen & Alho, 1995).",
            "score": 102.57772064208984
        },
        {
            "docid": "5664_64",
            "document": "Consciousness . In neuroscience, a great deal of effort has gone into investigating how the perceived world of conscious awareness is constructed inside the brain. The process is generally thought to involve two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals arising from sensory organs are transmitted to the brain and then processed in a series of stages, which extract multiple types of information from the raw input. In the visual system, for example, sensory signals from the eyes are transmitted to the thalamus and then to the primary visual cortex; inside the cerebral cortex they are sent to areas that extract features such as three-dimensional structure, shape, color, and motion. Memory comes into play in at least two ways. First, it allows sensory information to be evaluated in the context of previous experience. Second, and even more importantly, working memory allows information to be integrated over time so that it can generate a stable representation of the world\u2014Gerald Edelman expressed this point vividly by titling one of his books about consciousness \"The Remembered Present\". In computational neuroscience, Bayesian approaches to brain function have been used to understand both the evaluation of sensory information in light of previous experience, and the integration of information over time. Bayesian models of the brain are probabilistic inference models, in which the brain takes advantage of prior knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian models have successfully predicted many perceptual phenomena in vision and the nonvisual senses.",
            "score": 102.1793212890625
        },
        {
            "docid": "22509570_15",
            "document": "Lateralized readiness potential . As described above, experiments have used the LRP to generate support for a continuous model of stimulus evaluation and response selection. This model predicts that partial information is continuously available from the environment and information can accumulate to an eventual response or near response that is never actually committed. This is in contrast to a discrete model that predicts full stimulus evaluation must be complete before response initiation can start. Thus results using the LRP suggest that partial information is accumulated in the sensory systems and is sent to the motor system before and during response preparation (Coles et al., 1988).",
            "score": 101.02986145019531
        },
        {
            "docid": "1221571_2",
            "document": "Rescorla\u2013Wagner model . The Rescorla\u2013Wagner model (\"R-W\") is a model of classical conditioning, in which learning is conceptualized in terms of associations between conditioned (CS) and unconditioned (US) stimuli. A strong CS-US association means, essentially, that the CS signals or predicts the US. One might say that before conditioning, the subject is surprised by the US, but after conditioning, the subject is no longer surprised, because the CS predicts the coming of the US. The model casts the conditioning processes into discrete trials, during which stimuli may be either present or absent. The strength of prediction of the US on a trial can be represented as the summed associative strengths of all CSs present during the trial. This feature of the model represented a major advance over previous models, and it allowed a straightforward explanation of important experimental phenomena, most notably the blocking effect. Failures of the model have led to modifications, alternative models, and many additional findings. The model has had some impact on neural science in recent years, as studies have suggested that the phasic activity of dopamine neurons in mesostriatal DA projections in the midbrain encodes for the type of prediction error detailed in the model.",
            "score": 100.96928405761719
        },
        {
            "docid": "53953041_3",
            "document": "Predictive coding . Theoretical ancestors to predictive coding date back as early as 1860 with Helmholz\u2019s concept of unconscious inference (Clark, 2013). Unconscious inference refers to the idea that the human brain fills in visual information to make sense of a scene. For example, if something is relatively smaller than another object in the visual field, the brain uses that information as a likely cue of depth, such that the perceiver ultimately (and involuntarily) experiences depth. The understanding of perception as the interaction between sensory stimuli (bottom-up) and conceptual knowledge (top-down) continued to be established by Jerome Bruner (psychologist) who, starting in the 1940s, studied the ways in which needs, motivations and expectations influence perception, research that came to be known as 'New Look' psychology. In 1981, McClelland and Rumelhart in their seminal paper examined the interaction between processing features (lines and contours) which form letters, which in turn form words. While the features suggest the presence of a word, they found that when letters were situated in the context of a word, people were able to identify them faster than when they were situated in a non-word without semantic context. McClelland and Rumelhart\u2019s parallel processing model describes perception as the meeting of top-down (conceptual) and bottom-up (sensory) elements.",
            "score": 100.57910919189453
        },
        {
            "docid": "11233144_4",
            "document": "Read Montague . In pursuit of testing these prediction error ideas in humans, Montague founded the Human Neuroimaging Lab at Baylor College of Medicine in Houston, Texas, and pursued functional neuroimaging experiments analogous to those used in other model species. This work tested the reward prediction error model in human subjects using simple conditioning experiments directly analogous to those used in rodents and non-human primates. His group then tested the reward prediction error idea during an abstract task of social exchange between two interacting humans and showed striatal BOLD signals that changed their timing consistent with a prediction error signal, but in the context of a social exchange. They also tested the idea of cultural brand identity and its impact on reward prediction error signals. With Brooks King-Casas and colleagues, Montague later applied the same social exchange approach as a probe of Borderline Personality Disorder, and these efforts have been used to provide a new probe of psychopathology.",
            "score": 100.2254867553711
        },
        {
            "docid": "31285233_13",
            "document": "Motor program . This modular system can be used to describe both motor control and motor learning and requires adaptable internal forward and inverse models. Forward models describe the forward or causal relationship between system inputs, predicting sensory feedback that will occur. Inverse models (controllers) generate the motor command that will cause a desired change in state, given an environmental context. During motor learning, the forward and inverse models are paired and tightly coupled by a responsibility signal within modules. Using the forward model\u2019s predictions and sensory contextual cues, responsibility signals indicate the degree to which each pair should be responsible for controlling current behavior.",
            "score": 99.67414093017578
        },
        {
            "docid": "9690508_10",
            "document": "Pandemonium architecture . As mentioned earlier, this architecture makes error predictions based on the amount of overlapping features. Such as, the most likely error for R should be P. Thus, in order to show this architecture represents the human pattern recognition system we must put these predictions into test. Researchers have constructed scenarios where various letters are presented in situations that make them difficult to identify; then types of errors were observed, which was used to generate confusion matrices: where all of the errors for each letter are recorded. Generally, the results from these experiments matched the error predictions from the pandemonium architecture. Also as a result of these experiments, some researchers have proposed models that attempted to list all of the basic features in the Roman alphabet.",
            "score": 99.17082214355469
        },
        {
            "docid": "11233144_3",
            "document": "Read Montague . Montague\u2019s work has long focused on computational neuroscience \u2013 the connection between physical mechanisms present in real neural tissue and the computational functions that these mechanisms embody. His early theoretical work focused on the hypothesis that dopaminergic systems encode a particular kind of computational process, a reward prediction error signal, similar to those used in areas of artificial intelligence like optimal control. This work, carried out in collaboration with Peter Dayan and Terry Sejnowski, focused on prediction as a guiding concept in terms of synaptic learning rules that would underlie learning, valuation, and choice. This work proposed a modification to the then dominant idea of Hebbian or correlational learning. In particular, it was shown that dopamine neurons and homologous octopaminergic neurons in bees display a reward prediction error signal exactly consonant with the temporal difference error signal familiar from models of conditioning proposed by Sutton and Barto during the 1980s.",
            "score": 99.06344604492188
        },
        {
            "docid": "27314144_3",
            "document": "N200 (neuroscience) . The N2 component starts with the discovery of EEG which dates back as early as 1929 with Hans Berger demonstrating the ability to record electrical activity of the brain by simply placing electrodes over the scalp and then amplifying the signal. Later, in 1936, researcher Pauline and Hallowell Davis manipulated events in the environment and recorded the first known ERP's. One of the first experiments to find evidence of an N200 was by Sutton, Braren, and Zubin (1965) when examining the effects of stimulus uncertainty on sensory potentials. In their study, participants were presented with two types of paired stimuli. In the certain condition, a cue stimulus was presented that was predictive of the modality of the target stimulus, which was either clicks or light flashes. In the uncertain condition, the cue stimulus was not predictive and could be followed by either a click or a light flash. The researchers occasionally found a negativity that peaked on average 190ms post-stimulus in the uncertain condition (N200), in addition to a positivity 300ms post-stimulus (P300).",
            "score": 98.76336669921875
        },
        {
            "docid": "1935504_10",
            "document": "Functional integration (neurobiology) . Dynamic causal modeling (DCM) is a Bayesian method for deducing the structure of a neural system based on the observed hemodynamic (fMRI) or electrophysiologic (EEG/MEG) signal. The first step is to make a prediction as to the relationships between the brain regions of interest, and formulate a system of ordinary differential equations describing the causal relationship between them, although many parameters (and relationships) will be initially unknown. Using previous results on how neural activity is known to translate into fMRI or EEG signals, one can take the measured signal and determine the likelihood that model parameters have particular values. The elucidated model can then be used to predict relationships between the considered brain regions under different conditions. A key factor to consider during the design of neuroimaging experiments involving DCM is the relationship between the timing of tasks or stimuli presented to the subject and the ability of DCM to determine the underlying relationships between brain regions, which is partially determined by the temporal resolution of the imaging modality in use.",
            "score": 98.62499237060547
        },
        {
            "docid": "2843988_27",
            "document": "Motor control . Forward models are a predictive internal model of motor control that takes the available perceptual information, combined with a particular motor program, and tries to predict the outcome of the planned motor movement. Forward models structure action by determining how the forces, velocities, and positions of motor components affect changes in the environment and in the individual. It is proposed that forward models help with the Neural control of limb stiffness when individuals interact with their environment. Forward models are thought to use motor programs as input to predict the outcome of an action. An error signal is generated when the predictions made by a forward model do not match the actual outcome of the movement, prompting an update of an existing model and providing a mechanism for learning. These models explain why it is impossible to tickle yourself. A sensation is experienced as ticklish when it is unpredictable. However, forward models predict the outcome of your motor movements, meaning the motion is predictable, and therefore not ticklish.",
            "score": 98.06395721435547
        },
        {
            "docid": "53744937_5",
            "document": "Attention schema theory . The AST can be summarized in three broad points (Graziano, 2013). First, the brain is an information-processing device. Second, it has a capacity to focus its processing resources more on some signals than on others. That focus may be on select, incoming sensory signals, or it may be on internal information such as specific, recalled memories. That ability to process select information in a focused manner is sometimes called attention. Third, the brain not only uses the process of attention, but it also builds a set of information, or a representation, descriptive of attention. That representation, or internal model, is the attention schema.",
            "score": 97.58512115478516
        },
        {
            "docid": "5198024_4",
            "document": "Efficient coding hypothesis . A key prediction of the efficient coding hypothesis is that sensory processing in the brain should be adapted to natural stimuli. Neurons in the visual (or auditory) system should be optimized for coding images (or sounds) representative of those found in nature. Researchers have shown that filters optimized for coding natural images lead to filters which resemble the receptive fields of simple-cells in V1. In the auditory domain, optimizing a network for coding natural sounds leads to filters which resemble the impulse response of cochlear filters found in the inner ear.",
            "score": 97.54115295410156
        }
    ]
}