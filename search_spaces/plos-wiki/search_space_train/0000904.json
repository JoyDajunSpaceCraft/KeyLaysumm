{
    "q": [
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 102.90035605430603
        },
        {
            "docid": "25192046_3",
            "document": "Robert Desimone . As a graduate student at Princeton, Desimone and his thesis supervisor Charles Gross were the first to publish data that neurons respond specifically to faces. At NIMH, he described the physiological properties of neurons in extrastriate visual cortex, and he and Leslie Ungerleider mapped the topographic organization and anatomical connections of many new cortical visual areas. With Earl Miller, he first discovered a physiological basis for recency memory (repetition suppression) and working memory in inferior temporal cortex. He reported the first evidence for the role of attention in modulating the neuronal properties of areas in the ventral stream, and he and John Duncan proposed a Biased Competition Theory to explain many aspects of attention control. With John Reynolds, he proposed a quantitative model of biased competition to explain the effects of attention on neurons, which is formally a normalization model. With Pascal Fries, he first described the effects of attention on synchronized activity in extrastriate cortex, and he later found that synchronized activity between extrastriate cortex and prefrontal cortex is a mechanistic feature of selective attention",
            "score": 58.149088859558105
        },
        {
            "docid": "41175367_12",
            "document": "Natural scene perception . Ultra-rapid visual categorization is a model proposing an automatic feedforward mechanism that forms high-level object representations in parallel without focused attention. In this model, the mechanism cannot be sped up by training. Evidence for a feedforward mechanism can be found in studies that have shown that many neurons are already highly selective at the beginning of a visual response, thus suggesting that feedback mechanisms are not required for response selectivity to increase. Furthermore, recent fMRI and ERP studies have shown that masked visual stimuli that participants do not consciously perceive can significantly modulate activity in the motor system, thus suggesting somewhat sophisticated visual processing. VanRullen (2006) ran simulations showing that the feedforward propagation of one wave of spikes through high-level neurons, generated in response to a stimulus, could be enough for crude recognition and categorization that occurs in 150 ms or less.",
            "score": 92.64251565933228
        },
        {
            "docid": "32528_17",
            "document": "Visual cortex . The tuning properties of V1 neurons (what the neurons respond to) differ greatly over time. Early in time (40 ms and further) individual V1 neurons have strong tuning to a small set of stimuli. That is, the neuronal responses can discriminate small changes in visual orientations, spatial frequencies and colors. Furthermore, individual V1 neurons in humans and animals with binocular vision have ocular dominance, namely tuning to one of the two eyes. In V1, and primary sensory cortex in general, neurons with similar tuning properties tend to cluster together as cortical columns. David Hubel and Torsten Wiesel proposed the classic ice-cube organization model of cortical columns for two tuning properties: ocular dominance and orientation. However, this model cannot accommodate the color, spatial frequency and many other features to which neurons are tuned . The exact organization of all these cortical columns within V1 remains a hot topic of current research. The mathematical modeling of this function has been compared to Gabor transforms.",
            "score": 49.13260805606842
        },
        {
            "docid": "38442646_6",
            "document": "Gain-field encoding . One of the key components of gain-field encoding is the variability in the response amplitude of the action potentials from neurons. This variability, when independent of change in response selectivity, is called gain modulation. Gain Modulation takes place in many cortical areas and is believed to be a common mechanism of neuronal computation. It allows for the combination of different sensory and cognitive information. For example, neurons implicated in processing a part of the visual field see again in the response amplitude due to shifting focus to that part of the field of vision. Therefore, neurons that are gain modulated can represent multiple types of information. The multi-modal nature of these neurons makes them ideal for specific types of computations, mainly coordinate transformations. This creates the ability to think spatially, the main contributor to physical coordination.",
            "score": 48.8592791557312
        },
        {
            "docid": "19498707_2",
            "document": "Linear-nonlinear-Poisson cascade model . The linear-nonlinear-Poisson (LNP) cascade model is a simplified functional model of neural spike responses. It has been successfully used to describe the response characteristics of neurons in early sensory pathways, especially the visual system. The LNP model is generally implicit when using reverse correlation or the spike-triggered average to characterize neural responses with white-noise stimuli. There are three stages of the LNP cascade model. The first stage consists of a linear filter, or linear receptive field, which describes how the neuron integrates stimulus intensity over space and time. The output of this filter then passes through a nonlinear function, which gives the neuron's instantaneous spike rate as its output. Finally, the spike rate is used to generate spikes according to an inhomogeneous Poisson process.",
            "score": 50.737746238708496
        },
        {
            "docid": "3704475_29",
            "document": "Executive functions . Miller and Cohen draw explicitly upon an earlier theory of visual attention that conceptualises perception of visual scenes in terms of competition among multiple representations \u2013 such as colors, individuals, or objects. Selective visual attention acts to 'bias' this competition in favour of certain selected features or representations. For example, imagine that you are waiting at a busy train station for a friend who is wearing a red coat. You are able to selectively narrow the focus of your attention to search for red objects, in the hope of identifying your friend. Desimone and Duncan argue that the brain achieves this by selectively increasing the gain of neurons responsive to the color red, such that output from these neurons is more likely to reach a downstream processing stage, and, as a consequence, to guide behaviour. According to Miller and Cohen, this selective attention mechanism is in fact just a special case of cognitive control \u2013 one in which the biasing occurs in the sensory domain. According to Miller and Cohen's model, the PFC can exert control over input (sensory) or output (response) neurons, as well as over assemblies involved in memory, or emotion. Cognitive control is mediated by reciprocal PFC connectivity with the sensory and motor cortices, and with the limbic system. Within their approach, thus, the term 'cognitive control' is applied to any situation where a biasing signal is used to promote task-appropriate responding, and control thus becomes a crucial component of a wide range of psychological constructs such as selective attention, error monitoring, decision-making, memory inhibition, and response inhibition.",
            "score": 72.8675571680069
        },
        {
            "docid": "34780199_12",
            "document": "Broadbent's filter model of attention . Attention is commonly understood as the ability to select some things while ignoring others. Attention is controllable, selective, and limited. It is the progression by which external stimuli form internal representations that gain conscious awareness. Attention is part of nearly every waking moment for humans, as it is the focusing of one's thoughts. Selective attention utilizes cognitive processes to focus on relevant targets on input, thoughts or actions while neglecting irrelevant sources of input. This is the basis for how we attend to specific stimuli. Voluntary attention, otherwise known as top-down attention, is the aspect over which we have control, enabling us to act in a goal-directed manner. In contrast, reflexive attention is driven by exogenous stimuli redirecting our current focus of attention to a new stimulus, thus it is a bottom-up influence. These two divisions of attention are continuously competing to be the momentary foci of attention. Selection models of attention theorize how specific stimuli gain our awareness. Early selection models emphasize physical features of stimuli are attended to, while late selection models argue that semantic features are what determine our current focus of attention. These selection models are utilized by researchers to propose when stimulus information is attended to.",
            "score": 117.55180668830872
        },
        {
            "docid": "34021968_15",
            "document": "Visual tilt effects . Furthermore, mechanistic models of orientation tuning are used to assess the neural basis of experimental findings on tilt effects. Changes on tuning curves would shift population response resulting in tilt biases. Contextual stimuli can possibly change neural firing rates, tuning widths, and preferred orientations, which depends on the relationship between the orientation of the contextual stimuli and the preferred orientation of the neurons.",
            "score": 47.600769996643066
        },
        {
            "docid": "23798774_6",
            "document": "David LaBerge . 1. Mathematical models of choice behavior. A model for neutral elements (1959a, b) provided a way to represent noise elements in the Estes and Burke (1953) choice theory. A recruitment model for choice behavior (1962, 1994) assumes that processing a stimulus involves the recruiting (or accumulation) of elements by alternative response counters until a criterion number is reached and the corresponding response is evoked. 2. Early experiments of attention in response time experiments. Stimulus processing is biased by relative frequency of presentation (1964), by incentive value (1967), and by inserting an informative cue into a trial (1970). 3. Studies of automaticity. Measurement of automatic processing (1973a). A theory of automaticity in reading (1974) with S.J. Samuels. A theory of automaticity in perception (1975). 4. Measuring the spread of attention in visual space (1983, 1989). 5. Shifting attention by sense modality (1973b) and across visual space (1997). 6. Studies of thalamic involvement in selective attention. A brain scan study of the human pulvinar during sustained selective attention (1990) with Monte Buchsbaum. A neural network simulation study of thalamic circuit operations in selective attention (1992). 7. Development of a test for preparatory attention to location (2000) with Eric Sieroff, and tests of patients (2004, 2005). 8. Development of a cortex-wide circuit theory of attention: The Triangular Circuit of Attention, (1995, 1997). 9. Development of an apical dendrite theory of cognition, attention, and consciousness. A series of papers explored the hypothesis that the apical dendrite is not \"just another dendrite\" but has its own special functions (2001, 2002, 2005, 2006, 2007). The hypothesis that the apical dendrite resonates was illustrated informally by LaBerge and his daughter, Anne La Berge in three performances of a work entitled Resonant Dendrites, (2006, 2007, 2009), which featured film, narrative voice samples and music. A formal description of a theory of electric resonance in apical dendrites appeared in an article by Kasevich & LaBerge (2010), which shows how an apical dendrite can fine tune its own membrane oscillations to a specific peak frequency, and narrow the width of the resonance curve around this peak to less than 1\u00a0Hz. This refinement enables its associated cortical circuit to generate a specific resonant (\"carrier\") frequency by which the circuit can separate its signaling from that of other circuits. A more recent article by LaBerge & Kasevich (2013) describes signaling by neurons as the neural correlate of objective information processing and resonating in clusters of apical dendrites as the neural correlate of subjective impressions (e.g., impressions of sounds, colors, and feelings). These two \"articles provide theoretical support for the hypothesis that apical dendrite resonance supplements neural signaling as a major mode of neural function. Furthermore, the resonance-based subjective impressions may be regarded as the contents of consciousness.",
            "score": 88.44082760810852
        },
        {
            "docid": "30767825_8",
            "document": "Ephaptic coupling . More recent research, however, has focused on the more general case of electric fields that affect a variety of neurons. It has been observed that local field potentials in cortical neurons can serve to synchronize neuronal activity. Although the mechanism is unknown, it is hypothesized that neurons are ephaptically coupled to the frequencies of the local field potential. This coupling may effectively synchronize neurons into periods of enhanced excitability (or depression) and allow for specific patterns of action potential timing (often referred to as spike timing). This effect has been demonstrated and modeled in a variety of cases.",
            "score": 28.94966721534729
        },
        {
            "docid": "2920040_2",
            "document": "Neuronal tuning . Neuronal tuning refers to the hypothesized property of brain cells by which they selectively represent a particular type of sensory, association, motor, or cognitive information. Some neuronal responses have been hypothesized to be optimally tuned to specific patterns through experience. Neuronal tuning can be strong and sharp, as observed in primary visual cortex (area V1) (but see Carandini et al 2005 ), or weak and broad, as observed in neural ensembles. Single neurons are hypothesized to be simultaneously tuned to several modalities, such as visual, auditory, and olfactory. Neurons hypothesized to be tuned to different signals are often hypothesized to integrate information from the different sources. In computational models called neural networks, such integration is the major principle of operation. The best examples of neuronal tuning can be seen in the visual, auditory, olfactory, somatosensory, and memory systems, although due to the small number of stimuli tested the generality of neuronal tuning claims is still an open question.",
            "score": 59.716317772865295
        },
        {
            "docid": "2860457_5",
            "document": "Neural ensemble . In the 1980s, Apostolos Georgopoulos and his colleagues Ron Kettner, Andrew Schwartz, and Kenneth Johnson formulated a population vector hypothesis to explain how populations of motor cortex neurons encode movement direction. This hypothesis was based on the observation that individual neurons tended to discharge more for movements in particular directions, the so-called \"preferred directions\" for individual neurons. In the population vector model, individual neurons 'vote' for their preferred directions using their firing rate. The final vote is calculated by vectorial summation of individual preferred directions weighted by neuronal rates. This model proved to be successful in description of motor-cortex encoding of reach direction, and it was also capable to predict new effects. For example, Georgopoulos' population vector accurately described mental rotations made by the monkeys that were trained to translate locations of visual stimuli into spatially shifted locations of reach targets.",
            "score": 58.856414556503296
        },
        {
            "docid": "1947410_19",
            "document": "Critical period . In a follow-up experiment, Hubel and Wiesel (1963) explored the cortical responses present in kittens after binocular deprivation; they found it difficult to find any active cells in the cortex, and the responses they did get were either slow-moving or fast-fatiguing. Furthermore, the cells that did respond selected for edges and bars with distinct orientation preferences. Nevertheless, these kittens developed normal binocularity. Hubel and Wiesel first explained the mechanism, known as orientation selectivity, in the mammalian visual cortex. Orientation tuning, a model that originated with their model, is a concept in which receptive fields of neurons in the LGN excite a cortical simple cell and are arranged in rows. This model was important because it was able to describe a critical period for the proper development of normal ocular dominance columns in the lateral geniculate nucleus, and thus able to explain the effects of monocular deprivation during this critical period. The critical period for cats is about three months and for monkeys, about six months.",
            "score": 47.209022998809814
        },
        {
            "docid": "33244792_4",
            "document": "Non-spiking neuron . There are an abundance of neurons that propagate signals via action potentials and the mechanics of this particular kind of transmission is well understood. Spiking neurons exhibit action potentials as a result of a neuron characteristic known as membrane potential. Through studying these complex spiking networks in animals, a neuron that did not exhibit characteristic spiking behavior was discovered. These neurons use a graded potential to transmit data as they lack the membrane potential that spiking neurons possess. This method of transmission has a huge effect on the fidelity, strength, and lifetime of the signal. Non-spiking neurons were identified as a special kind of interneuron and function as an intermediary point of process for sensory-motor systems. Animals have become substantial models for understanding more about non-spiking neural networks and the role they play in an animal\u2019s ability to process information and its overall function. Animal models indicate that the interneurons modulate directional and posture coordinating behaviors. Crustaceans and arthropods such as the crawfish have created many opportunities to learn about the modulatory role that these neurons have in addition to their potential to be modulated regardless of their lack of exhibiting spiking behavior. Most of the known information about nonspiking neurons is derived from animal models. Studies focus on neuromuscular junctions and modulation of abdominal motor cells. Modulatory interneurons are neurons that are physically situated next to muscle fibers and innervate the nerve fibers which allow for some orienting movement. These modulatory interneurons are usually nonspiking neurons. Advances in studying nonspiking neurons included determining new delineations among the different types of interneurons. These discoveries were due to the usage of methods such as protein receptor silencing. Studies have been done on the non-spiking neuron qualities in animals of specific non-spiking neural networks that have a corollary in humans, e.g. retina amacrine cell of the eye.",
            "score": 51.0599730014801
        },
        {
            "docid": "34021968_17",
            "document": "Visual tilt effects . The effect of context on tilt also can be detected by measuring how the electrophysiological responses of single or population neurons to the test stimuli are changed by context. Electrophysiological results indicate contextual stimuli could suppress or enhance neuron firing rates, cause broadening or sharpening of orientation tuning widths, and shifts in preferred orientation. It has also been shown that responses of population neurons (by adding individual responses together) are changed by the context.",
            "score": 37.60913705825806
        },
        {
            "docid": "41121206_5",
            "document": "Phase resetting in neurons . Shifts in phase (or behavior of neurons) caused due to a perturbation (an external stimulus) can be quantified within a Phase Response Curve (PRC) to predict synchrony in coupled and oscillating neurons. These effects can be computed, in the case of advances or delays to responses, to observe the changes in the oscillatory behavior of neurons, pending on when a stimulus was applied in the phase cycle of an oscillating neuron. The key to understanding this is in the behavioral patterns of neurons and the routes neural information travels. Neural circuits are able to communicate efficiently and effectively within milliseconds of experiencing a stimulus and lead to the spread of information throughout the neural network. The study of neuron synchrony could provide information on the differences that occur in neural states such as normal and diseased states. Neurons that are involved significantly in diseases such as Alzheimers or Parkinsons diseases are shown to undergo phase resetting before launching into phase locking where clusters of neurons are able to begin firing rapidly to communicate information quickly. A phase response curve can be calculated by noting changes to its period over time depending on where in the cycle the input is applied. The perturbation left by the stimulus moves the stable cycle within the oscillation followed by a return to the stable cycle limit. The curve tracks the amount of advancement or delay due to the input in the oscillating neuron. The PRC assumes certain patterns of behavior in firing pattern as well as the network of oscillating neurons to model the oscillations. Currently, only a few circuits exist which can be modeled using an assumed firing pattern.",
            "score": 31.058207511901855
        },
        {
            "docid": "27169449_16",
            "document": "Auditory spatial attention . The first experiment used an endogenous or top down orthogonal cuing paradigm to investigate the cortical regions involved in audiospatial attention vs. visuospatial attention. The orthogonal cuing paradigm refers to the information provided by the cue stimuli; participants were asked to make a spatial up/down elevation judgement to stimuli that can appear either centrally, or laterally to the left / right side. While cues provided information to the lateralization of the target to be presented, they contained no information as to the correct elevation judgement. Such a procedure was used to dissociate the functional effects of spatial attention from those of motor-response priming. The same task was used for visual and auditory targets, in alternating blocks. Crucially, the primary focus of analysis was on \u201ccatch trials,\u201d in which cued targets are not presented. This allowed for investigation of functional activation related to attending to a specific location, free of contamination from target-stimulus related activity. In the auditory domain, comparing activation following peripheral right and left cues to central cues revealed significant activation in the posterior parietal cortex (PPC,) frontal eye fields (FEF), and supplementary motor area (SMA.) These areas overlap those that were significantly active during the visuospatial attention condition; a comparison of the activation during the auditory and visual spatial attention conditions found no significant difference between the two.",
            "score": 86.73338580131531
        },
        {
            "docid": "33818014_13",
            "document": "Nervous system network models . The neuron cell has three components\u00a0\u2013 dendrites, soma, and axon as shown in Figure 1. Dendrites, which have the shape of a tree with branches, called arbor, receive the message from other neurons with which the neuron is connected via synapses. The action potential received by each dendrite from the synapse is called the postsynaptic potential. The cumulative sum of the postsynaptic potentials is fed to the soma. The ionic components of the fluid inside and outside maintain the cell membrane at a resting potential of about 65 millivolts. When the cumulative postsynaptic potential exceeds the resting potential, an action potential is generated by the cell body or soma and propagated along the axon. The axon may have one or more terminals and these terminals transmit neurotransmitters to the synapses with which the neuron is connected. Depending on the stimulus received by the dendrites, soma may generate one or more well-separated action potentials or spike train. If the stimulus drives the membrane to a positive potential, it is an excitatory neuron; and if it drives the resting potential further in the negative direction, it is an inhibitory neuron. The generation of the action potential is called the \u201cfiring.\u201d The firing neuron described above is called a spiking neuron. We will model the electrical circuit of the neuron in Section 3.6. There are two types of spiking neurons. If the stimulus remains above the threshold level and the output is a spike train, it is called the Integrate-and-Fire (IF) neuron model. If output is modeled as dependent on the impulse response of the circuit, then it is called the Spike Response Model (SRM) (Gestner, W. (1995)).",
            "score": 31.948750495910645
        },
        {
            "docid": "34038330_46",
            "document": "Theta model . A group led by Boergers, used the theta model to explain why exposure to multiple simultaneous stimuli can reduce the response of the visual cortex below the normal response from a single (preferred) stimulus. Their computational results showed that this may happen due to strong stimulation of a large group of inhibitory neurons. This effect not only inhibits neighboring populations, but has the extra consequence of leaving the inhibitory neurons in disarray, thus increasing the effectiveness of inhibition.",
            "score": 55.43239939212799
        },
        {
            "docid": "2860430_15",
            "document": "Neural oscillation . Scientists have identified some intrinsic neuronal properties that play an important role in generating membrane potential oscillations. In particular, voltage-gated ion channels are critical in the generation of action potentials. The dynamics of these ion channels have been captured in the well-established Hodgkin\u2013Huxley model that describes how action potentials are initiated and propagated by means of a set of differential equations. Using bifurcation analysis, different oscillatory varieties of these neuronal models can be determined, allowing for the classification of types of neuronal responses. The oscillatory dynamics of neuronal spiking as identified in the Hodgkin\u2013Huxley model closely agree with empirical findings. In addition to periodic spiking, subthreshold membrane potential oscillations, i.e. resonance behavior that does not result in action potentials, may also contribute to oscillatory activity by facilitating synchronous activity of neighboring neurons. Like pacemaker neurons in central pattern generators, subtypes of cortical cells fire bursts of spikes (brief clusters of spikes) rhythmically at preferred frequencies. Bursting neurons have the potential to serve as pacemakers for synchronous network oscillations, and bursts of spikes may underlie or enhance neuronal resonance.",
            "score": 31.571147561073303
        },
        {
            "docid": "41121858_11",
            "document": "Binocular neurons . The stereo model is then made from a multitude of complex cell models that have differing disparities covering a testable range of disparities. Any individual stimulus is then distinguishable through finding the complex cell in the population with the strongest response to the stimuli. The stereo model accounts for most non-temporal physiological observations of binocular neurons as well as the correspondence problem. An important aspect of the stereo model is it accounts for disparity attraction and repulsion. An example of disparity attraction and repulsion is that at a close distance two objects appear closer in depth than in actuality, and at further distances from each other they appear further in depth than in actuality. Disparity attraction and repulsion is believed to be directly related to the physiological properties of binocular neurons in the visual cortex. Use of the stereo model has allowed for interpretation of the source of differing peak locations found in disparity tuning curves of some cells in visual cortex. These differing peak locations of the disparity tuning curves are called characteristic disparity. Due to the lack of defined disparity tuning curves for simple cells, they cannot have characteristic disparities., but the characteristic disparities can be attributed to complex cells instead. Two limitations of the stereo model is that it does not account for the response of binocular neurons in time, and that it does not give much insight into connectivity of binocular neurons.",
            "score": 48.12249779701233
        },
        {
            "docid": "35988954_3",
            "document": "Sensory enhancement theory of object-based attention . Single-cell recordings experiments were the first experiments to support the presence of sensory enhancement. V1 neurons in monkeys were measured for neural responses by Roelfsema, Lamme & Spekreijse (1998), while the monkeys performed a curve-tracing task. The neurons were found to be more active when their receptor fields were on the target-curve as opposed to when their receptor fields fell on the distractor-curve. Furthermore, enhancement was present in the neurons whose receptor fields were on segments of the target-curve relative to segments of the distractor-curve. This effect occurred regardless of whether the curves were spatially separate or overlapping. The presence of neural enhancement when the neurons receptor fields fell on the target-curve could suggest that attention is spreading to the boundaries of the object and then stopping. More recently, Roelfesema and Houtkamp (2011) found that there was a time difference in the onset of enhancement in these V1 neurons. The enhancement of the neuron took longer to appear as the spatial distance between the fixation of attention and receptor field increased. This finding is supported by the performance of mental curve tracing tasks in humans. The results of these single cell recording studies therefore suggest that attention when deployed within an object enhances the representations of the object as a whole and this process of enhancement is gradual so it takes time to complete.",
            "score": 60.64104151725769
        },
        {
            "docid": "41848173_3",
            "document": "Surround suppression . The classical model of early vision presumes that each neuron responds independently to a specific stimulus in a localized area of the visual field. (According to Carandini et al (2005), this computational model, which may be fit to various datasets, \"degrade[s] quickly if we change almost any aspect of the test stimulus.\") The stimulus and corresponding location in the visual field are collectively called the classical receptive field. However, not all effects can be explained by via ad hoc independent filters. Surround suppression is one of an infinite number of possible effects in which neurons do not behave according to the classical model. These effects are collectively called non-classical receptive field effects, and have recently become a substantial research area in vision and other sensory systems.",
            "score": 44.80369567871094
        },
        {
            "docid": "2920040_4",
            "document": "Neuronal tuning . While these simple cells in V1 respond to oriented bars through small receptive fields, the optimal visual stimulus becomes increasing complex as one moves toward the anterior of the brain. Neurons in area V4 are selectively tuned to different wavelengths, hues, and saturations of color. The middle temporal or area V5 is specifically tuned to the speed and direction of moving stimuli. At the apex of the ventral stream called the inferotemporal cortex, neurons became tuned to complex stimuli, such as faces. The specific tuning of intermediate neurons in the ventral stream is less clear, because the range of form variety that can be utilized for probing is nearly infinite.",
            "score": 48.22933268547058
        },
        {
            "docid": "2920040_3",
            "document": "Neuronal tuning . Accepted neuronal tuning models suggest that neurons respond to different degrees based on the similarity between the optimal stimulus of the neuron and the given stimulus. (Teller (1984), however, has challenged the \"detector\" view of neurons on logical grounds) The first major evidence of neuronal tuning in the visual system was provided by Hubel and Wiesel in 1959. They discovered that oriented slits of light were the most effective (of a very small set tested) stimuli for striate cortex \u201csimple cell\u201d neurons. Other neurons, \u201ccomplex cells,\" responded best to lines of a certain orientation moving in a specific direction. Overall, the V1 neurons were found to be selectively tuned to certain orientations, sizes, positions, and forms. Hubel and Wiesel won the Nobel Prize in Physiology or Medicine in 1981 for their discoveries concerning information processing in the visual system. (More recently, Carandini et al (2005) have pointed out that the distinction between \"simple\" and \"complex\" cells may not be a valid one, observing that \"simple and complex cells may not form a dichotomy at all.\" )",
            "score": 60.71063303947449
        },
        {
            "docid": "3382372_2",
            "document": "Normalization model . The normalization model is an influential model of responses of neurons in primary visual cortex. David Heeger developed the model in the early 1990s, and later refined it together with Matteo Carandini and J. Anthony Movshon. The model involves a divisive stage. In the numerator is the output of the classical receptive field. In the denominator, a constant plus a measure of local stimulus contrast. Although the normalization model was initially developed to explain responses in the primary visual cortex, normalization is now thought to operate throughout the visual system, and in many other sensory modalities and brain regions, including the representation of odors, the modulatory effects of visual attention, the encoding of value, and the integration of multisensory information. Its presence in such a diversity of neural systems in multiple species, from invertebrates to mammals, suggests that normalization serves as a canonical neural computation.",
            "score": 63.25689673423767
        },
        {
            "docid": "6455155_7",
            "document": "Chubb illusion . The Chubb illusion illustrates an error in contrast rather than luminance. The zero-luminance background of Figure 2 (A) becomes a zero-contrast field in the analogous portion of Figure 1, while the high-luminance field of Figure 2 (B) becomes a high-contrast texture field. Observers empirically perceive the texture disk of the leftmost portion of Figure 1 as having higher contrast than the disk on the right, even though the two are the same. After conducting experiments on contrast and lightness induction, interocular induction and induction between spatial frequency bands, they show that lateral inhibitory effect is monocular and adapted only for spatial frequency. Chubb et al. support \"a model in which the output gain of such a band-selective neuron is normalized relative to the average response amplitude of nearby neurons with the same frequency tuning.\"",
            "score": 41.58278954029083
        },
        {
            "docid": "41121858_9",
            "document": "Binocular neurons . An energy model, a kind of stimulus-response model, of binocular neurons allows for investigation behind the computational function these disparity tuned cells play in the creation of depth perception. Energy models of binocular neurons involve the combination of monocular receptive fields that are either shifted in position or phase. These shifts in either position or phase allow for the simulated binocular neurons to be sensitive to disparity. The relative contributions of phase and position shifts in simple and complex cells combine together in order to create depth perception of an object in 3-dimensional space. Binocular simple cells are modeled as linear neurons. Due to the linear nature of these neurons, positive and negative values are encoded by two neurons where one neuron encodes the positive part and the other the negative part. This results in the neurons being complements of each other where the excitatory region of one binocular simple cell overlaps with the inhibitory region of another. Each neuron's response is limited such that only one may have a non-zero response for any time. This kind of limitation is called halfwave-rectifing. Binocular complex cells are modeled as energy neurons since they do not have discrete on and off regions in their receptive fields. Energy neurons sum the squared responses of two pairs of linear neurons which must be 90 degrees out of phase. Alternatively, they can also be the sum the squared responses of four halfwave-rectified linear neurons.",
            "score": 37.20019221305847
        },
        {
            "docid": "4231622_6",
            "document": "Inferior temporal gyrus . The light energy that comes from the rays bouncing off of an object is converted into chemical energy by the cells in the retina of the eye. This chemical energy is then converted into action potentials that are transferred through the optic nerve and across the optic chiasm, where it is first processed by the lateral geniculate nucleus of the thalamus. From there the information is sent to the primary visual cortex, region V1. It then travels from the visual areas in the occipital lobe to the parietal and temporal lobes via two distinct anatomical streams. These two cortical visual systems were classified by Ungerleider and Mishkin (1982, see two-streams hypothesis). One stream travels ventrally to the inferior temporal cortex (from V1 to V2 then through V4 to ITC) while the other travels dorsally to the posterior parietal cortex. They are labeled the \u201cwhat\u201d and \u201cwhere\u201d streams, respectively. The Inferior Temporal Cortex receives information from the ventral stream, understandably so, as it is known to be a region essential in recognizing patterns, faces, and objects.  The understanding at the single-cell level of the IT cortex and its role of utilizing memory to identify objects and or process the visual field based on color and form visual information is a relatively recent in neuroscience. Early research indicated that the cellular connections of the temporal lobe to other memory associated areas of the brain \u2013 namely the hippocampus, the amygdala, the prefrontal cortex, among others. These cellular connections have recently been found to explain unique elements of memory, suggesting that unique single-cells can be linked to specific unique types and even specific memories. Research into the single-cell understanding of the IT cortex reveals many compelling characteristics of these cells: single-cells with similar selectivity of memory are clustered together across the cortical layers of the IT cortex; the temporal lobe neurons have recently been shown to display learning behaviors and possibly relate to long-term memory; and, cortical memory within the IT cortex is likely to be enhanced over time thanks to the influence of the afferent-neurons of the medial-temporal region. Further research of the single-cells of the IT cortex suggests that these cells not only have a direct link to the visual system pathway but also are deliberate in the visual stimuli they respond to: in certain cases, the single-cell IT cortex neurons do not initiate responses when spots or slits, namely simple visual stimuli, are present in the visual field; however, when complicated objects are put in place, this initiates a response in the single-cell neurons of the IT cortex. This provides evidence that not only are the single-cell neurons of the IT cortex related in having a unique specific response to visual stimuli but rather that each individual single-cell neuron has a specific response to a specific stimuli. The same study also reveals how the magnitude of the response of these single-cell neurons of the IT cortex do not change due to color and size but are only influenced by the shape. This led to even more interesting observations where specific IT neurons have been linked to the recognition of faces and hands. This is very interesting as to the possibility of relating to neurological disorders of prosopagnosia and explaining the complexity and interest in the human hand. Additional research form this study goes into more depth on the role of \"face neurons\" and \"hand neurons\" involved in the IT cortex.  The significance of the single-cell function in the IT cortex is that it is another pathway in addition to the lateral geniculate pathway that processes most visual system: this raises questions about how does it benefit our visual information processing in addition to normal visual pathways and what other functional units are involved in additional visual information processing.",
            "score": 70.10025334358215
        },
        {
            "docid": "14408479_47",
            "document": "Biological neuron model . The spiking neuron model by Nossenson & Messer produces the probability of the neuron to fire a spike as a function of either an external or pharmacological stimulus. The model consists of a cascade of a receptor layer model and a spiking neuron model, as shown in Fig 4. The connection between the external stimulus to the spiking probability is made in two steps: First, a receptor cell model translates the raw external stimulus to neurotransmitter concentration, then, a spiking neuron model connects between neurotransmitter concentration to the firing rate (spiking probability). Thus, the spiking neuron model by itself depends on neurotransmitter concentration at the input stage. An important feature of this model is the prediction for neurons firing rate pattern which captures, using a low number of free parameters, the characteristic edge emphasized response of neurons to a stimulus pulse, as shown in Fig. 5. The firing rate is identified both as a normalized probability for neural spike firing, and as a quantity proportional to the current of neurotransmitters released by the cell. The expression for the firing rate takes the following form:",
            "score": 31.670013785362244
        },
        {
            "docid": "505717_72",
            "document": "Image segmentation . Pulse-coupled neural networks (PCNNs) are neural models proposed by modeling a cat\u2019s visual cortex and developed for high-performance biomimetic image processing. In 1989, Eckhorn introduced a neural model to emulate the mechanism of a cat\u2019s visual cortex. The Eckhorn model provided a simple and effective tool for studying the visual cortex of small mammals, and was soon recognized as having significant application potential in image processing. In 1994, the Eckhorn model was adapted to be an image processing algorithm by Johnson, who termed this algorithm Pulse-Coupled Neural Network. Over the past decade, PCNNs have been utilized for a variety of image processing applications, including: image segmentation, feature generation, face extraction, motion detection, region growing, noise reduction, and so on. A PCNN is a two-dimensional neural network. Each neuron in the network corresponds to one pixel in an input image, receiving its corresponding pixel\u2019s color information (e.g. intensity) as an external stimulus. Each neuron also connects with its neighboring neurons, receiving local stimuli from them. The external and local stimuli are combined in an internal activation system, which accumulates the stimuli until it exceeds a dynamic threshold, resulting in a pulse output. Through iterative computation, PCNN neurons produce temporal series of pulse outputs. The temporal series of pulse outputs contain information of input images and can be utilized for various image processing applications, such as image segmentation and feature generation. Compared with conventional image processing means, PCNNs have several significant merits, including robustness against noise, independence of geometric variations in input patterns, capability of bridging minor intensity variations in input patterns, etc.",
            "score": 72.0326795578003
        }
    ],
    "r": [
        {
            "docid": "34780199_12",
            "document": "Broadbent's filter model of attention . Attention is commonly understood as the ability to select some things while ignoring others. Attention is controllable, selective, and limited. It is the progression by which external stimuli form internal representations that gain conscious awareness. Attention is part of nearly every waking moment for humans, as it is the focusing of one's thoughts. Selective attention utilizes cognitive processes to focus on relevant targets on input, thoughts or actions while neglecting irrelevant sources of input. This is the basis for how we attend to specific stimuli. Voluntary attention, otherwise known as top-down attention, is the aspect over which we have control, enabling us to act in a goal-directed manner. In contrast, reflexive attention is driven by exogenous stimuli redirecting our current focus of attention to a new stimulus, thus it is a bottom-up influence. These two divisions of attention are continuously competing to be the momentary foci of attention. Selection models of attention theorize how specific stimuli gain our awareness. Early selection models emphasize physical features of stimuli are attended to, while late selection models argue that semantic features are what determine our current focus of attention. These selection models are utilized by researchers to propose when stimulus information is attended to.",
            "score": 117.55180358886719
        },
        {
            "docid": "4236583_11",
            "document": "Visual search . Subsequently, competing theories of attention have come to dominate visual search discourse. The environment contains a vast amount of information. We are limited in the amount of information we are able to process at any one time, so it is therefore necessary that we have mechanisms by which extraneous stimuli can be filtered and only relevant information attended to. In the study of attention, psychologists distinguish between preattentitive and attentional processes. Preattentive processes are evenly distributed across all input signals, forming a kind of \"low-level\" attention. Attentional processes are more selective and can only be applied to specific preattentive input. A large part of the current debate in visual search theory centres on selective attention and what the visual system is capable of achieving without focal attention.",
            "score": 110.74321746826172
        },
        {
            "docid": "35982062_3",
            "document": "Biased Competition Theory . Research into the subject of attentional mechanisms in regard to visual perception was undertaken as an attempt to better understand the functional principles and potential constraints surrounding visual perception Visual search tasks are commonly used by experimenters to aid the exploration of visual perception. The classical view of visual attention suggests that there are two basic principles: the pre-attentive stage and the attentive stage. In the pre-attentive stage, an individual has an unlimited capacity for perception which is capable of processing information from the entire visual field concurrently. During the attentive stage, the processing of visual information corresponding to local spatial areas takes place. This classical view of visual attention suggests that there is no competition within the visual field. Within this theory an individual is assumed to be capable of processing all information provided concurrently. Until recently it was still thought that individuals had a pre-attentive stage. This is no longer the case, research has now suggested that the pre-attentive stage is now limited in its capacity.  The attentive stage of being able to process important information has now transformed into what is known as selectivity. The classical view of attention has built the ground work for the recent emergence of two new principles to benefit the understanding of visual attention. The first of these relates to the limited capacity of information processing. This suggests that at any given time, only a small amount of information can actually be retained and used to control behaviour. The principle of selectivity incorporates the notion that a person has the ability to filter out unwanted information. Koch and Ullman proposed that attentive selection could be implemented by competitive \"winner-takes-all\" networks. Robert Desimone and John Duncan expanded on this idea. They proposed that at some point between the visual input of objects and the response to objects in the visual field there is some competition occurring; competition for representation, analysis, and behavior. This suggests that attention to stimuli makes more demands on processing capacity than unattended stimuli. This idea of competition led researchers to develop a new theory of attention, which they termed the \u201cbiased competition theory\". The theory attempts to provide an explanation of the processes leading visual attention and their effects on the brain\u2019s neural systems.",
            "score": 109.61810302734375
        },
        {
            "docid": "35982062_9",
            "document": "Biased Competition Theory . A Top-down process is characterized by a high level of direction of sensory processing by more cognition; Top-down processing is based on pre-existing knowledge when interpreting sensory information. Top-down guidance of attention refers to when the properties of an object (i.e. color, shape) are activated and held in working memory to facilitate the visual search for that object. This controls visual search by guiding attention only to objects that could be the target and avoiding attention on irrelevant objects. Top-down processes are not a complete representation of the object but are coarse, which is why objects similar in color, shape or meaning are often attended to in the process of discriminating irrelevant objects. There is evidence that observers have Top-down control over the locations that will benefit from biased competition in spatial selection visual tasks. Evidence supports that observers can make voluntary decision about which locations are selected. or features that capture the attention in a stimulus-driven manner. Neurophysiology studies have showed that the neural mechanisms in Top-down processing are also seen in attention and working memory, suggesting Top-down processes play an important role in those functions as well. Additionally, Top-down processes can modulate Bottom-up processes by suppressing the \u201cpop-out\u201d features of Bottom-up processing from distracting from the visual search. fMRI studies have investigated the Top-down and Bottom-up processes involved in biased competition theory. Results of fMRI suggest that both Bottom-up and Top-down processes work in parallel to bias competition. Multiple studies have shown that stimuli in the visual field suppress each other when presented together, but not when each stimulus is presented alone. Kastner and colleagues also found that directing attention to the specific location of a stimulus reduces the suppressive effect. Increased activity in the visual cortex was also observed; this was the result of Top-down biasing due to the favoring of the attended location.",
            "score": 108.27088165283203
        },
        {
            "docid": "49990541_3",
            "document": "Visual selective attention in dementia . Visual selective attention is an essential factor in producing efficient, goal directed behaviour. Our processing resources as humans are limited, and it is therefore crucial to be able to distinguish important information in an environment which produces vast amounts of sensory input every second. In order to guide behaviour, only a small amount of that sensory input can be allowed to reach perceptual awareness. Therefore, to operate efficiently, this goal directed behaviour is mediated by visual selective attention. This allows us to selectively focus on and attend to specific information that is important or relevant to the situation or context we are in. This information then gains access to further processing, where it aids goal directed behaviour through enhancing the representation of salient and relevant stimuli, and suppressing distracting stimuli which are less relevant. The processing of distracting stimuli may interfere with the implementation of the intended behaviour.",
            "score": 106.74568939208984
        },
        {
            "docid": "27313901_12",
            "document": "Visual N1 . Although spatial attention has been shown to be unique in selection for perceptual information that will be further processed, objects have also been shown to be important in filtering information for further processing. For example, in a Filtering Paradigm (see above), rectangles were presented on either side of the visual field. Participants were directed to attend to one side of the visual field and to the top 50% of the object within that visual field. The target was a shaded region of the top right-hand side corner; however, similar targets were presented in the unattended bottom half of the object in the attended visual field and in the top and bottom halves of the object in the unattended visual field. As expected, when comparing targets in the attended visual field to targets in the unattended visual field, it was found that the amplitude of the N1 was greater for attended (vs. unattended) objects. Additionally, although the amplitude of the N1 was greatest for targets in the attended visual field and the attended part of object, the amplitude of the N1 for targets in the unattended portion of the attended object was larger than the amplitude of the N1 for targets at an equivalent distance from the locus of attention but on an unattended object. These results provide evidence that while spatial attention does serve as a selection mechanism for further processing, spatial attention can spread across objects and influences further perceptual processing.",
            "score": 104.68102264404297
        },
        {
            "docid": "1781678_17",
            "document": "Cocktail party effect . Diana Deutsch, best known for her work in music perception and auditory illusions, has also made important contributions to models of attention. In order to explain in more detail how words can be attended to on the basis of semantic importance, Deutsch & Deutsch and Norman proposed a model of attention which includes a second selection mechanism based on meaning. In what came to be known as the Deutsch-Norman model, information in the unattended stream is not processed all the way into working memory, as Treisman's model would imply. Instead, information on the unattended stream is passed through a secondary filter after pattern recognition. If the unattended information is recognized and deemed unimportant by the secondary filter, it is prevented from entering working memory. In this way, only immediately important information from the unattended channel can come to awareness.  Daniel Kahneman also proposed a model of attention, but it differs from previous models in that he describes attention not in terms of selection, but in terms of capacity. For Kahneman, attention is a resource to be distributed among various stimuli, a proposition which has received some support. This model describes not \"when\" attention is focused, but \"how\" it is focused. According to Kahneman, attention is generally determined by arousal; a general state of physiological activity. The Yerkes-Dodson law predicts that arousal will be optimal at moderate levels - performance will be poor when one is over- or under-aroused. Of particular relevance, Narayan et al. discovered a sharp decline in the ability to discriminate between auditory stimuli when background noises were too numerous and complex - this is evidence of the negative effect of overarousal on attention. Thus, arousal determines our available capacity for attention. Then, an \"allocation policy\" acts to distribute our available attention among a variety of possible activities. Those deemed most important by the allocation policy will have the most attention given to them. The allocation policy is affected by \"enduring dispositions\" (automatic influences on attention) and \"momentary intentions\" (a conscious decision to attend to something). \"Momentary intentions\" requiring a focused direction of attention rely on substantially more attention resources than \"enduring dispositions\". Additionally, there is an ongoing evaluation of the particular demands of certain activities on attention capacity. That is to say, activities that are particularly taxing on attention resources will lower attention capacity and will influence the allocation policy - in this case, if an activity is too draining on capacity, the allocation policy will likely cease directing resources to it and instead focus on less taxing tasks. Kahneman's model explains the cocktail party phenomenon in that \"momentary intentions\" might allow one to expressly focus on a particular auditory stimulus, but that \"enduring dispositions\" (which can include new events, and perhaps words of particular semantic importance) can capture our attention. It is important to note that Kahneman's model doesn't necessarily contradict selection models, and thus can be used to supplement them.",
            "score": 104.38481903076172
        },
        {
            "docid": "1781678_14",
            "document": "Cocktail party effect . Some of the earliest work in exploring mechanisms of early selective attention was performed by Donald Broadbent, who proposed a theory that came to be known as the \"filter model\". This model was established using the dichotic listening task. His research showed that most participants were accurate in recalling information that they actively attended to, but were far less accurate in recalling information that they had not attended to. This led Broadbent to the conclusion that there must be a \"filter\" mechanism in the brain that could block out information that was not selectively attended to. The filter model was hypothesized to work in the following way: as information enters the brain through sensory organs (in this case, the ears) it is stored in sensory memory, a buffer memory system that hosts an incoming stream of information long enough for us to pay attention to it. Before information is processed further, the filter mechanism allows only attended information to pass through. The selected attention is then passed into working memory, the set of mechanisms that underlies short-term memory and communicates with long-term memory. In this model, auditory information can be selectively attended to on the basis of its physical characteristics, such as location and volume. Others suggest that information can be attended to on the basis of Gestalt features, including continuity and closure. For Broadbent, this explained the mechanism by which people can choose to attend to only one source of information at a time while excluding others. However, Broadbent's model failed to account for the observation that words of semantic importance, for example the individual's own name, can be instantly attended to despite having been in an unattended channel.",
            "score": 103.69986724853516
        },
        {
            "docid": "37759941_4",
            "document": "Crossmodal attention . As cross-modal attention requires attending to two or more types of sensory information simultaneously, attentional resources are typically divided unequally. It has been suggested by most research that this divided attention can result in more attentional deficits than benefits. This has raised the question as to the effectiveness of multitasking and the potential dangers associated with it. Significant amounts of delay in reaction times are present when various distractions across modalities occur. In real-life situations these slower reaction times can result in dangerous situations. Recent concerns in the media on this topic revolve around the topic of cellphone usage while driving. Studies have found that processing, and therefore attending to, auditory information can impair the simultaneous processing of visual information. This suggests that attending to the auditory information from cellphone usage while driving will impair a driver's visual attention and ability to drive. This would result in the endangering of the driver, passengers of the driver, pedestrians, and other drivers and their passengers. Similar studies have examined how visual attention is affected by auditory stimuli as it relates to hemispatial neglect, responses to cuing, and general spatial processing. The majority of this research suggests that multitasking and dividing attention, while possible, degrade the quality of the directed attention. This also suggests that attention is a limited resource that cannot be infinitely divided between modalities and tasks.",
            "score": 103.61787414550781
        },
        {
            "docid": "35988494_3",
            "document": "Selective auditory attention . The cocktail party problem was first brought up in 1953 by Colin Cherry. This common problem is how our minds solves the issue of knowing what in the auditory scene is important and combining those in a coherent whole, such as the problem of how we can perceive our friend talking in the midst of a crowded cocktail party. He suggested that the auditory system can filter sounds being heard. Physical characteristics of the auditory information such as speaker's voice or location can improve a person's ability to focus on certain stimuli even if there is other auditory stimuli present. Cherry also did work with shadowing which involves different information being played into both ears and only one ear's information can be processed and remembered (Eysneck, 2012, p.\u00a084). Another psychologist, Albert Bregman, came up with the auditory scene analysis model. The model has three main characteristics: segmentation, integration, and segregation. Segmentation involves the division of auditory messages into segments of importance. The process of combining parts of an auditory message to form a whole is associated with integration. Segregation is the separation of important auditory messages and the unwanted information in the brain. It is important to note that Bregman also makes a link back to the idea of perception. He states that it is essential for one to make a useful representation of the world from sensory inputs around us. Without perception, an individual will not recognize or have the knowledge of what is going on around them. While Begman's seminal work is critical to understanding selective auditory attention, his studies did not focus on the way in which an auditory message is selected, if and when it was correctly segregated from other sounds in a mixture, which is a critical stage of selective auditory attention. Inspired in part by Bregman's work, a number of researchers then set out to link directly work on auditory scene analysis to the processes governing attention, including Maria Chait, Mounya Elhilali, Shihab Shamma, and Barbara Shinn-Cunningham.",
            "score": 103.22988891601562
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 102.90035247802734
        },
        {
            "docid": "37759941_2",
            "document": "Crossmodal attention . Crossmodal attention refers to the distribution of attention to different senses. Attention is the cognitive process of selectively emphasizing and ignoring sensory stimuli. According to the crossmodal attention perspective, attention often occurs simultaneously through multiple sensory modalities. These modalities process information from the different sensory fields, such as: visual, auditory, spatial, and tacitile. While each of these is designed to process a specific type of sensory information, there is considerable overlap between them which has led researchers to question whether attention is modality-specific or the result of shared \"cross-modal\" resources. \"Cross-modal attention\" is considered to be the overlap between modalities that can both enhance and limit attentional processing. The most common example given of crossmodal attention is the Cocktail Party Effect, which is when a person is able to focus and attend to one important stimulus instead of other less important stimuli. This phenomenon allows deeper levels of processing to occur for one stimuli while others are then ignored.",
            "score": 102.7892837524414
        },
        {
            "docid": "49990541_29",
            "document": "Visual selective attention in dementia . Individuals with PD may be impaired in their ability to attend selectively for several different reasons. These patients may show deficits in their ability to inhibit the processing of the irrelevant information which is presented, therefore there are enabling the irrelevant information to interfere with their processing of the target information; or PD patients may indeed be able to inhibit the processing of the irrelevant stimuli, but showed impairments in maintaining the selectivity of their attention to the relevant stimuli, supported by an abnormally rapid disengagement of attention from the location at which a visual cue last appeared.",
            "score": 101.80622100830078
        },
        {
            "docid": "31329046_5",
            "document": "Pre-attentive processing . The \"contingent-capture\" model emphasizes the idea that a person\u2019s current intentions and/or goals affect the speed and efficiency of pre-attentive processing. The brain directs an individual\u2019s attention towards stimuli with features that fit in with their goals. Consequently, these stimuli will be processed faster at the pre-attentive stage and will be more likely to be selected for attentive processing. Since this model focuses on the importance of conscious processes (rather than properties of the stimulus itself) in selecting information for attentive processing, it is sometimes called \"top-down\" selection. In support of this model, it has been shown that a target stimulus can be located faster if it is preceded by the presentation of a similar, priming stimulus. For example, if an individual is shown the color green and then required to find a green circle among distractors, the initial exposure to the color will make it easier to find the green circle. This is because they are already thinking about and envisioning the color green, so when it shows up again as the green circle, their brain readily directs its attention towards it. This suggests that processing an initial stimulus speeds up a person\u2019s ability to select a similar target from pre-attentive processing. However, it could be that the speed of pre-attentive processing itself is not affected by the first stimulus, but rather that people are simply able to quickly abandon dissimilar stimuli, enabling them to re-engage to the correct target more quickly. This would mean that the difference in reaction time occurs at the attentive level, after pre-attentive processing and stimulus selection has already taken place.",
            "score": 101.13774871826172
        },
        {
            "docid": "176315_10",
            "document": "Evoked potential . This technique allows several (e.g., four) SSEPs to be recorded simultaneously from any given location on the scalp. Different sites of stimulation or different stimuli can be tagged with slightly different frequencies that are virtually identical to the brain, but easily separated by Fourier series analyzers. For example, when two unpatterned lights are modulated at slightly different frequencies (F1 and F2) and superimposed, multiple nonlinear cross-modulation components of frequency (mF1 \u00b1 nF2) are created in the SSEP, where m and n are integers. These components allow nonlinear processing in the brain to be investigated. By frequency-tagging two superimposed gratings, spatial frequency and orientation tuning properties of the brain mechanisms that process spatial form can be isolated and studied. Stimuli of different sensory modalities can also be tagged. For example, a visual stimulus was flickered at Fv Hz and a simultaneously presented auditory tone was amplitude modulated at Fa Hz. The existence of a (2Fv + 2Fa) component in the evoked magnetic brain response demonstrated an audio-visual convergence area in the human brain, and the distribution of this response over the head allowed this brain area to be localized. More recently, frequency tagging has been extended from studies of sensory processing to studies of selective attention and of consciousness.",
            "score": 101.02269744873047
        },
        {
            "docid": "42980268_15",
            "document": "Visual spatial attention . It is debated in research on visual spatial attention whether it is possible to split attention across different areas in the visual field. The \u2018spotlight\u2019 and \u2018zoom-lens\u2019 accounts postulate that attention uses a single unitary focus. Therefore, spatial attention can only be allocated to adjacent areas in the visual field and consequently cannot be split. This was supported by an experiment that altered the spatial cueing paradigm by using two cues, a primary and a secondary cue. It was found that the secondary cue was only effective in focusing attention when its location was adjacent to the primary cue. In addition, it has been demonstrated that observers are unable to ignore stimuli presented in areas situated between two cued locations. These findings have proposed that attention cannot be split across two non-contiguous regions. However, other studies have demonstrated that spatial attention can be split across two locations. For example, observers were able to attend simultaneously to two different targets located in opposite hemifields. Research has even suggested that humans are able to focus attention across two to four locations in the visual field. Another perspective is that spatial attention can be split only under certain conditions. This perspective suggests that the splitting of spatial attention is flexible. Research demonstrated that whether spatial attention is unitary or divided depends on the goals of the task. Therefore, if dividing attention is beneficial to the observer then a divided focus of attention will be utilised.",
            "score": 99.50008392333984
        },
        {
            "docid": "2534964_14",
            "document": "Sensory processing . Perhaps one of the most studied sensory integrations is the relationship between vision and audition. These two senses perceive the same objects in the world in different ways, and by combining the two, they help us understand this information better. Vision dominates our perception of the world around us. This is because visual spatial information is one of the most reliable sensory modalities. Visual stimuli are recorded directly onto the retina, and there are few, if any, external distortions that provide incorrect information to the brain about the true location of an object. Other spatial information is not as reliable as visual spatial information. For example, consider auditory spatial input. The location of an object can sometimes be determined solely on its sound, but the sensory input can easily be modified or altered, thus giving a less reliable spatial representation of the object. Auditory information therefore is not spatially represented unlike visual stimuli. But once one has the spatial mapping from the visual information, multisensory integration helps bring the information from both the visual and auditory stimuli together to make a more robust mapping.",
            "score": 99.44009399414062
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 98.49896240234375
        },
        {
            "docid": "34780199_13",
            "document": "Broadbent's filter model of attention . The early selection model of attention, proposed by Broadbent, posits that stimuli are filtered, or selected to be attended to, at an early stage during processing. A filter can be regarded as the selector of relevant information based on basic features, such as color, pitch, or direction of stimuli. After stimuli are presented, the information is temporarily held in a preattentive store. Information with similar characteristics pass through the filter and is attended to so it can be processed for meaning; irrelevant attention is filtered out. The basic idea proposes that perception of the stimulus is not required prior to selecting its relevance.",
            "score": 98.27928161621094
        },
        {
            "docid": "27169449_13",
            "document": "Auditory spatial attention . Further evidence as to the modality specificity of the 'what' and 'where' pathways has been provided in a recent study by Diaconescu et al., who suggest that while 'what' processes have discrete pathways for vision and audition, the 'where' pathway may be supra-modal, shared by both modalities. Participants were asked in randomly alternating trials to respond to either the feature or spatial elements of stimuli, which varied between the auditory and visual domain in set blocks. Between two experiments, the modality of the cue was also varied; the first experiment contained auditory cues as to which element (feature or spatial) of the stimuli to respond to, while the second experiment utilized visual cues. During the period between cue and target, when participants were presumably attending to the cued feature to be presented, both auditory and vision spatial attention conditions elicited greater positivity in source space from a centro-medial location at 600-1200 ms following cue onset, which the authors of the study propose may be the result of a supra-modal pathway for spatial information. Conversely, source space activity for feature attention were not consistent between modalities, with auditory feature attention associated with greater positivity at the right auditory radial dipole around 300-600 ms, and spatial feature attention associated with greater negativity at the left-visual central-inferior dipole at 700-1050ms, suggested as evidence for separate feature or 'what' pathways for vision and audition.",
            "score": 96.55467987060547
        },
        {
            "docid": "27313901_14",
            "document": "Visual N1 . The large corpus of studies focused on factors that modulate the amplitude of the visual N1 have provided a wealth of evidence suggesting that, while the visual N1 is a sensory component evoked by any visual stimulus, it also reflects a benefit of correctly allocating attentional resources and that it is a manifestation of an important sensory gating mechanism of attention. When attention is focused on areas of the visual field in which relevant information is presented (vs. evenly distributed across the visual field or focused on an area in which relevant information is not presented), the amplitude of the N1 is largest and indicates a benefit of correctly allocating attentional resources. Additionally, the amplitude of the N1 is believed to represent a sensory gain control mechanism because focusing attention on one area of the visual field serves to increase the amplitude of the N1 to relevant perceptual information presented in that field (vs. the other visual field), and thus facilitates further perceptual processing of stimuli. This finding supports the Early Selection Model of Attention, which contends that attention acts (i.e., filters information) on a stimulus set early in the information processing stream.",
            "score": 96.19042205810547
        },
        {
            "docid": "2613534_19",
            "document": "Visual extinction . This condition does not inhibit patients from social interaction. In fact, most people would not be able to distinguish a visual extinction patient from a non-visual extinction patient in passing. Patients have selective spatial interactions, typically within the range of six degrees of the angle of vision. When two visual stimuli are presented to a patient, they can be processed as a single object due to the corresponding neuronal functions which are linked through long-range lateral interactions. Visual Extinction is often mistaken for attentional deficit. Some researchers believe visual extinction may be connected to a restriction in attention capacity. Attention allows a person to identify and react to pertinent objects in space, while ignoring other irrelevant objects. Patients with visual extinction, especially those with unilateral damage to the right parietal lobe, may be unable to attend and orient to objects in collateral space, therefore presenting neglect to visual stimuli.",
            "score": 95.56809997558594
        },
        {
            "docid": "195552_35",
            "document": "Artificial consciousness . In 2011, Michael Graziano and Sabine Kastler published a paper named \"Human consciousness and its relationship to social neuroscience: A novel hypothesis\" proposing a theory of consciousness as an attention schema. Graziano went on to publish an expanded discussion of this theory in his book \"Consciousness and the Social Brain\". This Attention Schema Theory of Consciousness, as he named it, proposes that the brain tracks attention to various sensory inputs by way of an attention schema, analogous to the well study body schema that tracks the spatial place of a person's body. This relates to artificial consciousness by proposing a specific mechanism of information handling, that produces what we allegedly experience and describe as consciousness, and which should be able to be duplicated by a machine using current technology. When the brain finds that person X is aware of thing Y, it is in effect modeling the state in which person X is applying an attentional enhancement to Y. In the attention schema theory, the same process can be applied to oneself. The brain tracks attention to various sensory inputs, and one's own awareness is a schematized model of one's attention. Graziano proposes specific locations in the brain for this process, and suggests that such awareness is a computed feature constructed by an expert system in the brain.",
            "score": 95.06742095947266
        },
        {
            "docid": "35982062_4",
            "document": "Biased Competition Theory . Biased competition serves to prioritize task relevant information to make visual search more efficient. A large amount of visual information is taken in at any given moment and there is a limited capacity available for processing. The visual system therefore needs a way to select relevant information and ignore irrelevant stimuli. A visual search usually has a target (e.g. a coffee cup), which is being searched for (task relevant) in the visual environment, and task irrelevant information is ignored. The biasing from neural mechanisms guides the search to logical spatial locations (e.g. the table) and items that have similar semantic or visual features to the item that is being searched for. It has been suggested that more than 30 cortical areas in the visual system are used for the processing of visual stimuli, and that there is competition from objects in the visual field that takes place in multiple areas of this extensive network.",
            "score": 94.07077026367188
        },
        {
            "docid": "37759941_5",
            "document": "Crossmodal attention . While research on cross-modal attention has found that deficits in attending often occur, this research has led to a better understanding of attentional processing. Some studies have used positron emission tomography (PET) to examine the neurological basis for how we selectively attend to information using different sensory modalities. Event related potentials (ERPs). have also been used to help researchers measure how humans encode and process attended information in the brain. By increasing our understanding of modality-specific and cross-modal attention, we are better able to understand how we think and direct our attention.",
            "score": 93.91902160644531
        },
        {
            "docid": "68753_10",
            "document": "Attention . A significant debate emerged in the last decade of the 20th century in which Treisman's 1993 Feature Integration Theory (FIT) was compared to Duncan and Humphrey's 1989 attentional engagement theory (AET). FIT posits that \"objects are retrieved from scenes by means of selective spatial attention that picks out objects' features, forms feature maps, and integrates those features that are found at the same location into forming objects.\" Duncan and Humphrey's AET understanding of attention maintained that \"there is an initial pre-attentive parallel phase of perceptual segmentation and analysis that encompasses all of the visual items present in a scene. At this phase, descriptions of the objects in a visual scene are generated into structural units; the outcome of this parallel phase is a multiple-spatial-scale structured representation. Selective attention intervenes after this stage to select information that will be entered into visual short-term memory.\" The contrast of the two theories placed a new emphasis on the separation of visual attention tasks alone and those mediated by supplementary cognitive processes. As Rastophopoulos summarizes the debate: \"Against Treisman's FIT, which posits spatial attention as a necessary condition for detection of objects, Humphreys argues that visual elements are encoded and bound together in an initial parallel phase without focal attention, and that attention serves to select among the objects that result from this initial grouping.\"",
            "score": 93.81993865966797
        },
        {
            "docid": "34780199_18",
            "document": "Broadbent's filter model of attention . Deutsch and Norman were not fully convinced by Broadbent's selection criteria based solely on physical features of a stimulus. For example, the cocktail party effect influenced researchers to look further than physical selection features, to semantic selecting features. The cocktail party effect is an example of how unattended information can gain one's attention. Suppose you were at a social gathering having a conversation with some friends, when you hear someone in a different conversation mention your name and it grasps your attention. This unattended-to information somehow gained your attention and was processed beyond its physical characteristics, for its meaning. Deutsch and Deutsch proposed a late selection model and suggested that people can recognize the information from both channels, but if the information does not have any personal relevance, the information will be forgotten Therefore, the issue is not a lack of perceptual processing, but rather the information has not entered into memory. Norman stated that not only is personal relevance necessary for attention, but so is the strength of the stimuli. This fueled the development of the memory selection model, which shares the same basic principle of early selection models that stimulus features are selected via their physical properties. However, attended and unattended information pass through the filter, to a second stage of selection on the basis of semantic characteristics or message content. Items which are selected are incorporated into short-term memory. Therefore, it is the second selection mechanism, rather than the filter, decides what information is attended to.",
            "score": 93.76846313476562
        },
        {
            "docid": "42980268_3",
            "document": "Visual spatial attention . Spatial attention allows humans to selectively process visual information through prioritization of an area within the visual field. A region of space within the visual field is selected for attention and the information within this region then receives further processing. Research shows that when spatial attention is evoked, an observer is typically faster and more accurate at detecting a target that appears in an expected location compared to an unexpected location.",
            "score": 93.64440155029297
        },
        {
            "docid": "34780199_4",
            "document": "Broadbent's filter model of attention . Due to this limited capacity, a selective filter is needed for information processing. Broadbent stated that all stimuli are processed initially for basic, physical properties. These basic characteristics can include pitch, color, loudness, and direction. Unlike the physical properties, Broadbent believed semantic features, due to their complexity, would impose a limited capacity on the temporary storehouse of incoming stimuli. Therefore, based on physical characteristics, the selective filter allows for certain stimuli to pass through the filter for further processing, while unattended stimuli will be filtered out and lost. Further, goal-directed behaviour requires attention to be controlled; hence a high degree of selectivity is put forth in the information-processing stream. When developing his model, Broadbent emphasized the splitting of incoming stimuli to attended or unattended channels. Channel selection is guided through attention. If one is attempting to attend to a stimulus based on their current goals, they will employ voluntary attention; whereas if a sensory event catches one's attention, reflexive attention will be employed. Information selected to pass through the filter is then available for short-term memory and manipulation of the selected information, prior to storage in long-term memory.",
            "score": 93.43091583251953
        },
        {
            "docid": "1616390_20",
            "document": "Simultanagnosia . One study developed a computer model of high-level visual processing, which contrasts with low-level visual processing in that it involves the use of previously stored information to identify objects and navigate. When the spatiotopic mapping subsystem of the model was partially damaged, simultanagnosic symptoms resulted. In the model simulation of simultanagnosia, the same location was assigned to all stimuli, therefore preventing the model from identifying multiple objects at once. Either the model \"locked\" onto the first object and was unable to disengage attention, or once recognition of the first object was completed, it \"disappeared\" from sight to be replaced by the second object.",
            "score": 93.33139038085938
        },
        {
            "docid": "4958509_4",
            "document": "Attentional shift . In attention research, one prominent theory attempting to explain how visual attention is shifted is the moving-spotlight theory. The primary idea being that attention is like a movable spotlight that is directed towards intended targets, focusing on each target in a serial manner. When information is illuminated by the spotlight, hence attended, processing proceeds in a more efficient manner, directing attention to a particular point and inhibiting input from any stimuli outside of the spotlight. However, when a shift of spatial attention occurs, the spotlight is, in effect, turned off while attention shifts to the next attended location. Attention, however, has also been proposed to adhere to a gradient theory in which attentional resources are given to a region in space rather than a spotlight, so that attentional resources are most concentrated at the center of attentional focus and then decrease the further a stimuli is from the center. Attention in this theory reflects both current and previous attentional allocation, so that attention can build up and decay across more than one attentional fixation over time. This means that time to detect a target may be dependent upon where attention was directed before the target was presented and attention needed to be shifted.",
            "score": 92.94924926757812
        },
        {
            "docid": "53744937_5",
            "document": "Attention schema theory . The AST can be summarized in three broad points (Graziano, 2013). First, the brain is an information-processing device. Second, it has a capacity to focus its processing resources more on some signals than on others. That focus may be on select, incoming sensory signals, or it may be on internal information such as specific, recalled memories. That ability to process select information in a focused manner is sometimes called attention. Third, the brain not only uses the process of attention, but it also builds a set of information, or a representation, descriptive of attention. That representation, or internal model, is the attention schema.",
            "score": 92.89759063720703
        }
    ]
}