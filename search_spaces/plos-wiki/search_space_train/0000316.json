{
    "q": [
        {
            "docid": "10571004_5",
            "document": "Biological network inference . Genes are the nodes and the edges are directed. A gene serves as the source of a direct regulatory edge to a target gene by producing an RNA or protein molecule that functions as a transcriptional activator or inhibitor of the target gene. If the gene is an activator, then it is the source of a positive regulatory connection; if an inhibitor, then it is the source of a negative regulatory connection. Computational algorithms take as primary input data measurements of mRNA expression levels of the genes under consideration for inclusion in the network, returning an estimate of the network topology. Such algorithms are typically based on linearity, independence or normality assumptions, which must be verified on a case-by-case basis. Clustering or some form of statistical classification is typically employed to perform an initial organization of the high-throughput mRNA expression values derived from microarray experiments, in particular to select sets of genes as candidates for network nodes. The question then arises: how can the clustering or classification results be connected to the underlying biology? Such results can be useful for pattern classification \u2013 for example, to classify subtypes of cancer, or to predict differential responses to a drug (pharmacogenomics). But to understand the relationships between the genes, that is, to more precisely define the influence of each gene on the others, the scientist typically attempts to reconstruct the transcriptional regulatory network. This can be done by data integration in dynamic models supported by background literature, or information in public databases, combined with the clustering results. The modelling can be done by a Boolean network, by Ordinary differential equations or Linear regression models, e.g. Least-angle regression, by Bayesian network or based on Information theory approaches. For instance it can be done by the application of a correlation-based inference algorithm, as will be discussed below, an approach which is having increased success as the size of the available microarray sets keeps increasing",
            "score": 99.81578266620636
        },
        {
            "docid": "53576321_30",
            "document": "Single-cell transcriptomics . Gene regulatory network inference is a technique that aims to construct a network, shown as a graph, in which the nodes represent the genes and edges indicate co-regulatory interactions. The method relies on the assumption that a strong statistical relationship between the expression of genes is an indication of a potential functional relationship. The most commonly used method to measure the strength of a statistical relationship is correlation. However, correlation fails to identify non-linear relationships and mutual information is used as an alternative. Gene clusters linked in a network signify genes that undergo coordinated changes in expression.",
            "score": 75.63238608837128
        },
        {
            "docid": "10571004_4",
            "document": "Biological network inference . There is great interest in network medicine for the modelling biological systems. This article focuses on a necessary prerequisite to dynamic modeling of a network: inference of the topology, that is, prediction of the \"wiring diagram\" of the network. More specifically, we focus here on inference of biological network structure using the growing sets of high-throughput expression data for genes, proteins, and metabolites. Briefly, methods using high-throughput data for inference of regulatory networks rely on searching for patterns of partial correlation or conditional probabilities that indicate causal influence. Such patterns of partial correlations found in the high-throughput data, possibly combined with other supplemental data on the genes or proteins in the proposed networks, or combined with other information on the organism, form the basis upon which such algorithms work. Such algorithms can be of use in inferring the topology of any network where the change in state of one node can affect the state of other nodes.",
            "score": 95.88090944290161
        },
        {
            "docid": "4214_30",
            "document": "Bioinformatics . The expression of many genes can be determined by measuring mRNA levels with multiple techniques including microarrays, expressed cDNA sequence tag (EST) sequencing, serial analysis of gene expression (SAGE) tag sequencing, massively parallel signature sequencing (MPSS), RNA-Seq, also known as \"Whole Transcriptome Shotgun Sequencing\" (WTSS), or various applications of multiplexed in-situ hybridization. All of these techniques are extremely noise-prone and/or subject to bias in the biological measurement, and a major research area in computational biology involves developing statistical tools to separate signal from noise in high-throughput gene expression studies. Such studies are often used to determine the genes implicated in a disorder: one might compare microarray data from cancerous epithelial cells to data from non-cancerous cells to determine the transcripts that are up-regulated and down-regulated in a particular population of cancer cells.",
            "score": 59.72920060157776
        },
        {
            "docid": "1181008_10",
            "document": "Computational science . Exciting new developments in biotechnology are now revolutionizing biology and biomedical research. Examples of these techniques are high-throughput sequencing, high-throughput quantitative PCR, intra-cellular imaging, in-situ hybridization of gene expression, three-dimensional imaging techniques like Light Sheet Fluorescence Microscopy and Optical Projection, (micro)-Computer Tomography. Given the massive amounts of complicated data that is generated by these techniques, their meaningful interpretation, and even their storage, form major challenges calling for new approaches. Going beyond current bioinformatics approaches, computational biology needs to develop new methods to discover meaningful patterns in these large data sets. Model-based reconstruction of gene networks can be used to organize the gene expression data in systematic way and to guide future data collection. A major challenge here is to understand how gene regulation is controlling fundamental biological processes like biomineralisation and embryogenesis. The sub-processes like gene regulation, organic molecules interacting with the mineral deposition process, cellular processes, physiology and other processes at the tissue and environmental levels are linked. Rather than being directed by a central control mechanism, biomineralisation and embryogenesis can be viewed as an emergent behavior resulting from a complex system in which several sub-processes on very different temporal and spatial scales (ranging from nanometer and nanoseconds to meters and years) are connected into a multi-scale system. One of the few available options to understand such systems is by developing a multi-scale model of the system.",
            "score": 71.53749489784241
        },
        {
            "docid": "1872854_31",
            "document": "Biochemical cascade . In the post-genomic age, high-throughput sequencing and gene/protein profiling techniques have transformed biological research by enabling comprehensive monitoring of a biological system, yielding a list of differentially expressed genes or proteins, which is useful in identifying genes that may have roles in a given phenomenon or phenotype. With DNA microarrays and genome-wide gene engineering, it is possible to screen global gene expression profiles to contribute a wealth of genomic data to the public domain. With RNA interference, it is possible to distill the inferences contained in the experimental literature and primary databases into knowledge bases that consist of annotated representations of biological pathways. In this case, individual genes and proteins are known to be involved in biological processes, components, or structures, as well as how and where gene products interact with each other. Pathway-oriented approaches for analyzing microarray data, by grouping long lists of individual genes, proteins, and/or other biological molecules according to the pathways they are involved in into smaller sets of related genes or proteins, which reduces the complexity, have proven useful for connecting genomic data to specific biological processes and systems. Identifying active pathways that differ between two conditions can have more explanatory power than a simple list of different genes or proteins. In addition, a large number of pathway analytic methods exploit pathway knowledge in public repositories such as Gene Ontology (GO) or Kyoto Encyclopedia of Genes and Genomes (KEGG), rather than inferring pathways from molecular measurements. Furthermore, different research focuses have given the word \"pathway\" different meanings. For example, 'pathway' can denote a metabolic pathway involving a sequence of enzyme-catalyzed reactions of small molecules, or a signaling pathway involving a set of protein phosphorylation reactions and gene regulation events. Therefore, the term \"pathway analysis\" has a very broad application. For instance, it can refer to the analysis physical interaction networks (e.g., protein\u2013protein interactions), kinetic simulation of pathways, and steady-state pathway analysis (e.g., flux-balance analysis), as well as its usage in the inference of pathways from expression and sequence data. Several functional enrichment analysis tools and algorithms have been developed to enhance data interpretation. The existing knowledge base\u2013driven pathway analysis methods in each generation have been summarized in recent literature.",
            "score": 85.69910514354706
        },
        {
            "docid": "28722065_2",
            "document": "Proteogenomics . Proteogenomics is a field of biological research that utilizes a combination of proteomics, genomics, and transcriptomics to aid in the discovery and identification of peptides. Protegenomics is used to identify new peptides by comparing MS/MS spectra against a protein database that has been derived from genomic and trancriptomic information. Proteogenomics often refers to studies that use proteomic information, often derived from mass spectrometry, to improve gene annotations. Genomics deals with the genetic code of entire organisms, while transcriptomics deals with the study of RNA sequencing and transcripts. proteomics utilizes tandem mass spectrometry and liquid chromatography to identify and study the functions of proteins. Proteomics is being utilized to discover all the proteins expressed within an organism, known as its proteome. The issue with proteomics is that it relies on the assumption that current gene models are correct and that the correct protein sequences can be found using a reference protein sequence database; however, this is not always the case as some peptides cannot be located in the database. In addition, novel protein sequences can occur through mutations. these issues can be fixed with the use of proteomic, genomic, and trancriptomic data. The utilization of both proteomics and genomics led to proteogeonmics which became its own field in 2004.",
            "score": 71.37910461425781
        },
        {
            "docid": "356382_22",
            "document": "Gene regulatory network . Continuous network models of GRNs are an extension of the boolean networks described above. Nodes still represent genes and connections between them regulatory influences on gene expression. Genes in biological systems display a continuous range of activity levels and it has been argued that using a continuous representation captures several properties of gene regulatory networks not present in the Boolean model. Formally most of these approaches are similar to an artificial neural network, as inputs to a node are summed up and the result serves as input to a sigmoid function, e.g., but proteins do often control gene expression in a synergistic, i.e. non-linear, way. However, there is now a continuous network model that allows grouping of inputs to a node thus realizing another level of regulation. This model is formally closer to a higher order recurrent neural network. The same model has also been used to mimic the evolution of cellular differentiation and even multicellular morphogenesis.",
            "score": 65.06741726398468
        },
        {
            "docid": "356382_7",
            "document": "Gene regulatory network . The nodes of this network can represent genes, proteins, mRNAs, protein/protein complexes or cellular processes. Nodes that are depicted as lying along vertical lines are associated with the cell/environment interfaces, while the others are free-floating and can diffuse. Edges between nodes represent interactions between the nodes, that can correspond to individual molecular reactions between DNA, mRNA, miRNA, proteins or molecular processes through which the products of one gene affect those of another, though the lack of experimentally obtained information often implies that some reactions are not modeled at such a fine level of detail. These interactions can be inductive (usually represented by arrowheads or the + sign), with an increase in the concentration of one leading to an increase in the other, inhibitory (represented with filled circles, blunt arrows or the minus sign), with an increase in one leading to a decrease in the other, or dual, when depending of the circumstances the regulator can activate or inhibit the target node. The nodes can regulate themselves directly or indirectly, creating feedback loops, which form cyclic chains of dependencies in the topological network. The network structure is an abstraction of the system's molecular or chemical dynamics, describing the manifold ways in which one substance affects all the others to which it is connected. In practice, such GRNs are inferred from the biological literature on a given system and represent a distillation of the collective knowledge about a set of related biochemical reactions. To speed up the manual curation of GRNs, some recent efforts try to use text mining, curated databases, network inference from massive data, model checking and other information extraction technologies for this purpose.",
            "score": 75.6081748008728
        },
        {
            "docid": "159266_62",
            "document": "Gene expression . Gene networks can also be constructed without formulating an explicit causal model. This is often the case when assembling networks from large expression data sets. Covariation and correlation of expression is computed across a large sample of cases and measurements (often transcriptome or proteome data). The source of variation can be either experimental or natural (observational). There are several ways to construct gene expression networks, but one common approach is to compute a matrix of all pair-wise correlations of expression across conditions, time points, or individuals and convert the matrix (after thresholding at some cut-off value) into a graphical representation in which nodes represent genes, transcripts, or proteins and edges connecting these nodes represent the strength of association (see ). Weighted correlation network analysis (WGCNA) involves weighted networks defined by soft-thresholding the pairwise correlations among variables (e.g. measures of transcript abundance). WGCNA can be applied to compute eigengenes, which are highly robust biomarkers (features) useful for diagnosis and prognosis.",
            "score": 78.14520919322968
        },
        {
            "docid": "11864322_8",
            "document": "Quasi-experiment . Though quasi-experiments are sometimes shunned by those who consider themselves to be experimental purists (leading Donald T. Campbell to coin the term \u201cqueasy experiments\u201d for them), they are exceptionally useful in areas where it is not feasible or desirable to conduct an experiment or randomized control trial. Such instances include evaluating the impact of public policy changes, educational interventions or large scale health interventions. The primary drawback of quasi-experimental designs is that they cannot eliminate the possibility of confounding bias, which can hinder one\u2019s ability to draw causal inferences. This drawback is often used to discount quasi-experimental results. However, such bias can be controlled for using various statistical techniques such as multiple regression, if one can identify and measure the confounding variable(s). Such techniques can be used to model and partial out the effects of confounding variables techniques, thereby improving the accuracy of the results obtained from quasi-experiments. Moreover, the developing use of propensity score matching to match participants on variables important to the treatment selection process can also improve the accuracy of quasi-experimental results. In fact, data derived from quasi-experimental analyses has been shown to closely match experimental data in certain cases, even when different criteria were used. In sum, quasi-experiments are a valuable tool, especially for the applied researcher. On their own, quasi-experimental designs do not allow one to make definitive causal inferences; however, they provide necessary and valuable information that cannot be obtained by experimental methods alone. Researchers, especially those interested in investigating applied research questions, should move beyond the traditional experimental design and avail themselves of the possibilities inherent in quasi-experimental designs.",
            "score": 64.68775188922882
        },
        {
            "docid": "8402086_5",
            "document": "Computational neurogenetic modeling . A gene regulatory network, protein regulatory network, or gene/protein regulatory network, is the level of processing in a computational neurogenetic model that models the interactions of genes and proteins relevant to synaptic activity and general cell functions. Genes and proteins are modeled as individual nodes, and the interactions that influence a gene are modeled as excitatory (increases gene/protein expression) or inhibitory (decreases gene/protein expression) inputs that are weighted to reflect the effect a gene or protein is having on another gene or protein. Gene regulatory networks are typically designed using data from microarrays.",
            "score": 67.51219892501831
        },
        {
            "docid": "152611_11",
            "document": "Cellular differentiation . Each specialized cell type in an organism expresses a subset of all the genes that constitute the genome of that species. Each cell type is defined by its particular pattern of regulated gene expression. Cell differentiation is thus a transition of a cell from one cell type to another and it involves a switch from one pattern of gene expression to another. Cellular differentiation during development can be understood as the result of a gene regulatory network. A regulatory gene and its cis-regulatory modules are nodes in a gene regulatory network; they receive input and create output elsewhere in the network. The systems biology approach to developmental biology emphasizes the importance of investigating how developmental mechanisms interact to produce predictable patterns (morphogenesis). (However, an alternative view has been proposed recently. Based on stochastic gene expression, cellular differentiation is the result of a Darwinian selective process occurring among cells. In this frame, protein and gene networks are the result of cellular processes and not their cause. See: Cellular Darwinism) A few evolutionarily conserved types of molecular processes are often involved in the cellular mechanisms that control these switches. The major types of molecular processes that control cellular differentiation involve cell signaling. Many of the signal molecules that convey information from cell to cell during the control of cellular differentiation are called growth factors. Although the details of specific signal transduction pathways vary, these pathways often share the following general steps. A ligand produced by one cell binds to a receptor in the extracellular region of another cell, inducing a conformational change in the receptor. The shape of the cytoplasmic domain of the receptor changes, and the receptor acquires enzymatic activity. The receptor then catalyzes reactions that phosphorylate other proteins, activating them. A cascade of phosphorylation reactions eventually activates a dormant transcription factor or cytoskeletal protein, thus contributing to the differentiation process in the target cell. Cells and tissues can vary in competence, their ability to respond to external signals.",
            "score": 72.88680005073547
        },
        {
            "docid": "21731590_16",
            "document": "RNA-Seq . Coexpression networks are data-derived representations of genes behaving in a similar way across tissues and experimental conditions. Their main purpose lies in hypothesis generation and guilt-by-association approaches for inferring functions of previously unknown genes. RNASeq data has been recently used to infer genes involved in specific pathways based on Pearson correlation, both in plants and mammals. The main advantage of RNASeq data in this kind of analysis over the microarray platforms is the capability to cover the entire transcriptome, therefore allowing the possibility to unravel more complete representations of the gene regulatory networks. Differential regulation of the splice isoforms of the same gene can be detected and used to predict and their biological functions.  Weighted gene co-expression network analysis has been successfully used to identify co-expression modules and intramodular hub genes based on RNA seq data. Co-expression modules may corresponds to cell types or pathways. Highly connected intramodular hubs can be interpreted as representatives of their respective module. Variance-Stabilizing Transformation approaches for estimating correlation coefficients based on RNA seq data have been proposed.",
            "score": 87.47160768508911
        },
        {
            "docid": "12499410_57",
            "document": "Network motif . Much experimental work has been devoted to understanding network motifs in gene regulatory networks. These networks control which genes are expressed in the cell in response to biological signals. The network is defined such that genes are nodes, and directed edges represent the control of one gene by a transcription factor (regulatory protein that binds DNA) encoded by another gene. Thus, network motifs are patterns of genes regulating each other's transcription rate. When analyzing transcription networks, it is seen that the same network motifs appear again and again in diverse organisms from bacteria to human. The transcription network of \"E. coli\" and yeast, for example, is made of three main motif families, that make up almost the entire network. The leading hypothesis is that the network motif were independently selected by evolutionary processes in a converging manner, since the creation or elimination of regulatory interactions is fast on evolutionary time scale, relative to the rate at which genes change, Furthermore, experiments on the dynamics generated by network motifs in living cells indicate that they have characteristic dynamical functions. This suggests that the network motif serve as building blocks in gene regulatory networks that are beneficial to the organism.",
            "score": 73.56988108158112
        },
        {
            "docid": "52821211_2",
            "document": "Phylogenetic inference using transcriptomic data . In molecular phylogenetics, relationships among individuals are determined using character traits, such as DNA, RNA or protein, which may be obtained using a variety of sequencing technologies. High-throughput next-generation sequencing has become a popular technique in transcriptomics, which represent a snapshot of gene expression. In eukaryotes, making phylogenetic inferences using RNA is complicated by alternative splicing, which produces multiple transcripts from a single gene. As such, a variety of approaches may be used to improve phylogenetic inference using transcriptomic data obtained from RNA-Seq and processed using computational phylogenetics.",
            "score": 73.11349368095398
        },
        {
            "docid": "356382_31",
            "document": "Gene regulatory network . Other work has focused on predicting the gene expression levels in a gene regulatory network. The approaches used to model gene regulatory networks have been constrained to be interpretable and, as a result, are generally simplified versions of the network. For example, Boolean networks have been used due to their simplicity and ability to handle noisy data but lose data information by having a binary representation of the genes. Also, artificial neural networks omit using a hidden layer so that they can be interpreted, losing the ability to model higher order correlations in the data. Using a model that is not constrained to be interpretable, a more accurate model can be produced. Being able to predict gene expressions more accurately provides a way to explore how drugs affect a system of genes as well as for finding which genes are interrelated in a process. This has been encouraged by the DREAM competition which promotes a competition for the best prediction algorithms. Some other recent work has used artificial neural networks with a hidden layer.",
            "score": 78.48958909511566
        },
        {
            "docid": "53576321_28",
            "document": "Single-cell transcriptomics . Pseudo-temporal ordering (or trajectory inference) is a technique that aims to infer gene expression dynamics from snapshot single-cell data. The method tries to order the cells in such a way that similar cells are closely positioned to each other. This trajectory of cells can be linear, but can also bifurcate or follow more complex graph structures. The trajectory therefore enables the inference of gene expression dynamics and the ordering of cells by their progression through differentiation or response to external stimuli. The method relies on the assumptions that the cells follow the same path through the process of interest and that their transcriptional state correlates to their progression. The algorithm can be applied to both mixed populations and temporal samples.",
            "score": 77.3455377817154
        },
        {
            "docid": "1053858_4",
            "document": "Functional genomics . Functional genomics includes function-related aspects of the genome itself such as mutation and polymorphism (such as single nucleotide polymorphism (SNP) analysis), as well as measurement of molecular activities. The latter comprise a number of \"-omics\" such as transcriptomics (gene expression), proteomics (protein production), and metabolomics. Functional genomics uses mostly multiplex techniques to measure the abundance of many or all gene products such as mRNAs or proteins within a biological sample. Together these measurement modalities endeavor to quantitate the various biological processes and improve our understanding of gene and protein functions and interactions.",
            "score": 54.581387758255005
        },
        {
            "docid": "773298_10",
            "document": "Conceptual system . A conceptual model is a representation of some phenomenon, data or theory by logical and mathematical objects such as functions, relations, tables, stochastic processes, formulas, axiom systems, rules of inference etc. A conceptual model has an ontology, that is the set of expressions in the model which are \"intended\" to denote some aspect of the modeled object. Here we are deliberately vague as to how expressions are constructed in a model and particularly what the logical structure of formulas in a model actually is. In fact, we have made no assumption that models are encoded in any formal logical system at all, although we briefly address this issue below. Moreover, the definition given here is oblivious to whether two expressions really should denote the same thing. Note that this notion of ontology is different from (and weaker than) ontology as is sometimes understood in philosophy; in our sense there is no claim that the expressions actually denote anything which exists \"physically\" or \"spatio-temporally\" (to use W. Quine's formulation).",
            "score": 57.16673386096954
        },
        {
            "docid": "22164509_10",
            "document": "Cis-regulatory module . While the assumption of Boolean logic is important for \"systems biology\", detailed studies show that in general the logic of gene regulation is not Boolean. This means, for example, that in the case of a \"cis\"-regulatory module regulated by two transcription factors, experimentally determined gene-regulation functions can not be described by the 16 possible Boolean functions of two variables. Non-Boolean extensions of the gene-regulatory logic have been proposed to correct for this issue.",
            "score": 65.02043223381042
        },
        {
            "docid": "15993546_6",
            "document": "Cis-natural antisense transcript . Molecular mechanisms behind the regulatory role of cis-NATs are not currently well understood. Three models have been proposed to explain the regulatory effects that cis-NATs have on gene expression. The first model attributes that base pairing between the cis-NAT and its complementary transcript result in a knockdown of mRNA expression. The assumption of this model is that there will be a precise alignment of at least 6 base pairs between the cis-NAT pair to make double stranded RNA. Epigenetic modifications like DNA methylation and post-translational modification of core histones form the basis of the second model. Although it is not yet clearly understood, it is thought that the reverse transcript guides methylation complexes and/or histone-modifying complexes to the promoter regions of the sense transcript and cause an inhibition of expression from the gene. Currently it is not known what attributes of cis-NATs are crucial for the epigenetic model of regulation. The final proposed model that has gained favour due to recent experimental evidence is the transcriptional collision model. During the process of transcription of cis-NATs, the transcriptional complexes assemble in the promoter regions of the gene. RNA polymerases will then begin transcribing the gene at the transcription initiation site laying down nucleotides in a 5' to 3' direction. In the areas of overlap between the cis-NATs the RNA polymerases will collide and stop at the crash site. Transcription is inhibited because RNA polymerases prematurely stop and their incomplete transcripts get degraded.",
            "score": 56.39587068557739
        },
        {
            "docid": "524466_18",
            "document": "Clique (graph theory) . Many different problems from bioinformatics have been modeled using cliques. For instance, model the problem of clustering gene expression data as one of finding the minimum number of changes needed to transform a graph describing the data into a graph formed as the disjoint union of cliques; discuss a similar biclustering problem for expression data in which the clusters are required to be cliques. uses cliques to model ecological niches in food webs. describe the problem of inferring evolutionary trees as one of finding maximum cliques in a graph that has as its vertices characteristics of the species, where two vertices share an edge if there exists a perfect phylogeny combining those two characters. model protein structure prediction as a problem of finding cliques in a graph whose vertices represent positions of subunits of the protein. And by searching for cliques in a protein-protein interaction network, found clusters of proteins that interact closely with each other and have few interactions with proteins outside the cluster. Power graph analysis is a method for simplifying complex biological networks by finding cliques and related structures in these networks.",
            "score": 56.17957866191864
        },
        {
            "docid": "8402086_18",
            "document": "Computational neurogenetic modeling . Because the amount of data on the interplay of genes and neurons and their effects is not enough to construct a rigorous model,  evolutionary computation is used to optimize artificial neural networks and gene regulatory networks, a common technique being the genetic algorithm. A genetic algorithm is a process that can be used to refine models by mimicking the process of natural selection observed in biological ecosystems. The primary advantages are that, due to not requiring derivative information, it can be applied to black box problems and multimodal optimization. The typical process for using genetic algorithms to refine a gene  regulatory network is: first, create a population; next, to create offspring via a crossover operation and  evaluate their fitness; then, on a group chosen for high fitness, simulate mutation via a mutation operator;  finally, taking the now mutated group, repeat this process until a desired level of fitness is demonstrated. Methods by which artificial neural networks may alter their structure without simulated mutation and fitness selection have been developed. A dynamically evolving neural network is one approach, as the creation of new connections and new neurons can  be modeled as the system adapts to new data. This enables the network to evolve in modeling accuracy without simulated natural selection. One method by which dynamically evolving networks may be optimized, called evolving layer neuron aggregation, combines neurons with sufficiently similar input weights into one neuron. This can take place during the training of the network, referred to as online aggregation, or between periods of training, referred to as offline aggregation. Experiments have suggested that offline aggregation is more efficient.",
            "score": 72.96155273914337
        },
        {
            "docid": "52821211_6",
            "document": "Phylogenetic inference using transcriptomic data . RNA-Seq data may be directly assembled into transcripts using sequence assembly.  Two main categories of sequence assembly are often distinguished:  Both methods attempt to generate biologically representative isoform-level constructs from RNA-seq data and generally attempt to associate isoforms with a gene-level construct. However, proper identification of gene-level constructs may be complicated by recent duplications, paralogs, alternative splicing or gene fusions. These complications may also cause downstream issues during ortholog inference. When selecting or generating sequence data, it is also vital to consider the tissue type, developmental stage and environmental conditions of the organisms. Since the transcriptome represents a snapshot of gene expression, minor changes to these conditions may significantly affect which transcripts are expressed. This may detrimentally affect downstream ortholog detection.",
            "score": 73.37668597698212
        },
        {
            "docid": "30818571_4",
            "document": "Wagner's gene network model . The model represents individuals as networks of interacting transcriptional regulators. Each individual expresses formula_1 genes encoding transcription factors. The product of each gene can regulate the expression level of itself and/or the other genes through cis-regulatory elements. The interactions among genes constitute a gene network that is represented by a formula_2 \u00d7 formula_2 regulatory matrix formula_4 in the model. The elements in matrix \"R\" represent the interaction strength. Positive values within the matrix represent the activation of the target gene, while negative ones represent repression. Matrix elements with value 0 indicate the absence of interactions between two genes.",
            "score": 52.4756498336792
        },
        {
            "docid": "17704946_4",
            "document": "Epigenomics . A more likely source of cellular plasticity is through the Regulation of gene expression, such that while two cells may have near identical DNA, the differential expression of certain genes results in variation. Research has shown that cells are capable of regulating gene expression at several stages: mRNA transcription, processing and transportation as well as in protein translation, post-translational processing and degradation. Regulatory proteins that bind to DNA, RNA, and/or proteins are key effectors in these processes and function by positively or negatively regulating specific protein level and function in a cell. And, while DNA binding transcription factors provide a mechanism for specific control of cellular responses, a model where DNA binding transcription factors are the sole regulators of gene activity is also unlikely. For example, in a study of Somatic-cell nuclear transfer, it was demonstrated that stable features of differentiation remain after the nucleus is transferred to a new cellular environment, suggesting that a stable and heritable mechanism of gene regulation was involved in the maintenance of the differentiated state in the absence of the DNA binding transcription factors.",
            "score": 67.36185038089752
        },
        {
            "docid": "356382_9",
            "document": "Gene regulatory network . Mathematical models of GRNs have been developed to capture the behavior of the system being modeled, and in some cases generate predictions corresponding with experimental observations. In some other cases, models have proven to make accurate novel predictions, which can be tested experimentally, thus suggesting new approaches to explore in an experiment that sometimes wouldn't be considered in the design of the protocol of an experimental laboratory. Modeling techniques include differential equations (ODEs), Boolean networks, Petri nets, Bayesian networks, graphical Gaussian models, Stochastic, and Process Calculi. Conversely, techniques have been proposed for generating models of GRNs that best explain a set of time series observations. Recently it has been shown that ChIP-seq signal of Histone modification are more correlated with transcription factor motifs at promoters in comparison to RNA level. Hence it is proposed that time-series histone modification ChIP-seq could provide more reliable inference of gene-regulatory networks in comparison to methods based on expression levels.",
            "score": 79.03066313266754
        },
        {
            "docid": "3869283_43",
            "document": "Dual inheritance theory . Evolutionary psychologists study the evolved architecture of the human mind. They see it as composed of many different programs that process information, each with assumptions and procedures that were specialized by natural selection to solve a different adaptive problem faced by our hunter-gatherer ancestors (e.g., choosing mates, hunting, avoiding predators, cooperating, using aggression). These evolved programs contain content-rich assumptions about how the world and other people work. As ideas are passed from mind to mind, they are changed by these evolved inference systems (much like messages get changed in a game of telephone). But the changes are not random. Evolved programs add and subtract information, reshaping the ideas in ways that make them more \"intuitive\", more memorable, and more attention-grabbing. In other words, \"memes\" (ideas) are not like genes. Genes are copied faithfully as they are replicated, but ideas are not. It\u2019s not just that ideas mutate every once in awhile, like genes do. Ideas are transformed every time they are passed from mind to mind, because the sender's message is being interpreted by evolved inference systems in the receiver. There is no necessary contradiction between evolutionary psychology and DIT, but evolutionary psychologists argue that the psychology implicit in many DIT models is too simple; evolved programs have a rich inferential structure not captured by the idea of a \"content bias\". They also argue that some of the phenomena DIT models attribute to cultural evolution are cases of \"evoked culture\"\u2014situations in which different evolved programs are activated in different places, in response to cues in the environment.",
            "score": 54.07047629356384
        },
        {
            "docid": "23386350_4",
            "document": "BioSim . Diabetes Efforts concentrate on the role of mutations that effect the ion channels of the insulin-producing beta-cells, on the genetic basis for the development of neonatal diabetes, on the study of human (as opposed to mice) pancreatic cells, on the mechanisms underlying the development of insulin resistance, and on the possible role of prenatal nutrition for the development of type-2 diabetes. Models are also developed to analyse the balance between fat and glucose metabolism and to describe the rate of absorption of different insulin variants. Cancer In this area the network uses computer models of the cell cycle and of its coupling to the 24 h day-and-night rhythm to improve the treatment of patients with cancer. The use of chronotherapy implies that the administration of anti-cancer drugs is adjusted in accordance with the circadian rhythm of the patient. For certain forms of cancer this has been found to increase the efficiency of the drug by a factor of five. Efforts are also devoted to the development of new anti-cancer drugs. Hypertension and cardiovascular diseases Activities area focus on the development of 3D heart models that can be used to test how a new drug affects the regularity of the heart rhythm. Work is performed to develop detailed models of the mechanisms by which the individual nephron of the kidney regulates the incoming blood flow and how neighboring nephrons interact. Mental disorders and neuronal systems Work includes application of mathematical models to develop less invasive and demand-controlled electrical stimulation techniques for the treatment of Parkinson's disease. Modelling studies are performed to examine the effect of sleep deprivation in the treatment of depression, and bioinformatic approaches are applied to try to identify forms of depression on the basis of the information available from blood samples. Methodological issues The area encompasses description of complex networks of oscillating biological units, studies of the mechanisms of temperature stabilization in biological feedback regulations, application of new methods of data analysis, and development of modeling software and biomedical search machines. The area includes application of new experimental techniques such as interference microscopy and surface enhanced Raman spectroscopy to study cellular processes. Regulatory issues and dialogue with the public Testing in animal and human subjects is a necessary part of the development of new drugs. Such experiments clearly raises a number of complicated ethical issues that the use of simulation models may reduce. This requires that the regulatory authorities can evaluate computer models and accept them as part of the required documentation.  During the last five years the BioSim Network has published nine books and 800 scientific publications. The network has organized or co-organized 30 conferences and workshops, edited four issues of international journals, and trained about 130 PhD students. New National Centres in Systems Biology have been established in relation to the BioSim partners in Manchester, Warwick, and Edinburgh.",
            "score": 68.8524911403656
        },
        {
            "docid": "42812309_4",
            "document": "Erik van Nimwegen . Erik van Nimwegen\u2019s main research topics concern genome evolution and the function and evolution of the regulatory networks by which cells control gene expression. He develops mathematical models for analyzing how regulatory networks evolve and function, and computational methods for the reconstruction of such networks from large biological data-sets. Van Nimwegen's work includes a general model for the evolution of robustness against mutations and the identification of a number of universal scaling laws of genome evolution. Further research topics are the development of general Bayesian methods for transcription factor and miRNA binding site prediction as well as models for inferring regulatory networks from genome-wide expression and chromatin state data.",
            "score": 81.20737743377686
        },
        {
            "docid": "27075922_35",
            "document": "Natural computing . Gene regulatory networks comprise gene-gene interactions, as well as interactions between genes and other substances in the cell. Genes are transcribed into messenger RNA (mRNA), and then translated into proteins according to the genetic code.  Each gene is associated with other DNA segments (promoters, enhancers, or silencers) that act as binding sites for activators or repressors for gene transcription.  Genes interact with each other either through their gene products (mRNA, proteins) which can regulate gene transcription, or through small RNA species that can directly regulate genes. These gene-gene interactions, together with genes' interactions with other substances in the cell, form the most basic interaction network: the gene regulatory networks. They perform information processing tasks within the cell, including the assembly and maintenance of other networks. Models of gene regulatory networks include random and probabilistic Boolean networks, asynchronous automata, and network motifs.",
            "score": 57.73495364189148
        }
    ],
    "r": [
        {
            "docid": "10571004_5",
            "document": "Biological network inference . Genes are the nodes and the edges are directed. A gene serves as the source of a direct regulatory edge to a target gene by producing an RNA or protein molecule that functions as a transcriptional activator or inhibitor of the target gene. If the gene is an activator, then it is the source of a positive regulatory connection; if an inhibitor, then it is the source of a negative regulatory connection. Computational algorithms take as primary input data measurements of mRNA expression levels of the genes under consideration for inclusion in the network, returning an estimate of the network topology. Such algorithms are typically based on linearity, independence or normality assumptions, which must be verified on a case-by-case basis. Clustering or some form of statistical classification is typically employed to perform an initial organization of the high-throughput mRNA expression values derived from microarray experiments, in particular to select sets of genes as candidates for network nodes. The question then arises: how can the clustering or classification results be connected to the underlying biology? Such results can be useful for pattern classification \u2013 for example, to classify subtypes of cancer, or to predict differential responses to a drug (pharmacogenomics). But to understand the relationships between the genes, that is, to more precisely define the influence of each gene on the others, the scientist typically attempts to reconstruct the transcriptional regulatory network. This can be done by data integration in dynamic models supported by background literature, or information in public databases, combined with the clustering results. The modelling can be done by a Boolean network, by Ordinary differential equations or Linear regression models, e.g. Least-angle regression, by Bayesian network or based on Information theory approaches. For instance it can be done by the application of a correlation-based inference algorithm, as will be discussed below, an approach which is having increased success as the size of the available microarray sets keeps increasing",
            "score": 99.81578063964844
        },
        {
            "docid": "10571004_4",
            "document": "Biological network inference . There is great interest in network medicine for the modelling biological systems. This article focuses on a necessary prerequisite to dynamic modeling of a network: inference of the topology, that is, prediction of the \"wiring diagram\" of the network. More specifically, we focus here on inference of biological network structure using the growing sets of high-throughput expression data for genes, proteins, and metabolites. Briefly, methods using high-throughput data for inference of regulatory networks rely on searching for patterns of partial correlation or conditional probabilities that indicate causal influence. Such patterns of partial correlations found in the high-throughput data, possibly combined with other supplemental data on the genes or proteins in the proposed networks, or combined with other information on the organism, form the basis upon which such algorithms work. Such algorithms can be of use in inferring the topology of any network where the change in state of one node can affect the state of other nodes.",
            "score": 95.88090515136719
        },
        {
            "docid": "21731590_16",
            "document": "RNA-Seq . Coexpression networks are data-derived representations of genes behaving in a similar way across tissues and experimental conditions. Their main purpose lies in hypothesis generation and guilt-by-association approaches for inferring functions of previously unknown genes. RNASeq data has been recently used to infer genes involved in specific pathways based on Pearson correlation, both in plants and mammals. The main advantage of RNASeq data in this kind of analysis over the microarray platforms is the capability to cover the entire transcriptome, therefore allowing the possibility to unravel more complete representations of the gene regulatory networks. Differential regulation of the splice isoforms of the same gene can be detected and used to predict and their biological functions.  Weighted gene co-expression network analysis has been successfully used to identify co-expression modules and intramodular hub genes based on RNA seq data. Co-expression modules may corresponds to cell types or pathways. Highly connected intramodular hubs can be interpreted as representatives of their respective module. Variance-Stabilizing Transformation approaches for estimating correlation coefficients based on RNA seq data have been proposed.",
            "score": 87.47161102294922
        },
        {
            "docid": "1872854_31",
            "document": "Biochemical cascade . In the post-genomic age, high-throughput sequencing and gene/protein profiling techniques have transformed biological research by enabling comprehensive monitoring of a biological system, yielding a list of differentially expressed genes or proteins, which is useful in identifying genes that may have roles in a given phenomenon or phenotype. With DNA microarrays and genome-wide gene engineering, it is possible to screen global gene expression profiles to contribute a wealth of genomic data to the public domain. With RNA interference, it is possible to distill the inferences contained in the experimental literature and primary databases into knowledge bases that consist of annotated representations of biological pathways. In this case, individual genes and proteins are known to be involved in biological processes, components, or structures, as well as how and where gene products interact with each other. Pathway-oriented approaches for analyzing microarray data, by grouping long lists of individual genes, proteins, and/or other biological molecules according to the pathways they are involved in into smaller sets of related genes or proteins, which reduces the complexity, have proven useful for connecting genomic data to specific biological processes and systems. Identifying active pathways that differ between two conditions can have more explanatory power than a simple list of different genes or proteins. In addition, a large number of pathway analytic methods exploit pathway knowledge in public repositories such as Gene Ontology (GO) or Kyoto Encyclopedia of Genes and Genomes (KEGG), rather than inferring pathways from molecular measurements. Furthermore, different research focuses have given the word \"pathway\" different meanings. For example, 'pathway' can denote a metabolic pathway involving a sequence of enzyme-catalyzed reactions of small molecules, or a signaling pathway involving a set of protein phosphorylation reactions and gene regulation events. Therefore, the term \"pathway analysis\" has a very broad application. For instance, it can refer to the analysis physical interaction networks (e.g., protein\u2013protein interactions), kinetic simulation of pathways, and steady-state pathway analysis (e.g., flux-balance analysis), as well as its usage in the inference of pathways from expression and sequence data. Several functional enrichment analysis tools and algorithms have been developed to enhance data interpretation. The existing knowledge base\u2013driven pathway analysis methods in each generation have been summarized in recent literature.",
            "score": 85.69910430908203
        },
        {
            "docid": "7766542_9",
            "document": "Microarray analysis techniques . Commercial systems for gene network analysis such as Ingenuity and Pathway studio create visual representations of differentially expressed genes based on current scientific literature. Non-commercial tools such as FunRich, GenMAPP and Moksiskaan also aid in organizing and visualizing gene network data procured from one or several microarray experiments. A wide variety of microarray analysis tools are available through Bioconductor written in the R programming language. The frequently cited SAM module and other microarray tools are available through Stanford University. Another set is available from Harvard and MIT. Specialized software tools for statistical analysis to determine the extent of over- or under-expression of a gene in a microarray experiment relative to a reference state have also been developed to aid in identifying genes or gene sets associated with particular phenotypes. One such method of analysis, known as Gene Set Enrichment Analysis (GSEA), uses a Kolmogorov-Smirnov-style statistic to identify groups of genes that are regulated together. This third-party statistics package offers the user information on the genes or gene sets of interest, including links to entries in databases such as NCBI's GenBank and curated databases such as Biocarta and Gene Ontology. Protein complex enrichment analysis tool (COMPLEAT) provides similar enrichment analysis at the level of protein complexes. The tool can identify the dynamic protein complex regulation under different condition or time points. Related system, PAINT and SCOPE performs a statistical analysis on gene promoter regions, identifying over and under representation of previously identified transcription factor response elements. Another statistical analysis tool is Rank Sum Statistics for Gene Set Collections (RssGsc), which uses rank sum probability distribution functions to find gene sets that explain experimental data. A further approach is contextual meta-analysis, i.e. finding out how a gene cluster responds to a variety of experimental contexts. Genevestigator is a public tool to perform contextual meta-analysis across contexts such as anatomical parts, stages of development, and response to diseases, chemicals, stresses, and neoplasms.",
            "score": 83.88714599609375
        },
        {
            "docid": "42812309_4",
            "document": "Erik van Nimwegen . Erik van Nimwegen\u2019s main research topics concern genome evolution and the function and evolution of the regulatory networks by which cells control gene expression. He develops mathematical models for analyzing how regulatory networks evolve and function, and computational methods for the reconstruction of such networks from large biological data-sets. Van Nimwegen's work includes a general model for the evolution of robustness against mutations and the identification of a number of universal scaling laws of genome evolution. Further research topics are the development of general Bayesian methods for transcription factor and miRNA binding site prediction as well as models for inferring regulatory networks from genome-wide expression and chromatin state data.",
            "score": 81.2073745727539
        },
        {
            "docid": "41224221_2",
            "document": "Weighted correlation network analysis . Weighted correlation network analysis, also known as weighted gene co-expression network analysis (WGCNA), is a widely used data mining method especially for studying biological networks based on pairwise correlations between variables. While it can be applied to most high-dimensional data sets, it has been most widely used in genomic applications. It allows one to define modules (clusters), intramodular hubs, and network nodes with regard to module membership, to study the relationships between co-expression modules, and to compare the network topology of different networks (differential network analysis). WGCNA can be used as a data reduction technique (related to oblique factor analysis ), as a clustering method (fuzzy clustering), as a feature selection method (e.g. as gene screening method), as a framework for integrating complementary (genomic) data (based on weighted correlations between quantitative variables), and as a data exploratory technique. Although WGCNA incorporates traditional data exploratory techniques, its intuitive network language and analysis framework transcend any standard analysis technique. Since it uses network methodology and is well suited for integrating complementary genomic data sets, it can be interpreted as systems biologic or systems genetic data analysis method. By selecting intramodular hubs in consensus modules, WGCNA also gives rise to network based meta analysis techniques.",
            "score": 79.09337615966797
        },
        {
            "docid": "356382_9",
            "document": "Gene regulatory network . Mathematical models of GRNs have been developed to capture the behavior of the system being modeled, and in some cases generate predictions corresponding with experimental observations. In some other cases, models have proven to make accurate novel predictions, which can be tested experimentally, thus suggesting new approaches to explore in an experiment that sometimes wouldn't be considered in the design of the protocol of an experimental laboratory. Modeling techniques include differential equations (ODEs), Boolean networks, Petri nets, Bayesian networks, graphical Gaussian models, Stochastic, and Process Calculi. Conversely, techniques have been proposed for generating models of GRNs that best explain a set of time series observations. Recently it has been shown that ChIP-seq signal of Histone modification are more correlated with transcription factor motifs at promoters in comparison to RNA level. Hence it is proposed that time-series histone modification ChIP-seq could provide more reliable inference of gene-regulatory networks in comparison to methods based on expression levels.",
            "score": 79.0306625366211
        },
        {
            "docid": "356382_31",
            "document": "Gene regulatory network . Other work has focused on predicting the gene expression levels in a gene regulatory network. The approaches used to model gene regulatory networks have been constrained to be interpretable and, as a result, are generally simplified versions of the network. For example, Boolean networks have been used due to their simplicity and ability to handle noisy data but lose data information by having a binary representation of the genes. Also, artificial neural networks omit using a hidden layer so that they can be interpreted, losing the ability to model higher order correlations in the data. Using a model that is not constrained to be interpretable, a more accurate model can be produced. Being able to predict gene expressions more accurately provides a way to explore how drugs affect a system of genes as well as for finding which genes are interrelated in a process. This has been encouraged by the DREAM competition which promotes a competition for the best prediction algorithms. Some other recent work has used artificial neural networks with a hidden layer.",
            "score": 78.48958587646484
        },
        {
            "docid": "159266_62",
            "document": "Gene expression . Gene networks can also be constructed without formulating an explicit causal model. This is often the case when assembling networks from large expression data sets. Covariation and correlation of expression is computed across a large sample of cases and measurements (often transcriptome or proteome data). The source of variation can be either experimental or natural (observational). There are several ways to construct gene expression networks, but one common approach is to compute a matrix of all pair-wise correlations of expression across conditions, time points, or individuals and convert the matrix (after thresholding at some cut-off value) into a graphical representation in which nodes represent genes, transcripts, or proteins and edges connecting these nodes represent the strength of association (see ). Weighted correlation network analysis (WGCNA) involves weighted networks defined by soft-thresholding the pairwise correlations among variables (e.g. measures of transcript abundance). WGCNA can be applied to compute eigengenes, which are highly robust biomarkers (features) useful for diagnosis and prognosis.",
            "score": 78.14521026611328
        },
        {
            "docid": "29467449_4",
            "document": "Protein function prediction . While techniques such as microarray analysis, RNA interference, and the yeast two-hybrid system can be used to experimentally demonstrate the function of a protein, advances in sequencing technologies have made the rate at which proteins can be experimentally characterized much slower than the rate at which new sequences become available. Thus, the annotation of new sequences is mostly by \"prediction\" through computational methods, as these types of annotation can often be done quickly and for many genes or proteins at once. The first such methods inferred function based on homologous proteins with known functions (homology-based function prediction). The development of context-based and structure based methods have expanded what information can be predicted, and a combination of methods can now be used to get a picture of complete cellular pathways based on sequence data. The importance and prevalence of computational prediction of gene function is underlined by an analysis of 'evidence codes' used by the GO database: as of 2010, 98% of annotations were listed under the code IEA (inferred from electronic annotation) while only 0.6% were based on experimental evidence.",
            "score": 77.85997009277344
        },
        {
            "docid": "53576321_28",
            "document": "Single-cell transcriptomics . Pseudo-temporal ordering (or trajectory inference) is a technique that aims to infer gene expression dynamics from snapshot single-cell data. The method tries to order the cells in such a way that similar cells are closely positioned to each other. This trajectory of cells can be linear, but can also bifurcate or follow more complex graph structures. The trajectory therefore enables the inference of gene expression dynamics and the ordering of cells by their progression through differentiation or response to external stimuli. The method relies on the assumptions that the cells follow the same path through the process of interest and that their transcriptional state correlates to their progression. The algorithm can be applied to both mixed populations and temporal samples.",
            "score": 77.34553527832031
        },
        {
            "docid": "8767449_15",
            "document": "Public health genomics . The term genomics, referring to the organism\u2019s whole genome, is also used to refer to gene informatics, or the collection and storage of genetic data, including the functional information associated with the genes, and the analysis of the data as combinations, patterns and networks by computer algorithms. Systems biology and genomics are natural partners, since the development of genomic information and systems naturally facilitates analysis of systems biology questions involving relationships between genes, their variants (SNPs) and biological function. Such questions include the investigation of signaling pathways, evolutionary trees, or biological networks, such as immune networks and pathways. For this reason, genomics and these approaches are particularly suited to studies in immunology. The study of immunology using genomics, as well as proteomics and transcriptomics (Includes gene profiles, either genomic or expressed gene mRNA profiles), has been termed immunomics.",
            "score": 77.09186553955078
        },
        {
            "docid": "53576321_30",
            "document": "Single-cell transcriptomics . Gene regulatory network inference is a technique that aims to construct a network, shown as a graph, in which the nodes represent the genes and edges indicate co-regulatory interactions. The method relies on the assumption that a strong statistical relationship between the expression of genes is an indication of a potential functional relationship. The most commonly used method to measure the strength of a statistical relationship is correlation. However, correlation fails to identify non-linear relationships and mutual information is used as an alternative. Gene clusters linked in a network signify genes that undergo coordinated changes in expression.",
            "score": 75.63238525390625
        },
        {
            "docid": "356382_7",
            "document": "Gene regulatory network . The nodes of this network can represent genes, proteins, mRNAs, protein/protein complexes or cellular processes. Nodes that are depicted as lying along vertical lines are associated with the cell/environment interfaces, while the others are free-floating and can diffuse. Edges between nodes represent interactions between the nodes, that can correspond to individual molecular reactions between DNA, mRNA, miRNA, proteins or molecular processes through which the products of one gene affect those of another, though the lack of experimentally obtained information often implies that some reactions are not modeled at such a fine level of detail. These interactions can be inductive (usually represented by arrowheads or the + sign), with an increase in the concentration of one leading to an increase in the other, inhibitory (represented with filled circles, blunt arrows or the minus sign), with an increase in one leading to a decrease in the other, or dual, when depending of the circumstances the regulator can activate or inhibit the target node. The nodes can regulate themselves directly or indirectly, creating feedback loops, which form cyclic chains of dependencies in the topological network. The network structure is an abstraction of the system's molecular or chemical dynamics, describing the manifold ways in which one substance affects all the others to which it is connected. In practice, such GRNs are inferred from the biological literature on a given system and represent a distillation of the collective knowledge about a set of related biochemical reactions. To speed up the manual curation of GRNs, some recent efforts try to use text mining, curated databases, network inference from massive data, model checking and other information extraction technologies for this purpose.",
            "score": 75.6081771850586
        },
        {
            "docid": "12499410_26",
            "document": "Network motif . Wernicke introduced an algorithm named \"RAND-ESU\" that provides a significant improvement over \"mfinder\". This algorithm, which is based on the exact enumeration algorithm \"ESU\", has been implemented as an application called \"FANMOD\". \"RAND-ESU\" is a NM discovery algorithm applicable for both directed and undirected networks, effectively exploits an unbiased node sampling throughout the network, and prevents overcounting sub-graphs more than once. Furthermore, \"RAND-ESU\" uses a novel analytical approach called \"DIRECT\" for determining sub-graph significance instead of using an ensemble of random networks as a Null-model. The \"DIRECT\" method estimates the sub-graph concentration without explicitly generating random networks. Empirically, the DIRECT method is more efficient in comparison with the random network ensemble in case of sub-graphs with a very low concentration; however, the classical Null-model is faster than the \"DIRECT\" method for highly concentrated sub-graphs. In the following, we detail the \"ESU\" algorithm and then we show how this exact algorithm can be modified efficiently to \"RAND-ESU\" that estimates sub-graphs concentrations.",
            "score": 74.81532287597656
        },
        {
            "docid": "1053858_2",
            "document": "Functional genomics . Functional genomics is a field of molecular biology that attempts to make use of the vast wealth of data given by genomic and transcriptomic projects (such as genome sequencing projects and RNA sequencing) to describe gene (and protein) functions and interactions. Unlike structural genomics, functional genomics focuses on the dynamic aspects such as gene transcription, translation, regulation of gene expression and protein\u2013protein interactions, as opposed to the static aspects of the genomic information such as DNA sequence or structures. Functional genomics attempts to answer questions about the function of DNA at the levels of genes, RNA transcripts, and protein products. A key characteristic of functional genomics studies is their genome-wide approach to these questions, generally involving high-throughput methods rather than a more traditional \u201cgene-by-gene\u201d approach. The goal of functional genomics is to understand the function of larger numbers of genes or proteins, eventually all components of a genome. A more long-term goal is to understand the relationship between an organism's genome and its phenotype. The term functional genomics is often used broadly to refer to the many technical approaches to study an organism's genes and proteins, including the \"biochemical, cellular, and/or physiological properties of each and every gene product\" while some authors include the study of nongenic elements in his definition. Functional genomics may also include studies of natural genetic variation over time (such as an organism's development) or space (such as its body regions), as well as functional disruptions such as mutations.",
            "score": 73.86518096923828
        },
        {
            "docid": "12499410_57",
            "document": "Network motif . Much experimental work has been devoted to understanding network motifs in gene regulatory networks. These networks control which genes are expressed in the cell in response to biological signals. The network is defined such that genes are nodes, and directed edges represent the control of one gene by a transcription factor (regulatory protein that binds DNA) encoded by another gene. Thus, network motifs are patterns of genes regulating each other's transcription rate. When analyzing transcription networks, it is seen that the same network motifs appear again and again in diverse organisms from bacteria to human. The transcription network of \"E. coli\" and yeast, for example, is made of three main motif families, that make up almost the entire network. The leading hypothesis is that the network motif were independently selected by evolutionary processes in a converging manner, since the creation or elimination of regulatory interactions is fast on evolutionary time scale, relative to the rate at which genes change, Furthermore, experiments on the dynamics generated by network motifs in living cells indicate that they have characteristic dynamical functions. This suggests that the network motif serve as building blocks in gene regulatory networks that are beneficial to the organism.",
            "score": 73.56987762451172
        },
        {
            "docid": "52821211_6",
            "document": "Phylogenetic inference using transcriptomic data . RNA-Seq data may be directly assembled into transcripts using sequence assembly.  Two main categories of sequence assembly are often distinguished:  Both methods attempt to generate biologically representative isoform-level constructs from RNA-seq data and generally attempt to associate isoforms with a gene-level construct. However, proper identification of gene-level constructs may be complicated by recent duplications, paralogs, alternative splicing or gene fusions. These complications may also cause downstream issues during ortholog inference. When selecting or generating sequence data, it is also vital to consider the tissue type, developmental stage and environmental conditions of the organisms. Since the transcriptome represents a snapshot of gene expression, minor changes to these conditions may significantly affect which transcripts are expressed. This may detrimentally affect downstream ortholog detection.",
            "score": 73.3766860961914
        },
        {
            "docid": "52821211_2",
            "document": "Phylogenetic inference using transcriptomic data . In molecular phylogenetics, relationships among individuals are determined using character traits, such as DNA, RNA or protein, which may be obtained using a variety of sequencing technologies. High-throughput next-generation sequencing has become a popular technique in transcriptomics, which represent a snapshot of gene expression. In eukaryotes, making phylogenetic inferences using RNA is complicated by alternative splicing, which produces multiple transcripts from a single gene. As such, a variety of approaches may be used to improve phylogenetic inference using transcriptomic data obtained from RNA-Seq and processed using computational phylogenetics.",
            "score": 73.11349487304688
        },
        {
            "docid": "15993546_4",
            "document": "Cis-natural antisense transcript . Identification of NATs in whole genomes is possible due to the large collection of sequence data available from multiple organisms. \"In silico\" methods for detecting NATs suffer from several shortcomings depending on the source of sequence information. Studies that use mRNA have sequences whose orientations are known, but the amount of mRNA sequence information available is small. Predicted gene models using algorithms trained to look for genes gives an increased coverage of the genome at the cost of confidence in the identified gene. Another resource is the extensive expressed sequence tag (EST) libraries but these small sequences must first be assigned an orientation before useful information can be extracted from them. Some studies have utilized special sequence information in the ESTs such as the poly(A) signal, poly(A) tail, and splicing sites to both filter the ESTs and to give them the correct transcriptional orientation. Combinations of the different sequence sources attempts to maximize coverage as well as maintain integrity in the data.",
            "score": 72.96465301513672
        },
        {
            "docid": "8402086_18",
            "document": "Computational neurogenetic modeling . Because the amount of data on the interplay of genes and neurons and their effects is not enough to construct a rigorous model,  evolutionary computation is used to optimize artificial neural networks and gene regulatory networks, a common technique being the genetic algorithm. A genetic algorithm is a process that can be used to refine models by mimicking the process of natural selection observed in biological ecosystems. The primary advantages are that, due to not requiring derivative information, it can be applied to black box problems and multimodal optimization. The typical process for using genetic algorithms to refine a gene  regulatory network is: first, create a population; next, to create offspring via a crossover operation and  evaluate their fitness; then, on a group chosen for high fitness, simulate mutation via a mutation operator;  finally, taking the now mutated group, repeat this process until a desired level of fitness is demonstrated. Methods by which artificial neural networks may alter their structure without simulated mutation and fitness selection have been developed. A dynamically evolving neural network is one approach, as the creation of new connections and new neurons can  be modeled as the system adapts to new data. This enables the network to evolve in modeling accuracy without simulated natural selection. One method by which dynamically evolving networks may be optimized, called evolving layer neuron aggregation, combines neurons with sufficiently similar input weights into one neuron. This can take place during the training of the network, referred to as online aggregation, or between periods of training, referred to as offline aggregation. Experiments have suggested that offline aggregation is more efficient.",
            "score": 72.96155548095703
        },
        {
            "docid": "152611_11",
            "document": "Cellular differentiation . Each specialized cell type in an organism expresses a subset of all the genes that constitute the genome of that species. Each cell type is defined by its particular pattern of regulated gene expression. Cell differentiation is thus a transition of a cell from one cell type to another and it involves a switch from one pattern of gene expression to another. Cellular differentiation during development can be understood as the result of a gene regulatory network. A regulatory gene and its cis-regulatory modules are nodes in a gene regulatory network; they receive input and create output elsewhere in the network. The systems biology approach to developmental biology emphasizes the importance of investigating how developmental mechanisms interact to produce predictable patterns (morphogenesis). (However, an alternative view has been proposed recently. Based on stochastic gene expression, cellular differentiation is the result of a Darwinian selective process occurring among cells. In this frame, protein and gene networks are the result of cellular processes and not their cause. See: Cellular Darwinism) A few evolutionarily conserved types of molecular processes are often involved in the cellular mechanisms that control these switches. The major types of molecular processes that control cellular differentiation involve cell signaling. Many of the signal molecules that convey information from cell to cell during the control of cellular differentiation are called growth factors. Although the details of specific signal transduction pathways vary, these pathways often share the following general steps. A ligand produced by one cell binds to a receptor in the extracellular region of another cell, inducing a conformational change in the receptor. The shape of the cytoplasmic domain of the receptor changes, and the receptor acquires enzymatic activity. The receptor then catalyzes reactions that phosphorylate other proteins, activating them. A cascade of phosphorylation reactions eventually activates a dormant transcription factor or cytoskeletal protein, thus contributing to the differentiation process in the target cell. Cells and tissues can vary in competence, their ability to respond to external signals.",
            "score": 72.88680267333984
        },
        {
            "docid": "5255433_4",
            "document": "Fiona Brinkman . Brinkman's current research interests center around improving understanding of how microbes evolve and improving computational methods that aid the analysis of microbes and the development of new vaccines, drugs and diagnostics for infectious diseases. Increasingly her methods have been applied for more environmental applications. She is noted for developing PSORTb, the most precise method available for computational protein subcellular localization prediction and the first computational method that exceeded the accuracy of some common high-throughput laboratory methods for such subcellular localization analysis. This method aids the prediction of cell surface and secreted proteins in a bacterial cell that may be suitable drug targets, vaccine components or diagnostics. She has also developed bioinformatics methods that aid the more accurate identification of genomic islands (i.e. IslandViewer) and orthologs (i.e. OrtholugeDB) . Her research has provided new insights into the evolution of pathogens and the role that horizontal gene transfer and genomic islands play. She confirmed the anecdotal assumption that virulence factors (disease-causing genes in pathogens) are disproportionately associated with genomic islands. She was among the first researchers to use whole genome sequencing to aid infectious disease outbreak investigations (\"genomic epidemiology\"), integrating genome sequence data with social network analysis. She was involved in the Pseudomonas Genome Project and is the coordinator of the Pseudomonas Genome Database, a database of Pseudomonas species genomic data and associated annotations that is continually updated. She has also developed databases (i.e. InnateDB and the Allergy and Asthma Portal) to aid more systems-based analysis of immune disorders and the immune response to infections in humans and other animals - databases that have aided the identification of new immune-modulating therapeutics. She has a long-standing interest in bioinformatics training, improving the curation of biological/bioinformatics data, and developing effective bioinformatics data standards and databases. She is a Thomson Reuter's Highly Cited Researcher, a member of national committees and Boards such as the Genome Canada Board of Directors, and has been Research Director for several Genomics projects. She has a growing interest in applying her methods to environmental applications as part of a broader interest in developing approaches for more holistic, sustainable infectious disease control and microbiome conservation - developing approaches that may select less for antimicrobial resistance, improve the tracking of pathogens and their origins, and better factor in the important role of societal changes and the environment in shaping microbiomes",
            "score": 72.59735107421875
        },
        {
            "docid": "25278985_10",
            "document": "Epistasis and functional genomics . The choice of genes examined within a given E-MAP is critical to achieving fruitful results. It is particularly important that a significant subset of the genes examined have been well established in the literature. These genes are thus able to act as controls for the E-MAP allowing for greater certainty in analyzing the data from uncharacterized genes. Clusters organized by sub-cellular localization and general cellular processes (e.g. cell cycle) have yielded profitable results in S. cerevisiae. Data from protein-protein interaction studies can also provide a useful basis for selecting gene groups for E-MAP data. We would expect genes which exhibit physical interactions to also demonstrate interactions at the genetic level and thus these can serve as adequate controls for E-MAP data. Collins et al. (2007) carried out a comparison of E-MAP scores and physical interaction data from large-scale affinity purification methods (AP-MS) and their data demonstrate that an E-MAP approach identifies protein-protein interactions with a specificity equal to that of traditional methods such as AP-MS .",
            "score": 72.51861572265625
        },
        {
            "docid": "46581687_3",
            "document": "Pathway analysis . The data for pathway analysis come from high throughput biology. This includes high throughput sequencing data and microarray data. Before pathway analysis can be done, the omics data should be normalized, and genes should be ranked by differential expression usually with help of Student's t-test, ANOVA or other statistics. In general, any list of statistical ranked genes can be analyzed by pathway analysis. For example, often the functional activity of proteins can be inferred using network enrichment analysis of genes deferentially expressed in the experiment. Such functional activity scores can then be used for pathway analysis to find pathways responsible for observed differential expression. In case when ranking is not available simply list of genes can be analyzed. Also it is possible to integrate multiple microarray data sets from different research groups by meta-analysis and cross-platform normalization. By using pathway analysis software, researchers can determine which gene groups such as pathways, cell processes or diseases are enriched with over and under expressed in experimental data genes. They can also infer associated upstream and downstream regulators, proteins, small molecules, drugs, etc. For example, pathway analysis of several independent microarray experiments (meta-analysis) helped to discover potential biomarkers in a single pathway important for fast-to-slow switch fiber type transition in Duchenne muscular dystrophy. In other study meta-analysis identified two biomarkers in blood of patients with Parkinson's Disease, which can be useful for monitoring the disease.",
            "score": 72.46869659423828
        },
        {
            "docid": "33178845_5",
            "document": "TopFIND . The data is presented to the user with a strong emphasis on the relation to curated background information and underlying evidence that led to the observation of a terminus, its modification or proteolytic cleavage. In brief the protein information, its domain structure, protein termini, terminus modifications and proteolytic processing of and by other proteins is listed. All information is accompanied by metadata like its original source, method of identification, confidence measurement or related publication. A positional cross correlation evaluation matches termini and cleavage sites with protein features (such as amino acid variants) and domains to highlight potential effects and dependencies in a unique way. Also, a network view of all proteins showing their functional dependency as protease, substrate or protease inhibitor tied in with protein interactions is provided for the easy evaluation of network wide effects. A powerful yet user friendly filtering mechanism allows the presented data to be filtered based on parameters like methodology used, in vivo relevance, confidence or data source (e.g. limited to a single laboratory or publication). This provides means to assess physiological relevant data and to deduce functional information and hypotheses relevant to the bench scientist. In a later release analysis tools for the evaluation of proteolytic pathways in experimental data have been added.",
            "score": 72.2468490600586
        },
        {
            "docid": "4214_34",
            "document": "Bioinformatics . Expression data can be used to infer gene regulation: one might compare microarray data from a wide variety of states of an organism to form hypotheses about the genes involved in each state. In a single-cell organism, one might compare stages of the cell cycle, along with various stress conditions (heat shock, starvation, etc.). One can then apply clustering algorithms to that expression data to determine which genes are co-expressed. For example, the upstream regions (promoters) of co-expressed genes can be searched for over-represented regulatory elements. Examples of clustering algorithms applied in gene clustering are k-means clustering, self-organizing maps (SOMs), hierarchical clustering, and consensus clustering methods.",
            "score": 71.84741973876953
        },
        {
            "docid": "54112223_6",
            "document": "Transcriptomics technologies . Studies of individual transcripts were being performed several decades before any transcriptomics approaches were available. Libraries of silkmoth mRNA transcripts were collected and converted to complementary DNA (cDNA) for storage using reverse transcriptase in the late 1970s. In the 1980s, low-throughput sequencing using the Sanger method was used to sequence random transcripts, producing expressed sequence tags (ESTs). The Sanger method of sequencing was predominant until the advent of high-throughput methods such as sequencing by synthesis (Solexa/Illumina). ESTs came to prominence during the 1990s as an efficient method to determine the gene content of an organism without sequencing the entire genome. Amounts of individual transcripts were quantified using Northern blotting, nylon membrane arrays, and later reverse transcriptase quantitative PCR (RT-qPCR) methods, but these methods are laborious and can only capture a tiny subsection of a transcriptome. Consequently, the manner in which a transcriptome as a whole is expressed and regulated remained unknown until higher-throughput techniques were developed.",
            "score": 71.6581039428711
        },
        {
            "docid": "29467449_19",
            "document": "Protein function prediction . Several networks based on different data sources can be combined into a composite network, which can then be used by a prediction algorithm to annotate candidate genes or proteins. For example, the developers of the bioPIXIE system used a wide variety of \"Saccharomyces cerevisiae\" (yeast) genomic data to produce a composite functional network for that species. This resource allows the visualization of known networks representing biological processes, as well as the prediction of novel components of those networks. Many algorithms have been developed to predict function based on the integration of several data sources (e.g. genomic, proteomic, protein interaction, etc.), and testing on previously annotated genes indicates a high level of accuracy. Disadvantages of some function prediction algorithms have included a lack of accessibility, and the time required for analysis. Faster, more accurate algorithms such as GeneMANIA (multiple association network integration algorithm) have however been developed in recent years and are publicly available on the web, indicating the future direction of function prediction.",
            "score": 71.62545013427734
        },
        {
            "docid": "1181008_10",
            "document": "Computational science . Exciting new developments in biotechnology are now revolutionizing biology and biomedical research. Examples of these techniques are high-throughput sequencing, high-throughput quantitative PCR, intra-cellular imaging, in-situ hybridization of gene expression, three-dimensional imaging techniques like Light Sheet Fluorescence Microscopy and Optical Projection, (micro)-Computer Tomography. Given the massive amounts of complicated data that is generated by these techniques, their meaningful interpretation, and even their storage, form major challenges calling for new approaches. Going beyond current bioinformatics approaches, computational biology needs to develop new methods to discover meaningful patterns in these large data sets. Model-based reconstruction of gene networks can be used to organize the gene expression data in systematic way and to guide future data collection. A major challenge here is to understand how gene regulation is controlling fundamental biological processes like biomineralisation and embryogenesis. The sub-processes like gene regulation, organic molecules interacting with the mineral deposition process, cellular processes, physiology and other processes at the tissue and environmental levels are linked. Rather than being directed by a central control mechanism, biomineralisation and embryogenesis can be viewed as an emergent behavior resulting from a complex system in which several sub-processes on very different temporal and spatial scales (ranging from nanometer and nanoseconds to meters and years) are connected into a multi-scale system. One of the few available options to understand such systems is by developing a multi-scale model of the system.",
            "score": 71.53749084472656
        },
        {
            "docid": "28722065_2",
            "document": "Proteogenomics . Proteogenomics is a field of biological research that utilizes a combination of proteomics, genomics, and transcriptomics to aid in the discovery and identification of peptides. Protegenomics is used to identify new peptides by comparing MS/MS spectra against a protein database that has been derived from genomic and trancriptomic information. Proteogenomics often refers to studies that use proteomic information, often derived from mass spectrometry, to improve gene annotations. Genomics deals with the genetic code of entire organisms, while transcriptomics deals with the study of RNA sequencing and transcripts. proteomics utilizes tandem mass spectrometry and liquid chromatography to identify and study the functions of proteins. Proteomics is being utilized to discover all the proteins expressed within an organism, known as its proteome. The issue with proteomics is that it relies on the assumption that current gene models are correct and that the correct protein sequences can be found using a reference protein sequence database; however, this is not always the case as some peptides cannot be located in the database. In addition, novel protein sequences can occur through mutations. these issues can be fixed with the use of proteomic, genomic, and trancriptomic data. The utilization of both proteomics and genomics led to proteogeonmics which became its own field in 2004.",
            "score": 71.37910461425781
        }
    ]
}