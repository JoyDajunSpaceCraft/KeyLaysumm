{
    "q": [
        {
            "docid": "8582684_19",
            "document": "Reward system . Rewarding stimuli can drive learning in both the form of classical conditioning (Pavlovian conditioning) and operant conditioning (instrumental conditioning). In classical conditioning, a reward can act as an unconditioned stimulus that, when associated with the conditioned stimulus, causes the conditioned stimulus to elicit both musculoskeletal (in the form of simple approach and avoidance behaviors) and vegetative responses. In operant conditioning, a reward may act as a reinforcing stimulus in that it increases or supports actions that lead to itself. Learned behaviors may or may not be sensitive to the value of the outcomes they lead to; behaviors that are sensitive to the contingency of an outcome on the performance of an action as well as the outcome value are goal-directed, while elicited actions that are insensitive to contingency or value are called habits. This distinction is thought to reflected two forms of learning, model free and model based. Model free learning involves the simple caching and updating of values. In contrast, model based learning involves the storage and construction of an internal model of events that allows inference and flexible prediction. Although pavlovian conditioning is generally assumed to be model free, the incentive salience assigned to a conditioned stimulus is flexible with regard to changes in internal motivational states.",
            "score": 61.647228479385376
        },
        {
            "docid": "1221571_2",
            "document": "Rescorla\u2013Wagner model . The Rescorla\u2013Wagner model (\"R-W\") is a model of classical conditioning, in which learning is conceptualized in terms of associations between conditioned (CS) and unconditioned (US) stimuli. A strong CS-US association means, essentially, that the CS signals or predicts the US. One might say that before conditioning, the subject is surprised by the US, but after conditioning, the subject is no longer surprised, because the CS predicts the coming of the US. The model casts the conditioning processes into discrete trials, during which stimuli may be either present or absent. The strength of prediction of the US on a trial can be represented as the summed associative strengths of all CSs present during the trial. This feature of the model represented a major advance over previous models, and it allowed a straightforward explanation of important experimental phenomena, most notably the blocking effect. Failures of the model have led to modifications, alternative models, and many additional findings. The model has had some impact on neural science in recent years, as studies have suggested that the phasic activity of dopamine neurons in mesostriatal DA projections in the midbrain encodes for the type of prediction error detailed in the model.",
            "score": 64.23525905609131
        },
        {
            "docid": "188540_48",
            "document": "Classical conditioning . An organism's need to predict future events is central to modern theories of conditioning. Most theories use associations between stimuli to take care of these predictions. For example: In the R\u2013W model, the associative strength of a CS tells us how strongly that CS predicts a US. A different approach to prediction is suggested by models such as that proposed by Gallistel & Gibbon (2000, 2002). Here the response is not determined by associative strengths. Instead, the organism records the times of onset and offset of CSs and USs and uses these to calculate the probability that the US will follow the CS. A number of experiments have shown that humans and animals can learn to time events (see Animal cognition), and the Gallistel & Gibbon model yields very good quantitative fits to a variety of experimental data. However, recent studies have suggested that duration-based models cannot account for some empirical findings as well as associative models.",
            "score": 71.63281035423279
        },
        {
            "docid": "24328441_6",
            "document": "Associative sequence learning . A further defining characteristic of the ASL model is its claim that the development of sensorimotor links is mediated by the same mechanisms of associative learning that produce Pavlovian conditioning. Crucially, Heyes therefore proposes that the development of sensorimotor associations is not only sensitive to temporal contiguity (the extent to which activation of sensory and motor representations are close together in time) but also to contingency (the extent to which activation of one representation is predictive of the other). This is a crucial feature of the ASL model as it explains why actors do not acquire spurious sensorimotor associations. Consider the example of two interactants, one of whom is scratching his ear when his colleague sneezes. Learning-based models which do not stipulate a sensitivity to contingency predict that the motor plan for ear-scratching ought to become associated with the visual representation of sneezing! However, ASL predicts that no association will develop because the act of ear-scratching is not predictive of the sight of sneezing \u2013 in other words there is no sensorimotor \"contingency\". The Hebbian learning account of the emergence of mirror neurons also emphasizes the importance of contingency, as it is known that the synaptic plasticity that underlies Hebbian learning is known to depend on contingency.",
            "score": 65.99217200279236
        },
        {
            "docid": "21167712_2",
            "document": "Comparator hypothesis . The comparator hypothesis is a psychological model of associative learning and performance. To understand the model, it helps to consider how associative learning is usually studied. For example, to study the learning of an association between cues, such as lights and sounds, and an outcome such as food, an experimenter typically pairs the cues and the food a number of times (the learning phase) and then tests with one or more of the cues to see if a response has been learned (the test phase). Most theories of associative learning have assumed that phenomena of interest (see Classical conditioning for a list of phenomena) depend on what happens during the learning phase. The comparator hypothesis assumes, on the contrary, that what happens during the learning phase is fairly simple, and that most interesting phenomena depend on what happens during the test phase. The comparator hypothesis arose primarily in response to so-called \u201ccue competition\u201d effects. If for example in classical conditioning, two conditioned stimuli A and B are presented with an unconditioned stimulus, one may find on test that the subject responds to A or to B or to both or not very much to either. How can one account for such varied results?  First proposed by Ralph Miller' the comparator hypothesis is a model of Pavlovian associations which posits that cue competition effects arise at the time of test, that is during \"performance\", not during learning. The model assumes, essentially, that during conditioning the subject acquires both CS-US and context-US associations. At the time of the test, the associations are compared, and a response to a CS occurs only if the CS-US association is stronger than the context-US association. The model was initially proposed to account for unexplained variations in cue competition effects such as recovery from blocking, but has been expanded to apply more broadly to learning phenomena. The success of the hypothesis has led to modifications in existing theories, such as Wagner's SOP and the Rescorla-Wagner model, enabling them to explain such phenomena as retrospective reevaluation, but other phenomena such as counteraction still pose difficulties for most models.",
            "score": 65.06431674957275
        },
        {
            "docid": "10302211_4",
            "document": "Blocking effect . This effect was most famously explained by the Rescorla\u2013Wagner model. The model says, essentially, that if one CS (here the light) already fully predicts that the US will come, nothing will be learned about a second CS (here the tone) that accompanies the first CS. Blocking is an outcome of other models that also base learning on the difference between what is predicted and what actually happens.",
            "score": 52.11382818222046
        },
        {
            "docid": "10790596_8",
            "document": "William Kaye Estes . Estes proposed a model of learning that he called Stimulus Sampling Theory (SST). SST is a probabilistic model that provides a statistical explanation of how we learn a stimulus-response association in a single trial, but require more stimulus-response repetitions to build an evident unit of learning. Stimulus-sampling models aid at least two functions. One is to make experimental predictions for situations in which the stimulus elements are controlled, in part at least, by the experimenter. The stimulus-sampling theory also aids as a heuristic device for discovering effective truisms about changes in response probabilities. The general theory of stimulus-sampling assumes the existence of a population of discrete stimulus elements and hypothesizes that an entity draws a sample from this population on each trial of a learning experiment. All stimulus-response theories have stimuli that are \"connected\" or \"conditioned\" to possible responses of the entity. A natural extension of SST theory provides explanations of discrimination, generalization, temporal processes, and even motivational phenomena.",
            "score": 58.76134717464447
        },
        {
            "docid": "11233144_3",
            "document": "Read Montague . Montague\u2019s work has long focused on computational neuroscience \u2013 the connection between physical mechanisms present in real neural tissue and the computational functions that these mechanisms embody. His early theoretical work focused on the hypothesis that dopaminergic systems encode a particular kind of computational process, a reward prediction error signal, similar to those used in areas of artificial intelligence like optimal control. This work, carried out in collaboration with Peter Dayan and Terry Sejnowski, focused on prediction as a guiding concept in terms of synaptic learning rules that would underlie learning, valuation, and choice. This work proposed a modification to the then dominant idea of Hebbian or correlational learning. In particular, it was shown that dopamine neurons and homologous octopaminergic neurons in bees display a reward prediction error signal exactly consonant with the temporal difference error signal familiar from models of conditioning proposed by Sutton and Barto during the 1980s.",
            "score": 57.71253728866577
        },
        {
            "docid": "2843988_27",
            "document": "Motor control . Forward models are a predictive internal model of motor control that takes the available perceptual information, combined with a particular motor program, and tries to predict the outcome of the planned motor movement. Forward models structure action by determining how the forces, velocities, and positions of motor components affect changes in the environment and in the individual. It is proposed that forward models help with the Neural control of limb stiffness when individuals interact with their environment. Forward models are thought to use motor programs as input to predict the outcome of an action. An error signal is generated when the predictions made by a forward model do not match the actual outcome of the movement, prompting an update of an existing model and providing a mechanism for learning. These models explain why it is impossible to tickle yourself. A sensation is experienced as ticklish when it is unpredictable. However, forward models predict the outcome of your motor movements, meaning the motion is predictable, and therefore not ticklish.",
            "score": 56.34974813461304
        },
        {
            "docid": "188540_37",
            "document": "Classical conditioning . In this model the degree of learning is measured by how well the CS predicts the US, which is given by the \"associative strength\" of the CS. In the equation, V represents the current associative strength of the CS, and \u2206V is the change in this strength that happens on a given trial. \u03a3V is the sum of the strengths of all stimuli present in the situation. \u03bb is the maximum associative strength that a given US will support; its value is usually set to 1 on trials when the US is present, and 0 when the US is absent. \u03b1 and \u03b2 are constants related to the salience of the CS and the speed of learning for a given US. How the equation predicts various experimental results is explained in following sections. For further details, see the main article on the model.",
            "score": 52.118465423583984
        },
        {
            "docid": "25225295_12",
            "document": "Consumer neuroscience . Brand loyalty has been shown to be the result of changes in neural activity in the striatum, which is part of the human action reward system. In order to become brand loyal the brain must make a decision of brand A over brand B, a process which relies on the brain to make predictions based upon expected reward and then evaluate the results to learn loyalty. The brain is required to remember both positive and negative outcomes of previous brand choices in order to accurately be able to make predictions regarding the expected outcome of future brand decisions. For example, a helpful salesman or a discount in price may serve as a reward to encourage future customer loyalty. It is thought that the amygdala and striatum are the two most prominent structures for predicting the outcomes of decisions, and that the brain learns to better predict in part by establishing a larger neural network in these structures.",
            "score": 44.98147702217102
        },
        {
            "docid": "188540_40",
            "document": "Classical conditioning . The most important and novel contribution of the R\u2013W model is its assumption that the conditioning of a CS depends not just on that CS alone, and its relationship to the US, but also on all other stimuli present in the conditioning situation. In particular, the model states that the US is predicted by the sum of the associative strengths of all stimuli present in the conditioning situation. Learning is controlled by the difference between this total associative strength and the strength supported by the US. When this sum of strengths reaches a maximum set by the US, conditioning ends as just described.",
            "score": 48.120620250701904
        },
        {
            "docid": "32107929_3",
            "document": "Mark A. Gluck . Gluck attended Harvard University as an undergraduate pursuing majors in both Psychology and Computer Science. During these years, Gluck worked under the supervision of William Kaye Estes on connectionist models of basic levels in category hierarchies. After graduating from Harvard University, Gluck pursued a Ph.D. degree at Stanford University in Cognitive Psychology, under Gordon H. Bower's tutelage. His dissertation focused on using network models to seek a rapprochement between theories of animal and human learning. It also included several experimental studies of human learning that validated predictions of the probabilistic category learning model that Gluck and Bower designed, and which was based on a generalization of the Rescorla\u2013Wagner model of Pavlovian conditioning. While at Stanford University and through his postdoctoral training he also worked with Richard F. Thompson on computational models of the neural bases of Pavlovian conditioning.",
            "score": 77.50741422176361
        },
        {
            "docid": "48514357_22",
            "document": "Urban traffic modeling and analysis . Newer methodologies taking into account data relational structure, forecast traffic density in time relying on linked data from multiple spatial positions at different moments in time, event future already predicted data. Studies using data relational structures have mainly used STARIMA models (space-time ARIMA), Kalman filters and Structural Time Series model. The use of a Statistical Relational Learning (SRL) framework is very effective to improve predictive accuracy of relational structured data. Statistical Relational Learning matches very well this field of research by its ability to describe dependencies and relations and include background knowledge in the model, as in a transportation network. Models generated with a Statistical Relational Learning method can represent a wide set of location thanks to its ability to perform concurrent grouping and regressions on its multiple sources and information levels. This makes it possible to such model to predict traffic conditions out of a network in a single interference process.",
            "score": 65.44408822059631
        },
        {
            "docid": "188540_41",
            "document": "Classical conditioning . The R\u2013W explanation of the blocking phenomenon illustrates one consequence of the assumption just stated. In blocking (see \"phenomena\" above), CS1 is paired with a US until conditioning is complete. Then on additional conditioning trials a second stimulus (CS2) appears together with CS1, and both are followed by the US. Finally CS2 is tested and shown to produce no response because learning about CS2 was \u201cblocked\u201d by the initial learning about CS1. The R\u2013W model explains this by saying that after the initial conditioning, CS1 fully predicts the US. Since there is no difference between what is predicted and what happens, no new learning happens on the additional trials with CS1+CS2, hence CS2 later yields no response.",
            "score": 47.22845911979675
        },
        {
            "docid": "11360852_2",
            "document": "Predictive state representation . In computer science, a predictive state representation (PSR) is a way to model a state of controlled dynamical system from a history of actions taken and resulting observations. PSR captures the state of a system as a vector of predictions for future tests (experiments) that can be done on the system. A test is a sequence of action-observation pairs and its prediction is the probability of the test's observation-sequence happening if the test's action-sequence were to be executed on the system. One of the advantage of using PSR is that the predictions are directly related to observable quantities. This is in contrast to other models of dynamical systems, such as partially observable Markov decision processes (POMDPs) where the state of the system is represented as a probability distribution over unobserved nominal states.",
            "score": 49.7751362323761
        },
        {
            "docid": "47411653_2",
            "document": "Brain Emotional Learning Inspired Models . Brain Emotional Learning-inspired Models or BELiMs can be considered as a primary step to take inspiration from emotional systems to form new computational Intelligence (CI) models. BELIMs have been inspired by fear conditioning that is one of the emotional systems in mammalians and is a mechanism by which a biological system learns how to predict aversive events.",
            "score": 71.233567237854
        },
        {
            "docid": "33932515_11",
            "document": "Social cue . Cognitive learning models illustrate how people connect cues with certain outcomes or responses. Learning can strengthen associations between predictive cues and outcomes and weaken the link between nondescriptive cues and outcomes. Two aspects of the EXIT model learning phenomena have been focused on by Collins et al. The first is blocking which happens when a new cue is introduced with a cue that already has meaning. The second is highlighting which happens when an individual pays close attention to a cue that will change the meaning of a cue that they already know. When a new cue is added along with a previous one it is said that individuals only focus on the new cue to gain a better understanding as to what is going on.",
            "score": 57.8631317615509
        },
        {
            "docid": "6352447_12",
            "document": "Artificial grammar learning . The mechanism behind the implicit learning that is hypothesized to occur while people engage in artificial grammar learning is statistical learning or, more specifically, Bayesian learning. Bayesian learning takes into account types of biases or \"prior probability distributions\" individuals have that contribute to the outcome of implicit learning tasks. These biases can be thought of as a probability distribution that contains the probability that each possible hypothesis is likely to be correct. Due to the structure of the Bayesian model, the inferences output by the model are in the form of a probability distribution rather than a single most probable event. This output distribution is a \"posterior probability distribution\". The posterior probability of each hypothesis in the original distribution is the probability of the hypothesis being true given the data and the probability of data given the hypothesis is true. This Bayesian model for learning is fundamental for understanding the pattern detection process involved in implicit learning and, therefore, the mechanisms that underlie the acquisition of artificial grammar learning rules. It is hypothesized that the implicit learning of grammar involves predicting co-occurrences of certain words in a certain order. For example, \"the dog chased the ball\" is a sentence that can be learned as grammatically correct on an implicit level due to the high co-occurrence of \"chase\" being one of the words to follow \"dog\". A sentence like \"the dog cat the ball\" is implicitly recognized as grammatically incorrect due to the lack of utterances that contain those words paired in that specific order. This process is important for teasing apart thematic roles and parts of speech in grammatical processing (see grammar). While the labeling of the thematic roles and parts of speech is explicit, the identification of words and parts of speech is implicit.",
            "score": 50.2933886051178
        },
        {
            "docid": "188540_38",
            "document": "Classical conditioning . The R\u2013W model measures conditioning by assigning an \"associative strength\" to the CS and other local stimuli. Before a CS is conditioned it has an associative strength of zero. Pairing the CS and the US causes a gradual increase in the associative strength of the CS. This increase is determined by the nature of the US (e.g. its intensity). The amount of learning that happens during any single CS-US pairing depends on the difference between the total associative strengths of CS and other stimuli present in the situation (\u03a3V in the equation), and a maximum set by the US (\u03bb in the equation). On the first pairing of the CS and US, this difference is large and the associative strength of the CS takes a big step up. As CS-US pairings accumulate, the US becomes more predictable, and the increase in associative strength on each trial becomes smaller and smaller. Finally the difference between the associative strength of the CS (plus any that may accrue to other stimuli) and the maximum strength reaches zero. That is, the US is fully predicted, the associative strength of the CS stops growing, and conditioning is complete.",
            "score": 43.405041456222534
        },
        {
            "docid": "188540_39",
            "document": "Classical conditioning . The associative process described by the R\u2013W model also accounts for extinction (see \"procedures\" above). The extinction procedure starts with a positive associative strength of the CS, which means that the CS predicts that the US will occur. On an extinction trial the US fails to occur after the CS. As a result of this \u201csurprising\u201d outcome, the associative strength of the CS takes a step down. Extinction is complete when the strength of the CS reaches zero; no US is predicted, and no US occurs. However, if that same CS is presented without the US but accompanied by a well-established conditioned inhibitor (CI), that is, a stimulus that predicts the absence of a US (in R-W terms, a stimulus with a negative associate strength) then R-W predicts that the CS will not undergo extinction (its V will not decrease in size).",
            "score": 42.40262842178345
        },
        {
            "docid": "2538775_26",
            "document": "Predictive modelling . Predictive modeling in trading is a modeling process wherein we predict the probability of an outcome using a set of predictor variables. Predictive models can be built for different assets like stocks, futures, currencies, commodities etc. Predictive modeling is still extensively used by trading firms to devise strategies and trade. It utilizes mathematically advanced software to evaluate indicators on price, volume, open interest and other historical data, to discover repeatable patterns.",
            "score": 57.62634825706482
        },
        {
            "docid": "65753_6",
            "document": "Rational expectations . Rational expectations theory defines this kind of expectations as being the \"best guess of the future\" (the optimal forecast) that uses all available information. Thus, it is assumed that outcomes that are being forecast do not differ systematically from the market equilibrium results. As a result, rational expectations do not differ systematically or predictably from equilibrium results. That is, it assumes that people do not make systematic errors when predicting the future, and deviations from \"perfect foresight\" are only random. In an economic model, this is typically modelled by assuming that the expected value of a variable is equal to the expected value predicted by the model.",
            "score": 37.54893732070923
        },
        {
            "docid": "30784948_6",
            "document": "Feedforward, Behavioral and Cognitive Science . The evidence for ultra-rapid learning, built from component behaviors that are reconfigured to appear as new skills, indicates the feedforward self model mechanism existing in the brain to control our future behavior. That is, if the conditions of learning are right, the brain takes pieces of existing skills, puts them together in new ways or in a different context, to produce a future image and a future response. Thus we learn from the future \u2013 more rapidly than we learn from the past. Further evidence comes from cognitive processes dubbed \"mental time travel\" and for parts of the hippocampus etc. where they occur. However, the links between these hot spots in the brain and feedforward learning have yet to be confirmed.",
            "score": 41.04301714897156
        },
        {
            "docid": "41057937_5",
            "document": "Helen Cassaday . Her research group investigates the underlying biology of associative learning processes, fundamental to normal cognition, in laboratory rats and mice. The animal learning theories can also be applied to our understanding of age-related cognitive decline, as well as to human diseases in which associative processes are disordered. When there is a time gap between events, we are less able to make a connection between them in learning and later memory. Thus it is harder to keep track of things that could in fact be causally related, in order - for example - to know that even distant engine noise can predict a future hazard or to anticipate dinner based on the smell of raw ingredients. The ability successfully to bridge a time gap between events is known to deteriorate with age in humans and other animals. This line of work (funded by the BBSRC) aims to identify the neural substrates of trace conditioning, and to compare these with those of delay-dependent forgetting measured in other procedures.",
            "score": 48.91044235229492
        },
        {
            "docid": "4316253_8",
            "document": "Robert A. Rescorla . In 1972, Robert A. Rescorla and his colleague, Allan R. Wagner, created the Rescorla\u2013Wagner model. This models classical conditioning. It is unique because it explains how the unexpected can influence learning. The model shows how the element of surprise can progress learning in an animal. Learning is subjective to how surprising the unconditioned stimulus (US) is. The surprise (US) that follows the conditioned stimulus (CS) in the initial trial was learned because it is unexpected, or very surprising. However, in the following trials, the subject learns less because the US is predictable - or less surprising",
            "score": 52.794535398483276
        },
        {
            "docid": "57091071_9",
            "document": "Intuitive statistics . Bayesian models have been quite popular among psychologists, particularly learning theorists, because they appear to emulate the iterative, predictive process by which people learn and develop expectations from new observations, while giving appropriate weight to previous observations. Andy Clark, a cognitive scientist and philosopher, recently wrote a detailed argument in support of understanding the brain as a constructive Bayesian engine that is fundamentally action-oriented and predictive, rather than passive or reactive. More classic lines of evidence cited among supporters of Bayesian inference include conservatism, or the phenomenon where people modify previous beliefs \"toward\", but not all the way to, a conclusion implied by previous observations. This pattern of behavior is similar to the pattern of posterior probability distributions when a Bayesian model is conditioned on data, though critics argued that this evidence had been overstated and lacked mathematical rigor.",
            "score": 53.22992551326752
        },
        {
            "docid": "3064522_17",
            "document": "Predictive maintenance . The use of Model Based Condition Monitoring for predictive maintenance programs is becoming increasingly popular over time. This method involves spectral analysis on the motor\u2019s current and voltage signals and then compares the measured parameters to a known and learned model of the motor to diagnose various electrical and mechanical anomalies. This process of \"model based\" condition monitoring was originally designed and used on NASA\u2019s space shuttle to monitor and detect developing faults in the space shuttle\u2019s main engine. It allows for the automation of data collection and analysis tasks, providing round the clock condition monitoring and warnings about faults as they develop.",
            "score": 54.59656596183777
        },
        {
            "docid": "14758355_4",
            "document": "Multinomial probit . The multinomial probit model is a statistical model that can be used to predict the likely outcome of an unobserved multi-way trial given the associated explanatory variables. In the process, the model attempts to explain the relative effect of differing explanatory variables on the different outcomes.",
            "score": 40.67126107215881
        },
        {
            "docid": "579390_17",
            "document": "Gene prediction . Advanced gene finders for both prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as hidden Markov models (HMMs) to combine information from a variety of different signal and content measurements. The GLIMMER system is a widely used and highly accurate gene finder for prokaryotes. GeneMark is another popular approach. Eukaryotic \"ab initio\" gene finders, by comparison, have achieved only limited success; notable examples are the GENSCAN and geneid programs. The SNAP gene finder is HMM-based like Genscan, and attempts to be more adaptable to different organisms, addressing problems related to using a gene finder on a genome sequence that it was not trained against. A few recent approaches like mSplicer, CONTRAST, or mGene also use machine learning techniques like support vector machines for successful gene prediction. They build a discriminative model using hidden Markov support vector machines or conditional random fields to learn an accurate gene prediction scoring function.",
            "score": 55.5979528427124
        },
        {
            "docid": "45329906_21",
            "document": "Solvent models . Quantitative Structure\u2013Activity Relationships (QSAR)/Quantitative Structure\u2013Property Relationships (QSPR), whilst unable to directly model the physical process occurring in a condensed solvent phase, can provide useful predictions of solvent and solvation properties and activities; such as the solubility of a solute. These methods come in a varied way from simple regression models to sophisticated machine learning methods. Generally, QSAR/QSPR methods require descriptors; these come in many different forms and are used to represent physical features and properties of a system of interest. Descriptors are generally single numerical values which hold some information about a physical property. A regression model or statistical learning model is then applied to find a correlation between the descriptor(s) and the property of interest. Once trained on some known data these model can be applied to similar unknown data to make predictions. Typically the known data comes from experimental measurement, although there is no reason why similar methods can not be used to correlate descriptor(s) with theoretical or predicted values. It is currently debated whether if more accurate experimental data was used to train these models whether the prediction from such models would be more accurate.",
            "score": 60.86208748817444
        },
        {
            "docid": "27260435_5",
            "document": "Structured prediction . Similar to commonly used supervised learning techniques, structured prediction models are typically trained by means of observed data in which the true prediction value is used to adjust model parameters. Due to the complexity of the model and the interrelations of predicted variables the process of prediction using a trained model and of training itself is often computationally infeasible and approximate inference and learning methods are used.",
            "score": 60.5366485118866
        }
    ],
    "r": [
        {
            "docid": "32107929_3",
            "document": "Mark A. Gluck . Gluck attended Harvard University as an undergraduate pursuing majors in both Psychology and Computer Science. During these years, Gluck worked under the supervision of William Kaye Estes on connectionist models of basic levels in category hierarchies. After graduating from Harvard University, Gluck pursued a Ph.D. degree at Stanford University in Cognitive Psychology, under Gordon H. Bower's tutelage. His dissertation focused on using network models to seek a rapprochement between theories of animal and human learning. It also included several experimental studies of human learning that validated predictions of the probabilistic category learning model that Gluck and Bower designed, and which was based on a generalization of the Rescorla\u2013Wagner model of Pavlovian conditioning. While at Stanford University and through his postdoctoral training he also worked with Richard F. Thompson on computational models of the neural bases of Pavlovian conditioning.",
            "score": 77.50741577148438
        },
        {
            "docid": "188540_48",
            "document": "Classical conditioning . An organism's need to predict future events is central to modern theories of conditioning. Most theories use associations between stimuli to take care of these predictions. For example: In the R\u2013W model, the associative strength of a CS tells us how strongly that CS predicts a US. A different approach to prediction is suggested by models such as that proposed by Gallistel & Gibbon (2000, 2002). Here the response is not determined by associative strengths. Instead, the organism records the times of onset and offset of CSs and USs and uses these to calculate the probability that the US will follow the CS. A number of experiments have shown that humans and animals can learn to time events (see Animal cognition), and the Gallistel & Gibbon model yields very good quantitative fits to a variety of experimental data. However, recent studies have suggested that duration-based models cannot account for some empirical findings as well as associative models.",
            "score": 71.6328125
        },
        {
            "docid": "47411653_2",
            "document": "Brain Emotional Learning Inspired Models . Brain Emotional Learning-inspired Models or BELiMs can be considered as a primary step to take inspiration from emotional systems to form new computational Intelligence (CI) models. BELIMs have been inspired by fear conditioning that is one of the emotional systems in mammalians and is a mechanism by which a biological system learns how to predict aversive events.",
            "score": 71.23356628417969
        },
        {
            "docid": "48972018_8",
            "document": "Hilary Mason (data scientist) . Fast Forward Labs\u2019 most recent report discusses refractors, which predict churn probabilities for telecom customers, probabilistic programming language, which makes Bayesian inference accessible by quantifying uncertainty through the use of data and domain knowledge and loan office simulators which uses metrics to generate probabilistic models of loan repayments to assist in decision making regarding loan approvals. They also offered advice on probabilistic real estate, which predicts house pricing across all the New York City boroughs and how deep learning can help computers learn identification of new objects in images.",
            "score": 67.99623107910156
        },
        {
            "docid": "20765789_7",
            "document": "Competition model . The competition model suggests that people interpret the meaning of a sentence by taking into account various linguistic cues contained in the sentence context ('cotext'), such as word order, morphology, and semantic characteristics (e.g., animacy), to compute a probabilistic value for each interpretation, eventually choosing the interpretation with the highest likelihood. According to the model, cue weights are learned inductively on the basis of a 'constrained set of sentence types' and 'limited predictions of sentence meaning' for each language.",
            "score": 66.30181121826172
        },
        {
            "docid": "24328441_6",
            "document": "Associative sequence learning . A further defining characteristic of the ASL model is its claim that the development of sensorimotor links is mediated by the same mechanisms of associative learning that produce Pavlovian conditioning. Crucially, Heyes therefore proposes that the development of sensorimotor associations is not only sensitive to temporal contiguity (the extent to which activation of sensory and motor representations are close together in time) but also to contingency (the extent to which activation of one representation is predictive of the other). This is a crucial feature of the ASL model as it explains why actors do not acquire spurious sensorimotor associations. Consider the example of two interactants, one of whom is scratching his ear when his colleague sneezes. Learning-based models which do not stipulate a sensitivity to contingency predict that the motor plan for ear-scratching ought to become associated with the visual representation of sneezing! However, ASL predicts that no association will develop because the act of ear-scratching is not predictive of the sight of sneezing \u2013 in other words there is no sensorimotor \"contingency\". The Hebbian learning account of the emergence of mirror neurons also emphasizes the importance of contingency, as it is known that the synaptic plasticity that underlies Hebbian learning is known to depend on contingency.",
            "score": 65.99217224121094
        },
        {
            "docid": "48514357_22",
            "document": "Urban traffic modeling and analysis . Newer methodologies taking into account data relational structure, forecast traffic density in time relying on linked data from multiple spatial positions at different moments in time, event future already predicted data. Studies using data relational structures have mainly used STARIMA models (space-time ARIMA), Kalman filters and Structural Time Series model. The use of a Statistical Relational Learning (SRL) framework is very effective to improve predictive accuracy of relational structured data. Statistical Relational Learning matches very well this field of research by its ability to describe dependencies and relations and include background knowledge in the model, as in a transportation network. Models generated with a Statistical Relational Learning method can represent a wide set of location thanks to its ability to perform concurrent grouping and regressions on its multiple sources and information levels. This makes it possible to such model to predict traffic conditions out of a network in a single interference process.",
            "score": 65.444091796875
        },
        {
            "docid": "21167712_2",
            "document": "Comparator hypothesis . The comparator hypothesis is a psychological model of associative learning and performance. To understand the model, it helps to consider how associative learning is usually studied. For example, to study the learning of an association between cues, such as lights and sounds, and an outcome such as food, an experimenter typically pairs the cues and the food a number of times (the learning phase) and then tests with one or more of the cues to see if a response has been learned (the test phase). Most theories of associative learning have assumed that phenomena of interest (see Classical conditioning for a list of phenomena) depend on what happens during the learning phase. The comparator hypothesis assumes, on the contrary, that what happens during the learning phase is fairly simple, and that most interesting phenomena depend on what happens during the test phase. The comparator hypothesis arose primarily in response to so-called \u201ccue competition\u201d effects. If for example in classical conditioning, two conditioned stimuli A and B are presented with an unconditioned stimulus, one may find on test that the subject responds to A or to B or to both or not very much to either. How can one account for such varied results?  First proposed by Ralph Miller' the comparator hypothesis is a model of Pavlovian associations which posits that cue competition effects arise at the time of test, that is during \"performance\", not during learning. The model assumes, essentially, that during conditioning the subject acquires both CS-US and context-US associations. At the time of the test, the associations are compared, and a response to a CS occurs only if the CS-US association is stronger than the context-US association. The model was initially proposed to account for unexplained variations in cue competition effects such as recovery from blocking, but has been expanded to apply more broadly to learning phenomena. The success of the hypothesis has led to modifications in existing theories, such as Wagner's SOP and the Rescorla-Wagner model, enabling them to explain such phenomena as retrospective reevaluation, but other phenomena such as counteraction still pose difficulties for most models.",
            "score": 65.06431579589844
        },
        {
            "docid": "40841348_11",
            "document": "Computational and Statistical Genetics . In this era of large amount of genetic and genomic data, accurate representation and identification of statistical interactions in biological/genetic/genomic data constitutes a vital basis for designing interventions and curative solutions for many complex diseases. Variations in human genome have been long known to make us susceptible to many diseases. We are hurtling towards the era of personal genomics and personalized medicine that require accurate predictions of disease risk posed by predisposing genetic factors. Computational and statistical methods for identifying these genetic variations, and building these into intelligent models for diseaseassociation and interaction analysis studies genome-wide are a dire necessity across many disease areas. The principal challenges are: (1) most complex diseases involve small or weak contributions from multiple genetic factors that explain only a minuscule fraction of the population variation attributed to genetic factors. (2) Biological data is inherently extremely noisy, so the underlying complexities of biological systems (such as linkage disequilibrium and genetic heterogeneity) need to be incorporated into the statistical models for disease association studies. The chances of developing many common diseases such as cancer, autoimmune diseases and cardiovascular diseases involves complex interactions between multiple genes and several endogenous and exogenous environmental agents or covariates. Many previous disease association studies could not produce significant results because of the lack of incorporation of statistical interactions in their mathematical models explaining the disease outcome. Consequently much of the genetic risks underlying several diseases and disorders remain unknown. Computational methods such as to model and identify the genetic/genomic variations underlying disease risks has a great potential to improve prediction of disease outcomes, understand the interactions and design better therapeutic methods based on them.",
            "score": 64.88133239746094
        },
        {
            "docid": "57091071_4",
            "document": "Intuitive statistics . Intuitive inferences can involve generating hypotheses from incoming sense data, such as categorization and concept structuring. Data are typically probabilistic and uncertainty is the rule, rather than the exception, in learning, perception, language, and thought. Recently, researchers have drawn from ideas in probability theory, philosophy of mind, computer science, and psychology to model cognition as a predictive and generative system of probabilistic representations, allowing information structures to support multiple inferences in a variety of contexts and combinations. This approach has been called a probabilistic language of thought because it constructs representations probabilistically, from pre-existing concepts to predict a possible and likely state of the world.",
            "score": 64.42467498779297
        },
        {
            "docid": "1221571_2",
            "document": "Rescorla\u2013Wagner model . The Rescorla\u2013Wagner model (\"R-W\") is a model of classical conditioning, in which learning is conceptualized in terms of associations between conditioned (CS) and unconditioned (US) stimuli. A strong CS-US association means, essentially, that the CS signals or predicts the US. One might say that before conditioning, the subject is surprised by the US, but after conditioning, the subject is no longer surprised, because the CS predicts the coming of the US. The model casts the conditioning processes into discrete trials, during which stimuli may be either present or absent. The strength of prediction of the US on a trial can be represented as the summed associative strengths of all CSs present during the trial. This feature of the model represented a major advance over previous models, and it allowed a straightforward explanation of important experimental phenomena, most notably the blocking effect. Failures of the model have led to modifications, alternative models, and many additional findings. The model has had some impact on neural science in recent years, as studies have suggested that the phasic activity of dopamine neurons in mesostriatal DA projections in the midbrain encodes for the type of prediction error detailed in the model.",
            "score": 64.23526000976562
        },
        {
            "docid": "24455245_8",
            "document": "Averaged one-dependence estimators . Like naive Bayes, AODE does not perform model selection and does not use tuneable parameters. As a result, it has low variance. It supports incremental learning whereby the classifier can be updated efficiently with information from new examples as they become available. It predicts class probabilities rather than simply predicting a single class, allowing the user to determine the confidence with which each classification can be made. Its probabilistic model can directly handle situations where some data are missing.",
            "score": 63.599308013916016
        },
        {
            "docid": "27051151_69",
            "document": "Big data . Much in the same line, it has been pointed out that the decisions based on the analysis of big data are inevitably \"informed by the world as it was in the past, or, at best, as it currently is\". Fed by a large number of data on past experiences, algorithms can predict future development if the future is similar to the past. If the systems dynamics of the future change (if it is not a stationary process), the past can say little about the future. In order to make predictions in changing environments, it would be necessary to have a thorough understanding of the systems dynamic, which requires theory. As a response to this critique Alemany Oliver and Vayre suggested to use \"abductive reasoning as a first step in the research process in order to bring context to consumers\u2019 digital traces and make new theories emerge\". Additionally, it has been suggested to combine big data approaches with computer simulations, such as agent-based models and Complex Systems. Agent-based models are increasingly getting better in predicting the outcome of social complexities of even unknown future scenarios through computer simulations that are based on a collection of mutually interdependent algorithms. Finally, use of multivariate methods that probe for the latent structure of the data, such as factor analysis and cluster analysis, have proven useful as analytic approaches that go well beyond the bi-variate approaches (cross-tabs) typically employed with smaller data sets.",
            "score": 62.96533966064453
        },
        {
            "docid": "4103640_7",
            "document": "Probabilistic forecasting . If it were possible to run the model for every possible set of initial conditions, each with an associated probability, then according to how many members (i.e., individual model runs) of the ensemble predict a certain event, one could compute the actual conditional probability of the given event. In practice, forecasters try to guess a small number of perturbations (usually around 20) that they deem are most likely to yield distinct weather outcomes. Two common techniques for this purpose are breeding vectors (BV) and singular vectors (SV). This technique is not guaranteed to yield an ensemble distribution identical to the actual forecast distribution, but attaining such probabilistic information is one goal of the choice of initial perturbations. Other variants of ensemble forecasting systems that have no immediate probabilistic interpretation include those that assemble the forecasts produced by different numerical weather prediction systems.",
            "score": 62.88908767700195
        },
        {
            "docid": "47411653_3",
            "document": "Brain Emotional Learning Inspired Models . The hypothesis behind the development of BELiMs is that \"the neural structure of fear conditioning can be considered as a natural system that consists of some components (e.g., the amygdala, thalamus, and the sensory cortex) and whose functionality is fulfilled through interaction among its components. Fear conditioning as a system shows an intelligent behavior by learning how to respond to fear-induced stimuli and thus can be utilized to design new CI models for prediction and decision-making applications\"",
            "score": 62.5405387878418
        },
        {
            "docid": "480289_22",
            "document": "Collaborative filtering . In this approach, models are developed using different data mining, machine learning algorithms to predict users' rating of unrated items. There are many model-based CF algorithms. Bayesian networks, clustering models, latent semantic models such as singular value decomposition, probabilistic latent semantic analysis, multiple multiplicative factor, latent Dirichlet allocation and Markov decision process based models.",
            "score": 62.25410461425781
        },
        {
            "docid": "33429735_36",
            "document": "Software reliability testing . In the assessment and prediction of software reliability, we use the reliability growth model. During operation of the software, any data about its failure is stored in statistical form and is given as input to the reliability growth model. Using this data, the reliability growth model can evaluate the reliability of software. Lots of data about reliability growth model is available with probability models claiming to represent failure process. But there is no model which is best suited for all conditions. Therefore, we must choose a model based on the appropriate conditions.",
            "score": 62.2149772644043
        },
        {
            "docid": "39400005_21",
            "document": "Fish acute toxicity syndrome . As mentioned previously, FATS have been used to establish models that predict toxicity of chemicals. For instance, FATS data is used to develop quantitative structure-activity relationship (QSAR) models. QSAR models developed using FATS data are then used to establish computer based systems that predict toxicity. For example, Russom and colleagues used Fathead Minnow (Pimephales promelas) 96-hour acute toxicity tests data, FATS data and QSARs to create a computer based expert system that predicts chemical toxicity based on chemical structures and properties. These models and systems are useful for screening chemicals to prioritize more toxic substances for further toxicity testing. This is particularly useful for industrial chemicals with unknown toxicity. This due to the quantity of industrial chemicals with unknown toxicity, for which individual toxicity testing is not realistic. In addition, models and computer systems that predict toxicity are also cost-effective in comparison to running toxicity tests on all unknown chemicals. In conclusion, predictive screening techniques derived from FATS data are practical and cost efficient.",
            "score": 61.8250732421875
        },
        {
            "docid": "8582684_19",
            "document": "Reward system . Rewarding stimuli can drive learning in both the form of classical conditioning (Pavlovian conditioning) and operant conditioning (instrumental conditioning). In classical conditioning, a reward can act as an unconditioned stimulus that, when associated with the conditioned stimulus, causes the conditioned stimulus to elicit both musculoskeletal (in the form of simple approach and avoidance behaviors) and vegetative responses. In operant conditioning, a reward may act as a reinforcing stimulus in that it increases or supports actions that lead to itself. Learned behaviors may or may not be sensitive to the value of the outcomes they lead to; behaviors that are sensitive to the contingency of an outcome on the performance of an action as well as the outcome value are goal-directed, while elicited actions that are insensitive to contingency or value are called habits. This distinction is thought to reflected two forms of learning, model free and model based. Model free learning involves the simple caching and updating of values. In contrast, model based learning involves the storage and construction of an internal model of events that allows inference and flexible prediction. Although pavlovian conditioning is generally assumed to be model free, the incentive salience assigned to a conditioned stimulus is flexible with regard to changes in internal motivational states.",
            "score": 61.6472282409668
        },
        {
            "docid": "13772374_13",
            "document": "Renaissance Computing Institute . Many of RENCI\u2019s projects in the Environmental Sciences focus on hydrology, coastal storm surges, and advanced modeling to assist in disaster preparedness. ADCIRC is an open source software model that applies advanced analytics to multiple data sources and types (e.g., hydrology data sets, atmospheric data sets, tropical storm forecasting data, Geographic Information System data, etc.) to enable real-time, high-resolution prediction of the impact of coastal storm surges and flooding after hurricanes and related events. In collaboration with researchers at the UNC Coastal Resilience Center and the National Hurricane Center, ADCIRC is being developed as a coastal forecasting system to assist with state and federal disaster planning and decision support. EarthCube is an NSF-funded initiative that aims \u201cto develop a framework over the next decade to assist researchers in understanding and predicting the Earth system from the Sun to the center of the Earth.\u201d EarthCube is being designed as an open dynamic cyberinfrastructure to enable community-governed data sharing across the geosciences, including ocean science, polar studies, atmospheric science, geospace, computer science, and other fields. HydroShare is supported by the NSF-funded CUAHSI (Consortium of Universities for the Advancement of Hydrologic Science Inc.) and is under development as an open collaboration cyberinfrastructure for hydrology. HydroShare allows water scientists to identify and retrieve water-related data sets and associated algorithms and models and then analyze and compute on the data using a distributed computing environment that includes grid-based cloud and high-performance computing and storage capabilities",
            "score": 61.568668365478516
        },
        {
            "docid": "53587467_3",
            "document": "Outline of machine learning . Machine learning \u2013 subfield of computer science (more particularly soft computing) that evolved from the study of pattern recognition and computational learning theory in artificial intelligence. In 1959, Arthur Samuel defined machine learning as a \"Field of study that gives computers the ability to learn without being explicitly programmed\". Machine learning explores the study and construction of algorithms that can learn from and make predictions on data. Such algorithms operate by building a model from an example \"training set\" of input observations in order to make data-driven predictions or decisions expressed as outputs, rather than following strictly static program instructions.",
            "score": 61.09877395629883
        },
        {
            "docid": "31285233_13",
            "document": "Motor program . This modular system can be used to describe both motor control and motor learning and requires adaptable internal forward and inverse models. Forward models describe the forward or causal relationship between system inputs, predicting sensory feedback that will occur. Inverse models (controllers) generate the motor command that will cause a desired change in state, given an environmental context. During motor learning, the forward and inverse models are paired and tightly coupled by a responsibility signal within modules. Using the forward model\u2019s predictions and sensory contextual cues, responsibility signals indicate the degree to which each pair should be responsible for controlling current behavior.",
            "score": 61.06814193725586
        },
        {
            "docid": "45329906_21",
            "document": "Solvent models . Quantitative Structure\u2013Activity Relationships (QSAR)/Quantitative Structure\u2013Property Relationships (QSPR), whilst unable to directly model the physical process occurring in a condensed solvent phase, can provide useful predictions of solvent and solvation properties and activities; such as the solubility of a solute. These methods come in a varied way from simple regression models to sophisticated machine learning methods. Generally, QSAR/QSPR methods require descriptors; these come in many different forms and are used to represent physical features and properties of a system of interest. Descriptors are generally single numerical values which hold some information about a physical property. A regression model or statistical learning model is then applied to find a correlation between the descriptor(s) and the property of interest. Once trained on some known data these model can be applied to similar unknown data to make predictions. Typically the known data comes from experimental measurement, although there is no reason why similar methods can not be used to correlate descriptor(s) with theoretical or predicted values. It is currently debated whether if more accurate experimental data was used to train these models whether the prediction from such models would be more accurate.",
            "score": 60.86208724975586
        },
        {
            "docid": "12155912_2",
            "document": "Discriminative model . Discriminative models, also called conditional models, are a class of models used in machine learning for modeling the dependence of unobserved (target) variables formula_1 on observed variables formula_2. Within a probabilistic framework, this is done by modeling the conditional probability distribution formula_3, which can be used for predicting formula_1 from formula_2.",
            "score": 60.85163497924805
        },
        {
            "docid": "44108758_19",
            "document": "Quantum machine learning . Hidden Quantum Markov Models (HQMMs) are a quantum-enhanced version of classical Hidden Markov Models (HMMs), which are typically used to model sequential data in various fields like robotics and natural language processing. Unlike the approach taken by other quantum-enhanced machine learning algorithms, HQMMs can be viewed as models inspired by quantum mechanics that can be run on classical computers as well. Where classical HMMs use probability vectors to represent hidden 'belief' states, HQMMs use the quantum analogue: density matrices. Recent work has shown that these models can be successfully learned by maximizing the log-likelihood of the given data via classical optimization, and there is some empirical evidence that these models can better model sequential data compared to classical HMMs in practice, although further work is needed to determine exactly when and how these benefits are derived. Additionally, since classical HMMs are a particular kind of Bayes net, an exciting aspect of HQMMs is that the techniques used show how we can perform quantum-analogous Bayesian inference, which should allow for the general construction of the quantum versions of probabilistic graphical models.",
            "score": 60.81167984008789
        },
        {
            "docid": "27260435_4",
            "document": "Structured prediction . Probabilistic graphical models form a large class of structured prediction models. In particular, Bayesian networks and random fields are popularly used to solve structured prediction problems in a wide variety of application domains including bioinformatics, natural language processing, speech recognition, and computer vision. Other algorithms and models for structured prediction include inductive logic programming, case-based reasoning, structured SVMs, Markov logic networks and constrained conditional models.",
            "score": 60.7209587097168
        },
        {
            "docid": "27260435_5",
            "document": "Structured prediction . Similar to commonly used supervised learning techniques, structured prediction models are typically trained by means of observed data in which the true prediction value is used to adjust model parameters. Due to the complexity of the model and the interrelations of predicted variables the process of prediction using a trained model and of training itself is often computationally infeasible and approximate inference and learning methods are used.",
            "score": 60.53664779663086
        },
        {
            "docid": "33882236_6",
            "document": "Adaptive collaborative control . Adaptive collaborative control is most accurately modeled as a closed loop feedback control system. Closed loop feedback control describes the event where the outputs of a system from an input are used to influence the present or future behavior of the system. The feedback control model is governed by a set of equations that are used to predict the future state of the simuland and regulate its behavior. These equations \u2013 in conjunction with principles of control theory \u2013 are used to evolve physical operations of the simuland to include, but not limited to: dialogue, path planning, motion, monitoring, and lifting objects over time. Many times, these equations are modeled as nonlinear partial differential equations over a continuous time domain.  Due to their complexity, powerful computers are necessary to implement these models. A consequence of using computers to simulate these models is that continuous systems cannot be fully calculated. Instead, numerical solutions, such as the Runge-Kutta methods, are utilized to approximate these continuous models.  These equations are initialized from the response of one or more sources and rates of changes and outputs are calculated. These rates of changes predict the states of the simuland a short time in the future. The time increment for this prediction is called a time step. These new states are applied to the model to determine the new rates of changes and observational data. This behavior is continued until the desired number of iterations is completed. In the event a future state violates or comes within a tolerance of the violation the simuland will confer with its human counterpart seeking advice on how to proceed from that point. The outputs, or observational data, are used by the human operators to determine what they believe is the best course of action for the simuland. Their commands are fed with the input into the control system and assessed regarding its effectiveness in resolving the issues. If the human commands are determined to be valuable, the simuland will adjust its control input to what the human suggested. If the human\u2019s commands are determined to be unbeneficial, malicious, or non-existent, the model will seek its own correction approach.",
            "score": 59.910400390625
        },
        {
            "docid": "54842715_43",
            "document": "Interoception . The EPIC model proposes a method of understanding the brain\u2019s response to stimuli contrary to the classic \"stimulus-response\" model. The classical view of information processing is that when a peripheral stimulus provided information to the central nervous system, it was processed in the brain, and a response was elicited. The EPIC model deviates from this and proposes that the brain is involved in a process of active inference, that is, assiduously making predictions about situations based on previous experiences. These predictions, when coupled with incoming sensory signals, allow the brain to compute a prediction error. Interoceptive prediction errors signal the occurrence of discrepancies within the body, which the brain attempts to minimize. This can be done by 1) modifying the predictions through brain-related pathways, 2) altering the body position/location in order to better align incoming sensory signals with the prediction, or 3) altering the brain\u2019s method of receiving incoming stimuli. Interoceptive prediction error signals are a key component of many theories of interoceptive dysfunction in physical and mental health.",
            "score": 59.88691711425781
        },
        {
            "docid": "65309_2",
            "document": "Support vector machine . In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.",
            "score": 59.629356384277344
        },
        {
            "docid": "1474524_2",
            "document": "Context mixing . Context mixing is a type of data compression algorithm in which the next-symbol predictions of two or more statistical models are combined to yield a prediction that is often more accurate than any of the individual predictions. For example, one simple method (not necessarily the best) is to average the probabilities assigned by each model. The random forest is another method: it outputs the prediction that is the mode of the predictions output by individual models. Combining models is an active area of research in machine learning.",
            "score": 59.15747833251953
        },
        {
            "docid": "42247256_6",
            "document": "Kernel methods for vector output . Much of the initial research in multitask learning in the machine learning community was algorithmic in nature, and applied to methods such as neural networks, decision trees and -nearest neighbors in the 1990s. The use of probabilistic models and Gaussian processes was pioneered and largely developed in the context of geostatistics, where prediction over vector-valued output data is known as cokriging. Geostatistical approaches to multivariate modeling are mostly formulated around the linear model of coregionalization (LMC), a generative approach for developing valid covariance functions that has been used for multivariate regression and in statistics for computer emulation of expensive multivariate computer codes. The regularization and kernel theory literature for vector-valued functions followed in the 2000s. While the Bayesian and regularization perspectives were developed independently, they are in fact closely related.",
            "score": 59.11283874511719
        }
    ]
}