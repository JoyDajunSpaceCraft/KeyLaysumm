{
    "q": [
        {
            "docid": "1872854_31",
            "document": "Biochemical cascade . In the post-genomic age, high-throughput sequencing and gene/protein profiling techniques have transformed biological research by enabling comprehensive monitoring of a biological system, yielding a list of differentially expressed genes or proteins, which is useful in identifying genes that may have roles in a given phenomenon or phenotype. With DNA microarrays and genome-wide gene engineering, it is possible to screen global gene expression profiles to contribute a wealth of genomic data to the public domain. With RNA interference, it is possible to distill the inferences contained in the experimental literature and primary databases into knowledge bases that consist of annotated representations of biological pathways. In this case, individual genes and proteins are known to be involved in biological processes, components, or structures, as well as how and where gene products interact with each other. Pathway-oriented approaches for analyzing microarray data, by grouping long lists of individual genes, proteins, and/or other biological molecules according to the pathways they are involved in into smaller sets of related genes or proteins, which reduces the complexity, have proven useful for connecting genomic data to specific biological processes and systems. Identifying active pathways that differ between two conditions can have more explanatory power than a simple list of different genes or proteins. In addition, a large number of pathway analytic methods exploit pathway knowledge in public repositories such as Gene Ontology (GO) or Kyoto Encyclopedia of Genes and Genomes (KEGG), rather than inferring pathways from molecular measurements. Furthermore, different research focuses have given the word \"pathway\" different meanings. For example, 'pathway' can denote a metabolic pathway involving a sequence of enzyme-catalyzed reactions of small molecules, or a signaling pathway involving a set of protein phosphorylation reactions and gene regulation events. Therefore, the term \"pathway analysis\" has a very broad application. For instance, it can refer to the analysis physical interaction networks (e.g., protein\u2013protein interactions), kinetic simulation of pathways, and steady-state pathway analysis (e.g., flux-balance analysis), as well as its usage in the inference of pathways from expression and sequence data. Several functional enrichment analysis tools and algorithms have been developed to enhance data interpretation. The existing knowledge base\u2013driven pathway analysis methods in each generation have been summarized in recent literature.",
            "score": 62.56374931335449
        },
        {
            "docid": "5824073_12",
            "document": "High-content screening . This technology allows a (very) large number of experiments to be performed, allowing explorative screening. Cell-based systems are mainly used in chemical genetics where large, diverse small molecule collections are systematically tested for their effect on cellular model systems. Novel drugs can be found using screens of tens of thousands of molecules, and these have promise for the future of drug development.  Beyond drug discovery, chemical genetics is aimed at functionalizing the genome by identifying small molecules that acts on most of the 21,000 gene products in a cell. High-content technology will be part of this effort which could provide useful tools for learning where and when proteins act by knocking them out chemically. This would be most useful for gene where knock out mice (missing one or several genes) can not be made because the protein is required for development, growth or otherwise lethal when it is not there. Chemical knock out could address how and where these genes work. Further the technology is used in combination with RNAi to identify sets of genes involved in specific mechanisms, for example cell division. Here, libraries of RNAis, covering a whole set of predicted genes inside the target organism's genome can be used to identify relevant subsets, facilitating the annotation of genes for which no clear role has been established beforehand. The large datasets produced by automated cell biology contain spatially resolved, quantitative data which can be used for building for systems level models and simulations of how cells and organisms function. Systems biology models of cell function would permit prediction of why, where and how the cell responds to external changes, growth and disease.",
            "score": 61.217156171798706
        },
        {
            "docid": "3259720_7",
            "document": "Multifactor dimensionality reduction . As illustrated above, the basic constructive induction algorithm in MDR is very simple. However, its implementation for mining patterns from real data can be computationally complex. As with any machine learning algorithm there is always concern about overfitting. That is, machine learning algorithms are good at finding patterns in completely random data. It is often difficult to determine whether a reported pattern is an important signal or just chance. One approach is to estimate the generalizability of a model to independent datasets using methods such as cross-validation. Models that describe random data typically don't generalize. Another approach is to generate many random permutations of the data to see what the data mining algorithm finds when given the chance to overfit. Permutation testing makes it possible to generate an empirical p-value for the result. Replication in independent data may also provide evidence for an MDR model but can be sensitive to difference in the data sets. These approaches have all been shown to be useful for choosing and evaluating MDR models. An important step in an machine learning exercise is interpretation. Several approaches have been used with MDR including entropy analysis and pathway analysis. Tips and approaches for using MDR to model gene-gene interactions have been reviewed.",
            "score": 51.40045177936554
        },
        {
            "docid": "356382_31",
            "document": "Gene regulatory network . Other work has focused on predicting the gene expression levels in a gene regulatory network. The approaches used to model gene regulatory networks have been constrained to be interpretable and, as a result, are generally simplified versions of the network. For example, Boolean networks have been used due to their simplicity and ability to handle noisy data but lose data information by having a binary representation of the genes. Also, artificial neural networks omit using a hidden layer so that they can be interpreted, losing the ability to model higher order correlations in the data. Using a model that is not constrained to be interpretable, a more accurate model can be produced. Being able to predict gene expressions more accurately provides a way to explore how drugs affect a system of genes as well as for finding which genes are interrelated in a process. This has been encouraged by the DREAM competition which promotes a competition for the best prediction algorithms. Some other recent work has used artificial neural networks with a hidden layer.",
            "score": 75.44737410545349
        },
        {
            "docid": "215038_12",
            "document": "Enhancer (genetics) . The development of genomic and epigenomic technologies, however, has dramatically changed the outlook for cis-regulatory modules (CRM) discovery. Next-generation sequencing (NGS) methods now enable high-throughput functional CRM discovery assays, and the vastly increasing amounts of available data, including large-scale libraries of transcription factor-binding site (TFBS) motifs, collections of annotated, validated CRMs, and extensive epigenetic data across many cell types, are making accurate computational CRM discovery an attainable goal. An example of NGS-based approach called DNase-seq have enabled identification of nucleosome-depleted, or open chromatin regions, which can contain CRM. Computational methods include comparative genomics, clustering of known or predicted TF-binding sites, and supervised machine-learning approaches trained on known CRMs.  All of these methods have proven effective for CRM discovery, but each has its own considerations and limitations, and each is subject to a greater or lesser number of false-positive identifications. In the comparative genomics approach, sequence conservation of non-coding regions can be indicative of enhancers. Sequences from multiple species are aligned, and conserved regions are identified computationally. Identified sequences can then be attached to a reporter gene such as green fluorescent protein or lacZ to determine the \"in vivo\" pattern of gene expression produced by the enhancer when injected into an embryo. mRNA expression of the reporter can be visualized by \"in situ\" hybridization, which provides a more direct measure of enhancer activity, since it is not subjected to the complexities of translation and protein folding. Although much evidence has pointed to sequence conservation for critical developmental enhancers, other work has shown that the function of enhancers can be conserved with little or no primary sequence conservation. For example, the \"RET\" enhancers in humans have very little sequence conservation to those in zebrafish, yet both species' sequences produce nearly identical patterns of reporter gene expression in zebrafish. Similarly, in highly diverged insects (separated by around 350 million years), similar gene expression patterns of several key genes was found to be regulated through similarly constituted CRMs although these CRMs do not show any appreciable sequence conservation detectable by standard sequence alignment methods such as BLAST.",
            "score": 60.91933727264404
        },
        {
            "docid": "21731590_16",
            "document": "RNA-Seq . Coexpression networks are data-derived representations of genes behaving in a similar way across tissues and experimental conditions. Their main purpose lies in hypothesis generation and guilt-by-association approaches for inferring functions of previously unknown genes. RNASeq data has been recently used to infer genes involved in specific pathways based on Pearson correlation, both in plants and mammals. The main advantage of RNASeq data in this kind of analysis over the microarray platforms is the capability to cover the entire transcriptome, therefore allowing the possibility to unravel more complete representations of the gene regulatory networks. Differential regulation of the splice isoforms of the same gene can be detected and used to predict and their biological functions.  Weighted gene co-expression network analysis has been successfully used to identify co-expression modules and intramodular hub genes based on RNA seq data. Co-expression modules may corresponds to cell types or pathways. Highly connected intramodular hubs can be interpreted as representatives of their respective module. Variance-Stabilizing Transformation approaches for estimating correlation coefficients based on RNA seq data have been proposed.",
            "score": 61.216453313827515
        },
        {
            "docid": "315084_23",
            "document": "Lip reading . Automated lip-reading has been a topic of interest in computational engineering, as well as in . The computational engineer Steve Omohundro, among others, pioneered its development. In facial animation, the aim is to generate realistic facial actions, especially mouth movements, that simulate human speech actions. Computer algorithms to deform or manipulate images of faces can be driven by heard or written language. Systems may be based on detailed models derived from facial movements (motion capture); on anatomical modelling of actions of the jaw, mouth and tongue; or on mapping of known viseme- phoneme properties. Facial animation has been used in speechreading training (demonstrating how different sounds 'look'). These systems are a subset of speech synthesis modelling which aim to deliver reliable 'text-to-(seen)-speech' outputs. A complementary aim\u2014the reverse of making faces move in speech\u2014is to develop computer algorithms that can deliver realistic interpretations of speech (i.e. a written transcript or audio record) from natural video data of a face in action: this is facial speech recognition. These models too can be sourced from a variety of data. Automatic visual speech recognition from video has been quite successful in distinguishing different languages (from a corpus of spoken language data). Demonstration models, using machine-learning algorithms, have had some success in lipreading speech elements, such as specific words, from video and for identifying hard-to-lipread phonemes from visemically similar seen mouth actions. Machine-based speechreading is now making successful use of neural-net based algorithms which use large databases of speakers and speech material (following the successful model for auditory automatic speech recognition).",
            "score": 45.51964461803436
        },
        {
            "docid": "1181008_10",
            "document": "Computational science . Exciting new developments in biotechnology are now revolutionizing biology and biomedical research. Examples of these techniques are high-throughput sequencing, high-throughput quantitative PCR, intra-cellular imaging, in-situ hybridization of gene expression, three-dimensional imaging techniques like Light Sheet Fluorescence Microscopy and Optical Projection, (micro)-Computer Tomography. Given the massive amounts of complicated data that is generated by these techniques, their meaningful interpretation, and even their storage, form major challenges calling for new approaches. Going beyond current bioinformatics approaches, computational biology needs to develop new methods to discover meaningful patterns in these large data sets. Model-based reconstruction of gene networks can be used to organize the gene expression data in systematic way and to guide future data collection. A major challenge here is to understand how gene regulation is controlling fundamental biological processes like biomineralisation and embryogenesis. The sub-processes like gene regulation, organic molecules interacting with the mineral deposition process, cellular processes, physiology and other processes at the tissue and environmental levels are linked. Rather than being directed by a central control mechanism, biomineralisation and embryogenesis can be viewed as an emergent behavior resulting from a complex system in which several sub-processes on very different temporal and spatial scales (ranging from nanometer and nanoseconds to meters and years) are connected into a multi-scale system. One of the few available options to understand such systems is by developing a multi-scale model of the system.",
            "score": 69.9749231338501
        },
        {
            "docid": "341038_8",
            "document": "Reporter gene . Reporter genes can also be used to assay for the expression of the gene of interest, which may produce a protein that has little obvious or immediate effect on the cell culture or organism. In these cases, the reporter is directly attached to the gene of interest to create a gene fusion. The two genes are under the same promoter elements and are transcribed into a single messenger RNA molecule. The mRNA is then translated into protein. In these cases it is important that both proteins be able to properly fold into their active conformations and interact with their substrates despite being fused. In building the DNA construct, a segment of DNA coding for a flexible polypeptide linker region is usually included so that the reporter and the gene product will only minimally interfere with one another. Reporter gene assay have been increasingly used in high throughput screening (HTS) to identify small molecule inhibitors and activators of protein targets and pathways for drug discovery and chemical biology. Because the reporter enzymes themselves (e.g. firefly luciferase) can be direct targets of small molecules and confound the interpretation of HTS data, novel coincidence reporter designs incorporating artifact suppression have been developed  Reporter genes can be used to assay for the activity of a particular promoter in a cell or organism. In this case there is no separate \"gene of interest\"; the reporter gene is simply placed under the control of the target promoter and the reporter gene product's activity is quantitatively measured. The results are normally reported relative to the activity under a \"consensus\" promoter known to induce strong gene expression.",
            "score": 77.32625579833984
        },
        {
            "docid": "143533_20",
            "document": "Green fluorescent protein . The availability of GFP and its derivatives has thoroughly redefined fluorescence microscopy and the way it is used in cell biology and other biological disciplines. While most small fluorescent molecules such as FITC (fluorescein isothiocyanate) are strongly phototoxic when used in live cells, fluorescent proteins such as GFP are usually much less harmful when illuminated in living cells. This has triggered the development of highly automated live-cell fluorescence microscopy systems, which can be used to observe cells over time expressing one or more proteins tagged with fluorescent proteins. For example, GFP had been widely used in labelling the spermatozoa of various organisms for identification purposes as in \"Drosophila melanogaster\", where expression of GFP can be used as a marker for a particular characteristic. GFP can also be expressed in different structures enabling morphological distinction. In such cases, the gene for the production of GFP is incorporated into the genome of the organism in the region of the DNA that codes for the target proteins and that is controlled by the same regulatory sequence; that is, the gene's regulatory sequence now controls the production of GFP, in addition to the tagged protein(s). In cells where the gene is expressed, and the tagged proteins are produced, GFP is produced at the same time. Thus, only those cells in which the tagged gene is expressed, or the target proteins are produced, will fluoresce when observed under fluorescence microscopy. Analysis of such time lapse movies has redefined the understanding of many biological processes including protein folding, protein transport, and RNA dynamics, which in the past had been studied using fixed (i.e., dead) material. Obtained data are also used to calibrate mathematical models of intracellular systems and to estimate rates of gene expression.",
            "score": 61.87382519245148
        },
        {
            "docid": "10571004_5",
            "document": "Biological network inference . Genes are the nodes and the edges are directed. A gene serves as the source of a direct regulatory edge to a target gene by producing an RNA or protein molecule that functions as a transcriptional activator or inhibitor of the target gene. If the gene is an activator, then it is the source of a positive regulatory connection; if an inhibitor, then it is the source of a negative regulatory connection. Computational algorithms take as primary input data measurements of mRNA expression levels of the genes under consideration for inclusion in the network, returning an estimate of the network topology. Such algorithms are typically based on linearity, independence or normality assumptions, which must be verified on a case-by-case basis. Clustering or some form of statistical classification is typically employed to perform an initial organization of the high-throughput mRNA expression values derived from microarray experiments, in particular to select sets of genes as candidates for network nodes. The question then arises: how can the clustering or classification results be connected to the underlying biology? Such results can be useful for pattern classification \u2013 for example, to classify subtypes of cancer, or to predict differential responses to a drug (pharmacogenomics). But to understand the relationships between the genes, that is, to more precisely define the influence of each gene on the others, the scientist typically attempts to reconstruct the transcriptional regulatory network. This can be done by data integration in dynamic models supported by background literature, or information in public databases, combined with the clustering results. The modelling can be done by a Boolean network, by Ordinary differential equations or Linear regression models, e.g. Least-angle regression, by Bayesian network or based on Information theory approaches. For instance it can be done by the application of a correlation-based inference algorithm, as will be discussed below, an approach which is having increased success as the size of the available microarray sets keeps increasing",
            "score": 61.52132260799408
        },
        {
            "docid": "27051151_69",
            "document": "Big data . Much in the same line, it has been pointed out that the decisions based on the analysis of big data are inevitably \"informed by the world as it was in the past, or, at best, as it currently is\". Fed by a large number of data on past experiences, algorithms can predict future development if the future is similar to the past. If the systems dynamics of the future change (if it is not a stationary process), the past can say little about the future. In order to make predictions in changing environments, it would be necessary to have a thorough understanding of the systems dynamic, which requires theory. As a response to this critique Alemany Oliver and Vayre suggested to use \"abductive reasoning as a first step in the research process in order to bring context to consumers\u2019 digital traces and make new theories emerge\". Additionally, it has been suggested to combine big data approaches with computer simulations, such as agent-based models and Complex Systems. Agent-based models are increasingly getting better in predicting the outcome of social complexities of even unknown future scenarios through computer simulations that are based on a collection of mutually interdependent algorithms. Finally, use of multivariate methods that probe for the latent structure of the data, such as factor analysis and cluster analysis, have proven useful as analytic approaches that go well beyond the bi-variate approaches (cross-tabs) typically employed with smaller data sets.",
            "score": 37.78127157688141
        },
        {
            "docid": "159266_62",
            "document": "Gene expression . Gene networks can also be constructed without formulating an explicit causal model. This is often the case when assembling networks from large expression data sets. Covariation and correlation of expression is computed across a large sample of cases and measurements (often transcriptome or proteome data). The source of variation can be either experimental or natural (observational). There are several ways to construct gene expression networks, but one common approach is to compute a matrix of all pair-wise correlations of expression across conditions, time points, or individuals and convert the matrix (after thresholding at some cut-off value) into a graphical representation in which nodes represent genes, transcripts, or proteins and edges connecting these nodes represent the strength of association (see ). Weighted correlation network analysis (WGCNA) involves weighted networks defined by soft-thresholding the pairwise correlations among variables (e.g. measures of transcript abundance). WGCNA can be applied to compute eigengenes, which are highly robust biomarkers (features) useful for diagnosis and prognosis.",
            "score": 58.07574820518494
        },
        {
            "docid": "7252_33",
            "document": "Cell cycle . Analyses of synchronized cultures of \"Saccharomyces cerevisiae\" under conditions that prevent DNA replication initiation without delaying cell cycle progression showed that origin licensing decreases the expression of genes with origins near their 3' ends, revealing that downstream origins can regulate the expression of upstream genes. This confirms previous predictions from mathematical modeling of a global causal coordination between DNA replication origin activity and mRNA expression, and shows that mathematical modeling of DNA microarray data can be used to correctly predict previously unknown biological modes of regulation.",
            "score": 50.1628794670105
        },
        {
            "docid": "12781902_6",
            "document": "User modeling . Though the first method is a good way to quickly collect main data it lacks the ability to automatically adapt to shifts in users' interests. It depends on the users' readiness to give information and it is unlikely that they are going to edit their answers once the registration process is finished. Therefore, there is a high likelihood that the user models are not up to date. However, this first method allows the users to have full control over the collected data about them. It is in their decision which information they are willing to provide. This possibility is missing in the second method. Adaptive changes in a system that learns users' preferences and needs only by interpreting their behavior might appear a bit opaque to the users, because they cannot fully understand and reconstruct why the system behaves the way it does. Moreover, the system is forced to collect a certain amount of data before it is able to predict the users' needs with the required accuracy. Therefore, it takes a certain learning time before a user can benefit from adaptive changes. However, afterwards these automatically adjusted user models allow a quite accurate adaptivity of the system. The hybrid approach tries to combine the advantages of both methods. Through collecting data by directly asking its users it gathers a first stock of information which can be used for adaptive changes. By learning from the users' interactions it can adjust the user models and reach more accuracy. Yet, the designer of the system has to decide, which of these information should have which amount of influence and what to do with learned data that contradicts some of the information given by a user.",
            "score": 55.17865562438965
        },
        {
            "docid": "53576321_5",
            "document": "Single-cell transcriptomics . Recent advances in biotechnology allow the measurement of gene expression in hundreds to thousands of individual cells simultaneously. Whilst these breakthroughs in transcriptomics technologies have enabled the generation of single-cell transcriptomic data there are new computational and analytical challenges presented by the data produced. Techniques used for analysing RNA-seq data from bulk cell populations can be used for single-cell data but many new computational approaches have been designed for this data type to facilitate a complete and detailed study of single-cell expression profiles.",
            "score": 57.91999578475952
        },
        {
            "docid": "43183712_14",
            "document": "Bioluminescent bacteria . All bioluminescent bacteria share a common gene sequence: the \"lux\" operon characterized by the \"luxCDABE\" gene organization. \"LuxAB\" codes for luciferase while \"luxCDE\" codes for a fatty-acid reductase complex that is responsible for synthesizing aldehydes for the bioluminescent reaction. Despite this common gene organization, variations, such as the presence of other lux genes, can be observed among species. Based on similarities in gene content and organization, the \"lux\" operon can be organized into the following four distinct types: the \"Aliivibrio\"/\"Shewanella\" type, the \"Photobacterium\" type, the\"Vibrio\"/\"Candidatus\" Photodesmus type, and the \"Photorhabdus\" type. While this organization follows the genera classification level for members of \"Vibrionaceae\" (\"Aliivibrio\", \"Photobacterium\", and \"Vibrio\"), its evolutionary history is not known.",
            "score": 58.50900721549988
        },
        {
            "docid": "34119149_26",
            "document": "Geotechnical centrifuge modeling . Centrifuge tests can also be used to obtain experimental data to verify a design procedure or a computer model. The rapid development of computational power over recent decades has revolutionized engineering analysis. Many computer models have been developed to predict the behavior of geotechnical structures during earthquakes and other loads. Before a computer model can be used with confidence, it must be proven to be valid based on evidence. The meager and unrepeatable data provided by natural earthquakes, for example, is usually insufficient for this purpose. Verification of the validity of assumptions made by a computational algorithm is especially important in the area of geotechnical engineering due to the complexity of soil behavior. Soils exhibit highly non-linear behavior, their strength and stiffness depend on their stress history and on the water pressure in the pore fluid, all of which may evolve during the loading caused by an earthquake. The computer models which are intended to simulate these phenomena are very complex and require extensive verification. Experimental data from centrifuge tests is useful for verifying assumptions made by a computational algorithm. If the results show the computer model to be inaccurate, the centrifuge test data provides insight into the physical processes which in turn stimulates the development of better computer models.",
            "score": 44.33276832103729
        },
        {
            "docid": "57177883_3",
            "document": "DeMix . Solid tumor samples obtained from clinical practice are highly heterogeneous. They consist of multiple clonal populations of cancer cells as well as adjacent normal tissue, stromal and infiltrating immune cells. The highly heterogeneous structure of tumor tissues could complicate or bias various genomic data analysis. Removing heterogeneity is of substantial interest to isolate expression data from mixed samples \"in silico\". It is important to estimate and account for the tumor purity, or the percentage of cancer cells in the tumor sample before analyses. Owing to the marked differences between cancer and normal cells, it is possible to estimate tumor purity from high-throughput genomic or epigenomic data. DeMix is a method that has been developed to estimate the proportion and gene expression profile from cancer cells in mixed samples. In this method the mixed sample is assumed to be composed only by two cell types: cancer cells (without any a priori known gene expression profile) and normal cells (with known gene expression data, which can either come from tumor-matched or unmatched samples). This method was developed for microarray data and shows that it was important to use the raw data as input assuming it follows a log-normal distribution as is the case for microarray, instead of working with log-transformed data like most other methods did. DeMix estimates the variance of the gene expression in the normal samples and uses this in the maximum likelihood estimation to predict the cancer cell gene expression and proportions, using thus implicitly a gene-specific weight for each gene. It is the first method to follow a linear mixture of gene expression levels on data before they are log-transformed. This method analyzes data from heterogeneous tumor samples before the data are log-transformed, estimates individual level expression levels in each sample and each gene in an unmatched design.",
            "score": 58.822372794151306
        },
        {
            "docid": "46581687_3",
            "document": "Pathway analysis . The data for pathway analysis come from high throughput biology. This includes high throughput sequencing data and microarray data. Before pathway analysis can be done, the omics data should be normalized, and genes should be ranked by differential expression usually with help of Student's t-test, ANOVA or other statistics. In general, any list of statistical ranked genes can be analyzed by pathway analysis. For example, often the functional activity of proteins can be inferred using network enrichment analysis of genes deferentially expressed in the experiment. Such functional activity scores can then be used for pathway analysis to find pathways responsible for observed differential expression. In case when ranking is not available simply list of genes can be analyzed. Also it is possible to integrate multiple microarray data sets from different research groups by meta-analysis and cross-platform normalization. By using pathway analysis software, researchers can determine which gene groups such as pathways, cell processes or diseases are enriched with over and under expressed in experimental data genes. They can also infer associated upstream and downstream regulators, proteins, small molecules, drugs, etc. For example, pathway analysis of several independent microarray experiments (meta-analysis) helped to discover potential biomarkers in a single pathway important for fast-to-slow switch fiber type transition in Duchenne muscular dystrophy. In other study meta-analysis identified two biomarkers in blood of patients with Parkinson's Disease, which can be useful for monitoring the disease.",
            "score": 57.19155550003052
        },
        {
            "docid": "43183712_10",
            "document": "Bioluminescent bacteria . After the discovery of the lux operon, the use of bioluminescent bacteria as a laboratory tool is claimed to have revolutionized the area of environmental microbiology. The applications of bioluminescent bacteria include biosensors for detection of contaminants, measurement of pollutant toxicity and monitoring of genetically engineered bacteria released into the environment. Biosensors, created by placing a \"lux\" gene construct under the control of an inducible promoter, can be used to determine the concentration of specific pollutants. Biosensors are also able to distinguish between pollutants that are bioavailable and those that are inert and unavailable. For example, \"Pseudomonas fluorescens\" has been genetically engineered to be capable of degrading salicylate and naphthalene, and is used as a biosensor to assess the bioavailability of salicylate and naphthalene. Biosensors can also be used as an indicator of cellular metabolic activity and to detect the presence of pathogens.",
            "score": 74.55980014801025
        },
        {
            "docid": "18166009_14",
            "document": "Lower critical solution temperature . There are three groups of methods for correlating and predicting LCSTs. The first group proposes models that are based on a solid theoretical background using liquid\u2013liquid or vapor\u2013liquid experimental data. These methods require experimental data to adjust the unknown parameters, resulting in limited predictive ability . Another approach uses empirical equations that correlate \u03b8(LCST) with physicochemical properties such as density, critical properties etc., but suffers from the disadvantage that these properties are not always available. A new approach proposed by Liu and Zhong develops linear models for the prediction of \u03b8(LCST) using molecular connectivity indices, which depends only on the solvent and polymer structures. The latter approach has proven to be a very useful technique in quantitative structure\u2013activity/property relationships (QSAR/QSPR) research for polymers and polymer solutions. QSAR/QSPR studies constitute an attempt to reduce the trial-and-error element in the design of compounds with desired activity/properties by establishing mathematical relationships between the activity/property of interest and measurable or computable parameters, such as topological, physicochemical, stereochemistry, or electronic indices. More recently QSPR models for the prediction of the \u03b8 (LCST) using molecular (electronic, physicochemical etc.) descriptors have been published. Using validated robust QSPR models, experimental time and effort can be reduced significantly as reliable estimates of \u03b8(LCST) for polymer solutions can be obtained before they are actually synthesized in the laboratory.",
            "score": 42.89042842388153
        },
        {
            "docid": "26100025_4",
            "document": "UrbanSim . The initial implementation of UrbanSim was implemented in Java. The software architecture was modularized and reimplemented in Python beginning in 2005, making extensive use of the Numpy numerical library. The software has been generalized and abstracted from the UrbanSim model system, and is now referred to as the Open Platform for Urban Simulation (OPUS), in order to facilitate a plug-in architecture for models such as activity-based travel, dynamic traffic assignment, emissions, and land cover change. OPUS includes a Graphical User Interface, and a concise expression language to facilitate access to complex internal operations by non-programmers. Beginning in 2012, UrbanSim was re-implemented using current Scientific Python libraries such as Pandas. UrbanSim Inc. has developed the UrbanSim Cloud Platform that deploys simulations on the cloud for scalability, enabling hundreds or even thousands of simulations to be run simultaneously, and a web browser based User Interface that features a 3D web map view of inputs and outputs from the simulation. UrbanSim models have been pre-built for 400 metropolitan areas within the United States at a census block level of detail. Users anywhere in the world can also build UrbanSim models using zone and parcel templates, by uploading local data and using the cloud resources to auto-specify and calibrate the models using local data. Details are available at www.urbansim.com.",
            "score": 42.86283326148987
        },
        {
            "docid": "203711_42",
            "document": "Bioluminescence . Bioluminescent organisms are a target for many areas of research. Luciferase systems are widely used in genetic engineering as reporter genes, each producing a different colour by fluorescence, and for biomedical research using bioluminescence imaging. For example, the firefly luciferase gene was used as early as 1986 for research using transgenic tobacco plants. \"Vibrio\" bacteria symbiose with marine invertebrates such as the Hawaiian bobtail squid (\"Euprymna scolopes\"), are key experimental models for bioluminescence. Bioluminescent activated destruction is an experimental cancer treatment. See also optogenetics which involves the use of light to control cells in living tissue, typically neurons, that have been genetically modified to express light-sensitive ion channels, and also see biophoton, a photon of non-thermal origin in the visible and ultraviolet spectrum emitted from a biological system.",
            "score": 79.24362444877625
        },
        {
            "docid": "1872854_30",
            "document": "Biochemical cascade . Given the genetic makeup of an organism, the complete set of possible reactions constitutes its reactome. Reactome, located at http://www.reactome.org is a curated, peer-reviewed resource of human biological processes/pathway data. The basic unit of the Reactome database is a reaction; reactions are then grouped into causal chains to form pathways The Reactome data model allows us to represent many diverse processes in the human system, including the pathways of intermediary metabolism, regulatory pathways, and signal transduction, and high-level processes, such as the cell cycle. Reactome provides a qualitative framework, on which quantitative data can be superimposed. Tools have been developed to facilitate custom data entry and annotation by expert biologists, and to allow visualization and exploration of the finished dataset as an interactive process map. Although the primary curational domain is pathways from Homo sapiens, electronic projections of human pathways onto other organisms are regularly created via putative orthologs, thus making Reactome relevant to model organism research communities. The database is publicly available under open source terms, which allows both its content and its software infrastructure to be freely used and redistributed. Studying whole transcriptional profiles and cataloging protein\u2013protein interactions has yielded much valuable biological information, from the genome or proteome to the physiology of an organism, an organ, a tissue or even a single cell. The Reactome database containing a framework of possible reactions which, when combined with expression and enzyme kinetic data, provides the infrastructure for quantitative models, therefore, an integrated view of biological processes, which links such gene products and can be systematically mined by using bioinformatics applications. Reactome data available in a variety of standard formats, including BioPAX, SBML and PSI-MI, and also enable data exchange with other pathway databases, such as the Cycs, KEGG and amaze, and molecular interaction databases, such as BIND and HPRD. The next data release will cover apoptosis, including the death receptor signaling pathways, and the Bcl2 pathways, as well as pathways involved in hemostasis. Other topics currently under development include several signaling pathways, mitosis, visual phototransduction and hematopoeisis. In summary, Reactome provides high-quality curated summaries of fundamental biological processes in humans in a form of biologist-friendly visualization of pathways data, and is an open-source project.",
            "score": 41.06249380111694
        },
        {
            "docid": "3408308_21",
            "document": "Metabolic network modelling . In order to perform a dynamic simulation with such a network it is necessary to construct an ordinary differential equation system that describes the rates of change in each metabolite's concentration or amount. To this end, a rate law, i.e., a kinetic equation that determines the rate of reaction based on the concentrations of all reactants is required for each reaction. Software packages that include numerical integrators, such as COPASI or SBMLsimulator, are then able to simulate the system dynamics given an initial condition. Often these rate laws contain kinetic parameters with uncertain values. In many cases it is desired to estimate these parameter values with respect to given time-series data of metabolite concentrations. The system is then supposed to reproduce the given data. For this purpose the distance between the given data set and the result of the simulation, i.e., the numerically or in few cases analytically obtained solution of the differential equation system is computed. The values of the parameters are then estimated to minimize this distance. One step further, it may be desired to estimate the mathematical structure of the differential equation system because the real rate laws are not known for the reactions within the system under study. To this end, the program SBMLsqueezer allows automatic creation of appropriate rate laws for all reactions with the network. Synthetic accessibility is a simple approach to network simulation whose goal is to predict which metabolic gene knockouts are lethal. The synthetic accessibility approach uses the topology of the metabolic network to calculate the sum of the minimum number of steps needed to traverse the metabolic network graph from the inputs, those metabolites available to the organism from the environment, to the outputs, metabolites needed by the organism to survive. To simulate a gene knockout, the reactions enabled by the gene are removed from the network and the synthetic accessibility metric is recalculated. An increase in the total number of steps is predicted to cause lethality. Wunderlich and Mirny showed this simple, parameter-free approach predicted knockout lethality in \"E. coli\" and \"S. cerevisiae\" as well as elementary mode analysis and flux balance analysis in a variety of media.",
            "score": 39.163891315460205
        },
        {
            "docid": "31113866_2",
            "document": "Mammalian promoter database . MPromDb (Mammalian Promoter Database) is a curated database of gene promoters identified from ChIP-seq The proximal promoter region (upstream of the core-promoter region) contains the cis-regulatory elements of most of the transcription factors (TFs). Recently a better approach to annotate active promoters has been demonstrated with a combination of ChIP-seq and computational technique. This technique has been used to find the target genes of TFs in mammalian systems. The MPromDb is based on this technology. Curated promoter sequences for eukaryotic organisms are provided by EPD database, however, promoter activity information at tissue/ cell centric level is not offered. The MPromDb data base added active RNAP-II promoters identified after analyzing ten different mouse cell/tissue ChIP-seq experiments performed with RNAP-II antibody and six different human cell types. The data was acquired by a series of computational methods followed by manual correction to ensure its high level quality. In the newest version of MPromDb, about 507 million uniquely aligned RNA Pol-II ChIP-seq reads have already been analyzed from 26 different databases, including six human cell-types and 10 distinct mouse cell/tissues.",
            "score": 54.28322124481201
        },
        {
            "docid": "33882236_6",
            "document": "Adaptive collaborative control . Adaptive collaborative control is most accurately modeled as a closed loop feedback control system. Closed loop feedback control describes the event where the outputs of a system from an input are used to influence the present or future behavior of the system. The feedback control model is governed by a set of equations that are used to predict the future state of the simuland and regulate its behavior. These equations \u2013 in conjunction with principles of control theory \u2013 are used to evolve physical operations of the simuland to include, but not limited to: dialogue, path planning, motion, monitoring, and lifting objects over time. Many times, these equations are modeled as nonlinear partial differential equations over a continuous time domain.  Due to their complexity, powerful computers are necessary to implement these models. A consequence of using computers to simulate these models is that continuous systems cannot be fully calculated. Instead, numerical solutions, such as the Runge-Kutta methods, are utilized to approximate these continuous models.  These equations are initialized from the response of one or more sources and rates of changes and outputs are calculated. These rates of changes predict the states of the simuland a short time in the future. The time increment for this prediction is called a time step. These new states are applied to the model to determine the new rates of changes and observational data. This behavior is continued until the desired number of iterations is completed. In the event a future state violates or comes within a tolerance of the violation the simuland will confer with its human counterpart seeking advice on how to proceed from that point. The outputs, or observational data, are used by the human operators to determine what they believe is the best course of action for the simuland. Their commands are fed with the input into the control system and assessed regarding its effectiveness in resolving the issues. If the human commands are determined to be valuable, the simuland will adjust its control input to what the human suggested. If the human\u2019s commands are determined to be unbeneficial, malicious, or non-existent, the model will seek its own correction approach.",
            "score": 42.3886239528656
        },
        {
            "docid": "10571004_4",
            "document": "Biological network inference . There is great interest in network medicine for the modelling biological systems. This article focuses on a necessary prerequisite to dynamic modeling of a network: inference of the topology, that is, prediction of the \"wiring diagram\" of the network. More specifically, we focus here on inference of biological network structure using the growing sets of high-throughput expression data for genes, proteins, and metabolites. Briefly, methods using high-throughput data for inference of regulatory networks rely on searching for patterns of partial correlation or conditional probabilities that indicate causal influence. Such patterns of partial correlations found in the high-throughput data, possibly combined with other supplemental data on the genes or proteins in the proposed networks, or combined with other information on the organism, form the basis upon which such algorithms work. Such algorithms can be of use in inferring the topology of any network where the change in state of one node can affect the state of other nodes.",
            "score": 53.5372416973114
        },
        {
            "docid": "1075179_7",
            "document": "Regulome . One of the objectives of systems biology is the modelization of biological processes using mathematics and computer simulation. The production of data from techniques of genomic analysis is not always amenable to interpretation mainly due to the complexity of the data and the large amount of data points. Modelization can handle the data and allow to test a hypothesis (for example, gene A is regulated by protein B) that can be verified experimentally.",
            "score": 48.045268416404724
        },
        {
            "docid": "20374_50",
            "document": "Metabolism . An idea of the complexity of the metabolic networks in cells that contain thousands of different enzymes is given by the figure showing the interactions between just 43 proteins and 40 metabolites to the right: the sequences of genomes provide lists containing anything up to 45,000 genes. However, it is now possible to use this genomic data to reconstruct complete networks of biochemical reactions and produce more holistic mathematical models that may explain and predict their behavior. These models are especially powerful when used to integrate the pathway and metabolite data obtained through classical methods with data on gene expression from proteomic and DNA microarray studies. Using these techniques, a model of human metabolism has now been produced, which will guide future drug discovery and biochemical research. These models are now used in network analysis, to classify human diseases into groups that share common proteins or metabolites.",
            "score": 43.98049974441528
        },
        {
            "docid": "43010228_9",
            "document": "WormBase . The gene models of \"C. elegans\", \"C. briggsae\", \"C. remanei\", and \"C. brenneri\" genes are manually curated. The majority of gene structure changes have been based on transcript data from large scale projects such as Yuji Kohara\u2019s EST libraries, Mark Vidal\u2019s Orfeome project (worfdb.dfci.harvard.edu/) Waterston and Hillier\u2019s Illumina data and Makedonka Mitreva\u2019s 454 data. However, other data types (e.g. protein alignments, \"ab initio\" prediction programs, trans-splice leader sites, poly-A signals and addition sites, SAGE and TEC-RED transcript tags, mass-spectroscopic peptides, and conserved protein domains) are useful in refining the structures, especially where expression is low and so transcripts are not sufficiently available. When genes are conserved between the available nematode species, comparative analysis can also be very informative.",
            "score": 49.267155170440674
        }
    ],
    "r": [
        {
            "docid": "203711_42",
            "document": "Bioluminescence . Bioluminescent organisms are a target for many areas of research. Luciferase systems are widely used in genetic engineering as reporter genes, each producing a different colour by fluorescence, and for biomedical research using bioluminescence imaging. For example, the firefly luciferase gene was used as early as 1986 for research using transgenic tobacco plants. \"Vibrio\" bacteria symbiose with marine invertebrates such as the Hawaiian bobtail squid (\"Euprymna scolopes\"), are key experimental models for bioluminescence. Bioluminescent activated destruction is an experimental cancer treatment. See also optogenetics which involves the use of light to control cells in living tissue, typically neurons, that have been genetically modified to express light-sensitive ion channels, and also see biophoton, a photon of non-thermal origin in the visible and ultraviolet spectrum emitted from a biological system.",
            "score": 79.24362182617188
        },
        {
            "docid": "341038_8",
            "document": "Reporter gene . Reporter genes can also be used to assay for the expression of the gene of interest, which may produce a protein that has little obvious or immediate effect on the cell culture or organism. In these cases, the reporter is directly attached to the gene of interest to create a gene fusion. The two genes are under the same promoter elements and are transcribed into a single messenger RNA molecule. The mRNA is then translated into protein. In these cases it is important that both proteins be able to properly fold into their active conformations and interact with their substrates despite being fused. In building the DNA construct, a segment of DNA coding for a flexible polypeptide linker region is usually included so that the reporter and the gene product will only minimally interfere with one another. Reporter gene assay have been increasingly used in high throughput screening (HTS) to identify small molecule inhibitors and activators of protein targets and pathways for drug discovery and chemical biology. Because the reporter enzymes themselves (e.g. firefly luciferase) can be direct targets of small molecules and confound the interpretation of HTS data, novel coincidence reporter designs incorporating artifact suppression have been developed  Reporter genes can be used to assay for the activity of a particular promoter in a cell or organism. In this case there is no separate \"gene of interest\"; the reporter gene is simply placed under the control of the target promoter and the reporter gene product's activity is quantitatively measured. The results are normally reported relative to the activity under a \"consensus\" promoter known to induce strong gene expression.",
            "score": 77.32625579833984
        },
        {
            "docid": "356382_31",
            "document": "Gene regulatory network . Other work has focused on predicting the gene expression levels in a gene regulatory network. The approaches used to model gene regulatory networks have been constrained to be interpretable and, as a result, are generally simplified versions of the network. For example, Boolean networks have been used due to their simplicity and ability to handle noisy data but lose data information by having a binary representation of the genes. Also, artificial neural networks omit using a hidden layer so that they can be interpreted, losing the ability to model higher order correlations in the data. Using a model that is not constrained to be interpretable, a more accurate model can be produced. Being able to predict gene expressions more accurately provides a way to explore how drugs affect a system of genes as well as for finding which genes are interrelated in a process. This has been encouraged by the DREAM competition which promotes a competition for the best prediction algorithms. Some other recent work has used artificial neural networks with a hidden layer.",
            "score": 75.44737243652344
        },
        {
            "docid": "43183712_10",
            "document": "Bioluminescent bacteria . After the discovery of the lux operon, the use of bioluminescent bacteria as a laboratory tool is claimed to have revolutionized the area of environmental microbiology. The applications of bioluminescent bacteria include biosensors for detection of contaminants, measurement of pollutant toxicity and monitoring of genetically engineered bacteria released into the environment. Biosensors, created by placing a \"lux\" gene construct under the control of an inducible promoter, can be used to determine the concentration of specific pollutants. Biosensors are also able to distinguish between pollutants that are bioavailable and those that are inert and unavailable. For example, \"Pseudomonas fluorescens\" has been genetically engineered to be capable of degrading salicylate and naphthalene, and is used as a biosensor to assess the bioavailability of salicylate and naphthalene. Biosensors can also be used as an indicator of cellular metabolic activity and to detect the presence of pathogens.",
            "score": 74.55979919433594
        },
        {
            "docid": "18964603_5",
            "document": "Bioreporter . Luciferase is a generic name for an enzyme that catalyzes a light-emitting reaction. Luciferases can be found in bacteria, algae, fungi, jellyfish, insects, shrimp, and squid, and the resulting light that these organisms produce is termed bioluminescence. In bacteria, the genes responsible for the light-emitting reaction (the \"lux\" genes) have been isolated and used extensively in the construction of bioreporters that emit a blue-green light with a maximum intensity at 490\u00a0nm. Three variants of \"lux\" are available, one that functions at < 30\u00b0C, another at < 37\u00b0C, and a third at < 45\u00b0C. The \"lux\" genetic system consists of five genes, \"luxA\", \"luxB\", \"luxC\", \"luxD\", and \"luxE\". Depending on the combination of these genes used, several different types of bioluminescent bioreporters can be constructed.",
            "score": 71.40974426269531
        },
        {
            "docid": "1891323_8",
            "document": "Spatiotemporal gene expression . Several methods are being pursued for controlling gene expression spatially, temporally and in different degrees. One method is by using operon inducer/repressor system which provides temporal control of gene expression. To control gene expression spatially inkjet printers are underdevelopment for printing ligands on gel culture. Other popular method involves use of light to control gene expression in spatiotemporal fashion. Since light can also be controlled easily in space, time and degree, several methods of controlling gene expression at DNA and RNA level have been developed and are under study. For example, RNA interference can be controlled using light and also patterning of gene expression has been performed in cell monolayer and in zebrafish embryos using caged morpholino or peptide nucleic acid demonstrating the control of gene expression spatiotemporally. Recently light based control has been shown at DNA level using transgene based system or caged triplex forming oligos",
            "score": 70.39653015136719
        },
        {
            "docid": "1181008_10",
            "document": "Computational science . Exciting new developments in biotechnology are now revolutionizing biology and biomedical research. Examples of these techniques are high-throughput sequencing, high-throughput quantitative PCR, intra-cellular imaging, in-situ hybridization of gene expression, three-dimensional imaging techniques like Light Sheet Fluorescence Microscopy and Optical Projection, (micro)-Computer Tomography. Given the massive amounts of complicated data that is generated by these techniques, their meaningful interpretation, and even their storage, form major challenges calling for new approaches. Going beyond current bioinformatics approaches, computational biology needs to develop new methods to discover meaningful patterns in these large data sets. Model-based reconstruction of gene networks can be used to organize the gene expression data in systematic way and to guide future data collection. A major challenge here is to understand how gene regulation is controlling fundamental biological processes like biomineralisation and embryogenesis. The sub-processes like gene regulation, organic molecules interacting with the mineral deposition process, cellular processes, physiology and other processes at the tissue and environmental levels are linked. Rather than being directed by a central control mechanism, biomineralisation and embryogenesis can be viewed as an emergent behavior resulting from a complex system in which several sub-processes on very different temporal and spatial scales (ranging from nanometer and nanoseconds to meters and years) are connected into a multi-scale system. One of the few available options to understand such systems is by developing a multi-scale model of the system.",
            "score": 69.97492218017578
        },
        {
            "docid": "61289_40",
            "document": "Forensic entomology . Although physical characteristics and sizes at various instars have been used to estimate fly age, a more recent study has been conducted to determine the age of an egg based on the expression of particular genes. This is particularly useful in determining developmental stages that are not evidenced by change in size; such as the egg or pupa and where only a general time interval can be estimated based on the duration of the particular developmental stage. This is done by breaking the stages down into smaller units separated by predictable changed in gene expression. Three genes were measured in an experiment with \"Drosophila melanogaster\": bicoid (bcd), slalom (sll), and chitin synthase (cs). These three genes were used because they are likely to be in varied levels during different times of the egg development process. These genes all share a linear relationship in regards to age of the egg; that is, the older the egg is the more of the particular gene is expressed. However, all of the genes are expressed in varying amounts. Different genes on different loci would need to be selected for another fly species. The genes expressions are mapped in a control sample to formulate a developmental chart of the gene expression at certain time intervals. This chart can then be compared to the measured values of gene expression to accurately predict the age of an egg to within two hours with a high confidence level. Even though this technique can be used to estimate the age of an egg, the feasibility and legal acceptance of this must be considered for it to be a widely utilized forensic technique. One benefit of this would be that it is like other DNA-based techniques so most labs would be equipped to conduct similar experiments without requiring new capital investment. This style of age determination is in the process of being used to more accurately find the age of the instars and pupa; however, it is much more complicated, as there are more genes being expressed during these stages. The hope is that with this and other similar techniques a more accurate PMI can be obtained.",
            "score": 69.7600326538086
        },
        {
            "docid": "55410471_16",
            "document": "DCas9 activation system . One research group used a system in which dCas9 was fused to a particular domain, C1B1. When blue light is shined on the cell, the Cry2 domain binds to C1B1. The Cry2 domain is fused to a transcriptional activator, so blue light targets the activator to the spot where dCas9 is bound. The use of light allows a great deal of control over when the targeted gene is activated. Removing the light from the cell results in only dCas9 remaining at the target gene, so expression is not increased. In this way, the system is reversible. A similar system was developed using chemical control. In this system, dCas9 recruits an MS2 fusion protein that contains the domain FKBP. In the presence of the chemical RAP, an FRB domain fused to a chromatin modifying complex binds to FKBP. Whenever RAP is added to the cells, a specific chromatin modifier complex can be targeted to the gene. That allows scientists to examine how specific chromatin modifications affect the expression of a gene. The dCAs9-VPR system is used as an activator by targeting it to the promotor of a gene upstream of the coding region. A study used various sgRNAs to target different portions of the gene, finding that the dCas9-VPR activator can act as an activator or a repressor, depending on the location it binds. In a cell, sgRNAs targeting the promoter could allow dCas9-VPR to increase expression, while sgRNAs targeting the coding region of the gene result in dCas9-VPR decreasing expression.",
            "score": 68.7752685546875
        },
        {
            "docid": "43183712_11",
            "document": "Bioluminescent bacteria . The light-producing chemistry behind bioluminescence varies across the lineages of bioluminescent organisms. Based on this observation, bioluminescence is believed to have evolved independently at least 40 times. In bioluminescent bacteria, the reclassification of the members of\"Vibrio fischeri\" species group as a new genus, \"Aliivibrio,\" has led to increased interest in the evolutionary origins of bioluminescence\".\" Among bacteria, the distribution of bioluminescent species is polyphyletic. For instance, while all species in the terrestrial genus \"Photorhabdus\" are luminescent, the genera \"Aliivibrio, Photobacterium, Shewanella\" and \"Vibrio\" contain both luminous and non-luminous species. Despite bioluminescence in bacteria not sharing a common origin, they all share a gene sequence in common. The appearance of the highly conserved lux operon in bacteria from very different ecological niches suggests a strong selective advantage despite the high energetic costs of producing light. DNA repair is thought to be the initial selective advantage for light production in bacteria. Consequently, the lux operon may have been lost in bacteria that evolved more efficient DNA repair systems but retained in those where visible light became a selective advantage. The evolution of quorum sensing is believed to have afforded further selective advantage for light production. Quorum sensing allows bacteria to conserve energy by ensuring that they do not synthesize light-producing chemicals unless a sufficient concentration are present to be visible.",
            "score": 68.63456726074219
        },
        {
            "docid": "188183_5",
            "document": "Transactivation . Artificial transactivation of a gene is achieved by inserting it into the genome at the appropriate area as transactivator gene adjoined to special promoter regions of DNA. The transactivator gene expresses a transcription factor that binds to specific promoter region of DNA. By binding to the promoter region of a gene, the transcription factor causes that gene to be expressed. The expression of one transactivator gene can activate multiple genes, as long as they have the same, specific promoter region attached. Because the expression of the transactivator gene can be controlled, transactivation can be used to turn genes on and off. If this specific promoter region is also attached to a reporter gene, we can measure when the transactivator is being expressed.",
            "score": 67.47894287109375
        },
        {
            "docid": "203711_43",
            "document": "Bioluminescence . The structures of photophores, the light producing organs in bioluminescent organisms, are being investigated by industrial designers. Engineered bioluminescence could perhaps one day be used to reduce the need for street lighting, or for decorative purposes if it becomes possible to produce light that is both bright enough and can be sustained for long periods at a workable price. The gene that makes the tails of fireflies glow has been added to mustard plants. The plants glow faintly for an hour when touched, but a sensitive camera is needed to see the glow. University of Wisconsin\u2013Madison is researching the use of genetically engineered bioluminescent E. coli bacteria, for use as bioluminescent bacteria in a light bulb.  In 2011, Philips launched a microbial system for ambience lighting in the home. An iGEM team from Cambridge (England) has started to address the problem that luciferin is consumed in the light-producing reaction by developing a genetic biotechnology part that codes for a luciferin regenerating enzyme from the North American firefly; this enzyme \"helps to strengthen and sustain light output\". In 2016, Glowee, a French company started selling bioluminescent lights, targeting shop fronts and municipal street signs as their main markets. France has a law that forbids retailers and offices from illuminating their windows between 1 and 7 in the morning in order to minimise energy consumption and pollution. Glowee hoped their product would get around this ban. They used bacteria called \"Aliivibrio fischeri\" which glow in the dark, but the maximum lifetime of their product was three days.",
            "score": 66.38935852050781
        },
        {
            "docid": "18964603_7",
            "document": "Bioreporter . Instead of containing only the \"luxA\" and \"luxB\" genes, bioreporters can contain all five genes of the \"lux\" cassette, thereby allowing for a completely independent light generating system that requires no extraneous additions of substrate nor any excitation by an external light source. So in this bioassay, the bioreporter is simply exposed to a target analyte and a quantitative increase in bioluminescence results, often within less than one hour. Due to their rapidity and ease of use, along with the ability to perform the bioassay repetitively in real time and on-line, makes \"luxCDABE\" bioreporters extremely attractive. Consequently, they have been incorporated into a diverse array of detection methodologies ranging from the sensing of environmental contaminants to the real-time monitoring of pathogen infections in living mice.",
            "score": 66.17112731933594
        },
        {
            "docid": "53763747_4",
            "document": "Andrew Millar (scientist) . As a pioneering chronobiologist, Millar is known for his use of luciferase reporters for the purpose of studying plant circadian biology. Millar began experimenting with the firefly luciferase reporter gene as a graduate student at The Rockefeller University. In 1992, Millar and colleagues fused the Arabidopsis \"cab2\" promoter and the firefly luciferase gene to establish a real-time reporter for circadian-regulated gene expression in plants. Millar tracked the rhythm of transcription from the \"cab2\" promoter using a low-light video imaging system which tracks luciferase bioluminescence. Millar hypothesized that this model could be used to isolate mutants in the plant circadian clock.",
            "score": 65.01953125
        },
        {
            "docid": "237704_32",
            "document": "Saccharomyces cerevisiae . \"S. cerevisiae\" has been highly studied as a model organism to better understand aging for more than five decades and has contributed to the identification of more mammalian genes affecting aging than any other model organism. Some of the topics studied using yeast are calorie restriction, as well as in genes and cellular pathways involved in senescence. The two most common methods of measuring aging in yeast are Replicative Life Span, which measures the number of times a cell divides, and Chronological Life Span, which measures how long a cell can survive in a non-dividing stasis state. Limiting the amount of glucose or amino acids in the growth medium has been shown to increase RLS and CLS in yeast as well as other organisms. At first, this was thought to increase RLS by up-regulating the sir2 enzyme, however it was later discovered that this effect is independent of sir2. Over-expression of the genes sir2 and fob1 has been shown to increase RLS by preventing the accumulation of extrachromosomal rDNA circles, which are thought to be one of the causes of senescence in yeast. The effects of dietary restriction may be the result of a decreased signaling in the TOR cellular pathway. This pathway modulates the cell's response to nutrients, and mutations that decrease TOR activity were found to increase CLS and RLS. This has also been shown to be the case in other animals. A yeast mutant lacking the genes sch9 and ras2 has recently been shown to have a tenfold increase in chronological lifespan under conditions of calorie restriction and is the largest increase achieved in any organism.",
            "score": 64.44229888916016
        },
        {
            "docid": "22072718_9",
            "document": "Biological network . Gene co-expression networks can be interpreted as association networks between variables that measure transcript abundances. These networks have been used to provide a systems biologic analysis of DNA microarray data, RNA-seq data, miRNA data etc. weighted gene co-expression network analysis is widely used to identify co-expression modules and intramodular hub genes. Co-expression modules may correspond to cell types or pathways. Highly connected intramodular hubs can be interpreted as representatives of their respective module.",
            "score": 63.86994171142578
        },
        {
            "docid": "2384297_6",
            "document": "The Lives of a Cell: Notes of a Biology Watcher . This essay focuses on how connected humanity is to nature and how we must make strides to understand our role. Thomas argues that even our own bodies are not solely ours since the mitochondria and other organelles are descended from other organisms. He creates a metaphor of the Earth as a giant cell itself with humans just as one part of a vast system. Astronauts must be decontaminated before they are allowed to interact on Earth. Thomas states that this is an act of \u201chuman chauvinism.\u201d Most organisms on Earth are symbiotic or, if harmful, have both adapted to warn the other. All organisms on Earth are interdependent and a stray virus or bacteria from the moon will not be adapted to harm us since it is not part of this connection. Bacteria are interconnected to the point where some cannot survive without others and some even live within others. We must recognize how interconnected even the smallest organisms are on Earth; especially if we must interact with life outside our planet. Thomas introduces one of his key metaphors of humans behaving like ants. He suggests that this metaphor is not used because humans do not like to be compared to insects that, as a society, can function as an organism. There are many examples of animals acting as a large organism when in large groups from termites and slime molds to birds and fish. Thomas argues that the communication of results in science puts humans in the same model as these other species. As all scientists communicate and build on each other\u2019s work in order to explore that which we do not know. Humans fear pheromones because we believe we have gone above the basic secretion of chemicals in our communication. However, there are signs that point to humans relying on pheromones as well as our most technological forms of communication. Thomas shows pheromones in the animal world with examples of moths and fish. He then goes on to explain what impact pheromones in humans could have on the future such as in the perfume industry and finding histocompatible donors. Music is the only form of communication that saves us from an overwhelming amount of small talk. This is not only a human phenomenon, but happens throughout the animal world. Thomas makes examples of animals from termites and earthworms to gorillas and alligators that perform some sort of rhythmic noise making that can be interpreted as music if we had full range of hearing. From the vast number of animals that participate in music it is clear that the need to make music is a fundamental characteristic of biology. Thomas proposes that the animal world is continuing a musical memory that has been going since the beginning of time. Thomas argues that even though we have the technological advancements to destroy the Earth that we do not know near enough about the world in which we live. To solve this problem he suggests that we should not be able to fire nuclear weapons without being able to explain one living thing fully. The organism that Thomas proposes is the protozoan Myxotricha paradoxa. There is information known about this protozoan that lives in the digestive tract of Australian termites but with more study it could be a model for how our cells developed. It is seen throughout nature that organisms cooperate and progress into more complex forms. We cannot destroy vast amounts of Earth with nuclear weapons until we understand how interconnected we all are. Thomas presents the three levels of technology in medicine: \u201cnontechnology\u201d that helps patients with diseases that are not well understood but does not help solve the underlying mechanisms of the disease, \u201chalfway technology\u201d that makes up for disease or postpones death for diseases whose courses we cannot do much about, and \u201chigh technology\u201d that from understanding the mechanism of the disease we are now able to cure. When looking at the costs of the three different technologies they are all needed, but once a \u201chigh technology\u201d is found for a disease the benefits outweigh the costs of studying the mechanism of the disease so thoroughly. Thomas suggests that in order to save money in health care, the highest priority in funding should be given to basic research. Humans leave a trace of chemicals in every place they go and on everything they touch. Other animals use signaling mechanisms to leave trails or identify each other. The sense of smell is an important sense in using these mechanisms, but it is still not well understood. Humans, compared to the rest of the animal world, do not have a good olfactory sense though we may be better than we first assume. Johannes Kepler once argued that the Earth is an immense organism itself, with chemical signals spreading across the globe through various organisms in order to keep the world functioning and well informed. Tau Ceti is a nearby sun-like star that we are on the verge of being able to begin making contact with, as well as other celestial bodies, to search for life. We have been attracted to the vast regions of space outside our Earth bubble and what they could hold. If extraterrestrial life is found, it scientifically would make sense, but the social impact of no longer being unique would give humans a new sense of community. The question of what information to send out is answered by Thomas by sending music, specifically Bach. It is timeless and the best language we have to express who we are. If possible Thomas also suggests sending art. However, the questions of what to send will not stop once we receive a reply. As humans we always evade death, despite how it is a natural part of our lives. Unless it is far removed, as in war or on television, then we can discuss it without a problem. It is a subconscious effort that by not thinking about death we may continue to live. Nevertheless, even if we cured all diseases we still would die one day. We must not fear death and research the dying process just as we would any other biological process. Most people who have a near death experience do not recall any pain or fear. It is perhaps the loss of consciousness that people fear more than death itself. Thomas returns to his pondering of the social behaviors of insects in this essay. He discusses the change in behavior of insects in groups and singular insects. We have used insects and their behavior to convey lessons, rules, and virtues and now they have been used in art. Thomas describes an art exhibit with living ants, surrounded by humans who act in a similar manner to the ants themselves. Thomas praises the Marine Biological Laboratory as \u201ca paradigm, a human institution possessed of a life of its own, self-regenerating, touched all around by human meddle but consistently improved, embellished by it.\u201d It attracts the brightest minds and makes great strides in science autonomously. Thomas paints pictures with his description of scientists covering the beach with their diagrams and making \u201cmusic\u201d of discussion after a lecture at the MBL. Humans have to learn how to walk, skip, and ride a bicycle but inside our bodies perform specific manipulations from birth that we do not need to learn. There is new research that suggests humans may be able to change these inner processes with teaching. Thomas reasons that his body has been functioning fine without him trying to control every little process so he will let it continue to do so. He suggests to try the exact opposite and try to disconnect from your body altogether. The biologic revolution is filling in the gaps in understanding about how our cells function. As we begin to understand more about organelles it is clear that they are not originally created from our cells. Mitochondria and chloroplasts most likely have a bacterial ancestry and flagellae and cilia most likely were once spirochetes. It is not necessarily a master-slave relationship that we have with our organelles, but one where their ancestors found an easy way to stay protected and secure. We have brought them along with us as we evolved and yet we do not understand them completely. Organelles and eukaryotic cells are one of the most established symbiotic relationships. We treat bacteria as an ever present enemy even though there are only a small number that actually cause disease, and by accident in most cases. Bacteria normally do not gain anything by causing illness or death in their hosts. Our illness is mostly caused by our immune system doing too great of a job in response to bacteria in our system. The strength of our response is not necessary for most cases, but remains from a primitive time. Health care has become the new name for medicine though this is a misnomer since illness and death cannot be totally eradicated. Thomas argues that to understand how medicine should be used we should look to those internists that are involved in the system. Most things get better in a short while by themselves, so we should no longer be instilling in the public a constant fear of failed health. This will be the best way to solve the problem of funding health care since people will only use it when it is necessary. There are different degrees of social behavior in animals. However, it is not clear where humans fit on the scale. Most signs point that we are above the social behavior of ants and bees that go about a singular task as a whole community. Language is the one trait that brings us to the level of such animals. All humans engage in language and are born with the understanding of language. Language, and perhaps along with art and music, is the core of our social behavior. The human mind comes with the understanding of how to deal with and use language. We store up information as a cell stores energy, though with language, this information can be put to further use. Another main difference between language and other communication systems in biology is the ambiguity that is a necessity in language which would cause the other communication systems to fail. Death is not supposed to happen in the open, along highways and in sight of others. Everything is in the process of dying all around us, though we keep it hidden from our sight and minds. Death is part of the cycle and we need to understand we are part of a larger process. The process of dying is necessary for the birth of the new and we will all experience it together. Thomas explains science as a wild manifestation of human behavior. He explains that science and discovery is a compulsion that scientists seem to have written in their very genes. Science cannot be organized and forced; it must be free to go where the next question leads. It is similar to a bee hive in some sense, but also to animals on a hunt. The activity is never ending and the conglomeration of minds always yearning for the next discovery cannot be kept under control. How humans approach nature has been changing throughout recent years. We used to view nature as ours to control and use to better mankind. Now we have moved away from this view and seen that we are part of the larger system and not the ruler of it. However Thomas argues that we must see ourselves as \u201cindispensable elements of nature\u201d and work for the betterment of the Earth but also be able to protect ourselves. This essay focuses on the tribe of Iks in northern Uganda. Thomas comments on an anthropologist\u2019s report on the Iks that argues that they represent the basic elements of mankind. Thomas instead thinks that each Ik acts as a group and that by observing the whole tribe of Iks you can see how we behave in groups ranging from committees to nations. In order to improve upon our group interactions, we must stay human even when in masses. Computers are approaching humanity, but they will never be able to fully replace us for they will not be able to replicate our collective behavior because we do not understand it ourselves. We are involved in a never ending transfer of information and collective thinking. This is the cause of the unpredictability in our future. The one problem with our information transfer is that we are much better at gaining information than giving output back. Thomas explains in this essay his view on scientific funding and planning. He believes that research should be focused in basic science. Unlike basic science, disease problems do not have the right type of questions to allow for great discoveries. The distinguishing factor of basic science is that there can be an element of surprise that allows for even more discoveries to be made. It is difficult to organize plans for this type of surprise in research even though it may seem a better business model to do so. It is the improbability and maze of puzzles that occur in basic research that Thomas believes will lead us to the most knowledge. Mythical creatures were created by our ancestors but even though we presently have no need for these beasts we continue to use them. The hybridization of animals in mythology is present from multiple ancient people such as the Ganesha, Griffon, Centaur, and Sphinx. Thomas suggests that perhaps we look to replace these mythological creatures which are more biological. He suggests the Myxotricha paradoxa, blepharisma, bacteria, and plant-animal combinations that are either made up of different organisms or set up joint endeavors with more than one organism to survive. From Thomas\u2019s metaphor on how humans behave like ants, he again argues that language is the quality that best resembles social insects. Without any outside direction, humans continually change language. We build language like ants build their hill, without ever knowing what the final result is and how our minuscule changes affect any other part. Thomas explains how some words have changed and developed different meanings. Two words, gene and bheu, are two words that we have derived a great number of current words from. Their descended words: kind, nature, physics are related in the present but also in its ancestry. Thomas compares language to the social behavior of termites in this essay. He thinks of language as an organism that is alive and changing. The genes of language are how words originated when you look into each of their histories. He traces multiple words to their origins to prove his point. He comments that it would be near impossible to keep track of all roots of words back to Indo-European that you use. We should be in awe that we exist and are unique among all the humans on Earth according to probability. Though we are indeed individual organisms, Thomas argues that one\u2019s own self is a myth. He believes we are part of a larger organization of information sharing. Through this system we are adapting and creating. By being more open with communication and less restrictive we will be able to uncover even more surprising discoveries. Thomas compares the Earth to a living cell, one with its own membrane that allows it to keep out disorder. He shows how the evolution of cells was closely tied to the \u201cbreath\u201d of the Earth, the cycling of oxygen concentration in the atmosphere. The atmosphere is \u201cfor sheer size and perfection of function, it is far and away the grandest product of collaboration in all of nature.\u201d It gives us the oxygen we need, protection from UV light, and protection from the millions of meteorites.",
            "score": 63.84157180786133
        },
        {
            "docid": "9458068_26",
            "document": "RNA silencing . Artificial introduction of long dsRNAs or siRNAs has been adopted as a tool to inactivate gene expression, both in cultured cells and in living organisms. Structural and functional resolution of small RNAs as the effectors of RNA silencing has had a direct impact on experimental biology. For example, dsRNA may be synthesized to have a specific sequence complementary to a gene of interest. Once introduced into a cell or biological system, it is recognized as exogenous genetic material and activates the corresponding RNA silencing pathway. This mechanism can be used to effect decreases in gene expression with respect to the target, useful for investigating loss of function for genes relative to a phenotype. That is, studying the phenotypic and/or physiologic effects of expression decreases can reveal the role of a gene product. The observable effects can be nuanced, such that some methods can distinguish between \u201cknockdown\u201d (decrease expression) and \u201cknockout\u201d (eliminate expression) of a gene. RNA interference technologies have been noted recently as one of the most widely utilized techniques in functional genomics. Screens developed using small RNAs have been used to identify genes involved in fundamental processes such as cell division, apoptosis and fat regulation.",
            "score": 63.251792907714844
        },
        {
            "docid": "841429_28",
            "document": "Synthetic biology . A biosensor refers to an engineered organism, usually a bacterium,that is capable of reporting some ambient phenomenon such as the presence of heavy metals or toxins. One such system is the Lux operon of \"Aliivibrio fischeri,\" which codes for the enzyme that is the source of bacterial bioluminescence, and can be placed after a respondent promoter to express the luminescence genes in response to a specific environmental stimulus. One such sensor created consisted of a bioluminescent bacterial coating on a photosensitive computer chip to detect certain petroleum pollutants. When the bacteria sense the pollutant, they luminesce.",
            "score": 63.062774658203125
        },
        {
            "docid": "25351840_8",
            "document": "Fine structure genetics . A similar method can be used to study novel phenotypes created by tissue specific gain-of-function or loss of function. In order to create gain-of-function, the TE is inserted with not just with a reporter gene, but also with the GAL4 transcriptional activator. When this line is crossed with an organism with a gene fused with a GAL4 mediated promoter. This way anytime that particular promoter is turned on, it will not only express its original gene, it will also turn on expression of any gene the experimenter would like turned on. This is an easy way to ensure tissue or time specific expression of a gene where it is not usually expressed. Under a similar principle, the GAL4 transcriptional activator can be replaced with an RNAi construct for a specific gene. This can make any promoter into an inhibitor of a gene in a specific location.",
            "score": 63.005733489990234
        },
        {
            "docid": "1078549_12",
            "document": "Aliivibrio fischeri . \"A. fischeri\" is one of many species of bacteria that commonly form symbiotic relationships with marine organisms. Marine organisms contain bacteria that use bioluminescence so they can find mates, ward off predators, attract prey, or communicate with other organisms. In return, the organism the bacteria are living within provides the bacteria with a nutrient-rich environment. The \"lux\" operon is a 9-kilobase fragment of the \"A. fischeri\" genome that controls bioluminescence through the catalytic activity of the enzyme luciferase. This operon has a known gene sequence of \"luxCDAB(F)E\", where \"luxA\" and \"luxB\" code for the protein subunits of the luciferase enzyme, and the \"luxCDE\" codes for a fatty acid reductase complex that makes the fatty acids necessary for the luciferase mechanism.\" luxC \"codes for the enzyme acyl-reductase, \"luxD\" codes for acyl-transferase, and \"luxE\" makes the proteins needed for the enzyme acyl-protein synthetase. Luciferase produces blue/green light through the oxidation of reduced flavin mononucleotide and a long-chain aldehyde by diatomic oxygen. The reaction is summarized as:",
            "score": 62.73477554321289
        },
        {
            "docid": "3487107_7",
            "document": "Real-time polymerase chain reaction . Quantitative PCR and DNA microarray are modern methodologies for studying gene expression. Older methods were used to measure mRNA abundance: Differential display, RNase protection assay and Northern blot. Northern blotting is often used to estimate the expression level of a gene by visualizing the abundance of its mRNA transcript in a sample. In this method, purified RNA is separated by agarose gel electrophoresis, transferred to a solid matrix (such as a nylon membrane), and probed with a specific DNA or RNA probe that is complementary to the gene of interest. Although this technique is still used to assess gene expression, it requires relatively large amounts of RNA and provides only qualitative or semi quantitative information of mRNA levels. Estimation errors arising from variations in the quantification method can be the result of DNA integrity, enzyme efficiency and many other factors. For this reason a number of standardization systems (often called normalization methods) have been developed. Some have been developed for quantifying total gene expression, but the most common are aimed at quantifying the specific gene being studied in relation to another gene called a normalizing gene, which is selected for its almost constant level of expression. These genes are often selected from housekeeping genes as their functions related to basic cellular survival normally imply constitutive gene expression. This enables researchers to report a ratio for the expression of the genes of interest divided by the expression of the selected normalizer, thereby allowing comparison of the former without actually knowing its absolute level of expression.",
            "score": 62.676734924316406
        },
        {
            "docid": "43183712_2",
            "document": "Bioluminescent bacteria . Bioluminescent bacteria are light-producing bacteria that are predominantly present in sea water, marine sediments, the surface of decomposing fish and in the gut of marine animals. While not as common, bacterial bioluminescence is also found in terrestrial and freshwater bacteria. These bacteria may be free living (such as \"Vibrio harveyi\") or in symbiosis with animals such as the Hawaiian Bobtail squid (\"Aliivibrio fischeri\") or terrestrial nematodes (\"Photorhabdus luminescens\"). The host organisms provide these bacteria a safe home and sufficient nutrition. In exchange, the hosts use the light produced by the bacteria for camouflage, prey and/or mate attraction. Bioluminescent bacteria have evolved symbiotic relationships with other organisms in which both participants benefit close to equally. Another possible reason bacteria use luminescence reaction is for quorum sensing, an ability to regulate gene expression in response to bacterial cell density.",
            "score": 62.56974411010742
        },
        {
            "docid": "1872854_31",
            "document": "Biochemical cascade . In the post-genomic age, high-throughput sequencing and gene/protein profiling techniques have transformed biological research by enabling comprehensive monitoring of a biological system, yielding a list of differentially expressed genes or proteins, which is useful in identifying genes that may have roles in a given phenomenon or phenotype. With DNA microarrays and genome-wide gene engineering, it is possible to screen global gene expression profiles to contribute a wealth of genomic data to the public domain. With RNA interference, it is possible to distill the inferences contained in the experimental literature and primary databases into knowledge bases that consist of annotated representations of biological pathways. In this case, individual genes and proteins are known to be involved in biological processes, components, or structures, as well as how and where gene products interact with each other. Pathway-oriented approaches for analyzing microarray data, by grouping long lists of individual genes, proteins, and/or other biological molecules according to the pathways they are involved in into smaller sets of related genes or proteins, which reduces the complexity, have proven useful for connecting genomic data to specific biological processes and systems. Identifying active pathways that differ between two conditions can have more explanatory power than a simple list of different genes or proteins. In addition, a large number of pathway analytic methods exploit pathway knowledge in public repositories such as Gene Ontology (GO) or Kyoto Encyclopedia of Genes and Genomes (KEGG), rather than inferring pathways from molecular measurements. Furthermore, different research focuses have given the word \"pathway\" different meanings. For example, 'pathway' can denote a metabolic pathway involving a sequence of enzyme-catalyzed reactions of small molecules, or a signaling pathway involving a set of protein phosphorylation reactions and gene regulation events. Therefore, the term \"pathway analysis\" has a very broad application. For instance, it can refer to the analysis physical interaction networks (e.g., protein\u2013protein interactions), kinetic simulation of pathways, and steady-state pathway analysis (e.g., flux-balance analysis), as well as its usage in the inference of pathways from expression and sequence data. Several functional enrichment analysis tools and algorithms have been developed to enhance data interpretation. The existing knowledge base\u2013driven pathway analysis methods in each generation have been summarized in recent literature.",
            "score": 62.563751220703125
        },
        {
            "docid": "8310787_32",
            "document": "Survivin . In order to see whether p53 re-expression in cancer cells (that have lost p53 expression) has the suppressive effect on the promoter of the survivin gene, a luciferase reporter construct was made. The isolated survivin promoter was placed upstream of the luciferase reporter gene. In a luciferase reporter assay, if the promoter is active, the luciferase gene is transcribed and translated into a product that gives off light that can measured quantitatively and, thus, represents the activity of the promoter. This construct was transfected into cancer cells that had either wild-type or mutant p53. High luciferase activity was measured in the cells with mutant p53 and significantly lower luciferase levels were measured for cells with wild-type p53.",
            "score": 62.472076416015625
        },
        {
            "docid": "356382_8",
            "document": "Gene regulatory network . Genes can be viewed as nodes in the network, with input being proteins such as transcription factors, and outputs being the level of gene expression. The value of the node depends of a function which depends in the value of its regulators in previous time steps (in the Boolean network described below these are Boolean functions, typically AND, OR, and NOT). These functions have been interpreted as performing a kind of information processing within the cell, which determines cellular behavior. The basic drivers within cells are concentrations of some proteins, which determine both spatial (location within the cell or tissue) and temporal (cell cycle or developmental stage) coordinates of the cell, as a kind of \"cellular memory\". The gene networks are only beginning to be understood, and it is a next step for biology to attempt to deduce the functions for each gene \"node\", to help understand the behavior of the system in increasing levels of complexity, from gene to signaling pathway, cell or tissue level.",
            "score": 62.34344482421875
        },
        {
            "docid": "13570238_3",
            "document": "PER1 . The PER1 protein is important to the maintenance of circadian rhythms in cells, and may also play a role in the development of cancer. This gene is a member of the period family of genes. It is expressed with a daily oscillating circadian rhythm, or an oscillation that cycles with a period of approximately 24 hours. PER1 is most notably expressed in the region of the brain called the suprachiasmatic nucleus (SCN), which is the primary circadian pacemaker in the mammalian brain. PER1 is also expressed throughout mammalian peripheral tissues. Genes in this family encode components of the circadian rhythms of locomotor activity, metabolism, and behavior. Circadian expression of PER1 in the suprachiasmatic nucleus will free-run in constant darkness, meaning that the 24-hour period of the cycle will persist without the aid of external light cues. Subsequently, a shift in the light/dark cycle evokes a proportional shift of gene expression in the suprachiasmatic nucleus. The time of gene expression is sensitive to light, as light during a mammal's subjective night results in a sudden increase in per expression and thus a shift in phase in the suprachiasmatic nucleus. Alternative splicing has been observed in this gene; however, these variants have not been fully described. There is some disagreement between experts over the occurrence of polymorphisms with functional significance. Many scientists state that there are no known polymorphisms of the human PER1 gene with significance at a population level that results in measurable behavioral or physiological changes. Still, some believe that even silent mutations can cause significant behavioral phenotypes,and result in major phase changes.",
            "score": 62.25047302246094
        },
        {
            "docid": "1891323_4",
            "document": "Spatiotemporal gene expression . What causes spatial and temporal differences in the expression of a single gene? Because current expression patterns depend strictly on previous expression patterns, there is a regressive problem of explaining what caused the first differences in gene expression. The process by which uniform gene expression becomes spatially and temporally differential is known as symmetry breaking. For example, in the case of embryonic \"Drosophila\" development, the genes \"nanos\" and \"bicoid\" are asymmetrically expressed in the oocyte because maternal cells deposit messenger RNA (mRNA) for these genes in the poles of the egg before it is laid. One way to identify the expression pattern of a particular gene is to place a reporter gene downstream of its promoter. In this configuration, the promoter gene will cause the reporter gene to be expressed only where and when the gene of interest is expressed. The expression distribution of the reporter gene can be determined by visualizing it. For example, the reporter gene green fluorescent protein can be visualized by stimulating it with blue light and then using a digital camera to record green fluorescent emission.",
            "score": 61.92449951171875
        },
        {
            "docid": "143533_20",
            "document": "Green fluorescent protein . The availability of GFP and its derivatives has thoroughly redefined fluorescence microscopy and the way it is used in cell biology and other biological disciplines. While most small fluorescent molecules such as FITC (fluorescein isothiocyanate) are strongly phototoxic when used in live cells, fluorescent proteins such as GFP are usually much less harmful when illuminated in living cells. This has triggered the development of highly automated live-cell fluorescence microscopy systems, which can be used to observe cells over time expressing one or more proteins tagged with fluorescent proteins. For example, GFP had been widely used in labelling the spermatozoa of various organisms for identification purposes as in \"Drosophila melanogaster\", where expression of GFP can be used as a marker for a particular characteristic. GFP can also be expressed in different structures enabling morphological distinction. In such cases, the gene for the production of GFP is incorporated into the genome of the organism in the region of the DNA that codes for the target proteins and that is controlled by the same regulatory sequence; that is, the gene's regulatory sequence now controls the production of GFP, in addition to the tagged protein(s). In cells where the gene is expressed, and the tagged proteins are produced, GFP is produced at the same time. Thus, only those cells in which the tagged gene is expressed, or the target proteins are produced, will fluoresce when observed under fluorescence microscopy. Analysis of such time lapse movies has redefined the understanding of many biological processes including protein folding, protein transport, and RNA dynamics, which in the past had been studied using fixed (i.e., dead) material. Obtained data are also used to calibrate mathematical models of intracellular systems and to estimate rates of gene expression.",
            "score": 61.87382507324219
        },
        {
            "docid": "3325140_39",
            "document": "Entropy in thermodynamics and information theory . Boltzmann's equation is presumed to provide a link between thermodynamic entropy \"S\" and information entropy \"H = \u2212\u03a3i pi ln pi\" = ln(W)\" where p=1/W\" are the equal probabilities of a given microstate. This interpretation has been criticized also. While some say that the equation is merely a unit conversion equation between thermodynamic and information entropy, this is not completely correct. A unit conversion equation will, e.g., change inches to centimeters, and yield two measurements in different units of the same physical quantity (length). Since thermodynamic and information entropy are dimensionally unequal (energy/unit temperature vs. units of information), Boltzmann's equation is more akin to \"x = c t\" where \"x\" is the distance travelled by a light beam in time \"t\", \"c\" being the speed of light. While we cannot say that length \"x\" and time \"t\" represent the same physical quantity, we can say that, in the case of a light beam, since \"c\" is a universal constant, they will provide perfectly accurate measures of each other. (For example, the light-year is used as a measure of distance). Likewise, in the case of Boltzmann's equation, while we cannot say that thermodynamic entropy \"S\" and information entropy \"H\" represent the same physical quantity, we can say that, in the case of a thermodynamic system, since \"k\" is a universal constant, they will provide perfectly accurate measures of each other.",
            "score": 61.86783218383789
        },
        {
            "docid": "10571004_5",
            "document": "Biological network inference . Genes are the nodes and the edges are directed. A gene serves as the source of a direct regulatory edge to a target gene by producing an RNA or protein molecule that functions as a transcriptional activator or inhibitor of the target gene. If the gene is an activator, then it is the source of a positive regulatory connection; if an inhibitor, then it is the source of a negative regulatory connection. Computational algorithms take as primary input data measurements of mRNA expression levels of the genes under consideration for inclusion in the network, returning an estimate of the network topology. Such algorithms are typically based on linearity, independence or normality assumptions, which must be verified on a case-by-case basis. Clustering or some form of statistical classification is typically employed to perform an initial organization of the high-throughput mRNA expression values derived from microarray experiments, in particular to select sets of genes as candidates for network nodes. The question then arises: how can the clustering or classification results be connected to the underlying biology? Such results can be useful for pattern classification \u2013 for example, to classify subtypes of cancer, or to predict differential responses to a drug (pharmacogenomics). But to understand the relationships between the genes, that is, to more precisely define the influence of each gene on the others, the scientist typically attempts to reconstruct the transcriptional regulatory network. This can be done by data integration in dynamic models supported by background literature, or information in public databases, combined with the clustering results. The modelling can be done by a Boolean network, by Ordinary differential equations or Linear regression models, e.g. Least-angle regression, by Bayesian network or based on Information theory approaches. For instance it can be done by the application of a correlation-based inference algorithm, as will be discussed below, an approach which is having increased success as the size of the available microarray sets keeps increasing",
            "score": 61.521324157714844
        },
        {
            "docid": "5824073_12",
            "document": "High-content screening . This technology allows a (very) large number of experiments to be performed, allowing explorative screening. Cell-based systems are mainly used in chemical genetics where large, diverse small molecule collections are systematically tested for their effect on cellular model systems. Novel drugs can be found using screens of tens of thousands of molecules, and these have promise for the future of drug development.  Beyond drug discovery, chemical genetics is aimed at functionalizing the genome by identifying small molecules that acts on most of the 21,000 gene products in a cell. High-content technology will be part of this effort which could provide useful tools for learning where and when proteins act by knocking them out chemically. This would be most useful for gene where knock out mice (missing one or several genes) can not be made because the protein is required for development, growth or otherwise lethal when it is not there. Chemical knock out could address how and where these genes work. Further the technology is used in combination with RNAi to identify sets of genes involved in specific mechanisms, for example cell division. Here, libraries of RNAis, covering a whole set of predicted genes inside the target organism's genome can be used to identify relevant subsets, facilitating the annotation of genes for which no clear role has been established beforehand. The large datasets produced by automated cell biology contain spatially resolved, quantitative data which can be used for building for systems level models and simulations of how cells and organisms function. Systems biology models of cell function would permit prediction of why, where and how the cell responds to external changes, growth and disease.",
            "score": 61.21715545654297
        }
    ]
}