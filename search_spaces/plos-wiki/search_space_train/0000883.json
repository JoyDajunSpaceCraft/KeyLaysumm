{
    "q": [
        {
            "docid": "40841348_9",
            "document": "Computational and Statistical Genetics . Over the past few years, genome-wide association studies (GWAS) have become a powerful tool for investigating the genetic basis of common diseases and has improved our understanding of the genetic basis of many complex traits. Traditional single SNP (single-nucleotide polymorphism) GWAS is the most commonly used method to find trait associated DNA sequence variants - associations between variants and one or more phenotypes of interest are investigated by studying individuals with different phenotypes and examining their genotypes at the position of each SNP individually. The SNPs for which one variant is statistically more common in individuals belonging to one phenotypic group are then reported as being associated with the phenotype. However, most complex common diseases involve small population-level contributions from multiple genomic loci. To detect such small effects as genome-wide significant, traditional GWAS rely on increased sample size e.g. to detect an effect which accounts for 0.1% of total variance, traditional GWAS needs to sample almost 30,000 individuals. Although the development of high throughput SNP genotyping technologies has lowered the cost and improved the efficiency of genotyping. Performing such a large scale study still costs considerable money and time. Recently, association analysis methods utilizing gene-based tests have been proposed that are based on the fact that variations in protein-coding and adjacent regulatory regions are more likely to have functional relevance. These methods have the advantage that they can account for multiple independent functional variants within a gene, with the potential to greatly increase the power to identify disease/trait associated genes. Also, imputation of ungenotyped markers using known reference panels(e.g. HapMap and the 1000 Genomes Project) predicts genotypes at the missing or untyped markers thereby allowing one to accurately evaluate the evidence for association at genetic markers that are not directly genotyped (in addition to the typed markers) and has been shown to improve the power of GWAS to detect disease associated loci.",
            "score": 137.8192321062088
        },
        {
            "docid": "43778895_11",
            "document": "Predictive genomics . Type 2 diabetes (T2D), an extremely common metabolic disorder, has demonstrated interplay between many environmental and genetic risk factors leading to disease onset. A number of risk assessment models incorporating a number of demographic, environmental and clinical risk factors are already shown to elicit reasonable discrimination in case-control studies; it has been proposed that identifying genetic variants that contribute to T2D as for standalone prediction or in conjunction with current risk models can improve prediction of T2D risk, if current models lack sufficient coverage of the full effect of an individual's genotype. Approximately 20 associated SNPs have been replicated in T2D; however, their effect sizes do not seem to be substantial: OR 1.37 for SNPs in the \"TCF7L2\" gene purported to give highest genetic risk.",
            "score": 106.82582712173462
        },
        {
            "docid": "14771927_3",
            "document": "GeneMark . The GeneMark.hmm algorithm (1998) was designed to improve gene prediction accuracy in finding short genes and gene starts. The idea was to integrate the Markov chain models used in GeneMark into a hidden Markov model framework, with transition between coding and non-coding regions formally interpreted as transitions between hidden states. Additionally, the ribosome binding site model was used to improve accuracy of gene start prediction. Next step was done with development of the self-training gene prediction tool GeneMarkS (2001). GeneMarkS has been in active use by genomics community for gene identification in new prokaryotic genomic sequences. GeneMarkS+, extension of GeneMarkS integrating information on homologous proteins into gene prediction is used in the NCBI pipeline for prokaryotic genomes annotation; the pipeline can annotate up to 2000 genomes daily ().",
            "score": 94.28839421272278
        },
        {
            "docid": "16019737_8",
            "document": "Tiling array . Another popular use of tiling arrays is in finding expressed genes. Traditional methods of gene prediction for annotation of genomic sequences have had problems when used to map the transcriptome, such as not producing an accurate structure of the genes and also missing transcripts entirely. The method of sequencing cDNA to find transcribed genes also runs into problems, such as failing to detect rare or very short RNA molecules, and so do not detect genes that are active only in response to signals or specific to a time frame. Tiling arrays can solve these issues. Due to the high resolution and sensitivity, even small and rare molecules can be detected. The overlapping nature of the probes also allows detection of non-polyadenylated RNA and can produce a more precise picture of gene structure. Earlier studies on chromosome 21 and 22 showed the power of tiling arrays for identifying transcription units. The authors used 25-mer probes that were 35bp apart, spanning the entire chromosomes. Labeled targets were made from polyadenylated RNA. They found many more transcripts than predicted and 90% were outside of annotated exons. Another study with Arabidopsis used high-density oligonucleotide arrays that cover the entire genome. More than 10 times more transcripts were found than predicted by ESTs and other prediction tools. Also found were novel transcripts in the centromeric regions where it was thought that no genes are actively expressed. Many noncoding and natural antisense RNA have been identified using tiling arrays.",
            "score": 105.22725749015808
        },
        {
            "docid": "29467449_19",
            "document": "Protein function prediction . Several networks based on different data sources can be combined into a composite network, which can then be used by a prediction algorithm to annotate candidate genes or proteins. For example, the developers of the bioPIXIE system used a wide variety of \"Saccharomyces cerevisiae\" (yeast) genomic data to produce a composite functional network for that species. This resource allows the visualization of known networks representing biological processes, as well as the prediction of novel components of those networks. Many algorithms have been developed to predict function based on the integration of several data sources (e.g. genomic, proteomic, protein interaction, etc.), and testing on previously annotated genes indicates a high level of accuracy. Disadvantages of some function prediction algorithms have included a lack of accessibility, and the time required for analysis. Faster, more accurate algorithms such as GeneMANIA (multiple association network integration algorithm) have however been developed in recent years and are publicly available on the web, indicating the future direction of function prediction.",
            "score": 94.07747161388397
        },
        {
            "docid": "4635854_2",
            "document": "Hypothetical protein . In biochemistry, a hypothetical protein is a protein whose existence has been predicted, but for which there is a lack of experimental evidence that it is expressed in vivo. Sequencing of several genomes has resulted in numerous predicted open reading frames to which functions cannot be readily assigned. These proteins, either orphan or conserved hypothetical proteins, make up ~ 20% to 40% of proteins encoded in each newly sequenced genome. Even when there is enough evidence that the product of the gene is expressed, by techniques such as microarray and mass-spectrometry, it is difficult to assign a function to it given its lack of identity to protein sequences with annotated biochemical function. Nowadays, most protein sequences are inferred from computational analysis of genomic DNA sequence. Hypothetical proteins are created by gene prediction software during genome analysis. When the bioinformatic tool used for the gene identification finds a large open reading frame without a characterised homologue in the protein database, it returns \"hypothetical protein\" as an annotation remark.",
            "score": 81.14124953746796
        },
        {
            "docid": "4250553_58",
            "document": "Gene . Although the number of base-pairs of DNA in the human genome has been known since the 1960s, the estimated number of genes has changed over time as definitions of genes, and methods of detecting them have been refined. Initial theoretical predictions of the number of human genes were as high as 2,000,000. Early experimental measures indicated there to be 50,000\u2013100,000 \"transcribed\" genes (expressed sequence tags). Subsequently, the sequencing in the Human Genome Project indicated that many of these transcripts were alternative variants of the same genes, and the total number of protein-coding genes was revised down to ~20,000 with 13 genes encoded on the mitochondrial genome. With the GENCODE annotation project, that estimate has continued to fall to 19,000. Of the human genome, only 1\u20132% consists of protein-coding genes, with the remainder being 'noncoding' DNA such as introns, retrotransposons, and noncoding RNAs. Every multicellular organism has all its genes in each cell of its body but not every gene functions in every cell .",
            "score": 102.14054012298584
        },
        {
            "docid": "34142465_10",
            "document": "Linkage based QTL mapping . Linkage and association analysis are primary tool for gene discovery, localization and functional analysis. While conceptual underpinning of these approaches have been long known, advances in recent decades in molecular genetics, development in efficient algorithms, and computing power have enabled the large scale application of these methods. While linkage studies seek to identify loci that cosegregate with the trait within families, association studies seek to identify particular variants that are associated with the phenotype at the population level. These are complementary methods that, together, provide means to probe the genome and describe etiology of complex human traits. In linkage studies, we seek to identify the loci that cosegregate with a specific genomic region, tagged by polymorphic markers, within families. In contrast, in association studies, we seek a correlation between a specific genetic variation and trait variation in sample of individuals, implicating a causal role of the variant. Linkage tests are powerful and specific for gene discovery, the localization of locus can be achieved only to a certain level of precision \u2013 on order of megabases \u2013 that potentially represents a region that potentially include hundreds of genes.",
            "score": 100.75357723236084
        },
        {
            "docid": "1732638_4",
            "document": "Expressivity (genetics) . Variable expressivity occurs when a phenotype is expressed to a different degree among individuals with the same genotype. For example, individuals with the same allele for a gene involved in a quantitative trait like body height might have large variance (some are taller than others), making prediction of the phenotype from a particular genotype alone difficult. The expression of a phenotype may be modified by the effects of aging, other genetic loci, or environmental factors. Another example is neurofibromatosis, where patients with the same genetic mutation show different signs and symptoms of the disease.",
            "score": 98.65071129798889
        },
        {
            "docid": "235550_13",
            "document": "Sequence analysis . Gene prediction or gene finding refers to the process of identifying the regions of genomic DNA that encode genes. This includes protein-coding genes as well as RNA genes, but may also include the prediction of other functional elements such as regulatory regions. Gene finding is one of the first and most important steps in understanding the genome of a species once it has been sequenced. In general, the prediction of bacterial genes is significantly simpler and more accurate than the prediction of genes in eukaryotic species that usually have complex intron/exon patterns. Identifying genes in long sequences remains a problem, especially when the number of genes is unknown. Hidden markov models can be part of the solution. Machine learning has played a significant role in predicting the sequence of transcription factors. Traditional sequencing analysis focused on the statistical parameters of the nucleotide sequence itself (The most common programs used are listed in Table 4.1). Another method is to identify homologous sequences based on other known gene sequences (Tools see Table 4.3). The two methods described here are focused on the sequence. However, the shape feature of these molecules such as DNA and protein have also been studied and proposed to have an equivalent, if not higher, influence on the behaviors of these molecules.",
            "score": 107.09430265426636
        },
        {
            "docid": "14771927_2",
            "document": "GeneMark . GeneMark is a generic name for a family of ab initio gene prediction programs developed at the Georgia Institute of Technology in Atlanta. Developed in 1993, original GeneMark was used in 1995 as a primary gene prediction tool for annotation of the first completely sequenced bacterial genome of \"Haemophilus influenzae\", and in 1996 for the first archaeal genome of \"Methanococcus jannaschii\". The algorithm introduced inhomogeneous three-periodic Markov chain models of protein-coding DNA sequence that became standard in gene prediction as well as Bayesian approach to gene prediction in two DNA strands simultaneously. Species specific parameters of the models were estimated from training sets of sequences of known type (protein-coding and non-coding). The major step of the algorithm computes for a given DNA fragment posterior probabilities of either being \"protein-coding\" (carrying genetic code) in each of six possible reading frames (including three frames in complementary DNA strand) or being \"non-coding\". Original GeneMark (developed before the HMM era in Bioinformatics) is an HMM-like algorithm; it can be viewed as approximation to known in the HMM theory posterior decoding algorithm for appropriately defined HMM.",
            "score": 82.52176010608673
        },
        {
            "docid": "26418006_23",
            "document": "Exome sequencing . Current association studies have focused on common variation across the genome, as these are the easiest to identify with our current assays. However, disease-causing variants of large effect have been found to lie within exomes in candidate gene studies, and because of negative selection, are found in much lower allele frequencies and may remain untyped in current standard genotyping assays. Whole genome sequencing is a potential method to assay novel variant across the genome. However, in complex disorders (such as autism), a large number of genes are thought to be associated with disease risk. This heterogeneity of underlying risk means that very large sample sizes are required for gene discovery, and thus whole genome sequencing is not particularly cost-effective. This sample size issue is alleviated by the development of novel advanced analytic methods, which effectively map disease genes despite the genetic mutations are rare at variant level. In addition, variants in coding regions have been much more extensively studied and their functional implications are much easier to derive, making the practical applications of variants within the targeted exome region more immediately accessible.",
            "score": 120.01861584186554
        },
        {
            "docid": "356382_31",
            "document": "Gene regulatory network . Other work has focused on predicting the gene expression levels in a gene regulatory network. The approaches used to model gene regulatory networks have been constrained to be interpretable and, as a result, are generally simplified versions of the network. For example, Boolean networks have been used due to their simplicity and ability to handle noisy data but lose data information by having a binary representation of the genes. Also, artificial neural networks omit using a hidden layer so that they can be interpreted, losing the ability to model higher order correlations in the data. Using a model that is not constrained to be interpretable, a more accurate model can be produced. Being able to predict gene expressions more accurately provides a way to explore how drugs affect a system of genes as well as for finding which genes are interrelated in a process. This has been encouraged by the DREAM competition which promotes a competition for the best prediction algorithms. Some other recent work has used artificial neural networks with a hidden layer.",
            "score": 102.53410112857819
        },
        {
            "docid": "29467449_13",
            "document": "Protein function prediction . Genes involved in similar functions are also often co-transcribed, so that an unannotated protein can often be predicted to have a related function to proteins with which it co-expresses. The guilt by association algorithms developed based on this approach can be used to analyze large amounts of sequence data and identify genes with expression patterns similar to those of known genes. Often, a guilt by association study compares a group of candidate genes (unknown function) to a target group (for example, a group of genes known to be associated with a particular disease), and rank the candidate genes by their likelihood of belonging to the target group based on the data. Based on recent studies, however, it has been suggested that some problems exist with this type of analysis. For example, because many proteins are multifunctional, the genes encoding them may belong to several target groups. It is argued that such genes are more likely to be identified in guilt by association studies, and thus predictions are not specific.",
            "score": 91.76453530788422
        },
        {
            "docid": "40160407_8",
            "document": "Essential gene . While it may be difficult to prove that a gene is essential in humans, it can be demonstrated that a gene is not essential or not even causing disease. For instance, sequencing the genomes of 2,636 Icelandic citizens and the genotyping of 101,584 additional subjects found 8,041 individuals who had 1 gene completely knocked out (i.e. these people were homozygous for a non-functional gene). Of the 8,041 individuals with complete knock-outs, 6,885 were estimated to be homozygotes, 1,249 were estimated to be compound heterozygotes (i.e. they had both alleles of a gene knocked out but the two alleles had different mutations). In these individuals, a total of 1,171 of the 19,135 human (RefSeq) genes (6.1%) were completely knocked out. It was concluded that these 1,171 genes are \"non-essential\" in humans \u2014 at least no associated diseases were reported. Similarly, the exome sequences of 3222 British Pakistani-heritage adults with high parental relatedness revealed 1111 rare-variant homozygous genotypes with predicted loss of gene function (LOF = knockouts) in 781 genes. This study found an average of 140 predicted LOF genotypes (per subject), including 16 rare (minor allele frequency <1%) heterozygotes, 0.34 rare homozygotes, 83.2 common heterozygotes and 40.6 common homozygotes. Nearly all rare homozygous LOF genotypes were found within autozygous segments (94.9%). Even though most of these individuals had no obvious health issue arising from their defective genes, it is possible that minor health issues may be found upon more detailed examination.",
            "score": 88.44822478294373
        },
        {
            "docid": "57177883_3",
            "document": "DeMix . Solid tumor samples obtained from clinical practice are highly heterogeneous. They consist of multiple clonal populations of cancer cells as well as adjacent normal tissue, stromal and infiltrating immune cells. The highly heterogeneous structure of tumor tissues could complicate or bias various genomic data analysis. Removing heterogeneity is of substantial interest to isolate expression data from mixed samples \"in silico\". It is important to estimate and account for the tumor purity, or the percentage of cancer cells in the tumor sample before analyses. Owing to the marked differences between cancer and normal cells, it is possible to estimate tumor purity from high-throughput genomic or epigenomic data. DeMix is a method that has been developed to estimate the proportion and gene expression profile from cancer cells in mixed samples. In this method the mixed sample is assumed to be composed only by two cell types: cancer cells (without any a priori known gene expression profile) and normal cells (with known gene expression data, which can either come from tumor-matched or unmatched samples). This method was developed for microarray data and shows that it was important to use the raw data as input assuming it follows a log-normal distribution as is the case for microarray, instead of working with log-transformed data like most other methods did. DeMix estimates the variance of the gene expression in the normal samples and uses this in the maximum likelihood estimation to predict the cancer cell gene expression and proportions, using thus implicitly a gene-specific weight for each gene. It is the first method to follow a linear mixture of gene expression levels on data before they are log-transformed. This method analyzes data from heterogeneous tumor samples before the data are log-transformed, estimates individual level expression levels in each sample and each gene in an unmatched design.",
            "score": 99.13697671890259
        },
        {
            "docid": "58180_6",
            "document": "Freckle . The presence of freckles is related to rare alleles of the MC1R gene, though it does not differentiate whether an individual will have freckles if they have one or even two copies of this gene. Also, individuals with no copies of the MC1R do sometimes display freckles. Even so, individuals with a high number of freckling sites have one or more of variants of the MC1R gene. Of the variants of the MC1R gene Arg151Cys, Arg160Trp, and Asp294His are the most common in the freckled subjects. The MC1R gene is also associated with red hair more strongly than with freckles. Most red-haired individuals have two variants of the MC1R gene and almost all have one. The variants that cause red hair are the same that cause freckling. Freckling can also be found in areas, such as Japan, where red hair is not seen. These individuals have the variant Val92Met which is also found in Caucasians, although it has minimal effects on their pigmentation. The R162Q allele has a disputed involvement in freckling. The variants of the MC1R gene that are linked with freckles started to emerge in the human genotype when humans started to leave Africa. The variant Val92Met arose somewhere between 250,000 and 100,000 years ago, long enough for this gene to be carried by humans into central Asia. Arg160Trp is estimated to have arisen around 80,000 years ago while Arg151Cys and Asp294His have been estimated to arise around 30,000 years ago. The wide variation of the MC1R gene exists in people of European descent because of the lack of strong environmental pressures on the gene. The original allele of MC1R coded for dark skin with a high melanin content in the cells. The high melanin content is protective in areas of high UV light exposure. The need was less as humans moved into higher latitudes where incoming sunlight has lower UV light content. The adaptation of lighter skin is needed so that individuals in higher latitudes can still absorb enough UV for the production of vitamin D. Freckled individuals tend to tan less and have very light skin, which would have helped the individuals that expressed these genes absorb vitamin D.",
            "score": 94.42807197570801
        },
        {
            "docid": "44248347_18",
            "document": "Gene Disease Database . This one of the largest resources available for all genomic and genetic studies, it provides a centralized resource for geneticists, molecular biologists and other researchers studying the genomes of our own species and other vertebrates and model disease organisms. Ensembl is one of several well-known genome browsers for the retrieval of genomic-disease information. Ensembl imports variation data from a variety of different sources, Ensembl predicts the effects of variants. For each variation that is mapped to the reference genome, each Ensembl transcript is identified that overlap the variation. Then it uses a rule-based approach to predict the effects that each allele of the variation may have on the transcript. The set of consequence terms, defined by the Sequence Ontology (SO) can be currently assigned to each combination of an allele and a transcript. Each allele of each variation may have a different effect in different transcripts. A variety of different tools are used to predict human mutations in the Ensembl database, one of the most widely used is SIFT, that predicts whether an amino acid substitution is likely to affect protein function based on sequence homology and the physic-chemical similarity between the alternate amino acids. The data provided for each amino acid substitution is a score and a qualitative prediction (either 'tolerated' or 'deleterious'). The score is the normalized probability that the amino acid change is tolerated so scores near 0 are more likely to be deleterious. The qualitative prediction is derived from this score such that substitutions with a score < 0.05 are called 'deleterious' and all others are called 'tolerated'.SIFT can be applied to naturally occurring nonsynonymous polymorphisms and laboratory-induced missense mutations, that will lead to build relationships in phenotype characteristics, proteomics and genomics",
            "score": 109.63939118385315
        },
        {
            "docid": "1854663_38",
            "document": "GLIMMER . ELPH software( which was determined as highly effective at identifying RBS in the paper) is used for identifying RBS and is available at this website. Gibbs sampling algorithm is used to identify shared motif in any set of sequences. This shared motif sequences and their length is given as input to ELPH. ELPH then computes the position weight matrix(PWM) which will be used by GLIMMER 3 to score any potential RBS found by RBSfinder. The above process is done when we have a substantial amount of training genes. If there are inadequate number of training genes, GLIMMER 3 can bootstrap itself to generate a set of gene predictions which can be used as input to ELPH. ELPH now computes PWM and this PWM can be again used on the same set of genes to get more accurate results for start-sites. This process can be repeated for many iterations to obtain more consistent PWM and gene prediction results.",
            "score": 77.73351764678955
        },
        {
            "docid": "5824073_12",
            "document": "High-content screening . This technology allows a (very) large number of experiments to be performed, allowing explorative screening. Cell-based systems are mainly used in chemical genetics where large, diverse small molecule collections are systematically tested for their effect on cellular model systems. Novel drugs can be found using screens of tens of thousands of molecules, and these have promise for the future of drug development.  Beyond drug discovery, chemical genetics is aimed at functionalizing the genome by identifying small molecules that acts on most of the 21,000 gene products in a cell. High-content technology will be part of this effort which could provide useful tools for learning where and when proteins act by knocking them out chemically. This would be most useful for gene where knock out mice (missing one or several genes) can not be made because the protein is required for development, growth or otherwise lethal when it is not there. Chemical knock out could address how and where these genes work. Further the technology is used in combination with RNAi to identify sets of genes involved in specific mechanisms, for example cell division. Here, libraries of RNAis, covering a whole set of predicted genes inside the target organism's genome can be used to identify relevant subsets, facilitating the annotation of genes for which no clear role has been established beforehand. The large datasets produced by automated cell biology contain spatially resolved, quantitative data which can be used for building for systems level models and simulations of how cells and organisms function. Systems biology models of cell function would permit prediction of why, where and how the cell responds to external changes, growth and disease.",
            "score": 99.9157201051712
        },
        {
            "docid": "8767449_16",
            "document": "Public health genomics . Accurate and sensitive prediction of disease, or detection during early stages of disease, could allow the prevention or arrest of disease development as immunotherapy treatments become available. Type 1 diabetes markers associated with disease susceptibility have been identified, for example HLA class II gene variants, however possession of one or more of these genomic markers does not necessarily lead to disease. Lack of progression to disease is likely due to the absence of environmental triggers, absence of other susceptibility genes, presence of protective genes, or differences in the temporal expression or presence of these factors. Combinations of markers have also been associated with susceptibility to type 1 diabetes however again, their presence may not always predict disease development, and conversely, disease may be present without the marker group. Potential variant genes (SNPs) or markers that are linked to the disease include genes for cytokines, membrane-bound ligands, insulin and immune regulatory genes.",
            "score": 114.35453593730927
        },
        {
            "docid": "43778895_5",
            "document": "Predictive genomics . Whilst the single-gene, single-disease hypothesis holds for Mendelian disorders such as Huntington's disease and Cystic Fibrosis, complex diseases and traits are affected by a number of gene loci and genetic variants with varying risk. A precursor to the development of preventative, prognostic and diagnostic tools in these diseases requires mapping genetic loci in disease etiology and discovering causal mutations. Creating a \u2018genomic profile\u2019 of individuals with the number of variants at the genome-wide level facilitates not only the prediction of disease prior to onset, but also serves as a primer to increasing the knowledge of causal variants.",
            "score": 101.89043116569519
        },
        {
            "docid": "215038_12",
            "document": "Enhancer (genetics) . The development of genomic and epigenomic technologies, however, has dramatically changed the outlook for cis-regulatory modules (CRM) discovery. Next-generation sequencing (NGS) methods now enable high-throughput functional CRM discovery assays, and the vastly increasing amounts of available data, including large-scale libraries of transcription factor-binding site (TFBS) motifs, collections of annotated, validated CRMs, and extensive epigenetic data across many cell types, are making accurate computational CRM discovery an attainable goal. An example of NGS-based approach called DNase-seq have enabled identification of nucleosome-depleted, or open chromatin regions, which can contain CRM. Computational methods include comparative genomics, clustering of known or predicted TF-binding sites, and supervised machine-learning approaches trained on known CRMs.  All of these methods have proven effective for CRM discovery, but each has its own considerations and limitations, and each is subject to a greater or lesser number of false-positive identifications. In the comparative genomics approach, sequence conservation of non-coding regions can be indicative of enhancers. Sequences from multiple species are aligned, and conserved regions are identified computationally. Identified sequences can then be attached to a reporter gene such as green fluorescent protein or lacZ to determine the \"in vivo\" pattern of gene expression produced by the enhancer when injected into an embryo. mRNA expression of the reporter can be visualized by \"in situ\" hybridization, which provides a more direct measure of enhancer activity, since it is not subjected to the complexities of translation and protein folding. Although much evidence has pointed to sequence conservation for critical developmental enhancers, other work has shown that the function of enhancers can be conserved with little or no primary sequence conservation. For example, the \"RET\" enhancers in humans have very little sequence conservation to those in zebrafish, yet both species' sequences produce nearly identical patterns of reporter gene expression in zebrafish. Similarly, in highly diverged insects (separated by around 350 million years), similar gene expression patterns of several key genes was found to be regulated through similarly constituted CRMs although these CRMs do not show any appreciable sequence conservation detectable by standard sequence alignment methods such as BLAST.",
            "score": 102.69535398483276
        },
        {
            "docid": "25058426_4",
            "document": "Expression quantitative trait loci . Some cis eQTLs are detected in many tissue types but the majority of trans eQTLs are tissue-dependent (dynamic). eQTLs may act in cis (locally) or trans (at a distance) to a gene. The abundance of a gene transcript is directly modified by polymorphism in regulatory elements. Consequently, transcript abundance might be considered as a quantitative trait that can be mapped with considerable power. These have been named expression QTLs (eQTLs). The combination of whole-genome genetic association studies and the measurement of global gene expression allows the systematic identification of eQTLs. By assaying gene expression and genetic variation simultaneously on a genome-wide basis in a large number of individuals, statistical genetic methods can be used to map the genetic factors that underpin individual differences in quantitative levels of expression of many thousands of transcripts. Studies have shown that single nucleotide polymorphisms (SNPs) reproducibly associated with complex disorders as well as certain pharmacologic phenotypes are found to be significantly enriched for eQTLs, relative to frequency-matched control SNPs.",
            "score": 116.04413402080536
        },
        {
            "docid": "579390_7",
            "document": "Gene prediction . In empirical (similarity, homology or evidence-based) gene finding systems, the target genome is searched for sequences that are similar to extrinsic evidence in the form of the known expressed sequence tags, messenger RNA (mRNA), protein products, and homologous or orthologous sequences. Given an mRNA sequence, it is trivial to derive a unique genomic DNA sequence from which it had to have been transcribed. Given a protein sequence, a family of possible coding DNA sequences can be derived by reverse translation of the genetic code. Once candidate DNA sequences have been determined, it is a relatively straightforward algorithmic problem to efficiently search a target genome for matches, complete or partial, and exact or inexact. Given a sequence, local alignment algorithms such as BLAST, FASTA and Smith-Waterman look for regions of similarity between the target sequence and possible candidate matches. Matches can be complete or partial, and exact or inexact. The success of this approach is limited by the contents and accuracy of the sequence database.",
            "score": 75.11070895195007
        },
        {
            "docid": "52789_23",
            "document": "Androgen insensitivity syndrome . Mutations in the androgen receptor gene can cause problems with any of the steps involved in androgenization, from the synthesis of the androgen receptor protein itself, through the transcriptional ability of the dimerized, androgen-AR complex. AIS can result if even one of these steps is significantly disrupted, as each step is required for androgens to activate the AR successfully and regulate gene expression. Exactly which steps a particular mutation will impair can be predicted, to some extent, by identifying the area of the AR in which the mutation resides. This predictive ability is primarily retrospective in origin; the different functional domains of the AR gene have been elucidated by analyzing the effects of specific mutations in different regions of the AR. For example, mutations in the steroid binding domain have been known to affect androgen binding affinity or retention, mutations in the hinge region have been known to affect nuclear translocation, mutations in the DNA-binding domain have been known to affect dimerization and binding to target DNA, and mutations in the transactivation domain have been known to affect target gene transcription regulation. Unfortunately, even when the affected functional domain is known, predicting the phenotypical consequences of a particular mutation (see Correlation of genotype and phenotype) is difficult.",
            "score": 84.43457245826721
        },
        {
            "docid": "50518079_15",
            "document": "Human Genome Structural Variation . There are several structural variants in the human genome that have been observed but have not led to any obvious phenotypic effects. There are some, however, that play a role in gene dosage which could lead to genetic diseases or distinct phenotypes. Structural variants can directly affect gene expression, such as with copy-number variants, or indirectly through position effects. These effects can have significant implications in susceptibility to disease. The first gene dosage effect that was observed, and considered to be an autosomal dominant disease from an inherited DNA rearrangement, was Charcot-Marie Tooth (CMT) disease. Most of the associations found with CMT were with a 1.5 Mb tandem duplication in 17p11.2-p12 at the PMP22 gene. The proposed mechanism for the structural variation is shown in Figure 2. When an individual has three copies of the normal gene, it results in the disease phenotype. If the individual had only one copy of the PMP22 gene, on the other hand, the result was a clinically different heredity neuropathy with liability to pressure palsies. The differences in gene dosage created vastly different disease phenotypes which revealed the significant role that structural variation has on phenotype and susceptibility to disease.",
            "score": 120.69269788265228
        },
        {
            "docid": "52142704_3",
            "document": "Polygenic score . Polygenic scores are widely employed in animal, plant, and behavioral genetics for predicting and understanding genetic architectures. In a genome-wide association study (GWAS), polygenic scores having substantially higher predictive performance than the genome-wide statistically-significant hits indicates that the trait in question is affected by a larger number of variants than just the hits and larger sample sizes will yield more hits; a conjunction of low variance explained and high heritability as measured by GCTA, twin studies or other methods, indicates that a trait may be massively polygenic and affected by thousands of variants. Once a polygenic score has been created, which explains at least a few percent of a phenotype's variance and can therefore be assumed to effectively incorporate a significant fraction of the genetic variants affecting that phenotype, it can be used in several different ways: as a lower bound to test whether heritability estimates may be biased; as a measure of genetic overlap of traits (genetic correlation), which might indicate e.g. shared genetic bases for groups of mental disorders; as a means to assess group differences in a trait such as height, or to examine changes in a trait over time due to natural selection indicative of a soft selective sweep (as e.g. for intelligence where the changes in frequency would be too small to detect on each individual hit but not on the overall polygenic score); in Mendelian randomization (assuming no pleiotropy with relevant traits); to detect & control for the presence of genetic confounds in outcomes (e.g. the correlation of schizophrenia with poverty); or to investigate gene\u2013environment interactions.",
            "score": 111.08576774597168
        },
        {
            "docid": "43778895_8",
            "document": "Predictive genomics . The significance of translation from research to clinical usage relates to use of the complete knowledge of an individual to develop personalised approaches to disease management. The caveat with this is that there have been difficulties in both prediction and inference for complex diseases. Therefore, unless individuals have an overwhelming high or low number of risk alleles, there is a limit to the predictive accuracy of their \u2018genomic profiles\u2019. However, preliminary examples of predictive genomics for personalising healthcare include: using an individuals gene expression data to monitor progress to treatment, or using the genomic profile of the P450 drug metabolising system of individuals to assist dosage and selection.",
            "score": 86.47627544403076
        },
        {
            "docid": "579390_8",
            "document": "Gene prediction . A high degree of similarity to a known messenger RNA or protein product is strong evidence that a region of a target genome is a protein-coding gene. However, to apply this approach systemically requires extensive sequencing of mRNA and protein products. Not only is this expensive, but in complex organisms, only a subset of all genes in the organism's genome are expressed at any given time, meaning that extrinsic evidence for many genes is not readily accessible in any single cell culture. Thus, to collect extrinsic evidence for most or all of the genes in a complex organism requires the study of many hundreds or thousands of cell types, which presents further difficulties. For example, some human genes may be expressed only during development as an embryo or fetus, which might be difficult to study for ethical reasons.",
            "score": 77.20608115196228
        },
        {
            "docid": "23167397_21",
            "document": "GENCODE . The main approach to manual gene annotation is to annotate transcripts aligned to the genome and take the genomic sequences as the reference rather than the cDNAs. The finished genomic sequence is analyzed using a modified Ensembl pipeline, and BLAST results of cDNAs/ESTs and proteins, along with various ab initio predictions, can be analyzed manually in the annotation browser tool Otterlace. Thus, more alternative spliced variants can be predicted compared with cDNA annotation. Moreover, genomic annotation produces a more comprehensive analysis of pseudogenes. There are several analysis groups in the GENCODE consortium that run pipelines that aid the manual annotators in producing models in unannotated regions, and to identify potential missed or incorrect manual annotation, including completely missing loci, missing alternative isoforms, incorrect splice sites and incorrect biotypes. These are fed back to the manual annotators using the AnnoTrack tracking system. Some of these pipelines use data from other ENCODE subgroups including RNASeq data, histone modification and CAGE and Ditag data. RNAseq data is an important new source of evidence, but generating complete gene models from it is a difficult problem. As part of GENCODE, a competition was run to assess the quality of predictions produced by various RNAseq prediction pipelines (Refer to RGASP below). To confirm uncertain models, GENCODE also has an experimental validation pipeline using RNA sequencing and RACE",
            "score": 78.5754725933075
        },
        {
            "docid": "23167397_19",
            "document": "GENCODE . A comparison of key statistics from 3 major GENCODE releases is shown below. It is evident that although the coverage, in terms of total number of genes discovered, is steady increasing, the number of protein-coding genes has actually decreased. This is mostly attributed to new experimental evidence obtained using Cap Analysis Gene Expression (CAGE) clusters, annotated PolyA sites, and peptide hits. The general process to create an annotation for GENCODE involves manual curation, different computational analysis and targeted experimental approaches. Putative loci can be verified by wet-lab experiments and computational predictions are analysed manually. Currently, to ensure a set of annotation covers the complete genome rather than just the regions that have been manually annotated, a merged data set is created using manual annotations from HAVANA, together with automatic annotations from the Ensembl automatically annotated gene set. This process also adds unique full-length CDS predictions from the Ensembl protein coding set into manually annotated genes, to provide the most complete and up-to-date annotation of the genome possible.",
            "score": 89.53139925003052
        }
    ],
    "r": [
        {
            "docid": "40841348_9",
            "document": "Computational and Statistical Genetics . Over the past few years, genome-wide association studies (GWAS) have become a powerful tool for investigating the genetic basis of common diseases and has improved our understanding of the genetic basis of many complex traits. Traditional single SNP (single-nucleotide polymorphism) GWAS is the most commonly used method to find trait associated DNA sequence variants - associations between variants and one or more phenotypes of interest are investigated by studying individuals with different phenotypes and examining their genotypes at the position of each SNP individually. The SNPs for which one variant is statistically more common in individuals belonging to one phenotypic group are then reported as being associated with the phenotype. However, most complex common diseases involve small population-level contributions from multiple genomic loci. To detect such small effects as genome-wide significant, traditional GWAS rely on increased sample size e.g. to detect an effect which accounts for 0.1% of total variance, traditional GWAS needs to sample almost 30,000 individuals. Although the development of high throughput SNP genotyping technologies has lowered the cost and improved the efficiency of genotyping. Performing such a large scale study still costs considerable money and time. Recently, association analysis methods utilizing gene-based tests have been proposed that are based on the fact that variations in protein-coding and adjacent regulatory regions are more likely to have functional relevance. These methods have the advantage that they can account for multiple independent functional variants within a gene, with the potential to greatly increase the power to identify disease/trait associated genes. Also, imputation of ungenotyped markers using known reference panels(e.g. HapMap and the 1000 Genomes Project) predicts genotypes at the missing or untyped markers thereby allowing one to accurately evaluate the evidence for association at genetic markers that are not directly genotyped (in addition to the typed markers) and has been shown to improve the power of GWAS to detect disease associated loci.",
            "score": 137.81924438476562
        },
        {
            "docid": "50518079_15",
            "document": "Human Genome Structural Variation . There are several structural variants in the human genome that have been observed but have not led to any obvious phenotypic effects. There are some, however, that play a role in gene dosage which could lead to genetic diseases or distinct phenotypes. Structural variants can directly affect gene expression, such as with copy-number variants, or indirectly through position effects. These effects can have significant implications in susceptibility to disease. The first gene dosage effect that was observed, and considered to be an autosomal dominant disease from an inherited DNA rearrangement, was Charcot-Marie Tooth (CMT) disease. Most of the associations found with CMT were with a 1.5 Mb tandem duplication in 17p11.2-p12 at the PMP22 gene. The proposed mechanism for the structural variation is shown in Figure 2. When an individual has three copies of the normal gene, it results in the disease phenotype. If the individual had only one copy of the PMP22 gene, on the other hand, the result was a clinically different heredity neuropathy with liability to pressure palsies. The differences in gene dosage created vastly different disease phenotypes which revealed the significant role that structural variation has on phenotype and susceptibility to disease.",
            "score": 120.69269561767578
        },
        {
            "docid": "26418006_23",
            "document": "Exome sequencing . Current association studies have focused on common variation across the genome, as these are the easiest to identify with our current assays. However, disease-causing variants of large effect have been found to lie within exomes in candidate gene studies, and because of negative selection, are found in much lower allele frequencies and may remain untyped in current standard genotyping assays. Whole genome sequencing is a potential method to assay novel variant across the genome. However, in complex disorders (such as autism), a large number of genes are thought to be associated with disease risk. This heterogeneity of underlying risk means that very large sample sizes are required for gene discovery, and thus whole genome sequencing is not particularly cost-effective. This sample size issue is alleviated by the development of novel advanced analytic methods, which effectively map disease genes despite the genetic mutations are rare at variant level. In addition, variants in coding regions have been much more extensively studied and their functional implications are much easier to derive, making the practical applications of variants within the targeted exome region more immediately accessible.",
            "score": 120.01861572265625
        },
        {
            "docid": "40841348_11",
            "document": "Computational and Statistical Genetics . In this era of large amount of genetic and genomic data, accurate representation and identification of statistical interactions in biological/genetic/genomic data constitutes a vital basis for designing interventions and curative solutions for many complex diseases. Variations in human genome have been long known to make us susceptible to many diseases. We are hurtling towards the era of personal genomics and personalized medicine that require accurate predictions of disease risk posed by predisposing genetic factors. Computational and statistical methods for identifying these genetic variations, and building these into intelligent models for diseaseassociation and interaction analysis studies genome-wide are a dire necessity across many disease areas. The principal challenges are: (1) most complex diseases involve small or weak contributions from multiple genetic factors that explain only a minuscule fraction of the population variation attributed to genetic factors. (2) Biological data is inherently extremely noisy, so the underlying complexities of biological systems (such as linkage disequilibrium and genetic heterogeneity) need to be incorporated into the statistical models for disease association studies. The chances of developing many common diseases such as cancer, autoimmune diseases and cardiovascular diseases involves complex interactions between multiple genes and several endogenous and exogenous environmental agents or covariates. Many previous disease association studies could not produce significant results because of the lack of incorporation of statistical interactions in their mathematical models explaining the disease outcome. Consequently much of the genetic risks underlying several diseases and disorders remain unknown. Computational methods such as to model and identify the genetic/genomic variations underlying disease risks has a great potential to improve prediction of disease outcomes, understand the interactions and design better therapeutic methods based on them.",
            "score": 117.02129364013672
        },
        {
            "docid": "25058426_4",
            "document": "Expression quantitative trait loci . Some cis eQTLs are detected in many tissue types but the majority of trans eQTLs are tissue-dependent (dynamic). eQTLs may act in cis (locally) or trans (at a distance) to a gene. The abundance of a gene transcript is directly modified by polymorphism in regulatory elements. Consequently, transcript abundance might be considered as a quantitative trait that can be mapped with considerable power. These have been named expression QTLs (eQTLs). The combination of whole-genome genetic association studies and the measurement of global gene expression allows the systematic identification of eQTLs. By assaying gene expression and genetic variation simultaneously on a genome-wide basis in a large number of individuals, statistical genetic methods can be used to map the genetic factors that underpin individual differences in quantitative levels of expression of many thousands of transcripts. Studies have shown that single nucleotide polymorphisms (SNPs) reproducibly associated with complex disorders as well as certain pharmacologic phenotypes are found to be significantly enriched for eQTLs, relative to frequency-matched control SNPs.",
            "score": 116.04413604736328
        },
        {
            "docid": "8767449_16",
            "document": "Public health genomics . Accurate and sensitive prediction of disease, or detection during early stages of disease, could allow the prevention or arrest of disease development as immunotherapy treatments become available. Type 1 diabetes markers associated with disease susceptibility have been identified, for example HLA class II gene variants, however possession of one or more of these genomic markers does not necessarily lead to disease. Lack of progression to disease is likely due to the absence of environmental triggers, absence of other susceptibility genes, presence of protective genes, or differences in the temporal expression or presence of these factors. Combinations of markers have also been associated with susceptibility to type 1 diabetes however again, their presence may not always predict disease development, and conversely, disease may be present without the marker group. Potential variant genes (SNPs) or markers that are linked to the disease include genes for cytokines, membrane-bound ligands, insulin and immune regulatory genes.",
            "score": 114.35453796386719
        },
        {
            "docid": "8054792_5",
            "document": "Background selection . Background selection can be measured by assessing the degree of departure of the levels of neutral variants from the predictions of neutral model-based estimations of mutation rates and genetic drift. However, it is not enough to study variation alone because the two main forms of linked selection, background and hitchhiking, produce a loss in diversity, and the models both predict similar results in genomic regions of high recombination. The relative influence of these two effects is not yet well understood, though methods have been developed for differentiating between the two effects. One technique is to compare levels of nucleotide diversity in regions of low recombination, where the models differ appreciably in their predictions. Thus, studying variation in genomic neighborhoods with relatively low recombination rates, rather than across the whole genome, can yield insights about the relative prevalence of background and hitchhiking selection.",
            "score": 114.21039581298828
        },
        {
            "docid": "24984_45",
            "document": "Personality psychology . Ever since the Human Genome Project allowed for a much more in depth understanding of genetics, there has been an ongoing controversy involving heritability, personality traits, and environmental vs. genetic influence on personality. The human genome is known to play a role in the development of personality. Previously, genetic personality studies focused on specific genes correlating to specific personality traits. Today's view of the gene-personality relationship focuses primarily on the activation and expression of genes related to personality and forms part of what is referred to as behavioural genetics. Genes provide numerous options for varying cells to be expressed; however, the environment determines which of these are activated. Many studies have noted this relationship in varying ways in which our bodies can develop, but the interaction between genes and the shaping of our minds and personality is also relevant to this biological relationship. DNA-environment interactions are important in the development of personality because this relationship determines what part of the DNA code is actually made into proteins that will become part of an individual. It has been noted that while different choices are made available by the genome, in the end, the environment is the ultimate determinant of what becomes activated. Small changes in DNA in individuals are what lead to the uniqueness of every person as well as differences in looks, abilities, brain functioning, and all the factors that culminate to develop a cohesive personality.",
            "score": 114.15275573730469
        },
        {
            "docid": "22921_61",
            "document": "Psychology . All researched psychological traits are influenced by both genes and environment, to varying degrees. These two sources of influence are often confounded in observational research of individuals or families. An example is the transmission of depression from a depressed mother to her offspring. Theory may hold that the offspring, by virtue of having a depressed mother in his or her (the offspring's) environment, is at risk for developing depression. However, risk for depression is also influenced to some extent by genes. The mother may both carry genes that contribute to her depression but will also have passed those genes on to her offspring thus increasing the offspring's risk for depression. Genes and environment in this simple transmission model are completely confounded. Experimental and quasi-experimental behavioral genetic research uses genetic methodologies to disentangle this confound and understand the nature and origins of individual differences in behavior. Traditionally this research has been conducted using twin studies and adoption studies, two designs where genetic and environmental influences can be partially un-confounded. More recently, the availability of microarray molecular genetic or genome sequencing technologies allows researchers to measure participant DNA variation directly, and test whether individual genetic variants within genes are associated with psychological traits and psychopathology through methods including genome-wide association studies. One goal of such research is similar to that in positional cloning and its success in Huntington's: once a causal gene is discovered biological research can be conducted to understand how that gene influences the phenotype. One major result of genetic association studies is the general finding that psychological traits and psychopathology, as well as complex medical diseases, are highly polygenic, where a large number (on the order of hundreds to thousands) of genetic variants, each of small effect, contribute to individual differences in the behavioral trait or propensity to the disorder. Active research continues to understand the genetic and environmental bases of behavior and their interaction.",
            "score": 112.7010269165039
        },
        {
            "docid": "30487688_23",
            "document": "Diagnosis of schizophrenia . Estimates of the heritability of schizophrenia is around 80%, which implies that 80% of the individual differences in risk to schizophrenia is explained by individual differences in genetics. Although many genetic variants associated with schizophrenia have been identified, their effects are usually very small, so they are combined onto a polygenic risk score. These scores, despite accounting for hundreds of variants, only explain up to 6% in symptom variation and 7% of the risk for developing the disease. An example of a well-studied genetic biomarker in schizophrenia is the single nucleotide polymorphism in the HLA-DQB1 gene, which is part of the human leukocyte antigen (HLA) complex. A G to C replacement on position 6672 predicts risk of agranulocytosis, a side effect of clozapine that can be fatal.",
            "score": 111.75765991210938
        },
        {
            "docid": "52142704_3",
            "document": "Polygenic score . Polygenic scores are widely employed in animal, plant, and behavioral genetics for predicting and understanding genetic architectures. In a genome-wide association study (GWAS), polygenic scores having substantially higher predictive performance than the genome-wide statistically-significant hits indicates that the trait in question is affected by a larger number of variants than just the hits and larger sample sizes will yield more hits; a conjunction of low variance explained and high heritability as measured by GCTA, twin studies or other methods, indicates that a trait may be massively polygenic and affected by thousands of variants. Once a polygenic score has been created, which explains at least a few percent of a phenotype's variance and can therefore be assumed to effectively incorporate a significant fraction of the genetic variants affecting that phenotype, it can be used in several different ways: as a lower bound to test whether heritability estimates may be biased; as a measure of genetic overlap of traits (genetic correlation), which might indicate e.g. shared genetic bases for groups of mental disorders; as a means to assess group differences in a trait such as height, or to examine changes in a trait over time due to natural selection indicative of a soft selective sweep (as e.g. for intelligence where the changes in frequency would be too small to detect on each individual hit but not on the overall polygenic score); in Mendelian randomization (assuming no pleiotropy with relevant traits); to detect & control for the presence of genetic confounds in outcomes (e.g. the correlation of schizophrenia with poverty); or to investigate gene\u2013environment interactions.",
            "score": 111.08576202392578
        },
        {
            "docid": "44248347_18",
            "document": "Gene Disease Database . This one of the largest resources available for all genomic and genetic studies, it provides a centralized resource for geneticists, molecular biologists and other researchers studying the genomes of our own species and other vertebrates and model disease organisms. Ensembl is one of several well-known genome browsers for the retrieval of genomic-disease information. Ensembl imports variation data from a variety of different sources, Ensembl predicts the effects of variants. For each variation that is mapped to the reference genome, each Ensembl transcript is identified that overlap the variation. Then it uses a rule-based approach to predict the effects that each allele of the variation may have on the transcript. The set of consequence terms, defined by the Sequence Ontology (SO) can be currently assigned to each combination of an allele and a transcript. Each allele of each variation may have a different effect in different transcripts. A variety of different tools are used to predict human mutations in the Ensembl database, one of the most widely used is SIFT, that predicts whether an amino acid substitution is likely to affect protein function based on sequence homology and the physic-chemical similarity between the alternate amino acids. The data provided for each amino acid substitution is a score and a qualitative prediction (either 'tolerated' or 'deleterious'). The score is the normalized probability that the amino acid change is tolerated so scores near 0 are more likely to be deleterious. The qualitative prediction is derived from this score such that substitutions with a score < 0.05 are called 'deleterious' and all others are called 'tolerated'.SIFT can be applied to naturally occurring nonsynonymous polymorphisms and laboratory-induced missense mutations, that will lead to build relationships in phenotype characteristics, proteomics and genomics",
            "score": 109.63938903808594
        },
        {
            "docid": "25_15",
            "document": "Autism . It has long been presumed that there is a common cause at the genetic, cognitive, and neural levels for autism's characteristic triad of symptoms. However, there is increasing suspicion that autism is instead a complex disorder whose core aspects have distinct causes that often co-occur. Autism has a strong genetic basis, although the genetics of autism are complex and it is unclear whether ASD is explained more by rare mutations with major effects, or by rare multigene interactions of common genetic variants. Complexity arises due to interactions among multiple genes, the environment, and epigenetic factors which do not change DNA sequencing but are heritable and influence gene expression. Many genes have been associated with autism through sequencing the genomes of affected individuals and their parents.",
            "score": 108.91532897949219
        },
        {
            "docid": "50518079_11",
            "document": "Human Genome Structural Variation . The 1000 genomes project was able to successfully produce the DNA sequence of the human genome. They provided much sequencing data from many populations to analyze as well as a reference human genome for comparison and future studies. One study took advantage of this resource to question the structural variation differences between genomes from whole genome sequence data. It was known that human diseases are affected by duplications and deletions and that copy number analysis is common but multiallelic copy number variants (mCNVs) were not as well studied. The researchers got their data from the 1000 genomes project and analyzed 849 different genomes from a variety of populations that were sequenced in order to find large mCNVs. From their analysis, they found that mCNVs create most genetic variation in gene dosage compared to other structural variants and that the gene expression variation is created by the dosage diversity of genes created by mCNVs. The study underlined the great significance that structural variants, especially mCNVs, have on gene dosage which leads to variable gene expressions and human phenotypic diversity in the population.",
            "score": 108.4529800415039
        },
        {
            "docid": "841093_6",
            "document": "Essential hypertension . More than 50 genes have been examined in association studies with hypertension, and the number is constantly growing. One of these genes is the angiotensinogen (AGT) gene, studied extensively by Kim et al. They showed that increasing the number of AGT increases the blood pressure and hence this may cause hypertension. In single variant tests, it has been shown that SNPs were enriched for variants associated with adiposity, type 2 diabetes, coronary heart disease and kidney function in previously published GWAS, providing evidence that genetic loci related to blood pressure contribute to cardiovascular outcomes. Twins have been included in studies measuring ambulatory blood pressure; from these studies it has been suggested that there is a large genetic influence on essential hypertension. Supporting data has emerged from animal studies as well as clinical studies in human populations. The majority of these studies support the concept that the inheritance is probably multifactorial or that a number of different genetic defects each has an elevated blood pressure as one of its phenotypic expressions. However, the genetic influence on hypertension is not fully understood at the moment. It is believed that linking hypertension-related phenotypes with specific variations of the genome may yield definitive evidence of heritability. Another view is that hypertension can be caused by mutations in single genes, inherited on a Mendelian basis.",
            "score": 108.22784423828125
        },
        {
            "docid": "4726434_5",
            "document": "Attention deficit hyperactivity disorder controversies . ADHD is said to be highly heritable: twin studies suggest that genetics explain 70-80% in the variation of ADHD. However, interest in the potential role of gene-environment interactions in ADHD is also increasing; maternal alcohol or tobacco use during pregnancy may be one contributor. It has also been argued that ADHD is a heterogeneous disorder with multiple genetic and environmental factors converging on similar neurological changes. Authors of a review of ADHD etiology in 2004 noted: \"Although several genome-wide searches have identified chromosomal regions that are predicted to contain genes that contribute to ADHD susceptibility, to date no single gene with a major contribution to ADHD has been identified.\" However, many further studies have occurred since, and the same is true for many other heritable human traits (e.g., schizophrenia). The Online Mendelian Inheritance in Man (OMIM) database has a listing for ADHD under autosomal dominant heritable conditions, claiming that multiple genes contribute to the disorder. As of 2014, OMIM listed 6 genes with variants that have been associated with ADHD.",
            "score": 107.97456359863281
        },
        {
            "docid": "50518079_17",
            "document": "Human Genome Structural Variation . The factors that contribute to the development of schizophrenia have been studied extensively. A very recent study was conducted on the mechanism and genes responsible for schizophrenia development. It had been previously shown that variation at an MHC locus was associated with the development of schizophrenia. This study found that the association is caused partly by the complement component 4 (C4) genes and therefore implying that allele variants of the C4 genes contribute to the development of schizophrenia. Linkage disequilibrium helped researchers identify which C4 structural variant an individual had by looking at the SNP haplotypes. The SNP haplotypes and the C4 alleles were linked which was why they were in linkage disequilibrium, meaning that they segregated together. A single structural C4 variant was associated with many different SNP haplotypes, but different SNP haplotypes where associated with only one C4 structural variant. This was due to the linkage disequilibrium which allowed the researchers to determine the C4 structural variant easily by looking at the SNP haplotype. Their data suggested this because the results showed that the structural variants of C4 express the C4A protein at different levels and this difference in higher C4A protein expressions were associated with higher rates of schizophrenia development. The different structural variant alleles of the same gene were shown to have different phenotypes and susceptibility to disease. These studies exhibit the breadth of the involvement and significance of structural variation on the human genome. Its importance is demonstrated with its contribution to phenotypic diversity and disease susceptibility.",
            "score": 107.24358367919922
        },
        {
            "docid": "235550_13",
            "document": "Sequence analysis . Gene prediction or gene finding refers to the process of identifying the regions of genomic DNA that encode genes. This includes protein-coding genes as well as RNA genes, but may also include the prediction of other functional elements such as regulatory regions. Gene finding is one of the first and most important steps in understanding the genome of a species once it has been sequenced. In general, the prediction of bacterial genes is significantly simpler and more accurate than the prediction of genes in eukaryotic species that usually have complex intron/exon patterns. Identifying genes in long sequences remains a problem, especially when the number of genes is unknown. Hidden markov models can be part of the solution. Machine learning has played a significant role in predicting the sequence of transcription factors. Traditional sequencing analysis focused on the statistical parameters of the nucleotide sequence itself (The most common programs used are listed in Table 4.1). Another method is to identify homologous sequences based on other known gene sequences (Tools see Table 4.3). The two methods described here are focused on the sequence. However, the shape feature of these molecules such as DNA and protein have also been studied and proposed to have an equivalent, if not higher, influence on the behaviors of these molecules.",
            "score": 107.09429931640625
        },
        {
            "docid": "38203371_7",
            "document": "Classical genetics . Classical genetics is the part of genetics that is solely about the method in which genetic traits are transmitted via the acts of reproduction. Genetics is, generally, the study of genes, genetic variation, and heredity. The process by which characteristics are passed down from parents to their offspring is called heredity. In the sense of classical genetics, variation is known as the lack of resemblance in related individuals and can be categorized as discontinuous or continuous. Genes are a fundamental part of DNA that is aligned linearly on a eukaryotic chromosome. Chemical information that is transported and encoded by each gene is referred to as a trait. Many organisms possess two genes for each individual trait that is present within that particular individual. These paired genes that control the same trait is classified as an allele. In an individual, the allelic genes that are expressed can be either homozygous, meaning the same, or heterozygous, meaning different. Many pairs of alleles have differing effects that are portrayed in an offspring's phenotype and genotype. The phenotype is a general term that defines an individual's visible, physical traits. The genotype of an offspring is known as its genetic makeup. The alleles of genes can either be dominant or recessive. A dominant allele needs only one copy to be expressed while a recessive allele needs two copies (homozygous) in a diploid organism to be expressed. Dominant and recessive alleles help to determine the offspring\u2019s genotypes, and therefore phenotypes.",
            "score": 106.94143676757812
        },
        {
            "docid": "43778895_11",
            "document": "Predictive genomics . Type 2 diabetes (T2D), an extremely common metabolic disorder, has demonstrated interplay between many environmental and genetic risk factors leading to disease onset. A number of risk assessment models incorporating a number of demographic, environmental and clinical risk factors are already shown to elicit reasonable discrimination in case-control studies; it has been proposed that identifying genetic variants that contribute to T2D as for standalone prediction or in conjunction with current risk models can improve prediction of T2D risk, if current models lack sufficient coverage of the full effect of an individual's genotype. Approximately 20 associated SNPs have been replicated in T2D; however, their effect sizes do not seem to be substantial: OR 1.37 for SNPs in the \"TCF7L2\" gene purported to give highest genetic risk.",
            "score": 106.8258285522461
        },
        {
            "docid": "25058426_5",
            "document": "Expression quantitative trait loci . Mapping eQTLs is done using standard QTL mapping methods that test the linkage between variation in expression and genetic polymorphisms. The only considerable difference is that eQTL studies can involve a million or more expression microtraits. Standard gene mapping software packages can be used, although it is often faster to use custom code such as QTL Reaper or the web-based eQTL mapping system GeneNetwork. GeneNetwork hosts many large eQTL mapping data sets and provide access to fast algorithms to map single loci and epistatic interactions. As is true in all QTL mapping studies, the final steps in defining DNA variants that cause variation in traits are usually difficult and require a second round of experimentation. This is especially the case for trans eQTLs that do not benefit from the strong prior probability that relevant variants are in the immediate vicinity of the parent gene. Statistical, graphical, and bioinformatic methods are used to evaluate positional candidate genes and entire systems of interactions.",
            "score": 105.79190826416016
        },
        {
            "docid": "16019737_8",
            "document": "Tiling array . Another popular use of tiling arrays is in finding expressed genes. Traditional methods of gene prediction for annotation of genomic sequences have had problems when used to map the transcriptome, such as not producing an accurate structure of the genes and also missing transcripts entirely. The method of sequencing cDNA to find transcribed genes also runs into problems, such as failing to detect rare or very short RNA molecules, and so do not detect genes that are active only in response to signals or specific to a time frame. Tiling arrays can solve these issues. Due to the high resolution and sensitivity, even small and rare molecules can be detected. The overlapping nature of the probes also allows detection of non-polyadenylated RNA and can produce a more precise picture of gene structure. Earlier studies on chromosome 21 and 22 showed the power of tiling arrays for identifying transcription units. The authors used 25-mer probes that were 35bp apart, spanning the entire chromosomes. Labeled targets were made from polyadenylated RNA. They found many more transcripts than predicted and 90% were outside of annotated exons. Another study with Arabidopsis used high-density oligonucleotide arrays that cover the entire genome. More than 10 times more transcripts were found than predicted by ESTs and other prediction tools. Also found were novel transcripts in the centromeric regions where it was thought that no genes are actively expressed. Many noncoding and natural antisense RNA have been identified using tiling arrays.",
            "score": 105.22725677490234
        },
        {
            "docid": "18143331_12",
            "document": "Neurogenetics . Advances in molecular biology techniques and the species-wide genome project have made it possible to map out an individual's entire genome. Whether genetic or environmental factors are primarily responsible for an individual's personality has long been a topic of debate. Thanks to the advances being made in the field of neurogenetics, researchers have begun to tackle this question by beginning to map out genes and correlate them to different personality traits. There is little to no evidence to suggest that the presence of a \"single\" gene indicates that an individual will express one style of behavior over another; rather, having a specific gene could make one more predisposed to displaying this type of behavior. It is starting to become clear that most genetically influenced behaviors are due to the effects of many variants within \"many\" genes, in addition to other neurological regulating factors like neurotransmitter levels. Due to fact that many behavioral characteristics have been conserved across species for generations, researchers are able to use animal subjects such as mice and rats, but also fruit flies, worms, and zebrafish, to try to determine specific genes that correlate to behavior and attempt to match these with human genes.",
            "score": 105.16019439697266
        },
        {
            "docid": "327061_2",
            "document": "Gene flow . In population genetics, gene flow (also known as gene migration or allele flow) is the transfer of genetic variation from one population to another. If the rate of gene flow is high enough, then two populations are considered to have equivalent genetic diversity and therefore effectively a single population. It has been shown that it takes only \"One migrant per generation\" to prevent population diverging due to drift. Gene flow is an important mechanism for transferring genetic diversity among populations. Migrants result change the distribution of genetic diversity within the populations, by modifying the allele frequencies (the proportion of members carrying a particular variant of a gene). High rates of gene flow can reduce the genetic differentiation between the two groups, increasing homogeneity. For this reason,gene flow has been thought to constrain speciation by combining the gene pools of the groups, and thus, preventing the development of differences in genetic variation that would have led to full speciation. In some cases migration may also result in the addition of novel genetic variants to the gene pool of a species or population.",
            "score": 104.93731689453125
        },
        {
            "docid": "4421042_15",
            "document": "Histone H2A . H2A is coded by many genes in the human genome, including:  H2AFB1,  H2AFB2,  H2AFB3,  H2AFJ,  H2AFV,  H2AFX,  H2AFY,  H2AFY2,  and H2AFZ Genetic patterns among the different H2A molecules are mostly conserved among variants. The variability in gene expression exists among the regulatory machinery that manages H2A expression. Researchers studied eukaryotic evolutionary lineages of histone proteins and found diversification among the regulatory genes. The greatest differences were observed in core histone gene cis-regulatory sequence motifs and associated protein factors. Variability in gene sequence was seen in bacterial, fungi, plant, and mammalian genes.  One variant of H2A protein is H2ABbd (Barr body deficient) variant. This variant is composed of a different genetic sequence compared to H2A. The variant functions with transcriptionally active domains. Other variations associated with H2ABbd are located within its C-terminus. H2ABbd has a shorter C-terminal domain compared to the large C-terminal found on H2A. The two C terminals are about 48% identical. H2ABbd functions with active chromosomes. Thus far, it is missing from Xi chromosomes in fibroblast cells. Lastly, it found to be associated with acetylated H4. Different functions of H2A.Z compared to H2A are correlated with genetic differences between H2A and the variant. Resistance to nucleosomes occurs in H2A.Z by binding to H1 factor.  H2A.Z gene is an essential gene in yeast and it is denoted as Htz1. Comparatively, vertebrates have two H2A.Z genes. These genes, H2A.Z1 and H2A.Z2 encode for proteins that differ from H2A.Z by three residents.  At first researchers figured that these genes were redundant; however, when a mutant H2A.Z1 was created, it resulted in lethality during mammalian tests. Therefore, H2A.Z1 is an essential gene. On the other hand, researchers have not identified the function of H2A.Z2 variant. It is known that it is transcribed in mammals and this gene expression is conserved among mammalian species. This conservation suggests that the gene is functional. When studying H2A.Z in plants species, the protein different among residues from species to species. These differences contribute to differences in cell-cycle regulation. This phenomenon was only observed in plants.  Phylogenetic trees were created to show the divergence of variants from their ancestors. The divergence of variant, H2A.X, from H2A occurred at multiple origins in a phylogenetic tree. Acquisition of the phosphorylation motif was consistent with the many origins of H2A that arose from an ancestral H2A.X. Finally, the presence of H2A.X and absence of H2A in fungi leads researchers to believe that H2A.X was the original ancestor of the histone protein H2A",
            "score": 104.43190002441406
        },
        {
            "docid": "45552195_12",
            "document": "Albert de la Chapelle . Beginning in 1997 a main component of Dr. de la Chapelle\u2019s research has centered on detecting and annotating gene mutations that predispose to thyroid cancer, TC. Relying on ample experience from work with the Finnish Disease Heritage (see above) the de la Chapelle laboratory has used linkage and linkage disequilibrium analysis in search of genes with high penetrance. For genes with low penetrance, genome-wide associated analysis (GWAS) has been carried out. Presently some 10 high-penetrance genes and some 15 low-penetrance variants have been found and annotated. It is becoming increasingly clear that many predisposing genes of high penetrance exist, but each is rare or ultra-rare. Instead, single nucleotide polymorphisms and other variants of low penetrance account for most of the genetically determined risk. Ongoing research in the de la Chapelle lab aims at elucidating the functional aspects of the detected genes or variants. Ultimately, when up and downstream pathways are established, this information will inform research attempting to create drugs to treat TC. Moreover, the low-penetrance variants\u2019 effects are additive, allowing the extent of genetic risk of TC to be predicted in individuals under study for TC. The de la Chapelle lab belongs to a large and active Thyroid Cancer Program at The Ohio State University. The clinical arm of the group is essential in providing crucial material for the laboratory experiments at hand. Moreover, with an active group of genetic counselors at OSU the acquisition and characterization of families with more than one member affected by TC is efficient and useful for genetic studies.",
            "score": 104.32194519042969
        },
        {
            "docid": "7972254_7",
            "document": "Predictive medicine . The future of medicine's focus may potentially shift from treating existing diseases, typically late in their progression, to preventing disease before it sets in. Predictive health and predictive medicine is based on probabilities: while it evaluates susceptibility to diseases, it is not able to predict with 100% certainty that a specific disease will occur. Unlike many preventive interventions that are directed at groups (e.g., immunization programs), predictive medicine is conducted on an individualized basis. For example, glaucoma is a monogenic disease whose early detection can allow to prevent permanent loss of vision. Predictive medicine is expected to be most effective when applied to polygenic multifactorial disease that are prevalent in industrialized countries, such as diabetes mellitus, hypertension, and myocardial infarction. With careful usage, predictive medicine methods such as genetic screens can help diagnose inherited genetic disease caused by problems with a single gene (such as cystic fibrosis) and help early treatment. Some forms of cancer and heart disease are inherited as single-gene diseases and some people in these high-risk families may also benefit from access to genetic tests. As more and more genes associated with increased susceptibility to certain diseases are reported, predictive medicine becomes more useful.",
            "score": 103.94398498535156
        },
        {
            "docid": "50518079_16",
            "document": "Human Genome Structural Variation . Structural variation studies became increasingly popular due to the discovery of their possible roles and effects in the human genome. Copy number variation is a very important type of structural variation and has been studied extensively. A study on the influence of the CCL3L1 gene on HIV-1/AIDS susceptibility tested if the copy number of the CCL3L1 gene had any effect on an individual\u2019s susceptibility to HIV-1/AIDS. They sampled several different individuals and populations for their CCL3L1 copy number and compared it to their HIV acquirement risk. They found that there is an association between higher amounts in the copy number of CCL3L1 and susceptibility to HIV and AIDS since individuals who were more prone to HIV had a low copy number of CCL3L1. This difference in copy number was shown to play a possibly significant role in HIV susceptibility due to this association. Another study that focused on the pathogenesis of human obesity tested if structural variation of the NPY4R gene was significant in obesity. Studies had previously shown that 10q11.22 CNV had an association with obesity and that several copy number variants were associated with obesity. Their CNV analysis revealed that the NPY4R gene had a much higher frequency of 10q11.22 CNV loss in the patient population. The control population, on the other hand, had more CNV gain in the same region. This led the researchers to conclude that the NPY4R gene played an important role in the pathogenesis of obesity due to its copy number variation. Studies involving copy number variation as well as other structural variants have brought new insights to the significant roles that structural variants play in the human genome.",
            "score": 103.4523696899414
        },
        {
            "docid": "44248347_4",
            "document": "Gene Disease Database . Genetic illnesses are caused by aberrations in genes or chromosomes. Many genetic diseases are developed from before birth. Genetic disorders account for a significant number of the health care problems in our society. Advances in the understanding of this diseases have increased both the life span and quality of life for many of those affected by genetic disorders. Recent developments in bioinformatics and laboratory genetics have made possible the better delineation of certain malformation and mental retardation syndromes, so that their mode of inheritance can be understood. This information enables the genetic counselor to predict the risk for occurrence of a large number of genetic disorders. Most genetic counseling is done, however, only after the birth of at least one affected individual has alerted the family to their predilection for having children with a genetic disorder. The association of a single gene to a disease is rare and a genetic disease may or may not be a transmissible disorder. Some genetic diseases are inherited from the parent\u2019s genes, but others are caused by new mutations or changes to the DNA. In other occurrences, the same disease, for instance, some forms of carcinoma or melanoma, may stem from an inbred condition in some people, from new changes in other people, and from non-genetic causes in still other individuals.",
            "score": 102.86312866210938
        },
        {
            "docid": "215038_12",
            "document": "Enhancer (genetics) . The development of genomic and epigenomic technologies, however, has dramatically changed the outlook for cis-regulatory modules (CRM) discovery. Next-generation sequencing (NGS) methods now enable high-throughput functional CRM discovery assays, and the vastly increasing amounts of available data, including large-scale libraries of transcription factor-binding site (TFBS) motifs, collections of annotated, validated CRMs, and extensive epigenetic data across many cell types, are making accurate computational CRM discovery an attainable goal. An example of NGS-based approach called DNase-seq have enabled identification of nucleosome-depleted, or open chromatin regions, which can contain CRM. Computational methods include comparative genomics, clustering of known or predicted TF-binding sites, and supervised machine-learning approaches trained on known CRMs.  All of these methods have proven effective for CRM discovery, but each has its own considerations and limitations, and each is subject to a greater or lesser number of false-positive identifications. In the comparative genomics approach, sequence conservation of non-coding regions can be indicative of enhancers. Sequences from multiple species are aligned, and conserved regions are identified computationally. Identified sequences can then be attached to a reporter gene such as green fluorescent protein or lacZ to determine the \"in vivo\" pattern of gene expression produced by the enhancer when injected into an embryo. mRNA expression of the reporter can be visualized by \"in situ\" hybridization, which provides a more direct measure of enhancer activity, since it is not subjected to the complexities of translation and protein folding. Although much evidence has pointed to sequence conservation for critical developmental enhancers, other work has shown that the function of enhancers can be conserved with little or no primary sequence conservation. For example, the \"RET\" enhancers in humans have very little sequence conservation to those in zebrafish, yet both species' sequences produce nearly identical patterns of reporter gene expression in zebrafish. Similarly, in highly diverged insects (separated by around 350 million years), similar gene expression patterns of several key genes was found to be regulated through similarly constituted CRMs although these CRMs do not show any appreciable sequence conservation detectable by standard sequence alignment methods such as BLAST.",
            "score": 102.69535827636719
        },
        {
            "docid": "11808249_6",
            "document": "Genome-wide association study . Any two human genomes differ in millions of different ways. There are small variations in the individual nucleotides of the genomes (SNPs) as well as many larger variations, such as deletions, insertions and copy number variations. Any of these may cause alterations in an individual's traits, or phenotype, which can be anything from disease risk to physical properties such as height. Around the year 2000, prior to the introduction of GWA studies, the primary method of investigation was through inheritance studies of genetic linkage in families. This approach had proven highly useful towards single gene disorders. However, for common and complex diseases the results of genetic linkage studies proved hard to reproduce. A suggested alternative to linkage studies was the genetic association study. This study type asks if the allele of a genetic variant is found more often than expected in individuals with the phenotype of interest (e.g. with the disease being studied). Early calculations on statistical power indicated that this approach could be better than linkage studies at detecting weak genetic effects.",
            "score": 102.6483154296875
        },
        {
            "docid": "24127822_2",
            "document": "Leiden Open Variation Database . The Leiden Open Variation Database (LOVD) is a free, flexible web-based open source database developed in the Leiden University Medical Center in the Netherlands, designed to collect and display variants in the DNA sequence. The focus of an LOVD is usually the combination between a gene and a genetic (heritable) disease. All sequence variants found in individuals are collected in the database, together with information about whether they could be causally connected to the disease (i.e. a disease-causing variant or mutation) or not (i.e. a non-disease causing variant). Specialized doctors (clinical geneticists) use LOVDs to diagnose and advise patients carrying a genetic disease. Ideally, if a patient has been screened for mutations and one has been found, information in LOVD can predict the progress of the disease.",
            "score": 102.58499908447266
        }
    ]
}