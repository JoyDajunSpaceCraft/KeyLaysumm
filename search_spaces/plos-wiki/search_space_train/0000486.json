{
    "q": [
        {
            "docid": "1619306_3",
            "document": "Multisensory integration . Multimodal perception is a scientific term that describes how humans form coherent, valid, and robust perception by processing sensory stimuli from various modalities. Surrounded by multiple objects and receiving multiple sensory stimulations, the brain is faced with the decision of how to categorize the stimuli resulting from different objects or events in the physical world. The nervous system is thus responsible for whether to integrate or segregate certain groups of temporally coincident sensory signals based on the degree of spatial and structural congruence of those stimulations. Multimodal perception has been widely studied in cognitive science, behavioral science, and neuroscience.",
            "score": 77.99794125556946
        },
        {
            "docid": "37556_18",
            "document": "Asperger syndrome . Individuals with AS often have excellent auditory and visual perception. Children with ASD often demonstrate enhanced perception of small changes in patterns such as arrangements of objects or well-known images; typically this is domain-specific and involves processing of fine-grained features. Conversely, compared with individuals with high-functioning autism, individuals with AS have deficits in some tasks involving visual-spatial perception, auditory perception, or visual memory. Many accounts of individuals with AS and ASD report other unusual sensory and perceptual skills and experiences. They may be unusually sensitive or insensitive to sound, light, and other stimuli; these sensory responses are found in other developmental disorders and are not specific to AS or to ASD. There is little support for increased fight-or-flight response or failure of habituation in autism; there is more evidence of decreased responsiveness to sensory stimuli, although several studies show no differences.",
            "score": 67.72671747207642
        },
        {
            "docid": "7973164_13",
            "document": "Anomalous experiences . Psychotic-like symptoms, such as hallucinations and unusual perceptual experience, involve gross alterations in the experience of reality. Normal perception is substantially constructive and what we perceive is strongly influenced by our prior experiences and expectancies. Healthy individuals prone to hallucinations, or scoring highly on psychometric measures of positive schizotypy, tend to show a bias toward reporting stimuli that did not occur under perceptually ambiguous experimental conditions. During visual detection of fast-moving words, undergraduate students scoring highly on positive schizotypy had significantly high rates of false perceptions of words (i.e. reported seeing words that were not included in the experimental trials). Positive schizotypal symptoms in healthy adults seem to predict false perceptions in laboratory tasks and certain environmental parameters such as perceptual load and frequency of visual targets are critical in the generation of false perceptions. When detection of events becomes either effortless or cognitively demanding, generation of such biases can be prevented.",
            "score": 66.45948815345764
        },
        {
            "docid": "24978422_5",
            "document": "Visual adaptation . Perceptual aftereffects for face recognition occur for several different stimuli, including gender, ethnicity, identity, emotion, and attractiveness of a face. The fact that this distinction occurs, implies that face recognition is a process that happens on a higher level and later on in the visual encoding, rather than early on within visual adaptation. The fact that the aftereffects in face recognition in particular are so strong, suggests that it is for the purpose of regulation of how processes work. This provides a sense of constancy in an individual's perception, while adapting to differences and possible versions of a stimulus allows for constancy and stability, and makes it easier to adapt to variations in a stimulus, while recognizing commonalities. These face perception cues are encoded in an individual's brain for extended periods of time, ensuring consistency over the individual's lifespan. A young person would perceive stimuli the same way as an older individual.",
            "score": 52.847702503204346
        },
        {
            "docid": "2286012_6",
            "document": "Adaptation model of nursing . Basic to Roy\u2019s model are three concepts: the human being, adaptation, and nursing. The human being is viewed as a biopsychosocial being who is continually interacting with the environment. The human being\u2019s goal through this interaction is adaptation. According to Roy and Roberts (1981, p.\u00a043), \u2018The person has two major internal processing subsystems, the regulator and the cognator.\" These subsystems are the mechanisms used by human beings to cope with stimuli from the internal and external environment. The regulator mechanism works primarily through the autonomic nervous system and includes endocrine, neural, and perception pathways. This mechanism prepares the individual for coping with environmental stimuli. The cognator mechanism includes emotions, perceptual/information processing, learning, and judgment. The process of perception bridges the two mechanisms (Roy and Roberts, 1981).",
            "score": 57.66768431663513
        },
        {
            "docid": "21107290_6",
            "document": "Bayesian approaches to brain function . A wide range of studies interpret the results of psychophysical experiments in light of Bayesian perceptual models. Many aspects of human perceptual and motor behavior can be modeled with Bayesian statistics. This approach, with its emphasis on behavioral outcomes as the ultimate expressions of neural information processing, is also known for modeling sensory and motor decisions using Bayesian decision theory. Examples are the work of Landy, Jacobs, Jordan, Knill, Kording and Wolpert, and Goldreich.",
            "score": 51.89975905418396
        },
        {
            "docid": "386062_12",
            "document": "Wishful thinking . Some speculate that wishful seeing results from cognitive penetrability in that higher cognitive functions are able to directly influence perceptual experience instead of only influencing perception at higher levels of processing. Those that argue against cognitive penetrability feel that sensory systems operate in a modular fashion with cognitive states exerting their influence only after the stimuli has been perceived. The phenomenon of wishful seeing implicates cognitive penetrability in the perceptual experience. Wishful seeing has been observed to occur in early stages of categorization. Research using ambiguous figures and binocular rivalry exhibit this tendency. Perception is influenced by both top-down and bottom-up processing. In visual processing, bottom-up processing is a rigid route compared to flexible top-down processing. Within bottom-up processing, the stimuli are recognized by fixation points, proximity and focal areas to build objects, while top-down processing is more context sensitive. This effect can be observed via priming as well as with emotional states. The traditional hierarchical models of information processing describe early visual processing as a one-way street: early visual processing goes into conceptual systems, but conceptual systems do not affect visual processes. Currently, research rejects this model and suggests conceptual information can penetrate early visual processing rather than just biasing the perceptual systems. This occurrence is called conceptual or cognitive penetrability. Research on conceptual penetrability utilize stimuli of conceptual-category pairs and measure the reaction time to determine if the category effect influenced visual processing, The category effect is the difference in reaction times within the pairs such as \"Bb\" to \"Bp\". To test conceptual penetrability, there were simultaneous and sequential judgments of pairs. The reaction times decreased as the stimulus onset asynchrony increased, supporting categories affect visual representations and conceptual penetrability. Research with richer stimuli such as figures of cats and dogs allow for greater perceptual variability and analysis of stimulus typicality (cats and dogs were arranged in various positions, some more or less typical for recognition). Differentiating the pictures took longer when they were within the same category (dog-dog) compared between categories (dog-cat) supporting category knowledge influences categorization. Therefore, visual processing measured by physical differential judgments is affected by non-visual processing supporting conceptual penetrability.",
            "score": 61.446247816085815
        },
        {
            "docid": "24978422_3",
            "document": "Visual adaptation . The aftereffects of exposure to a visual stimulus or pattern causes loss of sensitivity to that pattern and induces stimulus bias. An example of this phenomenon is the \"lilac chaser\", introduced by Jeremy Hinton. The stimulus here are lilac circles, that once removed, leave green circles that then become the most prominent stimulus. The fading of the lilac circles is due to a loss of sensitivity to that stimulus and the adaptation to the new stimulus. To experience the \"lilac chaser\" effect, the subject needs to fixate their eyes on the cross in the middle of the image, and after a while the effect will settle in. Visual coding, a process involved in visual adaptation, is the means by which the brain adapts to certain stimuli, resulting in a biased perception of those stimuli. This phenomenon is referred to as visual plasticity; the brain's ability to change and adapt according to certain, repeated stimuli, altering the way information is perceived and processed. The rate and strength of visual adaptation depends heavily on the number of stimuli presented simultaneously, as well as the amount of time for which the stimulus is present. Visual adaptation was found to be weaker when there were more stimuli present. Moreover, studies have found that stimuli can rival each other, which explains why higher numbers of simultaneous stimuli lead to lower stimulus adaptation. Studies have also found that visual adaptation can have a reversing effect; if the stimulus is absent long enough, the aftereffects of visual adaptation will subside. Studies have also shown that visual adaptation occurs in the early stages of processing.",
            "score": 49.31767380237579
        },
        {
            "docid": "1619306_6",
            "document": "Multisensory integration . However, considerations of how unified conscious representations are formed are not the full focus of multisensory Integration research. It is obviously important for the senses to interact in order to maximize how efficiently people interact with the environment. For perceptual experience and behavior to benefit from the simultaneous stimulation of multiple sensory modalities, integration of the information from these modalities is necessary. Some of the mechanisms mediating this phenomenon and its subsequent effects on cognitive and behavioural processes will be examined hereafter. Perception is often defined as one's conscious experience, and thereby combines inputs from all relevant senses and prior knowledge. Perception is also defined and studied in terms of feature extraction, which is several hundred milliseconds away from conscious experience. Notwithstanding the existence of Gestalt psychology schools that advocate a holistic approach to the operation of the brain, the physiological processes underlying the formation of percepts and conscious experience have been vastly understudied. Nevertheless, burgeoning neuroscience research continues to enrich our understanding of the many details of the brain, including neural structures implicated in multisensory integration such as the superior colliculus (SC) and various cortical structures such as the superior temporal gyrus (GT) and visual and auditory association areas. Although the structure and function of the SC are well known, the cortex and the relationship between its constituent parts are presently the subject of much investigation. Concurrently, the recent impetus on integration has enabled investigation into perceptual phenomena such as the ventriloquism effect, rapid localization of stimuli and the McGurk effect; culminating in a more thorough understanding of the human brain and its functions.",
            "score": 78.45282673835754
        },
        {
            "docid": "20429570_14",
            "document": "Motor imagery . Motor imagery is close to the notion of simulation used in cognitive and social neuroscience to account for different processes. An individual who is engaging in simulation may replay his own past experience in order to extract from it pleasurable, motivational or strictly informational properties. Such a view was clearly described by the Swedish physiologist Hesslow. For this author, the simulation hypothesis states that thinking consists of simulated interaction with the environment, and rests on the following three core assumptions: (1) Simulation of actions: we can activate motor structures of the brain in a way that resembles activity during a normal action but does not cause any overt movement; (2) Simulation of perception: imagining perceiving something is essentially the same as actually perceiving it, only the perceptual activity is generated by the brain itself rather than by external stimuli; (3) Anticipation: there exist associative mechanisms that enable both behavioral and perceptual activity to elicit other perceptual activity in the sensory areas of the brain. Most importantly, a simulated action can elicit perceptual activity that resembles the activity that would have occurred if the action had actually been performed.",
            "score": 77.70984613895416
        },
        {
            "docid": "1677048_17",
            "document": "Inattentional blindness . This particular hypothesis bridges the gap between the early and late selection theories. Authors integrate the viewpoint of early selection stating that perception is a limited process (i.e. cognitive resources are limited), and that of the late selection theories assuming perception as an automatic process. This view proposes that the level of processing which occurs for any one stimulus is dependent on the current perceptual load. That is, if the current task is attentionally demanding and its processing exhausts all the available resources, little remains available to process other non-target stimuli in the visual field. Alternatively, if processing requires a small amount of attentional resources, perceptual load is low and attention is inescapably directed to the non-target stimuli.",
            "score": 54.044864654541016
        },
        {
            "docid": "5664_64",
            "document": "Consciousness . In neuroscience, a great deal of effort has gone into investigating how the perceived world of conscious awareness is constructed inside the brain. The process is generally thought to involve two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals arising from sensory organs are transmitted to the brain and then processed in a series of stages, which extract multiple types of information from the raw input. In the visual system, for example, sensory signals from the eyes are transmitted to the thalamus and then to the primary visual cortex; inside the cerebral cortex they are sent to areas that extract features such as three-dimensional structure, shape, color, and motion. Memory comes into play in at least two ways. First, it allows sensory information to be evaluated in the context of previous experience. Second, and even more importantly, working memory allows information to be integrated over time so that it can generate a stable representation of the world\u2014Gerald Edelman expressed this point vividly by titling one of his books about consciousness \"The Remembered Present\". In computational neuroscience, Bayesian approaches to brain function have been used to understand both the evaluation of sensory information in light of previous experience, and the integration of information over time. Bayesian models of the brain are probabilistic inference models, in which the brain takes advantage of prior knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian models have successfully predicted many perceptual phenomena in vision and the nonvisual senses.",
            "score": 79.65398395061493
        },
        {
            "docid": "49045837_6",
            "document": "Spatial ability . Spatial perception is also very relevant in sports. For example, a study found that cricket players who were faster at picking up information from briefly presented visual displays were significantly better batsmen in an actual game. A 2015 study published in the \"Journal of Vision\" found that soccer players had higher perceptual ability for body kinematics such as processing multitasking crowd scenes which involve pedestrians crossing a street or complex dynamic visual scenes. Another study published in the \"Journal of Human Kinetics\" on fencing athletes found that achievement level was highly correlated with spatial perceptual skills such as visual discrimination, visual-spatial relationships, visual sequential memory, narrow attentional focus and visual information processing. A review published in the journal of \"Neuropsychologia\" found that spatial perception involves attributing meaning to an object or space, so that their sensory processing is actually part of semantic processing of the incoming visual information. The review also found that spatial perception involves the human visual system in the brain and the parietal lobule which is responsible for visuomotor processing and visually goal-directed action. Studies have also found that individuals who played first person shooting games had better spatial perceptual skills like faster and more accurate performance in a peripheral and identification task while simultaneously performing a central search. Researchers suggested that, in addition to enhancing the ability to divide attention, playing action games significantly enhances perceptual skills like top-down guidance of attention to possible target locations.",
            "score": 67.74349308013916
        },
        {
            "docid": "35347567_7",
            "document": "Antti Revonsuo . According to Revonsuo, the dreaming brain is particularly suitable model system for the study of consciousness because it generates a conscious experience while being isolated from both sensory input and motor output. Regarding the rival paradigm of visual awareness, Revonsuo argues that it does not allow one to distinguish between consciousness and perception. Revonsuo holds that there is a \"'double dissociation' between consciousness and perceptual input\". Accordingly, dreams are conscious experiences, which occur without any perceptual stimuli, and, conversely, perceptual input does not automatically engender conscious experience. In support of the independence of consciousness from perception, Revonsuo cites Stephen LaBerge's case study on a lucid dreamer performing previously agreed upon eye movements to signal to the experimenters that he had become conscious of the fact that he was dreaming. A second study that supports Revonsuo's view of dreams was conducted by Allan Rechtschaffen and Foulkes (1965). In this study, subjects were made to sleep with their eyelids open, thus allowing the visual cortex to receive visual stimuli. Though their eyes were open, and the perceptual input was accessible, the subjects could not see the stimuli and did not report dreaming of it. It is the brain that is having the internal experience, independent of perceptual input. This internalist view of consciousness leads Revonsuo to compare both dreaming and waking consciousness with a virtual reality simulation decoupled from or only indirectly informed by a brain's external environment.",
            "score": 66.7871356010437
        },
        {
            "docid": "7316408_2",
            "document": "Eleanor J. Gibson . Eleanor Jack Gibson (7 December 1910 \u2013 30 December 2002) was an American psychologist who focused on reading development and perceptual learning in infants and toddlers. In the 1960s and 1970s Gibson, with her husband James J. Gibson, created the Gibsonian ecological theory of development which emphasized how important perception was because it allows humans to adapt to their environments. Perhaps her most well-known contribution to psychology was the \"visual cliff\", which studied depth perception and visual or motor impairments in both human and animal species. This led to a new understanding of perceptual development in infants. The environment provides information for the sensory system to develop with increased stimuli, so perceptual development corresponds with environmental stimuli. Infants develop from adapting to the environment. Gibson was elected to the National Academy of Sciences in 1971 and as a fellow of the American Academy of Arts and Sciences in 1977. In 1992 she was awarded the National Medal of Science, which is the highest scientific honor in the United States, and only five of which have been awarded to psychologists.",
            "score": 59.631184697151184
        },
        {
            "docid": "43374303_4",
            "document": "Andreas K. Engel . Andreas Engel has become known by his work on the so-called \u201ebinding problem\u201c. His research focuses on the hypothesis that temporal synchrony serves for dynamic coordination of signals in the brain. In addition to working on the experimental validation of this hypothesis, Engel pursues research on its cognitive and theoretical implications. As a postdoc with Wolf Singer at the Max Planck Institute for Brain Research at Frankfurt, Engel was involved in studies that demonstrated the relevance of neural synchrony, in particular of so-called gamma waves, for processing of perceptual information. In particular, the group provided evidence that temporal correlations can serve for the binding of features into coherent sensory representations. In addition to addressing the relevance of synchrony and neuronal oscillations in the visual system, the work of Engel's group yielded evidence for a relation between neural synchrony and visual awareness. In addition, Engel and coworkers contributed to demonstrating a functional role of neural synchrony for sensorimotor coupling. In the past 15 years, Engel's group has expanded their work to the human brain, using EEG and MEG in combination with source modeling techniques. The results of these studies demonstrate the importance of neuronal oscillations and synchrony for perceptual processing, attention, working memory, decision-making and consciousness. Recent work of the group on the interaction of visual, auditory and tactile systems suggests a role of temporal binding for multisensory integration. Furthermore, the group has developed novel methods for the electrophysiological analysis of resting state network activity. Engel's group also applies these approaches for the study of network malfunction in patients with movement disorders, multiple sclerosis and schizophrenia, in studies on pain, and altered networks after early sensory deprivation.  Engel also explores implications of these neurophysiogical results for theories of perception, cognition and action. A major focus of his work are the implications of the studies on neural synchrony for understanding the neural correlates of consciousness. Recent papers address links between neural dynamics and enactive views of cognition, investigating the grounding of cognition in sensorimotor coupling.",
            "score": 56.953649044036865
        },
        {
            "docid": "34042719_5",
            "document": "Visual processing abnormalities in schizophrenia . Motion perception is an important visual function and occurs from the earliest stages of cortical visual processing, with individual neurons being tuned to a preferred direction of motion. The cortical area MT (medial temporal cortex, also known as V5) plays a significant role in motion processing, and deactivation of this region using Transcranial magnetic stimulation can affect perception of motion. Subjects with schizophrenia have shown abnormalities in perceptual judgments of motion, speed and direction, with deficits in these judgments generally being reported. It has been suggested that these findings are related to the aforementioned magnocellular deficit purported to exist in this disorder. Inhibition of motion perception by the addition of a surround stimulus has also been examined in schizophrenia, with one group finding evidence both of impaired motion perception and weaker perceptual suppression effects in schizophrenia. This agrees with the findings mentioned previously related to weaker suppression of perceived contrast in this disorder. However, another recent report has disputed this finding, instead showing evidence consistent with stronger surround influence on motion perception in schizophrenia.",
            "score": 59.00258135795593
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 50.8012570142746
        },
        {
            "docid": "25335695_5",
            "document": "Perceptual learning . Perceptual learning is prevalent and occurs continuously in everyday life. As our perceptual system adapts to the natural world, we become better at discriminating between different stimuli when they belong to different categories than when they belong to the same category. We also tend to become less sensitive to the differences between two instances of the same category. These effects are described as the result of categorical perception. Categorical perception effects do not transfer across domains.",
            "score": 58.696723222732544
        },
        {
            "docid": "10184074_2",
            "document": "Perceptual narrowing . Perceptual narrowing is a developmental process during which the brain uses environmental experiences to shape perceptual abilities. This process improves the perception of things that people experience often and causes them to experience a decline in the ability to perceive some things to which they are not often exposed. This phenomenon is a result of neuroplasticity, including Hebbian learning and synaptic pruning. Through these mechanisms, neural pathways that are more consistently used are strengthened, making them more efficient, while those pathways that are unused become less efficient. This process is most evident during sensitive periods of development. The prevailing theory is that human infants are born with the ability to sense a wide variety of stimuli, and as they age, they begin to selectively narrow these perceptions by categorizing them in a more socio-culturally relevant way. Most of the research in this area focuses on facial discrimination and phoneme distinction in human infants. Perceptual narrowing has also been implicated in synaesthesia.",
            "score": 59.61473023891449
        },
        {
            "docid": "739262_10",
            "document": "Neural correlate . Neurophysiological studies in animals provided some insights on the neural correlates of conscious behavior. Vernon Mountcastle, in the early 1960s, set up to study this set of problems, which he termed \"the Mind/Brain problem\", by studying the neural basis of perception in the somatic sensory system. His labs at Johns Hopkins were among the first, along with Edward V.Evarts at NIH, to record neural activity from behaving monkeys. Struck with the elegance of SS Stevens approach of magnitude estimation, Mountcastle's group discovered three different modalities of somatic sensation shared one cognitive attribute: in all cases the firing rate of peripheral neurons was linearly related to the strength of the percept elicited. More recently, Ken H. Britten, William T. Newsome, and C. Daniel Salzman have shown that in area MT of monkeys, neurons respond with variability that suggests they are the basis of decision making about direction of motion. They first showed that neuronal rates are predictive of decisions using signal detection theory, and then that stimulation of these neurons could predictably bias the decision. Such studies were followed by Ranulfo Romo in the somatic sensory system, to confirm, using a different percept and brain area, that a small number of neurons in one brain area underlie perceptual decisions.",
            "score": 60.96066343784332
        },
        {
            "docid": "21402758_43",
            "document": "Qualia . E. J. Lowe, of Durham University, denies that holding to indirect realism (in which we have access only to sensory features internal to the brain) necessarily implies a Cartesian dualism. He agrees with Bertrand Russell that our \"retinal images\"\u2014that is, the distributions across our retinas\u2014are connected to \"patterns of neural activity in the cortex\" (Lowe 1986). He defends a version of the Causal Theory of Perception in which a causal path can be traced between the external object and the perception of it. He is careful to deny that we do any inferring from the sensory field, a view which he believes allows us to found an access to knowledge on that causal connection. In a later work he moves closer to the non-epistemic theory in that he postulates \"a wholly non-conceptual component of perceptual experience\", but he refrains from analyzing the relation between the perceptual and the \"non-conceptual\". Most recently he has drawn attention to the problems that hallucination raises for the direct realist and to their disinclination to enter the discussion on the topic.",
            "score": 68.13015735149384
        },
        {
            "docid": "10751304_11",
            "document": "Motion-induced blindness . Hsu \"et al.\" (2004) compared MIB to a similar phenomenon of perceptual filling-in (PFI), which likewise reveals a striking dissociation between the percept and the sensory input. They describe both as visual attributes which are perceived in a certain region of the visual field regardless of being in the background (in the same manner as colour, brightness or texture) thus inducing target disappearance. They argue that because in both MIB and PFI the disappearance; or the incorporation of the background motion stimuli; becomes more profound with an increase in eccentricity, decrease in contrast and when perceptual grouping with other stimuli is controlled for; the two illusions are very likely to be a result of intermutual processes. Since MBI and PFI show to be structurally similar, it seems plausible that MIB can be a phenomenon responsible for completing missing information across the blind spot and scotomas where motion is involved.",
            "score": 61.37307596206665
        },
        {
            "docid": "37940820_2",
            "document": "Emotion perception . Emotion perception refers to the capacities and abilities of recognizing and identifying emotions in others, in addition to biological and physiological processes involved. Emotions are typically viewed as having three components: subjective experience, physical changes, and cognitive appraisal; emotion perception is the ability to make accurate decisions about another's subjective experience by interpreting their physical changes through sensory systems responsible for converting these observed changes into mental representations. The ability to perceive emotion is believed to be both innate and subject to environmental influence and is also a critical component in social interactions. How emotion is experienced and interpreted depends on how it is perceived. Likewise, how emotion is perceived is dependent on past experiences and interpretations. Emotion can be accurately perceived in humans. Emotions can be perceived visually, audibly, through smell and also through bodily sensations and this process is believed to be different from the perception of non-emotional material.",
            "score": 69.04645371437073
        },
        {
            "docid": "25140_19",
            "document": "Perception . \"Perceptual constancy\" is the ability of perceptual systems to recognize the same object from widely varying sensory inputs. For example, individual people can be recognized from views, such as frontal and profile, which form very different shapes on the retina. A coin looked at face-on makes a circular image on the retina, but when held at angle it makes an elliptical image. In normal perception these are recognized as a single three-dimensional object. Without this correction process, an animal approaching from the distance would appear to gain in size. One kind of perceptual constancy is \"color constancy\": for example, a white piece of paper can be recognized as such under different colors and intensities of light. Another example is \"roughness constancy\": when a hand is drawn quickly across a surface, the touch nerves are stimulated more intensely. The brain compensates for this, so the speed of contact does not affect the perceived roughness. Other constancies include melody, odor, brightness and words. These constancies are not always total, but the variation in the percept is much less than the variation in the physical stimulus. The perceptual systems of the brain achieve perceptual constancy in a variety of ways, each specialized for the kind of information being processed, with phonemic restoration as a notable example from hearing.",
            "score": 72.92166602611542
        },
        {
            "docid": "41129520_6",
            "document": "Ambient optic array . Many critics have rejected at least some of Gibson's claims. Psychologist Richard Gregory asserted that Gibson's bottom-up approach to perception is incomplete. He argued that visual illusions like the Necker cube are the result of the brain's indecision between two equally plausible hypotheses about the cube's orientation. The cube appears to \"flip\" between these two orientations even though the sensory information remains static. Therefore, Gregory reasoned that top-down processes must mediate perception. In response, Gibson argued that illusions like the Necker cube are the result of artifice and would not be encountered by agents in realistic perceptual situations, and therefore are irrelevant. However, the waterfall illusion is an example of a naturally occurring illusion and cannot be accounted for by Gibson's theory. Nevertheless, these two approaches can be reconciled. For example, Ulric Neisser developed the perceptual cycle, which involves top-down and bottom-up perceptual processes interacting and informing each other. The processes are causally linked, but of equal importance.",
            "score": 59.43954885005951
        },
        {
            "docid": "12994741_13",
            "document": "Neurorobotics . Neurorobots have also been used to study sensory perception, particularly vision. These are primarily systems that result from embedding neural models of sensory pathways in automatas. This approach gives exposure to the sensory signals that occur during behavior and also enables a more realistic assessment of the degree of robustness of the neural model. It is well known that changes in the sensory signals produced by motor activity provide useful perceptual cues that are used extensively by organisms. For example, researchers have used the depth information that emerges during replication of human head and eye movements to establish robust representations of the visual scene.",
            "score": 65.2134895324707
        },
        {
            "docid": "1677048_9",
            "document": "Inattentional blindness . One of the most foremost conflicts among researchers of inattentional blindness surrounds the processing of unattended stimuli. More specifically, there is disagreement in the literature about exactly how much processing of a visual scene is completed before selection dictates which stimuli will be consciously perceived, and which will not be (i.e. inattentional blindness). There exists two basic schools of thought on the issue \u2013 those who believe selection occurs early in the perceptual process, and those who believe it occurs only after significant processing. Early selection theorists propose that perception of stimuli is a limited process requiring selection to proceed. This suggests that the decision to attend to specific stimuli occurs early in processing, soon after the rudimentary study of physical features; only those selected stimuli are then fully processed. On the other hand, proponents of late selection theories argue that perception is an unlimited operation, and all stimuli in a visual scene are processed simultaneously. In this case, selection of relevant information is done after full processing of all stimuli.",
            "score": 61.65197443962097
        },
        {
            "docid": "25492989_7",
            "document": "Amorphosynthesis . The amorphosynthesis of sensory stimuli is associated with different perceptual and conceptual effects relative to the severity of damage to the parietal lobe. The degree of sensory suppression has been explored with bilateral and ipsilateral double stimulation methods in patients with either extensive or superficial parietal lesions. Complete extinction is commonly observed in which patients with extensive right parietal damage show complete and constant inattention to tactile stimuli on the contralesional side of the body. Incomplete extinction is frequently associated with lesions that are less extensive or superficial in nature. This phenomenon is supported by studies showing that if two stimuli are simultaneously applied to both sides of the body, the patient [with their eyes closed] will ignore the stimulus that is applied to the affected side and report a tactile sensation from the unaffected side alone. If each side of the body is separately stimulated, then each stimulus is correctly reported without delay. Incomplete sensory suppression has also been observed using ipsilateral double stimulation to one side of the body. Results indicate that stimulation to a proximal and distal segment [for example, the face and hand] on one side of the body will result in a distal [hand] stimulus suppression, to which the patient will report feeling only the proximal [face] stimulation.  Further evidence suggests that the parietal lobe gives rise to the processing of attention and awareness that is necessary for sensory perception. In studies of double stimulation in which the patient has their eyes open, incomplete extinction is eliminated when attention is directed to the application of stimulus on the affected side. This phenomenon is not observed in patients with complete extinction in which there is extensive damage to the parietal lobe, suggesting that the subsequent sensory suppression is not affected by expectant attention",
            "score": 52.76049280166626
        },
        {
            "docid": "27336635_26",
            "document": "P3b . Another theory proposed by Kok proposed that the P3b reflects mechanisms involved in event categorization, or the process that leads to the decision about whether an external stimulus matches or does not match an internal representation of a specific category or stimulus. Categorization requires processes such as attention, perception, and working memory, all of which are known to affect P3b amplitude (as reviewed above), and thus this model integrates the research findings on P3b. Kok also discusses another \"template-matching model\", where subjects are required to detect a target and create a representation or \"template\" of the stimulus, and the P3b is strongest when the template is matched by presented stimuli. The template-matching model is similar to the event categorization model, and suggests that the P3b reflects processes that underlie recognition memory (which can also require working memory.) The event-categorization model has similarities to the model proposed by Verleger that suggests that the P3 is generated during the \"closure\" of a perceptual cycle. The cognitive version of Verleger's model suggests that the P3b is generated when a decision is made that a stimulus belongs to a task-relevant category. As Kok summarizes, P3b appears to integrate processes that are required to identify and match a stimulus with some kind of internal representation.",
            "score": 57.54383361339569
        },
        {
            "docid": "4788296_41",
            "document": "Plato's Problem . These studies point to the fact that even though we only attend to and process limited information, we have a vast amount of knowledge at our disposal through our highly unrestricted sensory registers. It is the selective attention, perception, and higher order cognitive processing that limits these inputs and it is precisely these processes that make up our conscious awareness. Thus, in order to formulate some explanations for Plato's Problem, our conscious awareness limits our experience; nevertheless, it seems as though some stimuli that are sensed by our sensory registers, although seemingly rejected by conscious awareness, are actually retained and abstracted into our memories for further processing. All of our fully functioning perceptual faculties enhance, supplement, and optimize our experiences.",
            "score": 69.29556465148926
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 50.948641300201416
        }
    ],
    "r": [
        {
            "docid": "1903855_7",
            "document": "Sensory substitution . In a regular visual system, the data collected by the retina is converted into an electrical stimulus in the optic nerve and relayed to the brain, which re-creates the image and perceives it. Because it is the brain that is responsible for the final perception, sensory substitution is possible. During sensory substitution an intact sensory modality relays information to the visual perception areas of the brain so that the person can perceive to see. With sensory substitution, information gained from one sensory modality can reach brain structures physiologically related to other sensory modalities. Touch-to-visual sensory substitution transfers information from touch receptors to the visual cortex for interpretation and perception. For example, through fMRI, we can determine which parts of the brain are activated during sensory perception. In blind persons, we can see that while they are only receiving tactile information, their visual cortex is also activated as they perceive to \"see\" objects. We can also have touch to touch sensory substitution where information from touch receptors of one region can be used to perceive touch in another region. For example, in one experiment by Bach-y-Rita, he was able to restore the touch perception in a patient who lost peripheral sensation from leprosy.",
            "score": 81.21390533447266
        },
        {
            "docid": "5664_64",
            "document": "Consciousness . In neuroscience, a great deal of effort has gone into investigating how the perceived world of conscious awareness is constructed inside the brain. The process is generally thought to involve two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals arising from sensory organs are transmitted to the brain and then processed in a series of stages, which extract multiple types of information from the raw input. In the visual system, for example, sensory signals from the eyes are transmitted to the thalamus and then to the primary visual cortex; inside the cerebral cortex they are sent to areas that extract features such as three-dimensional structure, shape, color, and motion. Memory comes into play in at least two ways. First, it allows sensory information to be evaluated in the context of previous experience. Second, and even more importantly, working memory allows information to be integrated over time so that it can generate a stable representation of the world\u2014Gerald Edelman expressed this point vividly by titling one of his books about consciousness \"The Remembered Present\". In computational neuroscience, Bayesian approaches to brain function have been used to understand both the evaluation of sensory information in light of previous experience, and the integration of information over time. Bayesian models of the brain are probabilistic inference models, in which the brain takes advantage of prior knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian models have successfully predicted many perceptual phenomena in vision and the nonvisual senses.",
            "score": 79.65398406982422
        },
        {
            "docid": "1619306_6",
            "document": "Multisensory integration . However, considerations of how unified conscious representations are formed are not the full focus of multisensory Integration research. It is obviously important for the senses to interact in order to maximize how efficiently people interact with the environment. For perceptual experience and behavior to benefit from the simultaneous stimulation of multiple sensory modalities, integration of the information from these modalities is necessary. Some of the mechanisms mediating this phenomenon and its subsequent effects on cognitive and behavioural processes will be examined hereafter. Perception is often defined as one's conscious experience, and thereby combines inputs from all relevant senses and prior knowledge. Perception is also defined and studied in terms of feature extraction, which is several hundred milliseconds away from conscious experience. Notwithstanding the existence of Gestalt psychology schools that advocate a holistic approach to the operation of the brain, the physiological processes underlying the formation of percepts and conscious experience have been vastly understudied. Nevertheless, burgeoning neuroscience research continues to enrich our understanding of the many details of the brain, including neural structures implicated in multisensory integration such as the superior colliculus (SC) and various cortical structures such as the superior temporal gyrus (GT) and visual and auditory association areas. Although the structure and function of the SC are well known, the cortex and the relationship between its constituent parts are presently the subject of much investigation. Concurrently, the recent impetus on integration has enabled investigation into perceptual phenomena such as the ventriloquism effect, rapid localization of stimuli and the McGurk effect; culminating in a more thorough understanding of the human brain and its functions.",
            "score": 78.45282745361328
        },
        {
            "docid": "1619306_3",
            "document": "Multisensory integration . Multimodal perception is a scientific term that describes how humans form coherent, valid, and robust perception by processing sensory stimuli from various modalities. Surrounded by multiple objects and receiving multiple sensory stimulations, the brain is faced with the decision of how to categorize the stimuli resulting from different objects or events in the physical world. The nervous system is thus responsible for whether to integrate or segregate certain groups of temporally coincident sensory signals based on the degree of spatial and structural congruence of those stimulations. Multimodal perception has been widely studied in cognitive science, behavioral science, and neuroscience.",
            "score": 77.99794006347656
        },
        {
            "docid": "20429570_14",
            "document": "Motor imagery . Motor imagery is close to the notion of simulation used in cognitive and social neuroscience to account for different processes. An individual who is engaging in simulation may replay his own past experience in order to extract from it pleasurable, motivational or strictly informational properties. Such a view was clearly described by the Swedish physiologist Hesslow. For this author, the simulation hypothesis states that thinking consists of simulated interaction with the environment, and rests on the following three core assumptions: (1) Simulation of actions: we can activate motor structures of the brain in a way that resembles activity during a normal action but does not cause any overt movement; (2) Simulation of perception: imagining perceiving something is essentially the same as actually perceiving it, only the perceptual activity is generated by the brain itself rather than by external stimuli; (3) Anticipation: there exist associative mechanisms that enable both behavioral and perceptual activity to elicit other perceptual activity in the sensory areas of the brain. Most importantly, a simulated action can elicit perceptual activity that resembles the activity that would have occurred if the action had actually been performed.",
            "score": 77.70984649658203
        },
        {
            "docid": "25140_7",
            "document": "Perception . Since the rise of experimental psychology in the 19th Century, psychology's understanding of perception has progressed by combining a variety of techniques. Psychophysics quantitatively describes the relationships between the physical qualities of the sensory input and perception. Sensory neuroscience studies the neural mechanisms underlying perception. Perceptual systems can also be studied computationally, in terms of the information they process. Perceptual issues in philosophy include the extent to which sensory qualities such as sound, smell or color exist in objective reality rather than in the mind of the perceiver.",
            "score": 76.40141296386719
        },
        {
            "docid": "433584_4",
            "document": "McGurk effect . Vision is the primary sense for humans, but speech perception is multimodal, which means that it involves information from more than one sensory modality, in particular, audition and vision. The McGurk effect arises during phonetic processing because the integration of audio and visual information happens early in speech perception. The McGurk effect is very robust; that is, knowledge about it seems to have little effect on one's perception of it. This is different from certain optical illusions, which break down once one 'sees through' them. Some people, including those that have been researching the phenomenon for more than twenty years, experience the effect even when they are aware that it is taking place. With the exception of people who can identify most of what is being said from speech-reading alone, most people are quite limited in their ability to identify speech from visual-only signals. A more extensive phenomenon is the ability of visual speech to increase the intelligibility of heard speech in a noisy environment. Visible speech can also alter the perception of perfectly audible speech sounds when the visual speech stimuli are mismatched with the auditory speech. Normally, speech perception is thought to be an auditory process; however, our use of information is immediate, automatic, and, to a large degree, unconscious and therefore, despite what is widely accepted as true, speech is not only something we hear. Speech is perceived by all of the senses working together (seeing, touching, and listening to a face move). The brain is often unaware of the separate sensory contributions of what it perceives. Therefore, when it comes to recognizing speech the brain cannot differentiate whether it is seeing or hearing the incoming information.",
            "score": 76.26423645019531
        },
        {
            "docid": "25140_19",
            "document": "Perception . \"Perceptual constancy\" is the ability of perceptual systems to recognize the same object from widely varying sensory inputs. For example, individual people can be recognized from views, such as frontal and profile, which form very different shapes on the retina. A coin looked at face-on makes a circular image on the retina, but when held at angle it makes an elliptical image. In normal perception these are recognized as a single three-dimensional object. Without this correction process, an animal approaching from the distance would appear to gain in size. One kind of perceptual constancy is \"color constancy\": for example, a white piece of paper can be recognized as such under different colors and intensities of light. Another example is \"roughness constancy\": when a hand is drawn quickly across a surface, the touch nerves are stimulated more intensely. The brain compensates for this, so the speed of contact does not affect the perceived roughness. Other constancies include melody, odor, brightness and words. These constancies are not always total, but the variation in the percept is much less than the variation in the physical stimulus. The perceptual systems of the brain achieve perceptual constancy in a variety of ways, each specialized for the kind of information being processed, with phonemic restoration as a notable example from hearing.",
            "score": 72.92166900634766
        },
        {
            "docid": "7652097_8",
            "document": "Perceptual paradox . One branch of research into perception attempts to explain what we perceive by applying formulae to sensory inputs and expecting outputs similar to that which we perceive. For example: what we measure with our eyes should be predicted by applying formulae to what we measure with instruments that imitate our eye.",
            "score": 72.0439453125
        },
        {
            "docid": "21647661_3",
            "document": "Self model . The PSM is an entity that \u201cactually exists, not only as a distinct theoretical entity but something that will be empirically discovered in the future- for instance, as a specific stage of the global neural dynamics in the human brain\u201d. Involved in the PSM are three phenomenal properties that must occur in order to explain the concept of the self. The first is mineness, \u201ca higher order property of particular forms of phenomenal content,\u201d or the idea of ownership. The second is perspectivalness, which is \u201ca global, structural property of phenomenal space as a whole\u201d. More simply, it is what is commonly referred to as the ecological self, the immovable center of perception. The third phenomenal property is selfhood, which is \u201cthe phenomenal target property\u201d or the idea of the self over time. It is the property of phenomenal selfhood that plays the most important role in creating the fictional self and the first person perspective. Metzinger defines the first person perspective as the \u201cexistence of single coherent and temporally stable model of reality which is representationally centered around or on a single coherent and temporally stable phenomenal subject\u201d. The first-person perspective can be non-conceptual and is autonomously active due to the constant reception of perceptual information by the brain. The brain, specifically the brainstem and hypothalamus, processes this information into representational content, namely linguistic reflections. The PSM then uses this representational content to attribute phenomenal states to our perceived objects and ourselves. We are thus what Metzinger calls na\u00efve realists, who believe we are perceiving reality directly when in actuality we are only perceiving representations of reality. The data structures and transport mechanisms of the data are \u201ctransparent\u201d so that we can introspect on our representations of perceptions, but cannot introspect on the data or mechanisms themselves. These systemic representational experiences are then connected by subjective experience to generate the phenomenal property of selfhood. Subjective experience is the result of the Phenomenal Model of Intentionality Relationship (PMIR). The PMIR is a \u201cconscious mental model, and its content is an ongoing, episodic subject-object relation\u201d. The model is a result of the combination of our unique set of sensory receptors that acquire input, our unique set of experiences that shape connections within the brain, and our unique positions in space that give our perception perspectivalness.",
            "score": 71.70941162109375
        },
        {
            "docid": "42238932_5",
            "document": "Tinkerbell effect . In the \"Journal of Consciousness Studies\", Frank H. Durgin applies this expression to the study of human motion detection and perception in his paper \"The Tinkerbell Effect: Motion Perception and Illusion\". He questions the common belief that visual consciousness is a direct translation of the information the visual sensory organs collect. He argues that \"perceptual awareness pretends to have access to more information than is actually available to visual cognition\". He relates his argument about the indirectness in motion perception to how, in the play version of Peter Pan, Tinkerbell's revival depends on the live audience expressing their belief in fairies through clapping. The Tinkerbell effect points out a significant flaw in the brain's system of receiving and interpreting visually available information: it is not directly representative of reality. With the overwhelming amount of sensory information, the brain summarizes it by filling in what it cannot make sense of. In other words, it is an act of imagination.",
            "score": 71.02180480957031
        },
        {
            "docid": "2534964_12",
            "document": "Sensory processing . It may seem redundant that we are being provided with multiple sensory inputs about the same object, but that is not necessarily the case. This so-called \"redundant\" information is in fact verification that what we are experiencing is in fact happening. Perceptions of the world are based on models that we build of the world. Sensory information informs these models, but this information can also confuse the models. Sensory illusions occur when these models do not match up. For example, where our visual system may fool us in one case, our auditory system can bring us back to a ground reality. This prevents sensory misrepresentations, because through the combination of multiple sensory modalities, the model that we create is much more robust and gives a better assessment of the situation. Thinking about it logically, it is far easier to fool one sense than it is to simultaneously fool two or more senses.",
            "score": 70.5250244140625
        },
        {
            "docid": "739262_11",
            "document": "Neural correlate . Other lab groups have followed Mountcastle's seminal work relating cognitive variables to neuronal activity with more complex cognitive tasks. Although monkeys cannot talk about their perceptions, behavioral tasks have been created in which animals made nonverbal reports, for example by producing hand movements. Many of these studies employ perceptual illusions as a way to dissociate sensations (\"i.e.\", the sensory information that the brain receives) from perceptions (\"i.e.\", how the consciousness interprets them). Neuronal patterns that represent perceptions rather than merely sensory input are interpreted as reflecting the neuronal correlate of consciousness.",
            "score": 69.97582244873047
        },
        {
            "docid": "2843988_32",
            "document": "Motor control . Direct perception in the cognitive sense is related to the philosophical notion of na\u00efve or direct realism in that it is predicated on the assumption that what we perceive is what is actually in the world. James J. Gibson is credited with recasting direct perception as ecological perception. While the problem of indirect perception proposes that physical information about object in our environment is not available due to the ambiguity of sensory information, proponents of direct perception (like Gibson) suggest that the relevant information encoded in sensory signals is not the physical properties of objects, but rather the action opportunities the environment affords. These affordances are directly perceivable without ambiguity, and thus preclude the need for internal models or representations of the world. Affordances exist only as a byproduct of the interactions between an agent and its environment, and thus perception is an \"ecological\" endeavor, depending on the whole agent/environment system rather than on the agent in isolation.",
            "score": 69.50267028808594
        },
        {
            "docid": "889172_4",
            "document": "Selective perception . Selective perception may refer to any number of cognitive biases in psychology related to the way expectations affect perception. Human judgment and decision making is distorted by an array of cognitive, perceptual and motivational biases, and people tend not to recognise their own bias, though they tend to easily recognise (and even overestimate) the operation of bias in human judgment by others. One of the reasons this might occur might be because people are simply bombarded with too much stimuli every day to pay equal attention to everything, therefore, they pick and choose according to their own needs.",
            "score": 69.45297241210938
        },
        {
            "docid": "37940820_8",
            "document": "Emotion perception . Although facial expressions convey key emotional information, context also plays an important role in both providing additional emotional information and modulating what emotion is actually perceived in a facial expression. Contexts come in three categories: stimulus-based context, in which a face is physically presented with other sensory input that has informational value; perceiver-based context, in which processes within the brain or body of a perceiver can shape emotion perception; and cultural contexts that affect either the encoding or the understanding of facial actions.",
            "score": 69.42643737792969
        },
        {
            "docid": "5366050_62",
            "document": "Speech perception . The fuzzy logical theory of speech perception developed by Dominic Massaro proposes that people remember speech sounds in a probabilistic, or graded, way. It suggests that people remember descriptions of the perceptual units of language, called prototypes. Within each prototype various features may combine. However, features are not just binary (true or false), there is a fuzzy value corresponding to how likely it is that a sound belongs to a particular speech category. Thus, when perceiving a speech signal our decision about what we actually hear is based on the relative goodness of the match between the stimulus information and values of particular prototypes. The final decision is based on multiple features or sources of information, even visual information (this explains the McGurk effect). Computer models of the fuzzy logical theory have been used to demonstrate that the theory's predictions of how speech sounds are categorized correspond to the behavior of human listeners.",
            "score": 69.33098602294922
        },
        {
            "docid": "4788296_41",
            "document": "Plato's Problem . These studies point to the fact that even though we only attend to and process limited information, we have a vast amount of knowledge at our disposal through our highly unrestricted sensory registers. It is the selective attention, perception, and higher order cognitive processing that limits these inputs and it is precisely these processes that make up our conscious awareness. Thus, in order to formulate some explanations for Plato's Problem, our conscious awareness limits our experience; nevertheless, it seems as though some stimuli that are sensed by our sensory registers, although seemingly rejected by conscious awareness, are actually retained and abstracted into our memories for further processing. All of our fully functioning perceptual faculties enhance, supplement, and optimize our experiences.",
            "score": 69.29556274414062
        },
        {
            "docid": "7330954_6",
            "document": "Pattern recognition (psychology) . Template matching theory describes the most basic approach to human pattern recognition. It is a theory that assumes every perceived object is stored as a \"template\" into long-term memory. Incoming information is compared to these templates to find an exact match. In other words, all sensory input is compared to multiple representations of an object to form one single conceptual understanding. The theory defines perception as a fundamentally recognition-based process. It assumes that everything we see, we understand only through past exposure, which then informs our future perception of the external world. For example, A, A, and \"A\" are all recognized as the letter A, but not B. This viewpoint is limited, however, in explaining how new experiences can be understood without being compared to an internal memory template.",
            "score": 69.16962432861328
        },
        {
            "docid": "19316440_4",
            "document": "Motor cognition . More recently, there is growing empirical evidence from cognitive psychology, developmental psychology, cognitive neuroscience, cognitive science, as well as social psychology which demonstrates that perception and action share common computational codes and underlying neural architectures. This evidence has been marshaled in the \"common coding theory\" put forward by Wolfgang Prinz and his colleagues at the Max Planck Institute for Human Cognitive and Brain Sciences in Leipzig, Germany. This theory claims parity between perception and action. Its core assumption is that actions are coded in terms of the perceivable effects (i.e., the distal perceptual events) they should generate. Performing a movement leaves behind a bidirectional association between the motor pattern it has generated by and the sensory effects that it produces. Such an association can then be used backwards to retrieve a movement by anticipating its effects. These perception/action codes are also accessible during action observation. Other authors suggest a new notion of the phylogenetic and ontogenetic origin of action understanding that utilizes the motor system; motor cognition hypothesis. This states that motor cognition provides both human and nonhuman primates with a direct, prereflexive understanding of biological actions that match their own action catalog.",
            "score": 69.08169555664062
        },
        {
            "docid": "37940820_2",
            "document": "Emotion perception . Emotion perception refers to the capacities and abilities of recognizing and identifying emotions in others, in addition to biological and physiological processes involved. Emotions are typically viewed as having three components: subjective experience, physical changes, and cognitive appraisal; emotion perception is the ability to make accurate decisions about another's subjective experience by interpreting their physical changes through sensory systems responsible for converting these observed changes into mental representations. The ability to perceive emotion is believed to be both innate and subject to environmental influence and is also a critical component in social interactions. How emotion is experienced and interpreted depends on how it is perceived. Likewise, how emotion is perceived is dependent on past experiences and interpretations. Emotion can be accurately perceived in humans. Emotions can be perceived visually, audibly, through smell and also through bodily sensations and this process is believed to be different from the perception of non-emotional material.",
            "score": 69.04645538330078
        },
        {
            "docid": "51547415_2",
            "document": "Interindividual differences in perception . Interindividual differences in perception describes the effect that differences in brain structure or factors such as culture, upbringing and environment have on the perception of humans. Interindividual (differing from person to person) variability is usually regarded as a source of noise for research. However, in recent years, it has become an interesting source to study sensory mechanisms and understand human behavior. With the help of modern neuroimaging methods such as fMRI and EEG, individual differences in perception could be related to the underlying brain mechanisms. This has helped to explain differences in behavior and cognition across the population. Common methods include studying the perception of illusions, as they can effectively demonstrate how different aspects such as culture, genetics and the environment can influence human behavior.",
            "score": 68.94918823242188
        },
        {
            "docid": "53472_4",
            "document": "Illusion . Some illusions are based on general assumptions the brain makes during perception. These assumptions are made using organizational principles (e.g., Gestalt theory), an individual's capacity for depth perception and motion perception, and perceptual constancy. Other illusions occur because of biological sensory structures within the human body or conditions outside the body within one's physical environment.",
            "score": 68.70533752441406
        },
        {
            "docid": "21402758_43",
            "document": "Qualia . E. J. Lowe, of Durham University, denies that holding to indirect realism (in which we have access only to sensory features internal to the brain) necessarily implies a Cartesian dualism. He agrees with Bertrand Russell that our \"retinal images\"\u2014that is, the distributions across our retinas\u2014are connected to \"patterns of neural activity in the cortex\" (Lowe 1986). He defends a version of the Causal Theory of Perception in which a causal path can be traced between the external object and the perception of it. He is careful to deny that we do any inferring from the sensory field, a view which he believes allows us to found an access to knowledge on that causal connection. In a later work he moves closer to the non-epistemic theory in that he postulates \"a wholly non-conceptual component of perceptual experience\", but he refrains from analyzing the relation between the perceptual and the \"non-conceptual\". Most recently he has drawn attention to the problems that hallucination raises for the direct realist and to their disinclination to enter the discussion on the topic.",
            "score": 68.13015747070312
        },
        {
            "docid": "6989876_6",
            "document": "Vision for perception and vision for action . However, while there exists to be two different hypotheses regarding the processing of vision in the human brain, it is still possible to accept both. Recent experiments prove that difficulties arise when deciphering between vision for action and vision for perception. A clear distinction between the two is difficult to make. Studies prove visual illusions that involve perception more so have considerable results on action. This can clearly rule out the first hypothesis noted above, indicating the thought that visually directed actions always avoid the matter of perception. However, a weaker form of the first hypothesis can still be considered. This states that the content of conscious perception will sometimes influence action, but that its impact on action is less asserted. Both the assumed ventral and dorsal streams can provide guidance of action, however information processed ventrally appears less pronounced and appears more substantial in the processing of perceptual tasks. It has been noted that one can still accept the two-stream hypothesis, but in doing so one must also realize that such a hypothesis still acknowledges the sharing of visual information across pathways and functions, heavily shaped by behavioral tasks.",
            "score": 68.01734924316406
        },
        {
            "docid": "52847257_3",
            "document": "Donald D. Hoffman . Hoffman studies consciousness, visual perception and evolutionary psychology using mathematical models and psychophysical experiments. His research subjects include facial attractiveness, the recognition of shape, the perception of motion and color, the evolution of perception, and the mind-body problem. He has coauthored two technical books: Observer Mechanics: A Formal Theory of Perception (1989) offers a theory of consciousness and its relationship to physics; Automotive Lighting and Human Vision (2005) applies vision science to vehicle lighting. His book Visual Intelligence: How We Create What We See (1998) presents the modern science of visual perception to a broad audience. His new book, tentatively titled Do We See Reality?, to appear at the end of 2017, expands on his 2015 TED Talk and explains how our perceptions have evolved to hide reality from us.",
            "score": 67.9450912475586
        },
        {
            "docid": "1678822_62",
            "document": "Perceptual control theory . Perceptual control theory currently proposes a hierarchy of 11 levels of perceptions controlled by systems in the human mind and neural architecture. These are: intensity, sensation, configuration, transition, event, relationship, category, sequence, program, principle, and system concept. Diverse perceptual signals at a lower level (e.g. visual perceptions of intensities) are combined in an input function to construct a single perception at the higher level (e.g. visual perception of a color sensation). The perceptions that are constructed and controlled at the lower levels are passed along as the perceptual inputs at the higher levels. The higher levels in turn control by telling the lower levels what to perceive: that is, they adjust the reference levels (goals) of the lower levels.",
            "score": 67.88550567626953
        },
        {
            "docid": "49045837_6",
            "document": "Spatial ability . Spatial perception is also very relevant in sports. For example, a study found that cricket players who were faster at picking up information from briefly presented visual displays were significantly better batsmen in an actual game. A 2015 study published in the \"Journal of Vision\" found that soccer players had higher perceptual ability for body kinematics such as processing multitasking crowd scenes which involve pedestrians crossing a street or complex dynamic visual scenes. Another study published in the \"Journal of Human Kinetics\" on fencing athletes found that achievement level was highly correlated with spatial perceptual skills such as visual discrimination, visual-spatial relationships, visual sequential memory, narrow attentional focus and visual information processing. A review published in the journal of \"Neuropsychologia\" found that spatial perception involves attributing meaning to an object or space, so that their sensory processing is actually part of semantic processing of the incoming visual information. The review also found that spatial perception involves the human visual system in the brain and the parietal lobule which is responsible for visuomotor processing and visually goal-directed action. Studies have also found that individuals who played first person shooting games had better spatial perceptual skills like faster and more accurate performance in a peripheral and identification task while simultaneously performing a central search. Researchers suggested that, in addition to enhancing the ability to divide attention, playing action games significantly enhances perceptual skills like top-down guidance of attention to possible target locations.",
            "score": 67.74349212646484
        },
        {
            "docid": "37556_18",
            "document": "Asperger syndrome . Individuals with AS often have excellent auditory and visual perception. Children with ASD often demonstrate enhanced perception of small changes in patterns such as arrangements of objects or well-known images; typically this is domain-specific and involves processing of fine-grained features. Conversely, compared with individuals with high-functioning autism, individuals with AS have deficits in some tasks involving visual-spatial perception, auditory perception, or visual memory. Many accounts of individuals with AS and ASD report other unusual sensory and perceptual skills and experiences. They may be unusually sensitive or insensitive to sound, light, and other stimuli; these sensory responses are found in other developmental disorders and are not specific to AS or to ASD. There is little support for increased fight-or-flight response or failure of habituation in autism; there is more evidence of decreased responsiveness to sensory stimuli, although several studies show no differences.",
            "score": 67.72671508789062
        },
        {
            "docid": "19319219_5",
            "document": "Wolfgang Prinz . Prinz is the father of the common coding theory. This theory claims parity between perception and action. Its core assumption is that actions are coded in terms of the perceivable effects (i.e., the distal perceptual events) they should generate Performing a movement leaves behind a bidirectional association between the motor pattern it has generated by and the sensory effects that it produces. Such an association can then be used backwards to retrieve a movement by anticipating its effects. These perception/action codes are also accessible during action observation (for an historical account of the ideo-motor principle, see Observation of an action should activate action representations to the degree that the perceived and the represented action are similar. Such a claim suggests that we represent observed, executed and imagined actions in a commensurate manner and makes specific predictions regarding the nature of action and perceptual representations. First, representations for observed and executed actions should rely on a shared neural substrate. Second, a common cognitive system predicts interference effects when action and perception attempt to access shared representations simultaneously. Third, such a system predicts facilitation of action based on directly prior perception and vice versa.",
            "score": 67.58523559570312
        },
        {
            "docid": "271430_18",
            "document": "Computational neuroscience . Current research in sensory processing is divided among a biophysical modelling of different subsystems and a more theoretical modelling of perception. Current models of perception have suggested that the brain performs some form of Bayesian inference and integration of different sensory information in generating our perception of the physical world.",
            "score": 67.55332946777344
        },
        {
            "docid": "889172_3",
            "document": "Selective perception . Selective perception is the process by which individuals perceive what they want to in media messages while ignoring opposing viewpoints. It is a broad term to identify the behavior all people exhibit to tend to \"see things\" based on their particular frame of reference. It also describes how we categorize and interpret sensory information in a way that favors one category or interpretation over another. In other words, selective perception is a form of bias because we interpret information in a way that is congruent with our existing values and beliefs. Psychologists believe this process occurs automatically.",
            "score": 67.53977966308594
        }
    ]
}