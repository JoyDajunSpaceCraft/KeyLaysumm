{
    "q": [
        {
            "docid": "22396342_9",
            "document": "H1 neuron . Visual information in optical systems is inhibited by the temporal and spatial attributes of the sensory input, and by the biophysical properties of the neuronal circuits. How neural circuits encode behaviorally relevant information is dependent on the computational capacity of the nervous system with relation to the ambient conditions the organisms normally operate in. H1 neurons are proven to be very efficient encoders of information via their high resilience to stimulus noise from external sources. The operational and encoding processes of sensory pathways are often negatively affected by both external noise (relating to the stimulus) and internal noise (imperfect physiological processes); however, the activity of H1 is unaffected by photon noise. Instead, neuronal noise intrinsic to the H1 neural architecture is the limiting factor for accurate responses to stimuli. This dramatically reduces the noise of H1 electrophysiological readings, and provides the reliability necessary for accurate study conclusions.",
            "score": 45.58775591850281
        },
        {
            "docid": "25335695_4",
            "document": "Perceptual learning . Laboratory studies reported many examples of dramatic improvements in sensitivities from appropriately structured perceptual learning tasks. In visual Vernier acuity tasks, observers judge whether one line is displaced above or below a second line. Untrained observers are often already very good with this task, but after training, observers' threshold has been shown to improve as much as 6 fold. Similar improvements have been found for visual motion discrimination and orientation sensitivity. In visual search tasks, observers are asked to find a target object hidden among distractors or in noise. Studies of perceptual learning with visual search show that experience leads to great gains in sensitivity and speed. In one study by Karni and Sagi, the time it took for subjects to search for an oblique line among a field of horizontal lines was found to improve dramatically, from about 200ms in one session to about 50ms in a later session. With appropriate practice, visual search can become automatic and very efficient, such that observers do not need more time to search when there are more items present on the search field. Tactile perceptual learning has been demonstrated on spatial acuity tasks such as tactile grating orientation discrimination, and on vibrotactile perceptual tasks such as frequency discrimination; tactile learning on these tasks has been found to transfer from trained to untrained fingers. Practice with Braille reading and daily reliance on the sense of touch may underlie the enhancement in tactile spatial acuity of blind compared to sighted individuals.",
            "score": 96.10046780109406
        },
        {
            "docid": "41848173_14",
            "document": "Surround suppression . Surround suppression likely participates in context-dependent perceptual tasks. Some specific tasks in which surround suppression may aid include: These tasks require the use of inputs over wide regions of visual space, meaning that independent responses to small parts of the visual field (a classical linear model of V1) would not be able to produce these effects. There is evidence that surround suppression participates in these tasks by either adjusting the representation of the classical receptive field or representing entirely different features that include both the classical receptive field and the surround. Direct comparison between physiology and psychophysical experiments have been done on several perceptual effects. These include: (1) the reduced apparent contrast of a grating texture embedded in a surrounding grating, (2) target identification when flanked by other features, (3) saliency of broken contours surrounded by edge segments of different orientations, and (4) orientation discrimination when surrounded by features of different orientations and spatial frequencies.",
            "score": 85.30408418178558
        },
        {
            "docid": "23026009_11",
            "document": "Biological theories of dyslexia . The concept of a perceptual noise exclusion deficit (impaired filtering of behaviorally irrelevant visual information in dyslexia or visual-noise) is an emerging hypothesis, supported by research showing that subjects with dyslexia experience difficulty in performing visual tasks (such as motion detection in the presence of perceptual distractions) but do not show the same impairment when the distracting factors are removed in an experimental setting. The researchers have analogized their findings concerning visual discrimination tasks to findings in other research related to auditory discrimination tasks. They assert that dyslexic symptoms arise because of an impaired ability to filter out both visual and auditory distractions, and to categorize information so as to distinguish the important sensory data from the irrelevant.",
            "score": 77.9924750328064
        },
        {
            "docid": "49045837_6",
            "document": "Spatial ability . Spatial perception is also very relevant in sports. For example, a study found that cricket players who were faster at picking up information from briefly presented visual displays were significantly better batsmen in an actual game. A 2015 study published in the \"Journal of Vision\" found that soccer players had higher perceptual ability for body kinematics such as processing multitasking crowd scenes which involve pedestrians crossing a street or complex dynamic visual scenes. Another study published in the \"Journal of Human Kinetics\" on fencing athletes found that achievement level was highly correlated with spatial perceptual skills such as visual discrimination, visual-spatial relationships, visual sequential memory, narrow attentional focus and visual information processing. A review published in the journal of \"Neuropsychologia\" found that spatial perception involves attributing meaning to an object or space, so that their sensory processing is actually part of semantic processing of the incoming visual information. The review also found that spatial perception involves the human visual system in the brain and the parietal lobule which is responsible for visuomotor processing and visually goal-directed action. Studies have also found that individuals who played first person shooting games had better spatial perceptual skills like faster and more accurate performance in a peripheral and identification task while simultaneously performing a central search. Researchers suggested that, in addition to enhancing the ability to divide attention, playing action games significantly enhances perceptual skills like top-down guidance of attention to possible target locations.",
            "score": 85.35716557502747
        },
        {
            "docid": "25335695_25",
            "document": "Perceptual learning . In 2005, Petrov, Dosher and Lu pointed out that perceptual learning may be explained in terms of the selection of which analyzers best perform the classification, even in simple discrimination tasks. They explain that the some part of the neural system responsible for particular decisions have specificity, while low-level perceptual units do not. In their model, encodings at the lowest level do not change. Rather, changes that occur in perceptual learning arise from changes in higher-level, abstract representations of the relevant stimuli. Because specificity can come from differentially selecting information, this \"selective reweighting theory\" allows for learning of complex, abstract representation. This corresponds to Gibson's earlier account of perceptual learning as selection and learning of distinguishing features. Selection may be the unifying principles of perceptual learning at all levels.",
            "score": 69.97044634819031
        },
        {
            "docid": "24766693_7",
            "document": "Glob (visual system) . Three types of retinal cone create signals that get transformed in the visual pathway to create the perception of color. However the neurons processing them in the retina, lateral geniculate nucleus, and V1 and V2 early parts of the visual cortex encode using the opponent process only a limited range of colors that does not reflect the dimensions of perceptual color space. It is only the next area where globs are found that along the visual processing hierarchy, show hue sensitivity, with the population of neurons representing most (if not all) of perceptual color space and which the color responses of neurons correspond to perception.",
            "score": 50.39665341377258
        },
        {
            "docid": "3037867_6",
            "document": "Spatial frequency . The spatial-frequency theory refers to the theory that the visual cortex operates on a code of spatial frequency, not on the code of straight edges and lines hypothesised by Hubel and Wiesel on the basis of early experiments on V1 neurons in the cat. In support of this theory is the experimental observation that the visual cortex neurons respond even more robustly to sine-wave gratings that are placed at specific angles in their receptive fields than they do to edges or bars. Most neurons in the primary visual cortex respond best when a sine-wave grating of a particular frequency is presented at a particular angle in a particular location in the visual field. (However, as noted by Teller (1984), it is probably not wise to treat the highest firing rate of a particular neuron as having a special significance with respect to its role in the perception of a particular stimulus, given that the neural code is known to be linked to relative firing rates. For example, in color coding by the three cones in the human retina, there is no special significance to the cone that is firing most strongly \u2013 what matters is the relative rate of firing of all three simultaneously. Teller (1984) similarly noted that a strong firing rate in response to a particular stimulus should not be interpreted as indicating that the neuron is somehow specialized for that stimulus, since there is an unlimited equivalence class of stimuli capable of producing similar firing rates.)",
            "score": 59.43081605434418
        },
        {
            "docid": "49990541_22",
            "document": "Visual selective attention in dementia . Visual selective attention requires many underlying cognitive processes, including detection of important sensory and perceptual information, the ability to inhibit information that is irrelevant to the task, and the ability to shift attention from feature or location to another. In this study, it was found that DLB patients in this task performed markedly worse than both AD patients and healthy controls in the single-target condition. This suggests that the perceptual filtering component of selective attention is significantly impaired in DLB. Difficulties in discrimination in DLB patients for visual stimuli may be due to reduced ability to select and encode relevant or important information in the target search. DLB patients\u2019 general slowness could have increased perceptual interference due to masking from distractors, and target selection and processing (in tasks such as the RSVP task) must be performed under time pressure.",
            "score": 75.55352520942688
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 78.76516556739807
        },
        {
            "docid": "25335695_13",
            "document": "Perceptual learning . Since the mid-1980s, there has been a new wave of interest in perceptual learning due to findings of cortical plasticity at the lowest sensory levels of sensory systems. Our increased understanding of the physiology and anatomy of our cortical systems has been used to connect the behavioral improvement to the underlying cortical areas. This trend began with earlier findings of Hubel and Wiesel that perceptual representations at sensory areas of the cortex are substantially modified during a short (\"critical\") period immediately following birth. Merzenich, Kaas and colleagues showed that though neuroplasticity is diminished, it is not eliminated when the critical period ends. Thus, when the external pattern of stimulation is substantially modified, neuronal representations in lower-level (e.g. primary) sensory areas are also modified. Research in this period centered on basic sensory discriminations, where remarkable improvements were found on almost any sensory task through discrimination practice. Following training, subjects were tested with novel conditions and learning transfer was assessed. This work departed from earlier work on perceptual learning, which spanned different tasks and levels.",
            "score": 44.70453405380249
        },
        {
            "docid": "35982062_8",
            "document": "Biased Competition Theory . Bottom-up processes are characterized by an absence of higher level direction in sensory processing. It primarily relies on sensory information and incoming sensory information is the starting point for all Bottom-up processing. Bottom-up refers to when a feature stands out in a visual search. This is commonly called the \u201cpop-out\u201d effect. Salient features like bright colors, movement and big objects make the object \u201cpop-out\u201d of the visual search. \u201cPop-out\u201d features can often attract attention without conscious processing. Objects that stand out are often given priority (bias) in processing. Bottom-up processing is data driven, and according to this stimuli are perceived on the basis of the data which is being experienced through the senses. Evidence suggests that simultaneously presented stimuli do in fact compete in order to be represented in the visual cortex, with stimuli mutually suppressing each other to gain this representation. This was examined by Reynolds and colleagues, who looked at the size of neurons\u2019 receptive field\u2019s within the visual cortex. It was found that the presentation of a single stimulus resulted in a low firing rate while two stimuli presented together resulted in a higher firing rate. Reynolds and colleagues also found that when comparing the neural response of an individually presented visual stimulus to responses gathered from simultaneously presented stimuli, the responses of the concurrent presented stimuli were less than the sum of the responses gathered when each stimuli was presented alone. This suggests that two stimuli presented together increase neural work load required for attention. This increased neural load creates suppressive processes and causes the stimuli to compete for neural representation in the brain. Proulx and Egeth predicted that brighter objects would bias attention in favor of that object. Another prediction is that larger objects would bias the attention in favor of that object. The experiment was a computer-based visual search task, where participants searched for a target among distractions. The results of the study suggested that when irrelevant stimuli were large or bright, attention was biased towards the irrelevant objects, prioritizing them for cognitive processing. This research shows the effects of Bottom-up (stimulus-driven) processing on biased competition theory.",
            "score": 62.210901498794556
        },
        {
            "docid": "8766922_2",
            "document": "Perceptual noise exclusion hypothesis . The concept of a perceptual noise exclusion deficit is an emerging hypothesis as to the origins and nature of dyslexia. It is supported by research showing that dyslexic adults and children experience difficulty in targeting visual information in the presence of visual perceptual distractions, but subjects do not show the same impairment when the distracting factors are removed in an experimental setting. Thus, some dyslexic symptoms appear to arise because of an impaired ability to filter out environmental distractions, and to categorize information so as to distinguish the important sensory data from the irrelevant.",
            "score": 55.13476324081421
        },
        {
            "docid": "33246145_11",
            "document": "Neural decoding . Timescales and frequencies of stimuli being presented to the observer are also of importance to decoding the neural code. Quicker timescales and higher frequencies demand faster and more precise responses in neural spike data. In humans, millisecond precision has been observed throughout the visual cortex, the retina, and the lateral geniculate nucleus, so one would suspect this to be the appropriate measuring frequency. This has been confirmed in studies that quantify the responses of neurons in the lateral geniculate nucleus to white-noise and naturalistic movie stimuli. At the cellular level, spike-timing-dependent plasticity operates at millisecond timescales; therefore, models seeking biological relevance should be able to perform at these temporal scales.",
            "score": 64.21749472618103
        },
        {
            "docid": "14339999_6",
            "document": "Virtual pitch . Terhardt rejected the idea of periodicity pitch, because it was not consistent with empirical data on pitch perception, e.g. measurements of the gradual shift of the virtual pitch of a complex tone with a missing fundamental when the partials were gradually shifted. Terhardt instead broke pitch perception into two steps: auditory frequency analysis in the inner ear, and harmonic pitch pattern recognition in the brain. The inner ear effectively performs a running frequency analysis of incoming sounds - otherwise we would not be able to hear out spectral pitches within a complex tone. Physiologically, each spectral pitch depends on both temporal and spectral aspects (i.e. periodicity of the waveform and position of excitation on the basilar membrane), but in Terhardt's approach the spectral pitch itself is a purely experiential parameter, not a physical parameter: it is the outcome of a psychoacoustical experiment in which the conscious listener plays an active role. Psychoacoustic measurements and models can predict which partials are \"perceptually relevant\" in a given complex tone; they are perceptually relevant if you can hear a difference in the whole sound if the frequency or amplitude of a partial is changed). The ear has evolved to separate spectral frequencies, because due to reflection and superposition in everyday environments spectral frequencies are more reliably carriers of environmental information than spectral amplitudies, which in turn are more reliable carriers of environmentally relevant information than phase relationships between partials (when perceived monoaurally). On this basis, Terhardt proposed that spectral pitches - which are what the listener experiences when hearing out partials (as opposed to the physical partials themselves) - are the only information available to the brain for the purpose of extracting virtual pitches. The \"pitch extraction\" process then involves the recognition of incomplete harmonic patterns and happens in neural networks.",
            "score": 59.216792583465576
        },
        {
            "docid": "6147487_47",
            "document": "Neural coding . A typical population code involves neurons with a Gaussian tuning curve whose means vary linearly with the stimulus intensity, meaning that the neuron responds most strongly (in terms of spikes per second) to a stimulus near the mean. The actual intensity could be recovered as the stimulus level corresponding to the mean of the neuron with the greatest response. However, the noise inherent in neural responses means that a maximum likelihood estimation function is more accurate. This type of code is used to encode continuous variables such as joint position, eye position, color, or sound frequency. Any individual neuron is too noisy to faithfully encode the variable using rate coding, but an entire population ensures greater fidelity and precision. For a population of unimodal tuning curves, i.e. with a single peak, the precision typically scales linearly with the number of neurons. Hence, for half the precision, half as many neurons are required. In contrast, when the tuning curves have multiple peaks, as in grid cells that represent space, the precision of the population can scale exponentially with the number of neurons. This greatly reduces the number of neurons required for the same precision.",
            "score": 31.23664927482605
        },
        {
            "docid": "3037867_8",
            "document": "Spatial frequency . The theory (for which empirical support has yet to be developed) states that in each functional module of the visual cortex, Fourier analysis is performed on the receptive field and the neurons in each module are thought to respond selectively to various orientations and frequencies of sine wave gratings. When all of the visual cortex neurons that are influenced by a specific scene respond together, the perception of the scene is created by the summation of the various sine-wave gratings. (This procedure, however, does not address the problem of the organization of the products of the summation into figures, grounds, and so on. It effectively recovers the original (pre-Fourier analysis) distribution of photon intensity and wavelengths across the retinal projection, but does not add information to this original distribution. So the functional value of such a hypothesized procedure is unclear. Some other objections to the \"Fourier theory\" are discussed by Westheimer (2001) ). One is generally not aware of the individual spatial frequency components since all of the elements are essentially blended together into one smooth representation. However, computer-based filtering procedures can be used to deconstruct an image into its individual spatial frequency components. Research on spatial frequency detection by visual neurons complements and extends previous research using straight edges rather than refuting it.",
            "score": 62.599609375
        },
        {
            "docid": "8766922_6",
            "document": "Perceptual noise exclusion hypothesis . This hypothesis is supported by a study showing dyslexic subjects in comparison to nondyslexic subjects in the research sample were less responsive to cueing in a visual discrimination task, suggesting that the dyslexics had greater difficulty than controls with prioritizing certain visual information based on previous exposure. The researchers also found that performance on the cuing task could be a more accurate means of discerning dyslexic from normal readers in comparison to the range of other psychophysical tasks typically used in dyslexia research.",
            "score": 74.40237545967102
        },
        {
            "docid": "33442648_14",
            "document": "Global precedence . When presented with a global-local task, children and adolescents exemplify a local bias. Younger children respond slower to different types of stimuli compared to older children, and thus local precedence seems more prevalent than global precedence in perceptual organization, at least until adolescence, when the transition to globally oriented visual perception begins. The ability to encode a global shape, which is necessary for efficiently recognizing and identifying objects, increases with age. However, it has also been found that there is a bias towards global information during infancy, which may be based upon high spatial frequency information, as well as limited vision. Therefore, global precedence during the early years of life may not be upwards but rather a U-shaped development.",
            "score": 62.309598445892334
        },
        {
            "docid": "48013821_11",
            "document": "Russell L. De Valois . In these studies De Valois and his co-workers found support for the conjecture that the early visual system transmits pattern information using a local 2-D spatial frequency or wavelet coding. Among the highlights of this work were that, for neurons in primary visual cortex (V1): \"i.\" most have receptive fields corresponding to a limited range of spatial frequencies and orientations; \"ii.\" a variety of frequencies and orientations are represented; and \"iii.\" responses to some more complex patterns can be predicted by the cell\u2019s spatial frequency tuning and the amplitude of the spatial frequency in the Fourier spectrum of the pattern. As in earlier studies, electrophysiological findings were complemented by monkey and human psychophysics.  Well into his 70\u2019s, De Valois continued to pursue the transformations of visual information in LGN and striate cortex. In studies with N. Cottaris and others, De Valois applied reverse correlation techniques to study transformations of spatial, temporal, and chromatic information in LGN and striate cortex.",
            "score": 59.94191491603851
        },
        {
            "docid": "32528_17",
            "document": "Visual cortex . The tuning properties of V1 neurons (what the neurons respond to) differ greatly over time. Early in time (40 ms and further) individual V1 neurons have strong tuning to a small set of stimuli. That is, the neuronal responses can discriminate small changes in visual orientations, spatial frequencies and colors. Furthermore, individual V1 neurons in humans and animals with binocular vision have ocular dominance, namely tuning to one of the two eyes. In V1, and primary sensory cortex in general, neurons with similar tuning properties tend to cluster together as cortical columns. David Hubel and Torsten Wiesel proposed the classic ice-cube organization model of cortical columns for two tuning properties: ocular dominance and orientation. However, this model cannot accommodate the color, spatial frequency and many other features to which neurons are tuned . The exact organization of all these cortical columns within V1 remains a hot topic of current research. The mathematical modeling of this function has been compared to Gabor transforms.",
            "score": 43.42969560623169
        },
        {
            "docid": "25335695_23",
            "document": "Perceptual learning . The Reverse Hierarchy Theory (RHT), proposed by Ahissar & Hochstein, aims to link between learning dynamics and specificity and the underlying neuronal sites. RHT proposes that na\u00efve performance is based on responses at high-level cortical areas, where crude, categorical level representations of the environment are represented. Hence initial learning stages involve understanding global aspects of the task. Subsequent practice may yield better perceptual resolution as a consequence of accessing lower-level information via the feedback connections going from high to low levels. Accessing the relevant low-level representations requires a backward search during which informative input populations of neurons in the low level are allocated. Hence, subsequent learning and its specificity reflect the resolution of lower levels. RHT thus proposes that initial performance is limited by the high-level resolution whereas post-training performance is limited by the resolution at low levels. Since high-level representations of different individuals differ due to their prior experience, their initial learning patterns may differ. Several imaging studies are in line with this interpretation, finding that initial performance is correlated with average (BOLD) responses at higher-level areas whereas subsequent performance is more correlated with activity at lower-level areas. RHT proposes that modifications at low levels will occur only when the backward search (from high to low levels of processing) is successful. Such success requires that the backward search will \"know\" which neurons in the lower level are informative. This \"knowledge\" is gained by training repeatedly on a limited set of stimuli, such that the same lower-level neuronal populations are informative during several trials. Recent studies found that mixing a broad range of stimuli may also yield effective learning if these stimuli are clearly perceived as different, or are explicitly tagged as different. These findings further support the requirement for top-down guidance in order to obtain effective learning.",
            "score": 59.45828866958618
        },
        {
            "docid": "18345264_14",
            "document": "Neural correlates of consciousness . Logothetis and colleagues recorded a variety of visual cortical areas in awake macaque monkeys performing a binocular rivalry task. Macaque monkeys can be trained to report whether they see the left or the right image. The distribution of the switching times and the way in which changing the contrast in one eye affects these leaves little doubt that monkeys and humans experience the same basic phenomenon. In the primary visual cortex (V1) only a small fraction of cells weakly modulated their response as a function of the percept of the monkey while most cells responded to one or the other retinal stimulus with little regard to what the animal perceived at the time. But in a high-level cortical area such as the inferior temporal cortex along the ventral stream almost all neurons responded only to the perceptually dominant stimulus, so that a \"face\" cell only fired when the animal indicated that it saw the face and not the pattern presented to the other eye. This implies that NCC involve neurons active in the inferior temporal cortex: it is likely that specific reciprocal actions of neurons in the inferior temporal and parts of the prefrontal cortex are necessary.",
            "score": 45.390546560287476
        },
        {
            "docid": "32528_24",
            "document": "Visual cortex . It is argued that the entire ventral visual-to-hippocampal stream is important for visual memory. This theory, unlike the dominant one, predicts that object-recognition memory (ORM) alterations could result from the manipulation in V2, an area that is highly interconnected within the ventral stream of visual cortices. In the monkey brain, this area receives strong feedforward connections from the primary visual cortex (V1) and sends strong projections to other secondary visual cortices (V3, V4, and V5). Most of the neurons of this area are tuned to simple visual characteristics such as orientation, spatial frequency, size, color, and shape. Anatomical studies implicate layer 3 of area V2 in visual-information processing. In contrast to layer 3, layer 6 of the visual cortex is composed of many types of neurons, and their response to visual stimuli is more complex.",
            "score": 41.12359571456909
        },
        {
            "docid": "2860430_26",
            "document": "Neural oscillation . Both single neurons and groups of neurons can generate oscillatory activity spontaneously. In addition, they may show oscillatory responses to perceptual input or motor output. Some types of neurons will fire rhythmically in the absence of any synaptic input. Likewise, brain-wide activity reveals oscillatory activity while subjects do not engage in any activity, so-called resting-state activity. These ongoing rhythms can change in different ways in response to perceptual input or motor output. Oscillatory activity may respond by increases or decreases in frequency and amplitude or show a temporary interruption, which is referred to as phase resetting. In addition, external activity may not interact with ongoing activity at all, resulting in an additive response.",
            "score": 36.48474955558777
        },
        {
            "docid": "25335695_18",
            "document": "Perceptual learning . Indeed, a relevant signal in a given behavioral condition may be considered noise in another. For example, when presented with two similar stimuli, one might endeavor to study the differences between their representations in order to improve one's ability to discriminate between them, or one may instead concentrate on the similarities to improve one's ability to identify both as belonging to the same category. A specific difference between them could be considered 'signal' in the first case and 'noise' in the second case. Thus, as we adapt to tasks and environments, we pay increasingly more attention to the perceptual features that are relevant and important for the task at hand, and at the same time, less attention to the irrelevant features. This mechanism is called attentional weighting.",
            "score": 68.4876856803894
        },
        {
            "docid": "1619306_35",
            "document": "Multisensory integration . In contrast, the dorsal auditory pathway, projecting from the temporal lobe is largely concerned with processing spatial information, and contains receptive fields that are topographically organized. Fibers from this region project directly to neurons governing corresponding receptive fields in V1. The perceptual consequences of this have not yet been empirically acknowledged. However, it can be hypothesized that these projections may be the precursors of increased acuity and emphasis of visual stimuli in relevant areas of perceptual space. Consequently, this finding rejects Jones and Powell's (1970) hypothesis and thus is in conflict with Sadato \"et al.\"'s (2004) findings. A resolution to this discrepancy includes the possibility that primary sensory areas can not be classified as a single group, and thus may be far more different from what was previously thought.",
            "score": 54.356706619262695
        },
        {
            "docid": "4236583_34",
            "document": "Visual search . Studies have consistently shown that autistic individuals performed better and with lower reaction times in feature and conjunctive visual search tasks than matched controls without autism. Several explanations for these observations have been suggested. One possibility is that people with autism have enhanced perceptual capacity. This means that autistic individuals are able to process larger amounts of perceptual information, allowing for superior parallel processing and hence faster target location. Second, autistic individuals show superior performance in discrimination tasks between similar stimuli and therefore may have an enhanced ability to differentiate between items in the visual search display. A third suggestion is that autistic individuals may have stronger top-down target excitation processing and stronger distractor inhibition processing than controls. Keehn et al. (2008) used an event-related functional magnetic resonance imaging design to study the neurofunctional correlates of visual search in autistic children and matched controls of typically developing children. Autistic children showed superior search efficiency and increased neural activation patterns in the frontal, parietal, and occipital lobes when compared to the typically developing children. Thus, autistic individuals' superior performance on visual search tasks may be due to enhanced discrimination of items on the display, which is associated with occipital activity, and increased top-down shifts of visual attention, which is associated with the frontal and parietal areas.",
            "score": 74.28047525882721
        },
        {
            "docid": "2664501_4",
            "document": "Microsaccade . Experiments in neurophysiology from different laboratories showed that fixational eye movements, particularly microsaccades, strongly modulate the activity of neurons in the visual areas of the macaque brain. In the lateral geniculate nucleus (LGN) and the primary visual cortex (V1), microsaccades can move a stationary stimulus in and out of a neuron's receptive field, thereby producing transient neural responses. Microsaccades might account for much of the response variability of neurons in visual area V1 of the awake monkey.",
            "score": 25.80510902404785
        },
        {
            "docid": "18345264_16",
            "document": "Neural correlates of consciousness . In a related perceptual phenomenon, \"flash suppression\", the percept associated with an image projected into one eye is suppressed by flashing another image into the other eye while the original image remains. Its methodological advantage over binocular rivalry is that the timing of the perceptual transition is determined by an external trigger rather than by an internal event. The majority of cells in the inferior temporal cortex and the superior temporal sulcus of monkeys trained to report their percept during flash suppression follow the animal's percept: when the cell's preferred stimulus is perceived, the cell responds. If the picture is still present on the retina but is perceptually suppressed, the cell falls silent, even though primary visual cortex neurons fire. Single-neuron recordings in the medial temporal lobe of epilepsy patients during flash suppression likewise demonstrate abolishment of response when the preferred stimulus is present but perceptually masked.",
            "score": 41.83533477783203
        },
        {
            "docid": "25335695_19",
            "document": "Perceptual learning . However, recent studies suggest that perceptual learning occurs without selective attention. Studies of such task-irrelevant perceptual learning (TIPL) show that the degree of TIPL is similar to that found through direct training procedures. TIPL for a stimulus depends on the relationship between that stimulus and important task events or upon stimulus reward contingencies. It has thus been suggested that learning (of task irrelevant stimuli) is contingent upon spatially diffusive learning signals. Similar effects, but upon a shorter time scale, have been found for memory processes and in some cases is called attentional boosting. Thus, when an important (alerting) event occurs, learning may also affect concurrent, non-attended and non-salient stimuli.",
            "score": 49.62272381782532
        },
        {
            "docid": "2860457_6",
            "document": "Neural ensemble . Neuronal ensembles encode information in a way somewhat similar to the principle of Wikipedia operation \u2013 multiple edits by many participants. Neuroscientists have discovered that individual neurons are very noisy. For example, by examining the activity of only a single neuron in the visual cortex, it is very difficult to reconstruct the visual scene that the owner of the brain is looking at. Like a single Wikipedia participant, an individual neuron does not 'know' everything and is likely to make mistakes. This problem is solved by the brain having billions of neurons. Information processing by the brain is population processing, and it is also distributed \u2013 in many cases each neuron knows a little bit about everything, and the more neurons participate in a job, the more precise the information encoding. In the distributed processing scheme, individual neurons may exhibit neuronal noise, but the population as a whole averages this noise out.",
            "score": 42.69058108329773
        }
    ],
    "r": [
        {
            "docid": "25335695_4",
            "document": "Perceptual learning . Laboratory studies reported many examples of dramatic improvements in sensitivities from appropriately structured perceptual learning tasks. In visual Vernier acuity tasks, observers judge whether one line is displaced above or below a second line. Untrained observers are often already very good with this task, but after training, observers' threshold has been shown to improve as much as 6 fold. Similar improvements have been found for visual motion discrimination and orientation sensitivity. In visual search tasks, observers are asked to find a target object hidden among distractors or in noise. Studies of perceptual learning with visual search show that experience leads to great gains in sensitivity and speed. In one study by Karni and Sagi, the time it took for subjects to search for an oblique line among a field of horizontal lines was found to improve dramatically, from about 200ms in one session to about 50ms in a later session. With appropriate practice, visual search can become automatic and very efficient, such that observers do not need more time to search when there are more items present on the search field. Tactile perceptual learning has been demonstrated on spatial acuity tasks such as tactile grating orientation discrimination, and on vibrotactile perceptual tasks such as frequency discrimination; tactile learning on these tasks has been found to transfer from trained to untrained fingers. Practice with Braille reading and daily reliance on the sense of touch may underlie the enhancement in tactile spatial acuity of blind compared to sighted individuals.",
            "score": 96.1004638671875
        },
        {
            "docid": "49045837_6",
            "document": "Spatial ability . Spatial perception is also very relevant in sports. For example, a study found that cricket players who were faster at picking up information from briefly presented visual displays were significantly better batsmen in an actual game. A 2015 study published in the \"Journal of Vision\" found that soccer players had higher perceptual ability for body kinematics such as processing multitasking crowd scenes which involve pedestrians crossing a street or complex dynamic visual scenes. Another study published in the \"Journal of Human Kinetics\" on fencing athletes found that achievement level was highly correlated with spatial perceptual skills such as visual discrimination, visual-spatial relationships, visual sequential memory, narrow attentional focus and visual information processing. A review published in the journal of \"Neuropsychologia\" found that spatial perception involves attributing meaning to an object or space, so that their sensory processing is actually part of semantic processing of the incoming visual information. The review also found that spatial perception involves the human visual system in the brain and the parietal lobule which is responsible for visuomotor processing and visually goal-directed action. Studies have also found that individuals who played first person shooting games had better spatial perceptual skills like faster and more accurate performance in a peripheral and identification task while simultaneously performing a central search. Researchers suggested that, in addition to enhancing the ability to divide attention, playing action games significantly enhances perceptual skills like top-down guidance of attention to possible target locations.",
            "score": 85.35716247558594
        },
        {
            "docid": "41848173_14",
            "document": "Surround suppression . Surround suppression likely participates in context-dependent perceptual tasks. Some specific tasks in which surround suppression may aid include: These tasks require the use of inputs over wide regions of visual space, meaning that independent responses to small parts of the visual field (a classical linear model of V1) would not be able to produce these effects. There is evidence that surround suppression participates in these tasks by either adjusting the representation of the classical receptive field or representing entirely different features that include both the classical receptive field and the surround. Direct comparison between physiology and psychophysical experiments have been done on several perceptual effects. These include: (1) the reduced apparent contrast of a grating texture embedded in a surrounding grating, (2) target identification when flanked by other features, (3) saliency of broken contours surrounded by edge segments of different orientations, and (4) orientation discrimination when surrounded by features of different orientations and spatial frequencies.",
            "score": 85.30408477783203
        },
        {
            "docid": "732493_9",
            "document": "Visual short-term memory . Psychophysical experiments suggest that information is encoded in VSTM across multiple parallel channels, each channel associated with a particular perceptual attribute (Magnussen, 2000). Within this framework, a decrease in an observer's ability to detect a change with increasing set-size can be attributed to two different processes: (1) if decisions are made across different channels, decreases in performance are typically small, and consistent with decreases expected when making multiple independent decisions (Greenlee & Thomas, 1993; Vincent & Regan, 1995); (2) if multiple decisions are made within the same channel, the decrease in performance is much greater than expected on the basis of increased decision-noise alone, and is attributed to interference caused by multiple decisions within the same perceptual channel (Magnussen & Greenlee, 1997).",
            "score": 84.12792205810547
        },
        {
            "docid": "35982062_6",
            "document": "Biased Competition Theory . There are two major neural pathways that process the information in the visual field; the ventral stream and the dorsal stream. The two pathways run in parallel and are both working simultaneously. The ventral stream is important for object recognition and often referred to as the \u201cwhat\u201d system of the brain; it projects to the inferior temporal cortex. The dorsal stream is important for spatial perception and performance and is referred to as the \u201cwhere\u201d system which projects to the posterior parietal cortex. According to the biased competition theory, an individual\u2019s visual system has limited capacity to process information about multiple objects at any given time. For example, if an individual was presented with two stimuli (objects) and was asked to identify attributes of each object at the same time, the individual\u2019s performance would be worse in comparison to if the objects were presented separately. This suggests multiple objects presented simultaneously in the visual field will compete for neural representation due to limited processing resources. Single cell recording studies conducted by Kastner and Ungerleider examined the neural mechanisms behind the biased competition theory. In their experiment the size of the receptive field's (RF) of neurons within the visual cortex were examined. A single visual stimulus was presented alone in a neuron\u2019s RF, followed with another stimulus presented simultaneously within the same RF. The single \u2018effective\u2019 stimuli produced a low firing rate, whereas the two stimuli presented together produced a high firing rate. The response to the paired stimuli was reduced. This suggests that when two stimuli are presented together within a neuron\u2019s RF, the stimuli are processed in a mutually suppressive manner, rather than being processed independently. This suppression process, according to Kastner and Ungerleider, occurs when two stimuli are presented together because they compete for neural representation, due to limited cognitive processing capacity. The RF experiment suggests that as the number of objects increase, the information available for each object will decrease due to increased neural workload (suppression), and decreased cognitive capacity. In order for an object in the visual field or RF be efficiently processed, there needs to be a way to bias these neurological resources towards the object. Attention prioritizes task relevant objects, biasing this process. For example, this bias can be towards an object which is currently attended to in the visual field or RF, or towards the object that is most relevant to one\u2019s behavior. Functional magnetic resonance imaging (fMRI) has shown that biased competition theory can explain the observed attention effects at a neuronal level. Attention effects bias the internal weight (strengthens connections) of task relevant features toward the attended object. This was shown by Reddy, Kanwisher, and van Rullen who found an increase in oxygenated blood to a specific neuron following a locational cue. Further neurological support comes from neurophysiological studies which have shown that attention results from Top-down biasing, which in turn influences neuronal spiking. In sum, external inputs affect the Top-down guidance of attention, which bias specific neurons in the brain.",
            "score": 78.76516723632812
        },
        {
            "docid": "23026009_11",
            "document": "Biological theories of dyslexia . The concept of a perceptual noise exclusion deficit (impaired filtering of behaviorally irrelevant visual information in dyslexia or visual-noise) is an emerging hypothesis, supported by research showing that subjects with dyslexia experience difficulty in performing visual tasks (such as motion detection in the presence of perceptual distractions) but do not show the same impairment when the distracting factors are removed in an experimental setting. The researchers have analogized their findings concerning visual discrimination tasks to findings in other research related to auditory discrimination tasks. They assert that dyslexic symptoms arise because of an impaired ability to filter out both visual and auditory distractions, and to categorize information so as to distinguish the important sensory data from the irrelevant.",
            "score": 77.99247741699219
        },
        {
            "docid": "5611461_3",
            "document": "Contrast (vision) . According to Campbell and Robson (1968), the human contrast sensitivity function shows a typical band-pass filter shape peaking at around 4\u00a0cycles per degree with sensitivity dropping off either side of the peak. This finding has led many to claim that the human visual system is most sensitive in detecting contrast differences occurring at 4\u00a0cycles per degree; i.e., at this spatial frequency humans can detect lower contrast differences than at any other angular frequency. However, the claim of frequency sensitivity is problematic given, for example, that changes of distance don't seem to affect the relevant perceptual patterns (as noted, for example, in the figure caption to Solomon and Pelli (1994) While the latter authors are referring specifically to letters, they make no objective distinction between these and other shapes. The relative insensitivity of contrast effects to distance (and thus spatial frequency) may also be observed by casual inspection of a paradigmantic sweep grating, as may be observed here",
            "score": 77.66709899902344
        },
        {
            "docid": "48013821_10",
            "document": "Russell L. De Valois . At the time of De Valois\u2019 move to Berkeley, linear systems analysis was emerging as a tool for studying the early stages of visual processing. Although this technique had long been applied to problems in optics and engineering, vision scientists Fergus Campbell and John Robson measured human sensitivity to patterns of spatial sinusoidal gratings of varying periodicity and first proposed spatial frequency selective \u201cchannels\u201d to explain a number of psychophysical phenomena in pattern perception. De Valois, consistent with his conviction that perception must be linked to neuronal responses, seized on these findings and began electrophysiological studies of the mechanisms of early visual processing of form.",
            "score": 76.5380859375
        },
        {
            "docid": "49990541_22",
            "document": "Visual selective attention in dementia . Visual selective attention requires many underlying cognitive processes, including detection of important sensory and perceptual information, the ability to inhibit information that is irrelevant to the task, and the ability to shift attention from feature or location to another. In this study, it was found that DLB patients in this task performed markedly worse than both AD patients and healthy controls in the single-target condition. This suggests that the perceptual filtering component of selective attention is significantly impaired in DLB. Difficulties in discrimination in DLB patients for visual stimuli may be due to reduced ability to select and encode relevant or important information in the target search. DLB patients\u2019 general slowness could have increased perceptual interference due to masking from distractors, and target selection and processing (in tasks such as the RSVP task) must be performed under time pressure.",
            "score": 75.55352783203125
        },
        {
            "docid": "18345264_13",
            "document": "Neural correlates of consciousness . The possibility of precisely manipulating visual percepts in time and space has made vision a preferred modality in the quest for the NCC. Psychologists have perfected a number of techniques \u2013 masking, binocular rivalry, continuous flash suppression, motion induced blindness, change blindness, inattentional blindness \u2013 in which the seemingly simple and unambiguous relationship between a physical stimulus in the world and its associated percept in the privacy of the subject's mind is disrupted. In particular a stimulus can be perceptually suppressed for seconds or even minutes at a time: the image is projected into one of the observer's eyes but is invisible, not seen. In this manner the neural mechanisms that respond to the subjective percept rather than the physical stimulus can be isolated, permitting visual consciousness to be tracked in the brain. In a \"perceptual illusion\", the physical stimulus remains fixed while the percept fluctuates. The best known example is the \"Necker cube\" whose 12 lines can be perceived in one of two different ways in depth. A perceptual illusion that can be precisely controlled is \"binocular rivalry\". Here, a small image, e.g., a horizontal grating, is presented to the left eye, and another image, e.g., a vertical grating, is shown to the corresponding location in the right eye. In spite of the constant visual stimulus, observers consciously see the horizontal grating alternate every few seconds with the vertical one. The brain does not allow for the simultaneous perception of both images.",
            "score": 75.23846435546875
        },
        {
            "docid": "8766922_6",
            "document": "Perceptual noise exclusion hypothesis . This hypothesis is supported by a study showing dyslexic subjects in comparison to nondyslexic subjects in the research sample were less responsive to cueing in a visual discrimination task, suggesting that the dyslexics had greater difficulty than controls with prioritizing certain visual information based on previous exposure. The researchers also found that performance on the cuing task could be a more accurate means of discerning dyslexic from normal readers in comparison to the range of other psychophysical tasks typically used in dyslexia research.",
            "score": 74.40237426757812
        },
        {
            "docid": "4236583_34",
            "document": "Visual search . Studies have consistently shown that autistic individuals performed better and with lower reaction times in feature and conjunctive visual search tasks than matched controls without autism. Several explanations for these observations have been suggested. One possibility is that people with autism have enhanced perceptual capacity. This means that autistic individuals are able to process larger amounts of perceptual information, allowing for superior parallel processing and hence faster target location. Second, autistic individuals show superior performance in discrimination tasks between similar stimuli and therefore may have an enhanced ability to differentiate between items in the visual search display. A third suggestion is that autistic individuals may have stronger top-down target excitation processing and stronger distractor inhibition processing than controls. Keehn et al. (2008) used an event-related functional magnetic resonance imaging design to study the neurofunctional correlates of visual search in autistic children and matched controls of typically developing children. Autistic children showed superior search efficiency and increased neural activation patterns in the frontal, parietal, and occipital lobes when compared to the typically developing children. Thus, autistic individuals' superior performance on visual search tasks may be due to enhanced discrimination of items on the display, which is associated with occipital activity, and increased top-down shifts of visual attention, which is associated with the frontal and parietal areas.",
            "score": 74.28047180175781
        },
        {
            "docid": "7214278_15",
            "document": "Decision field theory . The Decision Field Theory has demonstrated an ability to account for a wide range of findings from behavioral decision making for which the purely algebraic and deterministic models often used in economics and psychology cannot account. Recent studies that record neural activations in non-human primates during perceptual decision making tasks have revealed that neural firing rates closely mimic the accumulation of preference theorized by behaviorally-derived diffusion models of decision making.",
            "score": 72.95742797851562
        },
        {
            "docid": "3555532_6",
            "document": "Kappa effect . A Bayesian perceptual model replicates the tactile kappa effect and other tactile spatiotemporal illusions, including the tau effect and the cutaneous rabbit illusion. According to this model, brain circuitry encodes the expectation that tactile stimuli tend to move slowly. The Bayesian model reaches an optimal probabilistic inference by combining uncertain spatial and temporal sensory information with a prior expectation for low-speed movement. The expectation that stimuli tend to move slowly results in the perceptual overestimation of the time elapsed between rapidly successive taps applied to separate skin locations. Simultaneously, the model perceptually underestimates the spatial separation between stimuli, thereby reproducing the cutaneous rabbit illusion and the tau effect. Goldreich (2007) speculated that a Bayesian slow-speed prior might explain the visual kappa effect as well the tactile one. Recent empirical studies support this suggestion.",
            "score": 72.84103393554688
        },
        {
            "docid": "43374303_4",
            "document": "Andreas K. Engel . Andreas Engel has become known by his work on the so-called \u201ebinding problem\u201c. His research focuses on the hypothesis that temporal synchrony serves for dynamic coordination of signals in the brain. In addition to working on the experimental validation of this hypothesis, Engel pursues research on its cognitive and theoretical implications. As a postdoc with Wolf Singer at the Max Planck Institute for Brain Research at Frankfurt, Engel was involved in studies that demonstrated the relevance of neural synchrony, in particular of so-called gamma waves, for processing of perceptual information. In particular, the group provided evidence that temporal correlations can serve for the binding of features into coherent sensory representations. In addition to addressing the relevance of synchrony and neuronal oscillations in the visual system, the work of Engel's group yielded evidence for a relation between neural synchrony and visual awareness. In addition, Engel and coworkers contributed to demonstrating a functional role of neural synchrony for sensorimotor coupling. In the past 15 years, Engel's group has expanded their work to the human brain, using EEG and MEG in combination with source modeling techniques. The results of these studies demonstrate the importance of neuronal oscillations and synchrony for perceptual processing, attention, working memory, decision-making and consciousness. Recent work of the group on the interaction of visual, auditory and tactile systems suggests a role of temporal binding for multisensory integration. Furthermore, the group has developed novel methods for the electrophysiological analysis of resting state network activity. Engel's group also applies these approaches for the study of network malfunction in patients with movement disorders, multiple sclerosis and schizophrenia, in studies on pain, and altered networks after early sensory deprivation.  Engel also explores implications of these neurophysiogical results for theories of perception, cognition and action. A major focus of his work are the implications of the studies on neural synchrony for understanding the neural correlates of consciousness. Recent papers address links between neural dynamics and enactive views of cognition, investigating the grounding of cognition in sensorimotor coupling.",
            "score": 72.70150756835938
        },
        {
            "docid": "265752_42",
            "document": "Decision-making . A common laboratory paradigm for studying neural decision-making is the two-alternative forced choice task (2AFC), in which a subject has to choose between two alternatives within a certain time. A study of a two-alternative forced choice task involving rhesus monkeys found that neurons in the parietal cortex not only represent the formation of a decision but also signal the degree of certainty (or \"confidence\") associated with the decision. Another recent study found that lesions to the ACC in the macaque resulted in impaired decision-making in the long run of reinforcement guided tasks suggesting that the ACC may be involved in evaluating past reinforcement information and guiding future action. A 2012 study found that rats and humans can optimally accumulate incoming sensory evidence, to make statistically optimal decisions.",
            "score": 72.68773651123047
        },
        {
            "docid": "18874133_15",
            "document": "Polysubstance dependence . Another study that tried to find differences between the effects of particular drugs focused on polysubstance users who were seeking treatment for addictions to cannabis, cocaine, and heroin. They studied a group of polysubstance users and a group that was not dependent on any drugs. Because alcohol was a common co-substance for nearly all of the polysubstance user group, it was difficult to tell exactly which drugs were affecting certain cognitive functions. The researchers found that the difference in the two groups' performance levels on executive function, or higher-level cognitive processing tasks were consistently showing that the polysubstance group scored lower than the control group. In general, this meant that multiple substances negatively affected the polysubstance group's cognitive functioning. More specifically, the researchers found that the amount of cannabis and cocaine affected the verbal part of working memory, the reasoning task, and decision making, while cocaine and heroin had a similar negative effect on visual and spatial tasks, but cannabis particularly affected visual and spatial working memory. These results suggest that the combined use of cannabis, cocaine, and heroin impair more cognitive functions more severely than if used separately.",
            "score": 72.60321807861328
        },
        {
            "docid": "35982062_9",
            "document": "Biased Competition Theory . A Top-down process is characterized by a high level of direction of sensory processing by more cognition; Top-down processing is based on pre-existing knowledge when interpreting sensory information. Top-down guidance of attention refers to when the properties of an object (i.e. color, shape) are activated and held in working memory to facilitate the visual search for that object. This controls visual search by guiding attention only to objects that could be the target and avoiding attention on irrelevant objects. Top-down processes are not a complete representation of the object but are coarse, which is why objects similar in color, shape or meaning are often attended to in the process of discriminating irrelevant objects. There is evidence that observers have Top-down control over the locations that will benefit from biased competition in spatial selection visual tasks. Evidence supports that observers can make voluntary decision about which locations are selected. or features that capture the attention in a stimulus-driven manner. Neurophysiology studies have showed that the neural mechanisms in Top-down processing are also seen in attention and working memory, suggesting Top-down processes play an important role in those functions as well. Additionally, Top-down processes can modulate Bottom-up processes by suppressing the \u201cpop-out\u201d features of Bottom-up processing from distracting from the visual search. fMRI studies have investigated the Top-down and Bottom-up processes involved in biased competition theory. Results of fMRI suggest that both Bottom-up and Top-down processes work in parallel to bias competition. Multiple studies have shown that stimuli in the visual field suppress each other when presented together, but not when each stimulus is presented alone. Kastner and colleagues also found that directing attention to the specific location of a stimulus reduces the suppressive effect. Increased activity in the visual cortex was also observed; this was the result of Top-down biasing due to the favoring of the attended location.",
            "score": 72.5967788696289
        },
        {
            "docid": "27120661_6",
            "document": "Vigilance (psychology) . Green and Swets formulated the Signal Detection Theory, or SDT, in 1966 to characterize detection task performance sensitivity while accounting for both the observer's perceptual ability and willingness to respond. SDT assumes an active observer making perceptual judgments as conditions of uncertainty vary. A decision maker can vary their sensitivity, characterized by d', to allow more or less correct detections, but at the respective cost of more or less false alarms. This is termed a criterion shift. The degree to which the observer tolerates false alarms to achieve a higher rate of detection is termed the bias. Bias represents a strategy to minimize the consequences of missed targets and false alarms. As an example, the lookout during a bank robbery must set a threshold for how \"cop-like\" an approaching individual or vehicle may be. Failing to detect the \"cop\" in a timely fashion may result in jail time, but a false alarm will result in a lost opportunity to steal money. In order to produce a bias-free measure, d' is calculated by measuring the distance between the means of the signal and non-signals (noise) and scaling by the standard deviation of the noise. Mathematically, this can be accomplished by subtracting the z-score of the hit rate from the z-score of the false alarm rate. Application of SDT to the study of vigilance indicates that in most, but not all cases, vigilance decrement is not the result of a reduction in sensitivity over time. In most cases a reduction of detections is accompanied by a commensurate reduction in false alarms, such that d' is relatively unchanged.",
            "score": 71.91815185546875
        },
        {
            "docid": "49026556_3",
            "document": "Sex differences in cognition . Cognitive abilities are mental abilities that a person uses in everyday life, as well as specific demand tasks. The most basic of these abilities are memory, executive function, processing speed and perception, which combine to form a larger perceptual umbrella relating to different social, affective, verbal and spatial information. Memory, which is one of the primary core of cognitive abilities can be broken down into short-term memory, working memory and long-term memory. There are also other abilities relating to perceptual information such as mental rotation, spatial visualization ability, verbal fluency and reading comprehension. Other larger perceptual umbrellas include social cognition, empathy, spatial perception and verbal abilities.",
            "score": 71.83794403076172
        },
        {
            "docid": "1008632_5",
            "document": "Baddeley's model of working memory . Baddeley & Hitch's argument for the distinction of two domain-specific slave systems in the older model was derived from experimental findings with dual-task paradigms. Performance of two simultaneous tasks requiring the use of two separate perceptual domains (i.e. a visual and a verbal task) is nearly as efficient as performance of the tasks individually. In contrast, when a person tries to carry out two tasks simultaneously that use the same perceptual domain, performance is less efficient than when performing the tasks individually.",
            "score": 71.73796081542969
        },
        {
            "docid": "15670228_10",
            "document": "Integrative agnosia . In the second group of experiments, the patient, H.J.A, was tested on his ability to manipulate images, assess information using his spatial memory, and complete pattern tasks. The patient performed a series of tasks such as the Moscovitch Letter Manipulation Task, the Brooks Matrix Task, and a Compass Directions Task. The patient proved able to receive the spatial material well with short-term memory when manipulating materials without a reference frame. The patient was still able to make global processes, identify shapes, single lines, and letters, but lacked the ability to process configurations in perceptual representations, in the respective tasks. When visually holding an image for 10 seconds, the patient was able to process a spatial pattern and transfer that image onto paper accurately. The tasks that H.J.A were given showed where the parts specifically failed to integrate: the patent's perception on spatial elements without a point of reference. With a reference point, H.J.A is able to integrate the parts.",
            "score": 71.58037567138672
        },
        {
            "docid": "21659985_7",
            "document": "Ideal observer analysis . Geisler (2003) (slightly reworded): The central concept in ideal observer analysis is the \"ideal observer\", a theoretical device that performs a given task in an optimal fashion given the available information and some specified constraints. This is not to say that ideal observers perform without error, but rather that they perform at the physical limit of what is possible in the situation. The fundamental role of uncertainty and noise implies that ideal observers must be defined in probabilistic (statistical) terms. \"Ideal observer analysis\" involves determining the performance of the ideal observer in a given task and then comparing its performance to that of a real perceptual system, which (depending on the application) might be the system as a whole, a subsystem, or an elementary component of the system (e.g. a neuron).",
            "score": 71.01081848144531
        },
        {
            "docid": "42980268_15",
            "document": "Visual spatial attention . It is debated in research on visual spatial attention whether it is possible to split attention across different areas in the visual field. The \u2018spotlight\u2019 and \u2018zoom-lens\u2019 accounts postulate that attention uses a single unitary focus. Therefore, spatial attention can only be allocated to adjacent areas in the visual field and consequently cannot be split. This was supported by an experiment that altered the spatial cueing paradigm by using two cues, a primary and a secondary cue. It was found that the secondary cue was only effective in focusing attention when its location was adjacent to the primary cue. In addition, it has been demonstrated that observers are unable to ignore stimuli presented in areas situated between two cued locations. These findings have proposed that attention cannot be split across two non-contiguous regions. However, other studies have demonstrated that spatial attention can be split across two locations. For example, observers were able to attend simultaneously to two different targets located in opposite hemifields. Research has even suggested that humans are able to focus attention across two to four locations in the visual field. Another perspective is that spatial attention can be split only under certain conditions. This perspective suggests that the splitting of spatial attention is flexible. Research demonstrated that whether spatial attention is unitary or divided depends on the goals of the task. Therefore, if dividing attention is beneficial to the observer then a divided focus of attention will be utilised.",
            "score": 70.94832611083984
        },
        {
            "docid": "15670228_12",
            "document": "Integrative agnosia . It was concluded that the tasks performed well by H.J.A included the tasks involving ranges of imagery-based tasks, accurately make judgments about global representations such as the angles of a clock, maintained visual patterns over inter-stimulus intervals, mentally rotating letters, manipulating two elements of an image. In contrast, impairment was gauged to be the lack of the ability in recalling spatial layouts, judging spatial directions, judging relative positions of objects, The Brooks Matrix Test, Compass Direction Task, reproducing abstract patterns, and reproducing both possible and impossible figures. Due to the impairment, it was identified that the patient did not have intact imagery and visual short-term memory, made apparent by the spatial relations test. Due to Integrative Agnosia, the patients take information from a top-down manner, using stored knowledge to retrieve an objects perceptual properties. It is much more difficult for patients to use a bottom-up method, or perceiving through a visual stimulus, because of the inability to accurately code the patterns in the visual short-term memory.",
            "score": 70.92410278320312
        },
        {
            "docid": "2956315_6",
            "document": "Two-streams hypothesis . Goodale and Milner Accumulating an array of neuropsychological, electrophysiological, and behavioural evidence for their model. According to their data, the ventral \u2018perceptual\u2019 stream computes a detailed map of the world from visual input, which can then be used for cognitive operations, and the dorsal \u2018action\u2019 stream transforms incoming visual information to the requisite egocentric (head-centered) coordinate system for skilled motor planning. The model also posits that visual perception encodes spatial properties of objects, such as size and location, relative to other objects in the visual field; in other words, it utilizes relative metrics and scene-based frames of reference. Visual action planning and coordination, on the other hand, uses absolute metrics determined via egocentric frames of reference, computing the actual properties of objects relative to the observer. Thus, grasping movements directed towards objects embedded in size-contrast-ambiguous scenes have been shown to escape the effects of these illusions, as different frames of references and metrics are involved in the perception of the illusion versus the execution of the grasping act.  Norman proposed a similar dual-process model of vision, and described eight main differences between the two systems consistent with other two-system models.",
            "score": 70.73639678955078
        },
        {
            "docid": "56439577_40",
            "document": "Temporal envelope and fine structure . Psychophysical studies have suggested that degraded TFS processing due to age and hearing loss may underlie some suprathreshold deficits, such as speech perception; however, debate remains about the underlying neural correlates. The strength of phase locking to the temporal fine structure of signals (TFS) in quiet listening conditions remains normal in peripheral single-neuron responses following cochlear hearing loss. Although these data suggest that the fundamental ability of auditory-nerve fibers to follow the rapid fluctuations of sound remains intact following cochlear hearing loss, deficits in phase locking strength do emerge in background noise. This finding, which is consistent with the common observation that listeners with cochlear hearing loss have more difficulty in noisy conditions, results from reduced cochlear frequency selectivity associated with outer-hair-cell dysfunction. \u00a0Although only limited effects of age and hearing loss have been observed in terms of TFS coding strength of narrowband sounds, more dramatic deficits have been observed in TFS coding quality in response to broadband sounds, which are more relevant for everyday listening. \u00a0A dramatic loss of tonotopicity can occur following noise induced hearing loss, where auditory-nerve fibers that should be responding to mid frequencies (e.g., 2\u20134\u00a0kHz) have dominant TFS responses to lower frequencies (e.g., 700\u00a0Hz). \u00a0Notably, the loss of tonotopicity generally occurs only for TFS coding but not for ENV coding, which is consistent with greater perceptual deficits in TFS processing. This tonotopic degradation is likely to have important implications for speech perception, and can account for degraded coding of vowels following noise-induced hearing loss in which most of the cochlea responds to only the first formant, eliminating the normal tonotopic representation of the second and third formants.",
            "score": 70.58843231201172
        },
        {
            "docid": "8606019_3",
            "document": "FEAST test . The FEAST test package consists of 3 modules: Tests are administered in a standardized way and all results are scored by computer. This is done to ensure the objectivity of the process. The first phase of FEAST aims at measuring basic skills and abilities in decision-making, logical reasoning, visual perception, attention, multi-tasking and spatial orientation. This phase also includes a test on English language knowledge. All parts of the FEAST I consist of multiple choice questions. Once the candidate has successfully passed the FEAST I tests, she/he may be invited to attend a second round of testing. In this second phase she/he will do one or two work sample tests: These tests are aimed at measuring the multi-tasking abilities. The tests are more complex and will require the candidates to perform a number of different tasks at the same time like in the job of an Air Traffic Controller.  The third phase of FEAST consists in the assessment of personality traits and behavioral tendencies. The exact content of this phase will differ between organizations that use FEAST.",
            "score": 70.47819519042969
        },
        {
            "docid": "3037867_5",
            "document": "Spatial frequency . In the study of visual perception, sinusoidal gratings are frequently used to probe the capabilities of the visual system. In these stimuli, spatial frequency is expressed as the number of cycles per degree of visual angle. Sine-wave gratings also differ from one another in amplitude (the magnitude of difference in intensity between light and dark stripes), and angle.",
            "score": 70.45453643798828
        },
        {
            "docid": "25335695_25",
            "document": "Perceptual learning . In 2005, Petrov, Dosher and Lu pointed out that perceptual learning may be explained in terms of the selection of which analyzers best perform the classification, even in simple discrimination tasks. They explain that the some part of the neural system responsible for particular decisions have specificity, while low-level perceptual units do not. In their model, encodings at the lowest level do not change. Rather, changes that occur in perceptual learning arise from changes in higher-level, abstract representations of the relevant stimuli. Because specificity can come from differentially selecting information, this \"selective reweighting theory\" allows for learning of complex, abstract representation. This corresponds to Gibson's earlier account of perceptual learning as selection and learning of distinguishing features. Selection may be the unifying principles of perceptual learning at all levels.",
            "score": 69.97044372558594
        },
        {
            "docid": "27646607_7",
            "document": "Oddball paradigm . Studies of cognition often use an oddball paradigm to study effects of stimulus novelty and significance on information processing. However, an oddball tends to be perceptually more novel than the standard, repeated stimulus as well as more relevant to the ongoing task, making it difficult to disentangle effects due to perceptual novelty and stimulus significance. Evaluating different brain ERPs can decipher this effect. A frontro-central N2 component of ERP is primarily affected by perceptual novelty, whereas only the centro-parietal P3 component is modulated by both stimulus significance and novelty.",
            "score": 69.75707244873047
        },
        {
            "docid": "17523336_22",
            "document": "Olivocochlear system . Although Scharf et al.\u2019s (1993, 1994, 1997) experiments failed to produce any clear differences in the basic psychophysical characteristics of hearing (other than the detection of unexpected sounds), many other studies using both animals and humans have implicated the OCB in listening-in-noise tasks using more complex stimuli. In constant BGN, rhesus monkeys with intact OCBs have been observed to perform better in vowel discrimination tasks than those without (Dewson, 1968). In cats, an intact OCB is associated with better vowel identification (Heinz et al., 1998), sound localisation (May et al., 2004), and intensity discrimination (May and McQuone, 1995). All of these studies were performed in constant BGN. In humans, speech-in-noise discrimination measurements have been performed on individuals who had undergone unilateral vestibular neurectomy (resulting in OCB sectioning). Giraud et al. (1997) observed a small advantage in the healthy ear over the operated ear for phoneme recognition and speech intelligibility in BGN. Scharf et al. (1988) had previously investigated the role of auditory attention during speech perception, and suggested that speech-in-noise discrimination is assisted by attentional focus on frequency regions. In 2000, Zeng et al., reported that vestibular neurectomy did not directly affect pure-tone thresholds or intensity discrimination, confirming earlier findings of Scharf et al. 1994; 1997. For the listening-in-noise tasks, they observed a number of discrepancies between the healthy and operated ear. Consistent with the earlier findings of May and McQuone (1995), intensity discrimination in noise was observed to be slightly worse in the ear without olivocochlear bundle (OCB) input. However, Zeng et al.\u2019s main finding related to the \u201covershoot\u201d effect, which was found to be significantly reduced (~50%) in the operated ears. This effect was first observed by Zwicker (1965), and was characterised as an increased detection threshold of a tone when it is presented at the onset of the noise compared to when it is presented in constant, steady-state noise. Zeng et al. proposed that this finding is consistent with MOCS-evoked antimasking; that is, MOCS-evoked antimasking being absent at the onset of noise however becoming active during steady-state noise. This theory was supported by the time course of MOC activation; being similar to the time course of the overshoot effect (Zwicker, 1965), as well as the overshoot effect being disrupted in subjects with sensorineural hearing loss, for whom the MOCS would be most likely ineffectual (Bacon and Takahashi, 1992).",
            "score": 69.6490478515625
        }
    ]
}