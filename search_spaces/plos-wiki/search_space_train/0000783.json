{
    "q": [
        {
            "docid": "356382_8",
            "document": "Gene regulatory network . Genes can be viewed as nodes in the network, with input being proteins such as transcription factors, and outputs being the level of gene expression. The value of the node depends of a function which depends in the value of its regulators in previous time steps (in the Boolean network described below these are Boolean functions, typically AND, OR, and NOT). These functions have been interpreted as performing a kind of information processing within the cell, which determines cellular behavior. The basic drivers within cells are concentrations of some proteins, which determine both spatial (location within the cell or tissue) and temporal (cell cycle or developmental stage) coordinates of the cell, as a kind of \"cellular memory\". The gene networks are only beginning to be understood, and it is a next step for biology to attempt to deduce the functions for each gene \"node\", to help understand the behavior of the system in increasing levels of complexity, from gene to signaling pathway, cell or tissue level.",
            "score": 68.28764200210571
        },
        {
            "docid": "36035103_3",
            "document": "Zinc finger transcription factor . Zinc finger protein transcription factors can be encoded by genes small enough to fit a number of such genes into a single vector, allowing the medical intervention and control of expression of multiple genes and the initiation of an elaborate cascade of events. In this respect, it is also possible to target a sequence that is common to multiple (usually functionally related) genes in order to control the transcription of all these genes with a single transcription factor. Also, it is possible to target a family of related genes by targeting and modulating the expression of the endogenous transcription factor(s) that control(s) them. They also have the advantage that the targeted sequence need not be symmetrical unlike with most other DNA-binding motifs based on natural transcription factors that bind as dimers.",
            "score": 40.16373562812805
        },
        {
            "docid": "3454720_7",
            "document": "Regulator gene . Promoters reside at the beginning of the gene and serve as the site where the transcription machinery assembles and transcription of the gene begins. Enhancers turn on the promoters at specific locations, times, and levels and can be simply defined as the \u201cpromoters of the promoter.\u201d Silencers are thought to turn off gene expression at specific time points and locations. Insulators, also called boundary elements, are DNA sequences that create cis-regulatory boundaries that prevent the regulatory elements of one gene from affecting neighboring genes. The general dogma is that these regulatory elements get activated by the binding of transcription factors, proteins that bind to specific DNA sequences, and control mRNA transcription. There could be several transcription factors that need to bind to one regulatory element in order to activate it. In addition, several other proteins, called transcription cofactors, bind to the transcription factors themselves to control transcription.",
            "score": 51.453811168670654
        },
        {
            "docid": "4022741_2",
            "document": "Coactivator (genetics) . A coactivator is a type of transcriptional coregulator that binds to an activator (a transcription factor) to increase the rate of transcription of a gene or set of genes. The activator contains a DNA binding domain that binds either to a DNA promoter site or a specific DNA regulatory sequence called an enhancer. Binding of the activator-coactivator complex increases the speed of transcription by recruiting general transcription machinery to the promoter, therefore increasing gene expression. The use of activators and coactivators allows for highly specific expression of certain genes depending on cell type and developmental stage.",
            "score": 47.020891189575195
        },
        {
            "docid": "7252_30",
            "document": "Cell cycle . Many periodically expressed genes are driven by transcription factors that are also periodically expressed. One screen of single-gene knockouts identified 48 transcription factors (about 20% of all non-essential transcription factors) that show cell cycle progression defects. Genome-wide studies using high throughput technologies have identified the transcription factors that bind to the promoters of yeast genes, and correlating these findings with temporal expression patterns have allowed the identification of transcription factors that drive phase-specific gene expression. The expression profiles of these transcription factors are driven by the transcription factors that peak in the prior phase, and computational models have shown that a CDK-autonomous network of these transcription factors is sufficient to produce steady-state oscillations in gene expression).",
            "score": 58.20209515094757
        },
        {
            "docid": "22164509_6",
            "document": "Cis-regulatory module . The design of \"cis\"-regulatory modules is such that transcription factors and epigenetic modifications serve as inputs, and the output of the module is the command given to the transcription machinery, which in turn determines the rate of gene transcription or whether it is turned on or off. There are two types of transcription factor inputs: those that determine when the target gene is to be expressed and those that serve as functional \"drivers\", which come into play only during specific situations during development. These inputs can come from different time points, can represent different signal ligands, or can come from different domains or lineages of cells. However, a lot still remains unknown.",
            "score": 50.479857206344604
        },
        {
            "docid": "356382_29",
            "document": "Gene regulatory network . The GRN is created from a graph with the desired topology, imposing in-degree and out-degree distributions. Gene promoter activities are affected by other genes expression products that act as inputs, in the form of monomers or combined into multimers and set as direct or indirect. Next, each direct input is assigned to an operator site and different transcription factors can be allowed, or not, to compete for the same operator site, while indirect inputs are given a target. Finally, a function is assigned to each gene, defining the gene's response to a combination of transcription factors (promoter state). The transfer functions (that is, how genes respond to a combination of inputs) can be assigned to each combination of promoter states as desired.",
            "score": 50.5141019821167
        },
        {
            "docid": "34905782_3",
            "document": "Gene isoform . Cis-regulatory elements in the promoter contain sequences recognized by transcription factors and the basal transcription machinery. So the location of the TSS is important for understanding the biogenesis of specific isoforms.The idea that different binding partners confer different functional properties has been well studied in tissue-specific gene regulation. For example, the same transcription factor (TF) can direct gene expression in different tissues simply by binding with different TFs in each tissue. Isoforms harboring changes in the CDS have been the most thoroughly characterized because they commonly give rise to proteins with different functional properties. UTRs regulate the levels of primary transcript in numerous ways: transcript stability, folding and turnover, as well as translation efficiency. UTRs are often the target of miRNA, which typically downregulate transcript expression by triggering degradation or halting translation.",
            "score": 52.546236872673035
        },
        {
            "docid": "22072718_8",
            "document": "Biological network . The activity of genes is regulated by transcription factors, proteins that typically bind to DNA. Most transcription factors bind to multiple binding sites in a genome. As a result, all cells have complex gene regulatory networks. For instance, the human genome encodes on the order of 1,400 DNA-binding transcription factors that regulate the expression of more than 20,000 human genes. Technologies to study gene regulatory networks include ChIP-chip, ChIP-seq, CliP-seq, and others.",
            "score": 59.343539237976074
        },
        {
            "docid": "12499410_57",
            "document": "Network motif . Much experimental work has been devoted to understanding network motifs in gene regulatory networks. These networks control which genes are expressed in the cell in response to biological signals. The network is defined such that genes are nodes, and directed edges represent the control of one gene by a transcription factor (regulatory protein that binds DNA) encoded by another gene. Thus, network motifs are patterns of genes regulating each other's transcription rate. When analyzing transcription networks, it is seen that the same network motifs appear again and again in diverse organisms from bacteria to human. The transcription network of \"E. coli\" and yeast, for example, is made of three main motif families, that make up almost the entire network. The leading hypothesis is that the network motif were independently selected by evolutionary processes in a converging manner, since the creation or elimination of regulatory interactions is fast on evolutionary time scale, relative to the rate at which genes change, Furthermore, experiments on the dynamics generated by network motifs in living cells indicate that they have characteristic dynamical functions. This suggests that the network motif serve as building blocks in gene regulatory networks that are beneficial to the organism.",
            "score": 72.16897797584534
        },
        {
            "docid": "398124_9",
            "document": "Transcriptional regulation . While in prokaryotic systems the basal transcription state can be thought of as nonrestrictive (that is, \u201con\u201d in the absence of modifying factors), eukaryotes have a restrictive basal state which requires the recruitment of other factors in order to generate RNA transcripts. This difference is largely due to the compaction of the eukaryotic genome by winding DNA around histones to form higher order structures. This compaction makes the gene promoter inaccessible without the assistance of other factors in the nucleus, and thus chromatin structure is a common site of regulation. Similar to the sigma factors in prokaryotes, the general transcription factors (GTFs) are a set of factors in eukaryotes that are required for all transcription events. These factors are responsible for stabilizing binding interactions and opening the DNA helix to allow the RNA polymerase to access the template, but generally lack specificity for different promoter sites. A large part of gene regulation occurs through transcription factors that either recruit or inhibit the binding of the general transcription machinery and/or the polymerase. This can be accomplished through close interactions with core promoter elements, or through the long distance enhancer elements.",
            "score": 48.9559600353241
        },
        {
            "docid": "33785040_12",
            "document": "Ultrasensitivity . One example of a buffering mechanism is protein sequestration, which is a common mechanism found in signalling and regulatory networks. In 2009, Buchler and Cross constructed a synthetic genetic network that was regulated by protein sequestration of a transcriptional activator by a dominant-negative inhibitor. They showed that this system results in a flexibile ultrasensitive response in gene expression. It is flexible in that the degree of ultrasensitivity can be altered by changing expression levels of the dominant-negative inhibitor. Figure 1 in their article illustrates how an active transcription factor can be sequestered by an inhibitor into the inactive complex AB that is unable to bind DNA. This type of mechanism results in an \"all-or-none\" response, or ultransensitivy, when the concentration of the regulatory protein increases to the point of depleting the inhibitor. Robust buffering against a response exists below this concentration threshold, and when it is reached any small increase in input is amplified into a large change in output.",
            "score": 56.43348586559296
        },
        {
            "docid": "32898112_8",
            "document": "TRANSFAC . The TRANSFAC database can be used as an encyclopedia of eukaryotic transcription factors. The target sequences and the regulated genes can be listed for each TF, which can be used as benchmark for TFBS recognition tools or as training sets for new TFBS recognition algorithms. The TF classification enables to analyze such data sets with regard to the properties of the DNA-binding domains. Another application is to retrieve all TFs that regulate a given (set of) gene(s). In the context of systems-biological studies, the TF-target gene relations documented in TRANSFAC were used to construct and analyze transcription regulatory networks. By far the most frequent use of TRANSFAC is the computational prediction of potential transcription factor binding sites (TFBS). A number of algorithms exist which either use the individual binding sites or the matrix library for this purpose:",
            "score": 75.56039047241211
        },
        {
            "docid": "356382_11",
            "document": "Gene regulatory network . There are primarily two ways that networks can evolve, both of which can occur simultaneously. The first is that network topology can be changed by the addition or subtraction of nodes (genes) or parts of the network (modules) may be expressed in different contexts. The\" Drosophila\" Hippo signaling pathway provides a good example. The Hippo signaling pathway controls both mitotic growth and post-mitotic cellular differentiation. Recently it was found that the network the Hippo signaling pathway operates in differs between these two functions which in turn changes the behavior of the Hippo signaling pathway. This suggests that the Hippo signaling pathway operates as a conserved regulatory module that can be used for multiple functions depending on context. Thus, changing network topology can allow a conserved module to serve multiple functions and alter the final output of the network. The second way networks can evolve is by changing the strength of interactions between nodes, such as how strongly a transcription factor may bind to a cis-regulatory element. Such variation in strength of network edges has been shown to underlie between species variation in vulva cell fate patterning of \"Caenorhabditis\" worms.",
            "score": 57.98427057266235
        },
        {
            "docid": "53367602_3",
            "document": "SMiLE-Seq . Elucidating the regulatory mechanisms used to govern essential cellular processes is one of the most intensely studied branches of science. Cellular regulatory networks can be incredibly complex, and often involve the coordination of multiple processes that begin with the modulation of gene expression. The binding of transcription factor molecules to DNA, either alone or in combination with other transcription factors, is used to control gene expression in response to both intra- and extracellular stimuli. Characterizing the binding mechanisms and specificities of transcription factors to specific regions of DNA \u2013 and identifying these transcription factors \u2013 is a fundamental component of the process of resolving cellular regulatory dynamics. Before the introduction of SMiLE-seq technology, ChIP-seq (chromatin immunoprecipitation sequencing) and HT-SELEX (high throughput systematic evolution of ligands by exponential enrichment) technologies were used to successfully characterize nearly 500 transcription factor-DNA binding interactions. ChIP-seq uses immunoprecipitation to isolate specific transcription factors bound to DNA fragments. Immunoprecipitation is followed by DNA sequencing, which identifies the genomic regions to which transcription factors bind. HT-SELEX, a similar method, uses random, synthetically generated DNA molecules as bait for transcription factors \"in vitro\". Sequence preferences and binding affinities are characterized based on successful binding interactions between bait molecules and transcription factors. While many unique transcription factor-DNA binding interactions have been characterized using these methods, it is estimated that this described fraction represents fewer than 50% of the transcription factors present in humans. The development of SMiLE-seq technology has provided an attractive alternative method with the potential to facilitate identification and characterization of previously undescribed transcription factor-DNA binding interactions.",
            "score": 57.4786901473999
        },
        {
            "docid": "22164509_15",
            "document": "Cis-regulatory module . CR\u00c8ME examine clusters of target sites for transcription factors of interest. This program uses a database of confirmed transcription factor binding sites that were annotated across the human genome. A search algorithm is applied to the data set to identify possible combinations of transcription factors, which have binding sites that are close to the promoter of the gene set of interest. The possible cis-regulatory modules are then statistically analyzed and the significant combinations are graphically represented",
            "score": 30.650618076324463
        },
        {
            "docid": "398124_13",
            "document": "Transcriptional regulation . Transcription factors are proteins that bind to specific DNA sequences in order to regulate the expression of a given gene. The power of transcription factors resides in their ability to activate and/or repress wide repertoires of downstream target genes. The fact that these transcription factors work in a combinatorial fashion means that only a small subset of an organism's genome encodes transcription factors. Transcription factors function through a wide variety of mechanisms. Often they are at the end of a signal transduction pathway that functions to change something about the factor, like its subcellular localization or its activity. Post-translational modifications to transcription factors located in the cytosol can cause them to translocate to the nucleus where they can interact with their corresponding enhancers. Others are already in the nucleus, and are modified to enable the interaction with partner transcription factors. Some post-translational modifications known to regulate the functional state of transcription factors are phosphorylation, acetylation, SUMOylation and ubiquitylation. Transcription factors can be divided in two main categories: activators and repressors. While activators can interact directly or indirectly with the core machinery of transcription through enhancer binding, repressors predominantly recruit co-repressor complexes leading to transcriptional repression by chromatin condensation of enhancer regions. It may also happen that a repressor may function by allosteric competition against a determined activator to repress gene expression: overlapping DNA-binding motifs for both activators and repressors induce a physical competition to occupy the site of binding. If the repressor has a higher affinity for its motif than the activator, transcription would be effectively blocked in the presence of the repressor. Tight regulatory control is achieved by the highly dynamic nature of transcription factors. Again, many different mechanisms exist to control whether a transcription factor is active. These mechanisms include control over protein localization or control over whether the protein can bind DNA. An example of this is the protein HSF1, which remains bound to Hsp70 in the cytosol and is only translocated into the nucleus upon cellular stress such as heat shock. Thus the genes under the control of this transcription factor will remain untranscribed unless the cell is subjected to stress.",
            "score": 52.33164584636688
        },
        {
            "docid": "21673918_3",
            "document": "Bacterial one-hybrid system . Across all living organisms, regulation of gene expression is controlled by interactions between DNA-binding regulatory proteins (transcription factors) and cis-regulatory elements, DNA sequences in or around genes that act as target sites for DNA-binding proteins. By binding to cis-regulatory sequences and to each other, transcription factors fine-tune transcriptional levels by stabilizing/destabilizing binding of RNA polymerase to a gene's promoter. But despite their importance and ubiquity, little is known about where exactly each of these regulatory proteins binds. Literature suggests that nearly 8% of human genes encode transcription factors and the functions and specificities of their interactions remain largely unexplored. We are on the brink of a convergence of high-throughput technologies and genomic theory that is allowing researchers to start mapping these interactions on a genome-wide scale. Only recently has a complete survey of DNA-binding specificities been attempted for a large family of DNA-binding domains. B1H is just one emerging technique among many that is useful for studying protein\u2013DNA interactions.",
            "score": 64.17889654636383
        },
        {
            "docid": "38678086_3",
            "document": "STARR-seq . In eukaryotes, transcription is regulated by sequence-specific DNA-binding proteins (transcription factors) associated with a gene\u2019s promoter and also by distant control sequences including enhancers. Enhancers are non-coding DNA sequences, containing several binding sites for a variety of transcription factors. They typically recruit transcriptional factors that modulate chromatin structure and directly interact with the transcription machinery placed at the promoter of gene. Enhancers are able to regulate transcription of target genes in a cell type-specific manner, independent of their location or distance from the promoter of genes. Occasionally, they can regulate transcription of genes located in a different chromosome.  However, the knowledge about enhancers so far has been limited to studies of a small number of enhancers, as they have been difficult to identify accurately at a genome-wide scale. Moreover, many regulatory elements function only in certain cell types and specific conditions.",
            "score": 57.025275111198425
        },
        {
            "docid": "53362498_15",
            "document": "Epigenome-wide association study (EWAS) . The location of the associated CpG sites or islands/regions can then be analyzed \"in silico\" to imply possible functional relevance. For example, considering whether the associated CpGs are within a promoter region or determining distance from the transcription start site that may be relevant, especially when we assume that DNA methylation associated with a phenotype acts by regulating gene transcription. Many other inferences based on past biological knowledge can be inferred if that particular region of CpGs have been studied and associated with changes in transcription. This can be used as an additional filter for identifying regions to pursue for functional validation. Several bioinformatic tools that have been developed for functional enrichment analysis can be applied to differentially methylated regions by first mapping these regions to genes. This is done by mapping the distance between the CpGs and a gene promoter that is potentially regulated by this region. Enrichment analysis based on the genomic region has thus been suggested as a complementary approach and confers substantial interpretive potential. Differentially methylated regions can then be compared to a catalog of genomic regions including, for example, sites enriched for specific chromatin modifications or transcription factor binding sites.",
            "score": 61.753729701042175
        },
        {
            "docid": "22164509_14",
            "document": "Cis-regulatory module . Bayesian Networks use an algorithm that combines site predictions and tissue-specific expression data for transcription factors and target genes of interest. This model also uses regression trees to depict the relationship between the identified \"cis\"-regulatory module and the possible binding set of transcription factors.",
            "score": 43.69487404823303
        },
        {
            "docid": "31192209_4",
            "document": "Yeastract . Facilities are also provided to enable the exploitation of the gathered data when solving a number of biological questions, as exemplified in the Tutorial. YEASTRACT allows the identification of documented or potential transcription regulators of a given gene and of documented or potential regulons for each transcription factor. It also renders possible the comparison between DNA motifs and the transcription factor binding sites described in the literature. The system also provides a useful mechanism for grouping a list of genes (for instance a set of genes with similar expression profiles as revealed by microarray analysis) based on their regulatory associations with known transcription factors.",
            "score": 55.79211974143982
        },
        {
            "docid": "31474_22",
            "document": "Transcription factor . Most transcription factors do not work alone. Many large TF families form complex homotypic or heterotypic interactions through dimerization. For gene transcription to occur, a number of transcription factors must bind to DNA regulatory sequences. This collection of transcription factors, in turn, recruit intermediary proteins such as cofactors that allow efficient recruitment of the preinitiation complex and RNA polymerase. Thus, for a single transcription factor to initiate transcription, all of these other proteins must also be present, and the transcription factor must be in a state where it can bind to them if necessary. Cofactors are proteins that modulate the effects of transcription factors. Cofactors are interchangeable between specific gene promoters; the protein complex that occupies the promoter DNA and the amino acid sequence of the cofactor determine its spatial conformation. For example, certain steroid receptors can exchange cofactors with NF-\u03baB, which is a switch between inflammation and cellular differentiation; thereby steroids can affect the inflammatory response and function of certain tissues.",
            "score": 48.1015909910202
        },
        {
            "docid": "22164509_8",
            "document": "Cis-regulatory module . Within the assumption of the Boolean logic, principles guiding the operation of these modules includes the design of the module which determines the regulatory function. In relation to development, these modules can generate both positive and negative outputs. The output of each module is a product of the various operations performed on it. Common operations include \"OR\" logic gate \u2013 This design indicates that in an output will be given when either input is given [3]. \"AND\" logic gate \u2013 In this design two different regulatory factors are necessary to make sure that a positive output results. \"Toggle Switches\" \u2013 This design occurs when the signal ligand is absent while the transcription factor is present; this transcription factor ends up acting as a dominant repressor. However, once the signal ligand is present the transcription factor's role as repressor is eliminated and transcription can occur.",
            "score": 37.936755895614624
        },
        {
            "docid": "553121_11",
            "document": "Regulation of gene expression . Regulation of transcription thus controls when transcription occurs and how much RNA is created. Transcription of a gene by RNA polymerase can be regulated by several mechanisms. Specificity factors alter the specificity of RNA polymerase for a given promoter or set of promoters, making it more or less likely to bind to them (i.e., sigma factors used in prokaryotic transcription). Repressors bind to the Operator, coding sequences on the DNA strand that are close to or overlapping the promoter region, impeding RNA polymerase's progress along the strand, thus impeding the expression of the gene.The image to the right demonstrates regulation by a repressor in the lac operon. General transcription factors position RNA polymerase at the start of a protein-coding sequence and then release the polymerase to transcribe the mRNA. Activators enhance the interaction between RNA polymerase and a particular promoter, encouraging the expression of the gene. Activators do this by increasing the attraction of RNA polymerase for the promoter, through interactions with subunits of the RNA polymerase or indirectly by changing the structure of the DNA. Enhancers are sites on the DNA helix that are bound by activators in order to loop the DNA bringing a specific promoter to the initiation complex. Enhancers are much more common in eukaryotes than prokaryotes, where only a few examples exist (to date). Silencers are regions of DNA sequences that, when bound by particular transcription factors, can silence expression of the gene.",
            "score": 58.9612135887146
        },
        {
            "docid": "611074_17",
            "document": "Point mutation . Moreover, if the mutation occurs in the region of the gene where transcriptional machinery binds to the protein, the mutation can affect the binding of the transcription factors because the short nucleotide sequences recognized by the transcription factors will be altered. Mutations in this region can affect rate of efficiency of gene transcription, which in turn can alter levels of mRNA and, thus, protein levels in general.",
            "score": 35.544636249542236
        },
        {
            "docid": "53916738_7",
            "document": "KIAA0825 . Analysis of the promoter offers some insight into the expression of KIAA0825. One possible regulator found is the NeuroD1 transcription factor. This factor is an important regulator for the insulin gene, and a mutation in this gene can lead to Type II diabetes. This could explain why KIAA0825 is expressed at lower levels in patients with Type II diabetes. Another possible transcription factor is the Myeloid zinc finger 1 factor, which is tied to myeloid leukemia, because it delays apoptosis of cells in the presence of retinoic acid. There are also several places where Vertebrate SMAD family transcription factors can bind. These transcription factors are thought to be responsible for nucleocytoplasmic dynamics. This means that these SMAD transcription factors could affect KIAA0825, because subcellular localization suggests it shuttles across the nuclear envelope.",
            "score": 41.66947877407074
        },
        {
            "docid": "10905770_10",
            "document": "Farnesyl-diphosphate farnesyltransferase . SQS regulation occurs primarily at the level of SQS gene transcription. The sterol regulatory element binding protein (SREBP) class of transcription factors is central to regulating genes involved in cholesterol homeostasis, and is important for controlling levels of SQS transcription. When sterol levels are low, an inactive form of SREBP is cleaved to form the active transcription factor, which moves to the nucleus to induce transcription of the SQS gene. Of the three known SREBP transcription factors, only SREBP-1a and SREBP-2 activate SQS gene transcription in transgenic mouse livers. In cultured HepG2 cells, SREBP-1a appears more important than SREBP-2 in controlling activation of the SQS promoter. However, SQS promoters have been shown to respond differently to SREBP-1a and SREBP-2 in different experimental systems.",
            "score": 43.0344934463501
        },
        {
            "docid": "159266_61",
            "document": "Gene expression . Genes have sometimes been regarded as nodes in a network, with inputs being proteins such as transcription factors, and outputs being the level of gene expression. The node itself performs a function, and the operation of these functions have been interpreted as performing a kind of information processing within cells and determines cellular behavior.",
            "score": 41.1261146068573
        },
        {
            "docid": "12499410_59",
            "document": "Network motif . One of simplest and most abundant network motifs in \"E. coli\" is negative auto-regulation in which a transcription factor (TF) represses its own transcription. This motif was shown to perform two important functions. The first function is response acceleration. NAR was shown to speed-up the response to signals both theoretically and experimentally. This was first shown in a synthetic transcription network and later on in the natural context in the SOS DNA repair system of E .coli. The second function is increased stability of the auto-regulated gene product concentration against stochastic noise, thus reducing variations in protein levels between different cells.",
            "score": 50.76014757156372
        },
        {
            "docid": "42812309_4",
            "document": "Erik van Nimwegen . Erik van Nimwegen\u2019s main research topics concern genome evolution and the function and evolution of the regulatory networks by which cells control gene expression. He develops mathematical models for analyzing how regulatory networks evolve and function, and computational methods for the reconstruction of such networks from large biological data-sets. Van Nimwegen's work includes a general model for the evolution of robustness against mutations and the identification of a number of universal scaling laws of genome evolution. Further research topics are the development of general Bayesian methods for transcription factor and miRNA binding site prediction as well as models for inferring regulatory networks from genome-wide expression and chromatin state data.",
            "score": 65.46275186538696
        },
        {
            "docid": "22164509_7",
            "document": "Cis-regulatory module . Additionally, the regulation of chromatin structure and nuclear organization also play a role in determining and controlling the function of cis-regulatory modules. Thus gene-regulation functions (GRF) provide a unique characteristic of a cis-regulatory module (CRM), relating the concentrations of transcription factors (input) to the promoter activities (output). The challenge is to predict GRFs. This challenge still remains unsolved. In general, gene-regulation functions do not use Boolean logic, although in some cases the approximation of the Boolean logic is still very useful.",
            "score": 47.082215785980225
        }
    ],
    "r": [
        {
            "docid": "355240_6",
            "document": "Cognitive model . A computational model is a mathematical model in computational science that requires extensive computational resources to study the behavior of a complex system by computer simulation. The system under study is often a complex nonlinear system for which simple, intuitive analytical solutions are not readily available. Rather than deriving a mathematical analytical solution to the problem, experimentation with the model is done by changing the parameters of the system in the computer, and studying the differences in the outcome of the experiments. Theories of operation of the model can be derived/deduced from these computational experiments. Examples of common computational models are weather forecasting models, earth simulator models, flight simulator models, molecular protein folding models, and neural network models. . expressed in characters, usually nonnumeric, that require translation before they can be used \"subsymbolic\" if it is made by constituent entities that are not representations in their turn, e.g., pixels, sound images as perceived by the ear, signal samples; subsymbolic units in neural networks can be considered particular cases of this category Hybrid computers are computers that exhibit features of analog computers and digital computers. The digital component normally serves as the controller and provides logical operations, while the analog component normally serves as a solver of differential equations. See more details at hybrid intelligent system. In the traditional computational approach, representations are viewed as static structures of discrete symbols. Cognition takes place by transforming static symbol structures in discrete, sequential steps. Sensory information is transformed into symbolic inputs, which produce symbolic outputs that get transformed into motor outputs. The entire system operates in an ongoing cycle.",
            "score": 96.68074035644531
        },
        {
            "docid": "841429_27",
            "document": "Synthetic biology . A biological computer refers to an engineered biological system that can perform computer-like operations, which is a dominant paradigm in synthetic biology. Researchers built and characterized a variety of logic gates in a number of organisms, and demonstrated both analog and digital computation in living cells. They demonstrated that bacteria can be engineered to perform both analog and/or digital computation. In human cells research demonstrated a universal logic evaluator that operates in mammalian cells in 2007. Subsequently, researchers utilized this paradigm to demonstrate a proof-of-concept therapy that uses biological digital computation to detect and kill human cancer cells in 2011. Another group of researchers demonstrated in 2016 that principles of computer engineering, can be used to automate digital circuit design in bacterial cells. In 2017, researchers demonstrated the 'Boolean logic and arithmetic through DNA excision' (BLADE) system to engineer digital computation in human cells.",
            "score": 84.74530029296875
        },
        {
            "docid": "1181008_10",
            "document": "Computational science . Exciting new developments in biotechnology are now revolutionizing biology and biomedical research. Examples of these techniques are high-throughput sequencing, high-throughput quantitative PCR, intra-cellular imaging, in-situ hybridization of gene expression, three-dimensional imaging techniques like Light Sheet Fluorescence Microscopy and Optical Projection, (micro)-Computer Tomography. Given the massive amounts of complicated data that is generated by these techniques, their meaningful interpretation, and even their storage, form major challenges calling for new approaches. Going beyond current bioinformatics approaches, computational biology needs to develop new methods to discover meaningful patterns in these large data sets. Model-based reconstruction of gene networks can be used to organize the gene expression data in systematic way and to guide future data collection. A major challenge here is to understand how gene regulation is controlling fundamental biological processes like biomineralisation and embryogenesis. The sub-processes like gene regulation, organic molecules interacting with the mineral deposition process, cellular processes, physiology and other processes at the tissue and environmental levels are linked. Rather than being directed by a central control mechanism, biomineralisation and embryogenesis can be viewed as an emergent behavior resulting from a complex system in which several sub-processes on very different temporal and spatial scales (ranging from nanometer and nanoseconds to meters and years) are connected into a multi-scale system. One of the few available options to understand such systems is by developing a multi-scale model of the system.",
            "score": 84.49137878417969
        },
        {
            "docid": "1363296_2",
            "document": "Modelling biological systems . Modelling biological systems is a significant task of systems biology and mathematical biology. Computational systems biology aims to develop and use efficient algorithms, data structures, visualization and communication tools with the goal of computer modelling of biological systems. It involves the use of computer simulations of biological systems, including cellular subsystems (such as the networks of metabolites and enzymes which comprise metabolism, signal transduction pathways and gene regulatory networks), to both analyze and visualize the complex connections of these cellular processes.",
            "score": 82.61619567871094
        },
        {
            "docid": "149353_8",
            "document": "Computational biology . Computational biomodeling is a field concerned with building computer models of biological systems. Computational biomodeling aims to develop and use visual simulations in order to assess the complexity of biological systems. This is accomplished through the use of specialized algorithms, and visualization software. These models allow for prediction of how systems will react under different environments. This is useful for determining if a system is robust. A robust biological system is one that \u201cmaintain their state and functions against external and internal perturbations\u201d, which is essential for a biological system to survive. Computational biomodeling generates a large archive of such data, allowing for analysis from multiple users. While current techniques focus on small biological systems, researchers are working on approaches that will allow for larger networks to be analyzed and modeled. A majority of researchers believe that this will be essential in developing modern medical approaches to creating new drugs and gene therapy. A useful modelling approach is to use Petri nets via tools such as esyN",
            "score": 82.06864166259766
        },
        {
            "docid": "20756967_54",
            "document": "Cyborg . Theorists such as Andy Clark suggest that interactions between humans and technology result in the creation of a cyborg system. In this model \"cyborg\" is defined as a part biological, part mechanical system which results in the augmentation of the biological component and the creation of a more complex whole. Clark argues that this broadened definition is necessary to an understanding of human cognition. He suggests that any tool which is used to offload part of a cognitive process may be considered the mechanical component of a cyborg system. Examples of this human and technology cyborg system can be very low tech and simplistic, such as using a calculator to perform basic mathematical operations or pen and paper to make notes, or as high tech as using a personal computer or phone. According to Clark, these interactions between a person and a form of technology integrate that technology into the cognitive process in a way which is analogous to the way that a technology which would fit the traditional concept a cyborg augmentation becomes integrated with its biological host. Because all humans in some way use technology to augment their cognitive processes, Clark comes to the conclusion that we are \"natural-born cyborgs\".",
            "score": 81.65674591064453
        },
        {
            "docid": "27075922_4",
            "document": "Natural computing . Dually, one can view processes occurring in nature as information processing. Such processes include self-assembly,  developmental processes, gene regulation networks, protein\u2013protein interaction networks, biological transport (active transport, passive transport) networks, and gene assembly in unicellular organisms. Efforts to understand biological systems also include engineering of semi-synthetic organisms, and understanding the universe itself from the point of view of information processing. Indeed, the idea was even advanced that information is more fundamental than matter or energy.  The Zuse-Fredkin thesis, dating back to the 1960s, states that the entire universe is a huge cellular automaton which continuously updates its rules. Recently it has been suggested that the whole universe is a quantum computer that computes its own behaviour.",
            "score": 81.23188781738281
        },
        {
            "docid": "841429_24",
            "document": "Synthetic biology . Models inform the design of engineered biological systems by better predicting system behavior prior to fabrication. Synthetic biology benefits from better models of how biological molecules bind substrates and catalyze reactions, how DNA encodes the information needed to specify the cell and how multi-component integrated systems behave. Multiscale models of gene regulatory networks focus on synthetic biology applications. Simulations can model all biomolecular interactions in transcription, translation, regulation and induction of gene regulatory networks. In a living cell, molecular motifs are embedded in a bigger network with upstream and downstream components. These components may alter the signalling capability of the modeling module. In the case of ultrasensitive modules, the sensitivity contribution of a module can differ from the sensitivity that the module sustains in isolation.",
            "score": 80.89453125
        },
        {
            "docid": "33769881_2",
            "document": "Immunomics . Immunomics is the study of immune system regulation and response to pathogens using genome-wide approaches. With the rise of genomic and proteomic technologies, scientists have been able to visualize biological networks and infer interrelationships between genes and/or proteins; recently, these technologies have been used to help better understand how the immune system functions and how it is regulated. Two thirds of the genome is active in one or more immune cell types and less than 1% of genes are uniquely expressed in a given type of cell. Therefore, it is critical that the expression patterns of these immune cell types be deciphered in the context of a network, and not as an individual, so that their roles be correctly characterized and related to one another. Defects of the immune system such as autoimmune diseases, immunodeficiency, and malignancies can benefit from genomic insights on pathological processes. For example, analyzing the systematic variation of gene expression can relate these patterns with specific diseases and gene networks important for immune functions.",
            "score": 80.65028381347656
        },
        {
            "docid": "3630374_3",
            "document": "Neural computation . When comparing the three main traditions of the computational theory of mind, as well as the different possible forms of computation in the brain, it is helpful to define what we mean by computation in a general sense. Computation is the processing of vehicles, otherwise known as variables or entities, according to a set of rules. A rule in this sense is simply an instruction for executing a manipulation on the current state of the variable, in order to produce an specified output. In other words, a rule dictates which output to produce given a certain input to the computing system. A computing system is a mechanism whose components must be functionally organized to process the vehicles in accordance with the established set of rules. The types of vehicles processed by a computing system determines which type of computations it performs. Traditionally, in cognitive science there have been two proposed types of computation related to neural activity - digital and analog, with the vast majority of theoretical work incorporating a digital understanding of cognition. Computing systems which perform digital computation are functionally organized to execute operations on strings of digits with respect to the type and location of the digit on the string. It has been argued that neural spike train signaling implements some form of digital computation, since neural spikes may be considered as discrete units or digits, like 0 or 1 - the neuron either fires an action potential or it does not. Accordingly, neural spike trains could be seen as strings of digits. Alternatively, analog computing systems perform manipulations on non-discrete, irreducibly continuous variables, that is, entities which vary continuously as a function of time. These sorts of operations are characterized by systems of differential equations.",
            "score": 79.81590270996094
        },
        {
            "docid": "2506529_35",
            "document": "Cellular neural network . CNN processors are being used to understand systems that can be modeled using simple, coupled units, such as living cells, biological networks, physiological systems, and ecosystems. The CNN architecture captures some of the dynamics often seen in nature and is simple enough to analyze and conduct experiments. They are also being used for stochastic simulation techniques, which allow scientists to explore spin problems, population dynamics, lattice-based gas models, percolation, and other phenomena. Other simulation applications include heat transfer, mechanical vibrating systems, protein production, Josephson Transmission Line (JTL) problems, seismic wave propagation, and geothermal structures. Instances of 3D (Three Dimensional) CNN have been used to prove known complex shapes are emergent phenomena in complex systems, establishing a link between art, dynamical systems and VLSI technology. CNN processors have been used to research a variety of mathematical concepts, such as researching non-equilibrium systems, constructing non-linear systems of arbitrary complexity using a collection of simple, well-understood dynamic systems, studying emergent chaotic dynamics, generating chaotic signals, and in general discovering new dynamic behavior. They are often used in researching systemics, a trandisiplinary, scientific field that studies natural systems. The goal of systemics researchers is to develop a conceptual and mathematical framework necessary to analyze, model, and understand systems, including, but not limited to, atomic, mechanical, molecular, chemical, biological, ecological, social and economic systems. Topics explored are emergence, collective behavior, local activity and its impact on global behavior, and quantifying the complexity of an approximately spatial and topologically invariant system . Although another measure of complexity may not arouse enthusiasm (Seth Lloyd, a professor from Massachusetts Institute of Technology (MIT), has identified 32 different definitions of complexity), it can potentially be mathematically advantageous when analyzing systems such as economic and social systems.",
            "score": 79.18718719482422
        },
        {
            "docid": "2384297_6",
            "document": "The Lives of a Cell: Notes of a Biology Watcher . This essay focuses on how connected humanity is to nature and how we must make strides to understand our role. Thomas argues that even our own bodies are not solely ours since the mitochondria and other organelles are descended from other organisms. He creates a metaphor of the Earth as a giant cell itself with humans just as one part of a vast system. Astronauts must be decontaminated before they are allowed to interact on Earth. Thomas states that this is an act of \u201chuman chauvinism.\u201d Most organisms on Earth are symbiotic or, if harmful, have both adapted to warn the other. All organisms on Earth are interdependent and a stray virus or bacteria from the moon will not be adapted to harm us since it is not part of this connection. Bacteria are interconnected to the point where some cannot survive without others and some even live within others. We must recognize how interconnected even the smallest organisms are on Earth; especially if we must interact with life outside our planet. Thomas introduces one of his key metaphors of humans behaving like ants. He suggests that this metaphor is not used because humans do not like to be compared to insects that, as a society, can function as an organism. There are many examples of animals acting as a large organism when in large groups from termites and slime molds to birds and fish. Thomas argues that the communication of results in science puts humans in the same model as these other species. As all scientists communicate and build on each other\u2019s work in order to explore that which we do not know. Humans fear pheromones because we believe we have gone above the basic secretion of chemicals in our communication. However, there are signs that point to humans relying on pheromones as well as our most technological forms of communication. Thomas shows pheromones in the animal world with examples of moths and fish. He then goes on to explain what impact pheromones in humans could have on the future such as in the perfume industry and finding histocompatible donors. Music is the only form of communication that saves us from an overwhelming amount of small talk. This is not only a human phenomenon, but happens throughout the animal world. Thomas makes examples of animals from termites and earthworms to gorillas and alligators that perform some sort of rhythmic noise making that can be interpreted as music if we had full range of hearing. From the vast number of animals that participate in music it is clear that the need to make music is a fundamental characteristic of biology. Thomas proposes that the animal world is continuing a musical memory that has been going since the beginning of time. Thomas argues that even though we have the technological advancements to destroy the Earth that we do not know near enough about the world in which we live. To solve this problem he suggests that we should not be able to fire nuclear weapons without being able to explain one living thing fully. The organism that Thomas proposes is the protozoan Myxotricha paradoxa. There is information known about this protozoan that lives in the digestive tract of Australian termites but with more study it could be a model for how our cells developed. It is seen throughout nature that organisms cooperate and progress into more complex forms. We cannot destroy vast amounts of Earth with nuclear weapons until we understand how interconnected we all are. Thomas presents the three levels of technology in medicine: \u201cnontechnology\u201d that helps patients with diseases that are not well understood but does not help solve the underlying mechanisms of the disease, \u201chalfway technology\u201d that makes up for disease or postpones death for diseases whose courses we cannot do much about, and \u201chigh technology\u201d that from understanding the mechanism of the disease we are now able to cure. When looking at the costs of the three different technologies they are all needed, but once a \u201chigh technology\u201d is found for a disease the benefits outweigh the costs of studying the mechanism of the disease so thoroughly. Thomas suggests that in order to save money in health care, the highest priority in funding should be given to basic research. Humans leave a trace of chemicals in every place they go and on everything they touch. Other animals use signaling mechanisms to leave trails or identify each other. The sense of smell is an important sense in using these mechanisms, but it is still not well understood. Humans, compared to the rest of the animal world, do not have a good olfactory sense though we may be better than we first assume. Johannes Kepler once argued that the Earth is an immense organism itself, with chemical signals spreading across the globe through various organisms in order to keep the world functioning and well informed. Tau Ceti is a nearby sun-like star that we are on the verge of being able to begin making contact with, as well as other celestial bodies, to search for life. We have been attracted to the vast regions of space outside our Earth bubble and what they could hold. If extraterrestrial life is found, it scientifically would make sense, but the social impact of no longer being unique would give humans a new sense of community. The question of what information to send out is answered by Thomas by sending music, specifically Bach. It is timeless and the best language we have to express who we are. If possible Thomas also suggests sending art. However, the questions of what to send will not stop once we receive a reply. As humans we always evade death, despite how it is a natural part of our lives. Unless it is far removed, as in war or on television, then we can discuss it without a problem. It is a subconscious effort that by not thinking about death we may continue to live. Nevertheless, even if we cured all diseases we still would die one day. We must not fear death and research the dying process just as we would any other biological process. Most people who have a near death experience do not recall any pain or fear. It is perhaps the loss of consciousness that people fear more than death itself. Thomas returns to his pondering of the social behaviors of insects in this essay. He discusses the change in behavior of insects in groups and singular insects. We have used insects and their behavior to convey lessons, rules, and virtues and now they have been used in art. Thomas describes an art exhibit with living ants, surrounded by humans who act in a similar manner to the ants themselves. Thomas praises the Marine Biological Laboratory as \u201ca paradigm, a human institution possessed of a life of its own, self-regenerating, touched all around by human meddle but consistently improved, embellished by it.\u201d It attracts the brightest minds and makes great strides in science autonomously. Thomas paints pictures with his description of scientists covering the beach with their diagrams and making \u201cmusic\u201d of discussion after a lecture at the MBL. Humans have to learn how to walk, skip, and ride a bicycle but inside our bodies perform specific manipulations from birth that we do not need to learn. There is new research that suggests humans may be able to change these inner processes with teaching. Thomas reasons that his body has been functioning fine without him trying to control every little process so he will let it continue to do so. He suggests to try the exact opposite and try to disconnect from your body altogether. The biologic revolution is filling in the gaps in understanding about how our cells function. As we begin to understand more about organelles it is clear that they are not originally created from our cells. Mitochondria and chloroplasts most likely have a bacterial ancestry and flagellae and cilia most likely were once spirochetes. It is not necessarily a master-slave relationship that we have with our organelles, but one where their ancestors found an easy way to stay protected and secure. We have brought them along with us as we evolved and yet we do not understand them completely. Organelles and eukaryotic cells are one of the most established symbiotic relationships. We treat bacteria as an ever present enemy even though there are only a small number that actually cause disease, and by accident in most cases. Bacteria normally do not gain anything by causing illness or death in their hosts. Our illness is mostly caused by our immune system doing too great of a job in response to bacteria in our system. The strength of our response is not necessary for most cases, but remains from a primitive time. Health care has become the new name for medicine though this is a misnomer since illness and death cannot be totally eradicated. Thomas argues that to understand how medicine should be used we should look to those internists that are involved in the system. Most things get better in a short while by themselves, so we should no longer be instilling in the public a constant fear of failed health. This will be the best way to solve the problem of funding health care since people will only use it when it is necessary. There are different degrees of social behavior in animals. However, it is not clear where humans fit on the scale. Most signs point that we are above the social behavior of ants and bees that go about a singular task as a whole community. Language is the one trait that brings us to the level of such animals. All humans engage in language and are born with the understanding of language. Language, and perhaps along with art and music, is the core of our social behavior. The human mind comes with the understanding of how to deal with and use language. We store up information as a cell stores energy, though with language, this information can be put to further use. Another main difference between language and other communication systems in biology is the ambiguity that is a necessity in language which would cause the other communication systems to fail. Death is not supposed to happen in the open, along highways and in sight of others. Everything is in the process of dying all around us, though we keep it hidden from our sight and minds. Death is part of the cycle and we need to understand we are part of a larger process. The process of dying is necessary for the birth of the new and we will all experience it together. Thomas explains science as a wild manifestation of human behavior. He explains that science and discovery is a compulsion that scientists seem to have written in their very genes. Science cannot be organized and forced; it must be free to go where the next question leads. It is similar to a bee hive in some sense, but also to animals on a hunt. The activity is never ending and the conglomeration of minds always yearning for the next discovery cannot be kept under control. How humans approach nature has been changing throughout recent years. We used to view nature as ours to control and use to better mankind. Now we have moved away from this view and seen that we are part of the larger system and not the ruler of it. However Thomas argues that we must see ourselves as \u201cindispensable elements of nature\u201d and work for the betterment of the Earth but also be able to protect ourselves. This essay focuses on the tribe of Iks in northern Uganda. Thomas comments on an anthropologist\u2019s report on the Iks that argues that they represent the basic elements of mankind. Thomas instead thinks that each Ik acts as a group and that by observing the whole tribe of Iks you can see how we behave in groups ranging from committees to nations. In order to improve upon our group interactions, we must stay human even when in masses. Computers are approaching humanity, but they will never be able to fully replace us for they will not be able to replicate our collective behavior because we do not understand it ourselves. We are involved in a never ending transfer of information and collective thinking. This is the cause of the unpredictability in our future. The one problem with our information transfer is that we are much better at gaining information than giving output back. Thomas explains in this essay his view on scientific funding and planning. He believes that research should be focused in basic science. Unlike basic science, disease problems do not have the right type of questions to allow for great discoveries. The distinguishing factor of basic science is that there can be an element of surprise that allows for even more discoveries to be made. It is difficult to organize plans for this type of surprise in research even though it may seem a better business model to do so. It is the improbability and maze of puzzles that occur in basic research that Thomas believes will lead us to the most knowledge. Mythical creatures were created by our ancestors but even though we presently have no need for these beasts we continue to use them. The hybridization of animals in mythology is present from multiple ancient people such as the Ganesha, Griffon, Centaur, and Sphinx. Thomas suggests that perhaps we look to replace these mythological creatures which are more biological. He suggests the Myxotricha paradoxa, blepharisma, bacteria, and plant-animal combinations that are either made up of different organisms or set up joint endeavors with more than one organism to survive. From Thomas\u2019s metaphor on how humans behave like ants, he again argues that language is the quality that best resembles social insects. Without any outside direction, humans continually change language. We build language like ants build their hill, without ever knowing what the final result is and how our minuscule changes affect any other part. Thomas explains how some words have changed and developed different meanings. Two words, gene and bheu, are two words that we have derived a great number of current words from. Their descended words: kind, nature, physics are related in the present but also in its ancestry. Thomas compares language to the social behavior of termites in this essay. He thinks of language as an organism that is alive and changing. The genes of language are how words originated when you look into each of their histories. He traces multiple words to their origins to prove his point. He comments that it would be near impossible to keep track of all roots of words back to Indo-European that you use. We should be in awe that we exist and are unique among all the humans on Earth according to probability. Though we are indeed individual organisms, Thomas argues that one\u2019s own self is a myth. He believes we are part of a larger organization of information sharing. Through this system we are adapting and creating. By being more open with communication and less restrictive we will be able to uncover even more surprising discoveries. Thomas compares the Earth to a living cell, one with its own membrane that allows it to keep out disorder. He shows how the evolution of cells was closely tied to the \u201cbreath\u201d of the Earth, the cycling of oxygen concentration in the atmosphere. The atmosphere is \u201cfor sheer size and perfection of function, it is far and away the grandest product of collaboration in all of nature.\u201d It gives us the oxygen we need, protection from UV light, and protection from the millions of meteorites.",
            "score": 78.3606948852539
        },
        {
            "docid": "8402086_15",
            "document": "Computational neurogenetic modeling . Fuzzy logic is a system of reasoning that enables an artificial neural network to deal in non-binary and linguistic variables. Biological data is often unable to be processed using Boolean logic, and moreover accurate modeling of the capabilities of biological nervous systems requires fuzzy logic. Therefore, artificial neural networks that incorporate it, such as evolving fuzzy neural networks (EFuNN) or Dynamic Evolving Neural-Fuzzy Inference Systems (DENFIS), are often used in computational neurogenetic modeling. The use of fuzzy logic is especially relevant in gene regulatory networks, as the modeling of protein binding strength often requires non-binary variables.",
            "score": 77.94108581542969
        },
        {
            "docid": "27075922_34",
            "document": "Natural computing . Computational systems biology (or simply systems biology) is an integrative and qualitative approach that investigates the complex communications and interactions taking place in biological systems.  Thus, in systems biology, the focus of the study is the interaction networks themselves and the properties of biological systems that arise due to these networks, rather than the individual components of functional processes in an organism.  This type of research on organic components has focused strongly on four different interdependent interaction networks: gene-regulatory networks, biochemical networks, transport networks, and carbohydrate networks.",
            "score": 77.42628479003906
        },
        {
            "docid": "40841348_11",
            "document": "Computational and Statistical Genetics . In this era of large amount of genetic and genomic data, accurate representation and identification of statistical interactions in biological/genetic/genomic data constitutes a vital basis for designing interventions and curative solutions for many complex diseases. Variations in human genome have been long known to make us susceptible to many diseases. We are hurtling towards the era of personal genomics and personalized medicine that require accurate predictions of disease risk posed by predisposing genetic factors. Computational and statistical methods for identifying these genetic variations, and building these into intelligent models for diseaseassociation and interaction analysis studies genome-wide are a dire necessity across many disease areas. The principal challenges are: (1) most complex diseases involve small or weak contributions from multiple genetic factors that explain only a minuscule fraction of the population variation attributed to genetic factors. (2) Biological data is inherently extremely noisy, so the underlying complexities of biological systems (such as linkage disequilibrium and genetic heterogeneity) need to be incorporated into the statistical models for disease association studies. The chances of developing many common diseases such as cancer, autoimmune diseases and cardiovascular diseases involves complex interactions between multiple genes and several endogenous and exogenous environmental agents or covariates. Many previous disease association studies could not produce significant results because of the lack of incorporation of statistical interactions in their mathematical models explaining the disease outcome. Consequently much of the genetic risks underlying several diseases and disorders remain unknown. Computational methods such as to model and identify the genetic/genomic variations underlying disease risks has a great potential to improve prediction of disease outcomes, understand the interactions and design better therapeutic methods based on them.",
            "score": 77.15927124023438
        },
        {
            "docid": "1686404_10",
            "document": "Integrated nanoliter system . Another possible use of the integrated nanoliter system is in single-cell gene expression analysis. One benefit of using the integrated nanoliter system is its capability to detect the changes of a gene expression more accurately than the previous technique of microarray. The nanoliter system's microscopic scalability (nanoliter to picoliter scale) allows it to analyze the gene expression at the single-cell level (around 1 picoliter), while the microarray analyzes changes of the gene expression by averaging a large group of cells. Another convenient and important benefit is the integrated nanoliter system's capability of having all the necessary biological fluids in the system before operation by storing each biological fluid in a specific microfabricated fluidic network. The integrated nanoliter system is convenient because the biological fluids are all controlled by a computer compared to how previous systems required a manual loading of every biological fluid. The integrated nanoliter system is also important for the gene expression analysis because the analysis would not be undesirably influenced by contamination due to the \"closed\" system while in operation.",
            "score": 76.7330551147461
        },
        {
            "docid": "154505_12",
            "document": "Digital signal processor . Hardware is also an expression used within the computer engineering industry to explicitly distinguish the (electronic computer) hardware from the software that runs on it. But hardware, within the automation and software engineering disciplines, need not simply be a computer of some sort. A modern automobile runs vastly more software than the Apollo spacecraft. Also, modern aircraft cannot function without running tens of millions of computer instructions embedded and distributed throughout the aircraft and resident in both standard computer hardware and in specialized hardware components such as IC wired logic gates, analog and hybrid devices, and other digital components. The need to effectively model how separate physical components combine to form complex systems is important over a wide range of applications, including computers, personal digital assistants (PDAs), cell phones, surgical instrumentation, satellites, and submarines.",
            "score": 76.49528503417969
        },
        {
            "docid": "8402086_5",
            "document": "Computational neurogenetic modeling . A gene regulatory network, protein regulatory network, or gene/protein regulatory network, is the level of processing in a computational neurogenetic model that models the interactions of genes and proteins relevant to synaptic activity and general cell functions. Genes and proteins are modeled as individual nodes, and the interactions that influence a gene are modeled as excitatory (increases gene/protein expression) or inhibitory (decreases gene/protein expression) inputs that are weighted to reflect the effect a gene or protein is having on another gene or protein. Gene regulatory networks are typically designed using data from microarrays.",
            "score": 76.10047912597656
        },
        {
            "docid": "1363296_6",
            "document": "Modelling biological systems . Creating a cellular model has been a particularly challenging task of systems biology and mathematical biology. It involves the use of computer simulations of the many cellular subsystems such as the networks of metabolites and enzymes which comprise metabolism, signal transduction pathways and gene regulatory networks to both analyze and visualize the complex connections of these cellular processes.",
            "score": 75.8257064819336
        },
        {
            "docid": "237704_38",
            "document": "Saccharomyces cerevisiae . The availability of the \"S.\u00a0cerevisiae\" genome sequence and a set of deletion mutants covering 90% of the yeast genome has further enhanced the power of \"S.\u00a0cerevisiae\" as a model for understanding the regulation of eukaryotic cells. A project underway to analyze the genetic interactions of all double-deletion mutants through synthetic genetic array analysis will take this research one step further. The goal is to form a functional map of the cell's processes. As of 2010 a model of genetic interactions is most comprehensive yet to be constructed, containing \"the interaction profiles for ~75% of all genes in the Budding yeast\". This model was made from 5.4 million two-gene comparisons in which a double gene knockout for each combination of the genes studied was performed. The effect of the double knockout on the fitness of the cell was compared to the expected fitness. Expected fitness is determined from the sum of the results on fitness of single-gene knockouts for each compared gene. When there is a change in fitness from what is expected, the genes are presumed to interact with each other. This was tested by comparing the results to what was previously known. For example, the genes Par32, Ecm30, and Ubp15 had similar interaction profiles to genes involved in the Gap1-sorting module cellular process. Consistent with the results, these genes, when knocked out, disrupted that process, confirming that they are part of it. From this, 170,000 gene interactions were found and genes with similar interaction patterns were grouped together. Genes with similar genetic interaction profiles tend to be part of the same pathway or biological process. This information was used to construct a global network of gene interactions organized by function. This network can be used to predict the function of uncharacterized genes based on the functions of genes they are grouped with.",
            "score": 75.77061462402344
        },
        {
            "docid": "42646689_2",
            "document": "General purpose analog computer . The General Purpose Analog Computer (GPAC) is a mathematical model of analog computers first introduced in 1941 by Claude Shannon. This model consists of circuits where several basic units are interconnected in order to compute some function. The GPAC can be implemented in practice through the use of mechanical devices or analog electronics. Although analog computers have fallen almost into oblivion due to emergence of the digital computer, the GPAC has recently been studied as a way to provide evidence for the physical Church\u2013Turing thesis. This is because the GPAC is also known to model a large class of dynamical systems defined with ordinary differential equations, which appear frequently in the context of physics. In particular it was shown in 2007 that (a deterministic variant of) the GPAC is equivalent, in computability terms, to Turing machines, thereby proving the physical Church\u2013Turing thesis for the class of systems modelled by the GPAC. This was recently strengthened to polynomial time equivalence.",
            "score": 75.73937225341797
        },
        {
            "docid": "356382_22",
            "document": "Gene regulatory network . Continuous network models of GRNs are an extension of the boolean networks described above. Nodes still represent genes and connections between them regulatory influences on gene expression. Genes in biological systems display a continuous range of activity levels and it has been argued that using a continuous representation captures several properties of gene regulatory networks not present in the Boolean model. Formally most of these approaches are similar to an artificial neural network, as inputs to a node are summed up and the result serves as input to a sigmoid function, e.g., but proteins do often control gene expression in a synergistic, i.e. non-linear, way. However, there is now a continuous network model that allows grouping of inputs to a node thus realizing another level of regulation. This model is formally closer to a higher order recurrent neural network. The same model has also been used to mimic the evolution of cellular differentiation and even multicellular morphogenesis.",
            "score": 75.70571899414062
        },
        {
            "docid": "453086_2",
            "document": "Neuromorphic engineering . Neuromorphic engineering, also known as neuromorphic computing, is a concept developed by Carver Mead, in the late 1980s, describing the use of very-large-scale integration (VLSI) systems containing electronic analog circuits to mimic neuro-biological architectures present in the nervous system. In recent times the term \"neuromorphic\" has been used to describe analog, digital, mixed-mode analog/digital VLSI, and software systems that implement models of neural systems (for perception, motor control, or multisensory integration). The implementation of neuromorphic computing on the hardware level can be realized by oxide-based memristors, threshold switches, and transistors.",
            "score": 75.66561889648438
        },
        {
            "docid": "356382_31",
            "document": "Gene regulatory network . Other work has focused on predicting the gene expression levels in a gene regulatory network. The approaches used to model gene regulatory networks have been constrained to be interpretable and, as a result, are generally simplified versions of the network. For example, Boolean networks have been used due to their simplicity and ability to handle noisy data but lose data information by having a binary representation of the genes. Also, artificial neural networks omit using a hidden layer so that they can be interpreted, losing the ability to model higher order correlations in the data. Using a model that is not constrained to be interpretable, a more accurate model can be produced. Being able to predict gene expressions more accurately provides a way to explore how drugs affect a system of genes as well as for finding which genes are interrelated in a process. This has been encouraged by the DREAM competition which promotes a competition for the best prediction algorithms. Some other recent work has used artificial neural networks with a hidden layer.",
            "score": 75.58428955078125
        },
        {
            "docid": "32898112_8",
            "document": "TRANSFAC . The TRANSFAC database can be used as an encyclopedia of eukaryotic transcription factors. The target sequences and the regulated genes can be listed for each TF, which can be used as benchmark for TFBS recognition tools or as training sets for new TFBS recognition algorithms. The TF classification enables to analyze such data sets with regard to the properties of the DNA-binding domains. Another application is to retrieve all TFs that regulate a given (set of) gene(s). In the context of systems-biological studies, the TF-target gene relations documented in TRANSFAC were used to construct and analyze transcription regulatory networks. By far the most frequent use of TRANSFAC is the computational prediction of potential transcription factor binding sites (TFBS). A number of algorithms exist which either use the individual binding sites or the matrix library for this purpose:",
            "score": 75.56039428710938
        },
        {
            "docid": "2567511_11",
            "document": "Neural engineering . Engineers employ quantitative tools that can be used for understanding and interacting with complex neural systems. Methods of studying and generating chemical, electrical, magnetic, and optical signals responsible for extracellular field potentials and synaptic transmission in neural tissue aid researchers in the modulation of neural system activity (Babb et al. 2008).  To understand properties of neural system activity, engineers use signal processing techniques and computational modeling (Eliasmith & Anderson 2003). To process these signals, neural engineers must translate the voltages across neural membranes into corresponding code, a process known as neural coding. Neural coding uses studies on how the brain encodes simple commands in the form of central pattern generators (CPGs), movement vectors, the cerebellar internal model, and somatotopic maps to understand movement and sensory phenomena. Decoding of these signals in the realm of neuroscience is the process by which neurons understand the voltages that have been transmitted to them. Transformations involve the mechanisms that signals of a certain form get interpreted and then translated into another form. Engineers look to mathematically model these transformations (Eliasmith & Anderson 2003).  There are a variety of methods being used to record these voltage signals. These can be intracellular or extracellular. Extracellular methods involve single-unit recordings, extracellular field potentials, and amperometry; more recently, multielectrode arrays have been used to record and mimic signals.",
            "score": 75.50698852539062
        },
        {
            "docid": "34015182_3",
            "document": "Andreas Wagner . Wagner\u2019s work revolves around the robustness of biological systems, and about their ability to innovate, that is, to create novel organisms and traits that help them survive and reproduce. Robustness is the ability of a biological system to withstand perturbations, such as DNA mutations and environmental change. Early in his career Wagner developed a widely used mathematical model for gene regulatory circuits, (Wagner's gene network model) and used this model to demonstrate that natural selection can increase the robustness of such circuits to DNA mutations. Experimental work in Wagner\u2019s Z\u00fcrich laboratory showed that proteins can evolve robustness to perturbations. One source of robustness to mutations are redundant duplicate genes. Natural selection can maintain their redundancy and the ensuing robustness. However, more important than redundancy, Wagner has argued, is the \u201cdistributed robustness\u201d of complex biological systems, which arises from the cooperation of multiple different parts, such as proteins in a regulatory network.",
            "score": 75.40068817138672
        },
        {
            "docid": "38374635_2",
            "document": "Eric Schadt . Eric Emil Schadt (born January 31, 1965) is an American mathematician and computational biologist. He is Dean for Precision Medicine at the Icahn School of Medicine at Mount Sinai and Chief Executive Officer of Sema4, a spinout next generation health information company of the Mount Sinai Health System that provides advanced genomic testing and merges big data analytics with clinical diagnostics. He was previously founding director of the Icahn Institute for Genomics and Multiscale Biology and chair of the Department of Genetics and Genomics Sciences at the Icahn School of Medicine at Mount Sinai. Schadt\u2019s work combines supercomputing and advanced computational modeling with diverse biological data to understand the relationship between genes, gene products, other molecular features such as cells, organs, organisms, and communities and their impact on complex human traits such as disease. He is known for calling for a shift in molecular biology toward a network-oriented view of living systems to complement the reductionist, single-gene approaches that currently dominate biology to more accurately model the complexity of biological systems. Schadt has also worked to engage the public, encouraging people to participate in scientific research and helping them understand privacy concerns around DNA-based information.",
            "score": 75.33168029785156
        },
        {
            "docid": "25275445_7",
            "document": "Evolution in Variable Environment . With the rapid expansion of human understanding of cell, molecular, and chemical biology, a vast set of data has been generated on the metabolic pathways, signal-transductional pathways, and gene regulatory networks. Cellular modeling attempts to analyze and visualize these pathways with the help of computers. A substantial portion of EVE is devoted to writing algorithms, data structures, and visualization tools for these biological systems.",
            "score": 75.2991943359375
        },
        {
            "docid": "93070_13",
            "document": "A New Kind of Science . Wolfram argues that the computational realities of the universe make science hard for fundamental reasons. But he also argues that by understanding the importance of these realities, we can learn to use them in our favor. For instance, instead of reverse engineering our theories from observation, we can enumerate systems and then try to match them to the behaviors we observe. A major theme of \"NKS\" is investigating the structure of the possibility space. Wolfram argues that science is far too ad hoc, in part because the models used are too complicated and unnecessarily organized around the limited primitives of traditional mathematics. Wolfram advocates using models whose variations are enumerable and whose consequences are straightforward to compute and analyze.",
            "score": 75.18367767333984
        },
        {
            "docid": "159266_62",
            "document": "Gene expression . Gene networks can also be constructed without formulating an explicit causal model. This is often the case when assembling networks from large expression data sets. Covariation and correlation of expression is computed across a large sample of cases and measurements (often transcriptome or proteome data). The source of variation can be either experimental or natural (observational). There are several ways to construct gene expression networks, but one common approach is to compute a matrix of all pair-wise correlations of expression across conditions, time points, or individuals and convert the matrix (after thresholding at some cut-off value) into a graphical representation in which nodes represent genes, transcripts, or proteins and edges connecting these nodes represent the strength of association (see ). Weighted correlation network analysis (WGCNA) involves weighted networks defined by soft-thresholding the pairwise correlations among variables (e.g. measures of transcript abundance). WGCNA can be applied to compute eigengenes, which are highly robust biomarkers (features) useful for diagnosis and prognosis.",
            "score": 75.17512512207031
        },
        {
            "docid": "143533_20",
            "document": "Green fluorescent protein . The availability of GFP and its derivatives has thoroughly redefined fluorescence microscopy and the way it is used in cell biology and other biological disciplines. While most small fluorescent molecules such as FITC (fluorescein isothiocyanate) are strongly phototoxic when used in live cells, fluorescent proteins such as GFP are usually much less harmful when illuminated in living cells. This has triggered the development of highly automated live-cell fluorescence microscopy systems, which can be used to observe cells over time expressing one or more proteins tagged with fluorescent proteins. For example, GFP had been widely used in labelling the spermatozoa of various organisms for identification purposes as in \"Drosophila melanogaster\", where expression of GFP can be used as a marker for a particular characteristic. GFP can also be expressed in different structures enabling morphological distinction. In such cases, the gene for the production of GFP is incorporated into the genome of the organism in the region of the DNA that codes for the target proteins and that is controlled by the same regulatory sequence; that is, the gene's regulatory sequence now controls the production of GFP, in addition to the tagged protein(s). In cells where the gene is expressed, and the tagged proteins are produced, GFP is produced at the same time. Thus, only those cells in which the tagged gene is expressed, or the target proteins are produced, will fluoresce when observed under fluorescence microscopy. Analysis of such time lapse movies has redefined the understanding of many biological processes including protein folding, protein transport, and RNA dynamics, which in the past had been studied using fixed (i.e., dead) material. Obtained data are also used to calibrate mathematical models of intracellular systems and to estimate rates of gene expression.",
            "score": 75.09058380126953
        }
    ]
}