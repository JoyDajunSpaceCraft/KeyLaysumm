{
    "q": [
        {
            "docid": "3408308_4",
            "document": "Metabolic network modelling . A metabolic reconstruction provides a highly mathematical, structured platform on which to understand the systems biology of metabolic pathways within an organism. The integration of biochemical metabolic pathways with rapidly available, unannotated genome sequences has developed what are called genome-scale metabolic models. Simply put, these models correspond metabolic genes with metabolic pathways. In general, the more information about physiology, biochemistry and genetics is available for the target organism, the better the predictive capacity of the reconstructed models. Mechanically speaking, the process of reconstructing prokaryotic and eukaryotic metabolic networks is essentially the same. Having said this, eukaryote reconstructions are typically more challenging because of the size of genomes, coverage of knowledge, and the multitude of cellular compartments. The first genome-scale metabolic model was generated in 1995 for \"Haemophilus influenzae\". The first multicellular organism, \"C. elegans\", was reconstructed in 1998. Since then, many reconstructions have been formed. For a list of reconstructions that have been converted into a model and experimentally validated, see http://sbrg.ucsd.edu/InSilicoOrganisms/OtherOrganisms.",
            "score": 102.28526258468628
        },
        {
            "docid": "3408308_10",
            "document": "Metabolic network modelling . An initial metabolic reconstruction of a genome is typically far from perfect due to the high variability and diversity of microorganisms. Often, metabolic pathway databases such as KEGG and MetaCyc will have \"holes\", meaning that there is a conversion from a substrate to a product (i.e., an enzymatic activity) for which there is no known protein in the genome that encodes the enzyme that facilitates the catalysis. What can also happen in semi-automatically drafted reconstructions is that some pathways are falsely predicted and don't actually occur in the predicted manner. Because of this, a systematic verification is made in order to make sure no inconsistencies are present and that all the entries listed are correct and accurate. Furthermore, previous literature can be researched in order to support any information obtained from one of the many metabolic reaction and genome databases. This provides an added level of assurance for the reconstruction that the enzyme and the reaction it catalyzes do actually occur in the organism.",
            "score": 78.9486014842987
        },
        {
            "docid": "49734242_13",
            "document": "Metabolite damage . Metabolic network modelling aims at reproducing cellular metabolism \"in silico\". Metabolite damage and repair create cellular energy costs, and consequently need to be incorporated into genome-scale metabolic models so that these models can more effectively guide metabolic engineering design.",
            "score": 67.34595608711243
        },
        {
            "docid": "1392430_8",
            "document": "Geobacter . \"Geobacter\" species are often the predominant organisms when extracellular electron transfer is an important bioremediation process in subsurface environments. Therefore, a systems biology approach to understanding and optimizing bioremediation with \"Geobacter\" species has been initiated with the ultimate goal of developing \"in silico\" models that can predict the growth and metabolism of \"Geobacter\" species under a diversity of subsurface conditions. The genomes of multiple \"Geobacter\" species have been sequenced. Detailed functional genomic/physiological studies on one species, \"G. sulfurreducens\" was conducted. Genome-based models of several \"Geobacter\" species that are able to predict physiological responses under different environmental conditions are available. Quantitative analysis of gene transcript levels during \"in situ\" uranium bioremediation demonstrated that it is possible to track \"in situ\" rates of metabolism and the \"in situ\" metabolic state of \"Geobacter\" in the subsurface.",
            "score": 79.74155402183533
        },
        {
            "docid": "40160407_38",
            "document": "Essential gene . Metabolic modelling. Essential genes may be also predicted in completely sequenced genomes by metabolic reconstruction, that is, by reconstructing the complete metabolism from the gene content and then identifying those genes and pathways that have been found to be essential in other species. However, this method can be compromised by proteins of unknown function. In addition, many organisms have backup or alternative pathways which have to be taken into account (see figure 1). Metabolic modeling was also used by Basler (2015) to develop a method to predict essential metabolic genes. Flux balance analysis, a method of metabolic modeling, has recently been used to predict essential genes in clear cell renal cell carcinoma metabolism.",
            "score": 83.54384255409241
        },
        {
            "docid": "3408308_8",
            "document": "Metabolic network modelling . The predictive aspect of a metabolic reconstruction hinges on the ability to predict the biochemical reaction catalyzed by a protein using that protein's amino acid sequence as an input, and to infer the structure of a metabolic network based on the predicted set of reactions. A network of enzymes and metabolites is drafted to relate sequences and function. When an uncharacterized protein is found in the genome, its amino acid sequence is first compared to those of previously characterized proteins to search for homology. When a homologous protein is found, the proteins are considered to have a common ancestor and their functions are inferred as being similar. However, the quality of a reconstruction model is dependent on its ability to accurately infer phenotype directly from sequence, so this rough estimation of protein function will not be sufficient. A number of algorithms and bioinformatics resources have been developed for refinement of sequence homology-based assignments of protein functions:",
            "score": 70.62913584709167
        },
        {
            "docid": "3350262_17",
            "document": "Gompertz function . The metabolic function is particularly concerned with accounting for the rate of metabolism within an organism. This function can be applied to monitor tumor cells; metabolic rate is dynamic and is greatly flexible, making it more precise in detailing cancer growth.The metabolic curve takes in to consideration the energy the body provides in maintaining and creating tissue. This energy can be considered as metabolism and follows a specific pattern in cellular division. Energy conservation can be used to model such growth, irrespective of differing masses and development times. All taxons (a group of one or more populations of an organism) share a similar growth pattern and this model, as a result, considers cellular division, the foundation of the development of a tumor.",
            "score": 84.77726125717163
        },
        {
            "docid": "3408308_23",
            "document": "Metabolic network modelling . Metabolic network reconstructions and models are used to understand how an organism or parasite functions inside of the host cell. For example, if the parasite serves to compromise the immune system by lysing macrophages, then the goal of metabolic reconstruction/simulation would be to determine the metabolites that are essential to the organism's proliferation inside of macrophages. If the proliferation cycle is inhibited, then the parasite would not continue to evade the host's immune system. A reconstruction model serves as a first step to deciphering the complicated mechanisms surrounding disease. These models can also look at the minimal genes necessary for a cell to maintain virulence. The next step would be to use the predictions and postulates generated from a reconstruction model and apply it to discover novel biological functions such as drug-engineering and drug delivery techniques.",
            "score": 86.85028386116028
        },
        {
            "docid": "57508587_3",
            "document": "Pseudomonas teessidea . Rhamnolipids are predominantly produced by the microbe \"Pseudomonas aeruginosa\". However, \"Pseudomonas putida\" is a model organism with greater metabolic versatility and potential for industrial applications. Computational methods for metabolic engineering are able to model and optimise such biological models, leading to the improvement of a given biotechnological pipeline.The engineered genome-scale model of \"Pseudomonas putida\" built during a BBSRC Research project can already be used to predict and maximise rhamnolipid production and transport through the cell membrane. The promising results found during this project have strengthened the collaboration between TeeGene and the Computational Biology group at Teesside University. The resulting pipeline will finally be used to build a genome-scale model of \"Pseudomonas teessidea\" for which a model is unavailable. The resulting project will elucidate the metabolic engineering steps for overproduction of rhamnolipids and their transport out of the cell membrane.",
            "score": 89.70331144332886
        },
        {
            "docid": "3408308_16",
            "document": "Metabolic network modelling . Price, Reed, and Papin, from the Palsson lab, use a method of singular value decomposition (SVD) of extreme pathways in order to understand regulation of a human red blood cell metabolism. Extreme pathways are convex basis vectors that consist of steady state functions of a metabolic network. For any particular metabolic network, there is always a unique set of extreme pathways available. Furthermore, Price, Reed, and Papin, define a constraint-based approach, where through the help of constraints like mass balance and maximum reaction rates, it is possible to develop a \u2018solution space\u2019 where all the feasible options fall within. Then, using a kinetic model approach, a single solution that falls within the extreme pathway solution space can be determined. Therefore, in their study, Price, Reed, and Papin, use both constraint and kinetic approaches to understand the human red blood cell metabolism. In conclusion, using extreme pathways, the regulatory mechanisms of a metabolic network can be studied in further detail.",
            "score": 72.50383806228638
        },
        {
            "docid": "3408308_2",
            "document": "Metabolic network modelling . Metabolic network reconstruction and simulation allows for an in-depth insight into the molecular mechanisms of a particular organism. In particular, these models correlate the genome with molecular physiology. A reconstruction breaks down metabolic pathways (such as glycolysis and the citric acid cycle) into their respective reactions and enzymes, and analyzes them within the perspective of the entire network. In simplified terms, a reconstruction collects all of the relevant metabolic information of an organism and compiles it in a mathematical model. Validation and analysis of reconstructions can allow identification of key features of metabolism such as growth yield, resource distribution, network robustness, and gene essentiality. This knowledge can then be applied to create novel biotechnology.",
            "score": 90.9686872959137
        },
        {
            "docid": "4101904_26",
            "document": "Flux balance analysis . The objective function is essentially a measure of how each component in the system contributes to the production of the desired product. The product itself depends on the purpose of the model, but one of the most common examples is the study of total biomass. A notable example of the success of FBA is the ability to accurately predict the growth rate of the prokaryote \"E. coli\" when cultured in different conditions. In this case, the metabolic system was optimized to maximize the biomass objective function. However this model can be used to optimize the production of any product, and is often used to determine the output level of some biotechnologically relevant product. The model itself can be experimentally verified by cultivating organisms using a chemostat or similar tools to ensure that nutrient concentrations are held constant. Measurements of the production of the desired objective can then be used to correct the model.",
            "score": 85.7120611667633
        },
        {
            "docid": "662349_19",
            "document": "Metabolic theory of ecology . At the ecosystem level, MTE explains the relationship between temperature and production of total biomass. The average production to biomass ratio of organisms is higher in small organisms than large ones. This relationship is further regulated by temperature, and the rate of production increases with temperature. As production consistently scales with body mass, MTE provides a framework to assess the relative importance of organismal size, temperature, functional traits, soil and climate on variation in rates of production within and across ecosystems. Metabolic theory shows that variation in ecosystem production is characterized by a common scaling relationship, suggesting that global change models can incorporate the mechanisms governing this relationship to improve predictions of future ecosystem function.",
            "score": 57.79586839675903
        },
        {
            "docid": "20374_50",
            "document": "Metabolism . An idea of the complexity of the metabolic networks in cells that contain thousands of different enzymes is given by the figure showing the interactions between just 43 proteins and 40 metabolites to the right: the sequences of genomes provide lists containing anything up to 45,000 genes. However, it is now possible to use this genomic data to reconstruct complete networks of biochemical reactions and produce more holistic mathematical models that may explain and predict their behavior. These models are especially powerful when used to integrate the pathway and metabolite data obtained through classical methods with data on gene expression from proteomic and DNA microarray studies. Using these techniques, a model of human metabolism has now been produced, which will guide future drug discovery and biochemical research. These models are now used in network analysis, to classify human diseases into groups that share common proteins or metabolites.",
            "score": 86.79090619087219
        },
        {
            "docid": "3408308_17",
            "document": "Metabolic network modelling . Elementary mode analysis closely matches the approach used by extreme pathways. Similar to extreme pathways, there is always a unique set of elementary modes available for a particular metabolic network. These are the smallest sub-networks that allow a metabolic reconstruction network to function in steady state. According to Stelling (2002), elementary modes can be used to understand cellular objectives for the overall metabolic network. Furthermore, elementary mode analysis takes into account stoichiometrics and thermodynamics when evaluating whether a particular metabolic route or network is feasible and likely for a set of proteins/enzymes.",
            "score": 69.34090161323547
        },
        {
            "docid": "3408308_14",
            "document": "Metabolic network modelling . Therefore, systematic verification of the initial reconstruction will bring to light several inconsistencies that can adversely affect the final interpretation of the reconstruction, which is to accurately comprehend the molecular mechanisms of the organism. Furthermore, the simulation step also ensures that all the reactions present in the reconstruction are properly balanced. To sum up, a reconstruction that is fully accurate can lead to greater insight about understanding the functioning of the organism of interest.",
            "score": 66.32095313072205
        },
        {
            "docid": "4101904_2",
            "document": "Flux balance analysis . Flux balance analysis (FBA) is a mathematical method for simulating metabolism in genome-scale reconstructions of metabolic networks. In comparison to traditional methods of modeling, FBA is less intensive in terms of the input data required for constructing the model. Simulations performed using FBA are computationally inexpensive and can calculate steady-state metabolic fluxes for large models (over 2000 reactions) in a few seconds on modern personal computers.",
            "score": 74.9507384300232
        },
        {
            "docid": "23298857_3",
            "document": "Chemoton . The basic assumption of the model is that life should fundamentally and essentially have three properties: metabolism, self-replication, and a bilipid membrane. The metabolic and replication functions together form an autocatalytic subsystem necessary for the basic functions of life, and a membrane encloses this subsystem to separate it from the surrounding environment. Therefore, any system having such properties may be regarded as alive, and it will be subjected to natural selection and contain a self-sustaining cellular information. Some consider this model a significant contribution to origin of life as it provides a philosophy of evolutionary units.",
            "score": 56.98332953453064
        },
        {
            "docid": "4101904_28",
            "document": "Flux balance analysis . The key parts of model preparation are: creating a metabolic network without gaps, adding constraints to the model, and finally adding an objective function (often called the Biomass function), usually to simulate the growth of the organism being modelled.",
            "score": 68.89931344985962
        },
        {
            "docid": "36307309_2",
            "document": "Virtual Physiological Rat . sysThe Virtual Physiological Rat (VPR) Project is an international collaboration aimed simulating the integrated cardiovascular function of the rat and supported by the National Institute of General Medical Sciences as a National Center for Systems Biology. The project is motivated by the fact that, although there exist both a depth of knowledge of basic cardiovascular physiology and a host of physiological and genomic data from animal models of disease, there is a lack of understanding of how multiple genes and environmental factors interact to determine cardiovascular phenotype. The Virtual Physiological Rat Project is focused on developing computational tools to capture the underlying systems physiology as well as the pathophysiological perturbations associated with disease. These tools are being developed and validated based on experimental characterization of physiological function across a number of organ systems in rat strains engineered to show relevant disease phenotypes. Computer simulation is used to integrate disparate data (genomic, anatomic, physiological, etc.) to explain and predict function, and to translate the findings from animal models to yield new information on specific interrelated complex diseases in humans, including hypertension, kidney disease, heart failure, and metabolic syndrome.",
            "score": 86.8395403623581
        },
        {
            "docid": "3408308_11",
            "document": "Metabolic network modelling . Enzyme promiscuity and spontaneous chemical reactions can damage metabolites. This metabolite damage, and its repair or pre-emption, create energy costs that need to be incorporated into models. It is likely that many genes of unknown function encode proteins that repair or pre-empt metabolite damage, but most genome-scale metabolic reconstructions only include a fraction of all genes.",
            "score": 68.4406054019928
        },
        {
            "docid": "37887859_8",
            "document": "Jens Nielsen . Using his systems biology toolbox developed for microorganisms, Jens Nielsen initiated work on human metabolism. In connection with this he developed a comprehensive genome-scale metabolic model for human cells and he was the first to use a human GEM to illustrate the metabolic heterogeneity of cancer metabolism. His work on human metabolism has involved studies of different diseases such as obesity, NAFLD and NASH, and hepatocellular carcinoma. Jens Nielsen further used human GEMs to identify that combined measurements of several glycosaminoglycans can be used as a very strong biomarker for clear cell renal cell carcinoma, probably the first systems biomarker.",
            "score": 74.8265769481659
        },
        {
            "docid": "44514645_16",
            "document": "ASHRAE 55 . For humidity ratios above 0.012\u00a0kg HO/kg dry air (0.012\u00a0lb HO/lb dry air), or for metabolic rates up to 2.0 met, the analytical model must be used to determine thermal comfort sensation. Also based on the PMV model, this method uses tools such as the ASHRAE Thermal Comfort Tool or the online CBE Thermal Comfort Tool to evaluate thermal comfort. Users provide operative temperature (or air temperature and mean radiant temperature), air speed, humidity, metabolic rate, and clothing insulation value, and the tool evaluates predicted thermal sensation on a scale from -3 (cold) to +3 (hot). Compliance is achieved if the conditions provide thermal neutrality, measured as falling between -0.5 and +0.5 on the PMV scale.",
            "score": 60.71225547790527
        },
        {
            "docid": "18363322_13",
            "document": "Urban metabolism . Aside from the two accounting applications above, urban metabolism has begun to develop mathematical models to quantify and predict levels of particles and nutrients within the urban metabolism model. Such models have mostly been created and used by MFA scholars and are helpful in determining present and future sub-processes and material stocks and flows within the urban environment With the ability to predict future levels, these mathematical models allow progress to be made and possible pollution prevention programs to be instated rather than end-of-the-pipe solutions which have been favoured in the past.",
            "score": 63.26850724220276
        },
        {
            "docid": "9028799_62",
            "document": "Bacteria . Because of their ability to quickly grow and the relative ease with which they can be manipulated, bacteria are the workhorses for the fields of molecular biology, genetics and biochemistry. By making mutations in bacterial DNA and examining the resulting phenotypes, scientists can determine the function of genes, enzymes and metabolic pathways in bacteria, then apply this knowledge to more complex organisms. This aim of understanding the biochemistry of a cell reaches its most complex expression in the synthesis of huge amounts of enzyme kinetic and gene expression data into mathematical models of entire organisms. This is achievable in some well-studied bacteria, with models of \"Escherichia coli\" metabolism now being produced and tested. This understanding of bacterial metabolism and genetics allows the use of biotechnology to bioengineer bacteria for the production of therapeutic proteins, such as insulin, growth factors, or antibodies.",
            "score": 76.4539225101471
        },
        {
            "docid": "3408308_20",
            "document": "Metabolic network modelling . Furthermore, this particular approach can accurately define if the reaction stoichiometry is in line with predictions by providing fluxes for the balanced reactions. Also, flux balance analysis can highlight the most effective and efficient pathway through the network in order to achieve a particular objective function. In addition, gene knockout studies can be performed using flux balance analysis. The enzyme that correlates to the gene that needs to be removed is given a constraint value of 0. Then, the reaction that the particular enzyme catalyzes is completely removed from the analysis.",
            "score": 45.550421476364136
        },
        {
            "docid": "662349_10",
            "document": "Metabolic theory of ecology . Researchers disagree about the two main aspects of this theory, the pattern and the mechanism. The primary pattern in question is whether metabolic rate scales to the power of \u00be or \u2154w, or whether either of these can even be considered a universal constant. The majority view is currently that \u00be is the correct exponent, but a large minority believe that \u2154 is the more accurate value. In addition to disagreeing about the pattern, researchers also disagree about mechanism. Various authors have proposed at least eight different types of mechanisms that predict an allometric scaling exponent of either \u2154 or \u00be. Some of these models make a large number of testable predictions while others are less comprehensive.",
            "score": 57.248642444610596
        },
        {
            "docid": "50035615_16",
            "document": "UCERF3 . An important result is that the generally accepted Gutenberg-Richter (GR) relationship (that the distribution of earthquakes shows a certain relationship between magnitude and frequency) is inconsistent with certain parts of the current UCERF3 model. The model implies that achieving GR consistency would require certain changes in seismological understanding that \"fall outside the current bounds of consensus-level acceptability\". Whether the Gutenberg-Richter relation is inapplicable at the scale of individual faults, or some basis of the model is incorrect, \"will be equally profound scientifically, and quite consequential with respect to hazard.\"",
            "score": 61.938385248184204
        },
        {
            "docid": "54056007_6",
            "document": "Anne Ferguson-Smith . Her subsequent research in the Department of Physiology Development and Neuroscience (formerly Anatomy) at the University of Cambridge identified functions for, and regulatory mechanisms of, genomic imprinting, and contributed to its establishment as a model for understanding the epigenetic control of mammalian genome function. This work resulted in the characterisation of pathways important in mammalian development and growth, in the regulation of metabolism, and in the control of adult neurogenesis.",
            "score": 55.55466437339783
        },
        {
            "docid": "43778895_11",
            "document": "Predictive genomics . Type 2 diabetes (T2D), an extremely common metabolic disorder, has demonstrated interplay between many environmental and genetic risk factors leading to disease onset. A number of risk assessment models incorporating a number of demographic, environmental and clinical risk factors are already shown to elicit reasonable discrimination in case-control studies; it has been proposed that identifying genetic variants that contribute to T2D as for standalone prediction or in conjunction with current risk models can improve prediction of T2D risk, if current models lack sufficient coverage of the full effect of an individual's genotype. Approximately 20 associated SNPs have been replicated in T2D; however, their effect sizes do not seem to be substantial: OR 1.37 for SNPs in the \"TCF7L2\" gene purported to give highest genetic risk.",
            "score": 59.12872242927551
        },
        {
            "docid": "3350262_19",
            "document": "Gompertz function . The differentiation between energy used at rest and metabolic rate work allows for the model to more precisely determine the rate of growth. The energy at rest is lower than the energy used to maintain a tissue, and together represent the energy required to maintain the existing tissue. The use of these two factors, alongside the energy required to create new tissue, comprehensively map the rate of growth, and moreover, lead in to an accurate representation of the Lag phase. In the 1960s A.K. Laird for the first time successfully used the Gompertz curve to fit data of growth of tumors. In fact, tumors are cellular populations growing in a confined space where the availability of nutrients is limited. Denoting the tumor size as X(t) it is useful to write the Gompertz Curve as follows:",
            "score": 43.432350397109985
        },
        {
            "docid": "3408308_18",
            "document": "Metabolic network modelling . In 2009, Larhlimi and Bockmayr presented a new approach called \"minimal metabolic behaviors\" for the analysis of metabolic networks. Like elementary modes or extreme pathways, these are uniquely determined by the network, and yield a complete description of the flux cone. However, the new description is much more compact. In contrast with elementary modes and extreme pathways, which use an inner description based on generating vectors of the flux cone, MMBs are using an outer description of the flux cone. This approach is based on sets of non-negativity constraints. These can be identified with irreversible reactions, and thus have a direct biochemical interpretation. One can characterize a metabolic network by MMBs and the reversible metabolic space.",
            "score": 60.064138889312744
        }
    ],
    "r": [
        {
            "docid": "3408308_4",
            "document": "Metabolic network modelling . A metabolic reconstruction provides a highly mathematical, structured platform on which to understand the systems biology of metabolic pathways within an organism. The integration of biochemical metabolic pathways with rapidly available, unannotated genome sequences has developed what are called genome-scale metabolic models. Simply put, these models correspond metabolic genes with metabolic pathways. In general, the more information about physiology, biochemistry and genetics is available for the target organism, the better the predictive capacity of the reconstructed models. Mechanically speaking, the process of reconstructing prokaryotic and eukaryotic metabolic networks is essentially the same. Having said this, eukaryote reconstructions are typically more challenging because of the size of genomes, coverage of knowledge, and the multitude of cellular compartments. The first genome-scale metabolic model was generated in 1995 for \"Haemophilus influenzae\". The first multicellular organism, \"C. elegans\", was reconstructed in 1998. Since then, many reconstructions have been formed. For a list of reconstructions that have been converted into a model and experimentally validated, see http://sbrg.ucsd.edu/InSilicoOrganisms/OtherOrganisms.",
            "score": 102.28526306152344
        },
        {
            "docid": "3408308_7",
            "document": "Metabolic network modelling . A reconstruction is built by compiling data from the resources above. Database tools such as KEGG and BioCyc can be used in conjunction with each other to find all the metabolic genes in the organism of interest. These genes will be compared to closely related organisms that have already developed reconstructions to find homologous genes and reactions. These homologous genes and reactions are carried over from the known reconstructions to form the draft reconstruction of the organism of interest. Tools such as ERGO, Pathway Tools and Model SEED can compile data into pathways to form a network of metabolic and non-metabolic pathways. These networks are then verified and refined before being made into a mathematical simulation.",
            "score": 98.11253356933594
        },
        {
            "docid": "1872854_30",
            "document": "Biochemical cascade . Given the genetic makeup of an organism, the complete set of possible reactions constitutes its reactome. Reactome, located at http://www.reactome.org is a curated, peer-reviewed resource of human biological processes/pathway data. The basic unit of the Reactome database is a reaction; reactions are then grouped into causal chains to form pathways The Reactome data model allows us to represent many diverse processes in the human system, including the pathways of intermediary metabolism, regulatory pathways, and signal transduction, and high-level processes, such as the cell cycle. Reactome provides a qualitative framework, on which quantitative data can be superimposed. Tools have been developed to facilitate custom data entry and annotation by expert biologists, and to allow visualization and exploration of the finished dataset as an interactive process map. Although the primary curational domain is pathways from Homo sapiens, electronic projections of human pathways onto other organisms are regularly created via putative orthologs, thus making Reactome relevant to model organism research communities. The database is publicly available under open source terms, which allows both its content and its software infrastructure to be freely used and redistributed. Studying whole transcriptional profiles and cataloging protein\u2013protein interactions has yielded much valuable biological information, from the genome or proteome to the physiology of an organism, an organ, a tissue or even a single cell. The Reactome database containing a framework of possible reactions which, when combined with expression and enzyme kinetic data, provides the infrastructure for quantitative models, therefore, an integrated view of biological processes, which links such gene products and can be systematically mined by using bioinformatics applications. Reactome data available in a variety of standard formats, including BioPAX, SBML and PSI-MI, and also enable data exchange with other pathway databases, such as the Cycs, KEGG and amaze, and molecular interaction databases, such as BIND and HPRD. The next data release will cover apoptosis, including the death receptor signaling pathways, and the Bcl2 pathways, as well as pathways involved in hemostasis. Other topics currently under development include several signaling pathways, mitosis, visual phototransduction and hematopoeisis. In summary, Reactome provides high-quality curated summaries of fundamental biological processes in humans in a form of biologist-friendly visualization of pathways data, and is an open-source project.",
            "score": 95.89237976074219
        },
        {
            "docid": "40977477_14",
            "document": "Cross-species transmission . Alternative hosts can also potentially have a critical role in the evolution and diffusion of a pathogen. When a pathogen crosses species it often acquires new characteristics that allow it to breach host barriers. Different pathogen variants can have very different effects on host species. Thus it can be beneficial to CST analysis to compare the same pathogens occurring in different host species. Phylogenetic analysis can be used to track a pathogens history through different species populations. Even if a pathogen is new and highly divergent, phylogenetic comparison can be very insightful A useful strategy for investigating the history of epidemics caused by pathogen transmission combines molecular clock analysis, to estimate the timescale of the epidemic, and coalescent theory, to infer the demographic history of the pathogen. When constructing phylogenies, computer databases and tools are often used. Programs, such as BLAST, are used to annotate pathogen sequences, while databases like GenBank provide information about functions based on the pathogens genomic structure. Trees are constructed using computational methods such as MPR or Bayesian Inference, and models are created depending on the needs of the study. Single rate dated tip (SRDT) models, for example, allows for estimates of timescale under a phylogenetic tree. Models for CST prediction will vary depending on what parameters need to be accounted for when constructing the model.",
            "score": 94.73127746582031
        },
        {
            "docid": "8758178_2",
            "document": "FlyBase . FlyBase is an online bioinformatics database and the primary repository of genetic and molecular data for the insect family \"Drosophilidae\". For the most extensively studied species and model organism, \"Drosophila melanogaster\", a wide range of data are presented in different formats. Information in FlyBase originates from a variety of sources ranging from large-scale genome projects to the primary research literature. These data types include mutant phenotypes, molecular characterization of mutant alleles and other deviations, cytological maps, wild-type expression patterns, anatomical images, transgenic constructs and insertions, sequence-level gene models and molecular classification of gene product functions. Query tools allow navigation of FlyBase through DNA or protein sequence, by gene or mutant name, or through terms from the several ontologies used to capture functional, phenotypic, and anatomical data. The database offers several different query tools in order to provide efficient access to the data available and facilitate the discovery of significant relationships within the database. Links between FlyBase and external databases, such as BDGP or modENCODE, provide opportunity for further exploration into other model organism databases and other resources of biological and molecular information. The FlyBase project is carried out by a consortium of \"Drosophila\" researchers and computer scientists at Harvard University and Indiana University in the United States, and University of Cambridge in the United Kingdom.",
            "score": 93.55669403076172
        },
        {
            "docid": "50968824_2",
            "document": "Model organism databases . Model organism databases (MODs) are biological databases, or knowledgebases, dedicated to the provision of in-depth biological data for intensively studied model organisms. MODs allow researchers to easily find background information on large sets of genes, plan experiments efficiently, combine their data with existing knowledge, and construct novel hypotheses. They allow users to analyse results and interpret datasets, and the data they generate are increasingly used to describe less well studied species. Where possible, MODs share common approaches to collect and represent biological information. For example, all MODs use the Gene Ontology to describe functions, processes and cellular locations of specific gene products. Projects also exist to enable software sharing for curation, visualization and querying between different MODs. Organismal diversity and varying user requirements however mean that MODs are often required to customize capture, display, and provision of data.",
            "score": 92.02313232421875
        },
        {
            "docid": "15262886_8",
            "document": "Sustainable design standards . BIM (building information modeling) allows designers to work with many remote consultants on the same data file that represents all the decisions being made by the team. That same file is available to the climate and energy and environmental impact analysis and cost analysis tools and consultants, ... and of course to the prospective contractors and the regulators. Along with this new integrated access to the model there in needed a new way to integrate the conversation of so many people, each with some interest in reviewing each other's comments on the progress with the central design model. That is likely to involve development of wiki tools for the process. One such very early impliementation of a Wiki SD tool called \"4Dsustainability\" organizes the project design evolution around the general learning process of how you define the problem by exploring its environment, and following that through the project.",
            "score": 91.95194244384766
        },
        {
            "docid": "50311973_8",
            "document": "Microfluidic cell culture . Three-dimensional (3D) cell culture is cell culture that takes place in a biologically relevant matrix, usually this involves cells being embedded in a hydrogel containing extracellular molecules (e.g., collagen). By adding an additional dimension, more advanced cell architectures can be achieved, and cell behavior is more representative of \"in vivo\" dynamics; cells can engage in enhanced communication with neighboring cells and cell-extracellular matrix interactions can be modeled. These simplified 3D cell culture models can be combined in a manner that recapitulates tissue- and organ-level functions in devices known as organ-on-a-chip. In these devices, chambers or collagen layers containing different cell types can interact with one another for multiple days while various channels deliver nutrients to the cells. An advantage of these devices is that tissue function can be characterized and observed under controlled conditions (e.g., effect of shear stress on cells, effect of cyclic strain or other forces) to better understand the overall function of the organ. While these 3D models often better model organ function on a cellular level compared with 2D models, there are still challenges. Some of the challenges include: imaging of the cells, control of gradients in static models (i.e., without a perfusion system), and difficulty recreating vasculature. Despite these challenges, 3D models are still used as tools for studying and testing drug responses in pharmacological studies.",
            "score": 91.42964935302734
        },
        {
            "docid": "3408308_2",
            "document": "Metabolic network modelling . Metabolic network reconstruction and simulation allows for an in-depth insight into the molecular mechanisms of a particular organism. In particular, these models correlate the genome with molecular physiology. A reconstruction breaks down metabolic pathways (such as glycolysis and the citric acid cycle) into their respective reactions and enzymes, and analyzes them within the perspective of the entire network. In simplified terms, a reconstruction collects all of the relevant metabolic information of an organism and compiles it in a mathematical model. Validation and analysis of reconstructions can allow identification of key features of metabolism such as growth yield, resource distribution, network robustness, and gene essentiality. This knowledge can then be applied to create novel biotechnology.",
            "score": 90.96868896484375
        },
        {
            "docid": "7028968_2",
            "document": "Procedural modeling . Procedural modeling is an umbrella term for a number of techniques in computer graphics to create 3D models and textures from sets of rules. L-Systems, fractals, and generative modeling are procedural modeling techniques since they apply algorithms for producing scenes. The set of rules may either be embedded into the algorithm, configurable by parameters, or the set of rules is separate from the evaluation engine. The output is called procedural content, which can be used in computer games, films, be uploaded to the internet, or the user may edit the content manually. Procedural models often exhibit database amplification, meaning that large scenes can be generated from a much smaller amount of rules. If the employed algorithm produces the same output every time, the output need not be stored. Often, it suffices to start the algorithm with the same random seed to achieve this. Although all modeling techniques on a computer require algorithms to manage and store data at some point, procedural modeling focuses on creating a model from a rule set, rather than editing the model via user input.  Procedural modeling is often applied when it would be too cumbersome to create a 3D model using generic 3D modelers, or when more specialized tools are required. This is often the case for plants, architecture or landscapes.",
            "score": 90.77124786376953
        },
        {
            "docid": "23386350_4",
            "document": "BioSim . Diabetes Efforts concentrate on the role of mutations that effect the ion channels of the insulin-producing beta-cells, on the genetic basis for the development of neonatal diabetes, on the study of human (as opposed to mice) pancreatic cells, on the mechanisms underlying the development of insulin resistance, and on the possible role of prenatal nutrition for the development of type-2 diabetes. Models are also developed to analyse the balance between fat and glucose metabolism and to describe the rate of absorption of different insulin variants. Cancer In this area the network uses computer models of the cell cycle and of its coupling to the 24 h day-and-night rhythm to improve the treatment of patients with cancer. The use of chronotherapy implies that the administration of anti-cancer drugs is adjusted in accordance with the circadian rhythm of the patient. For certain forms of cancer this has been found to increase the efficiency of the drug by a factor of five. Efforts are also devoted to the development of new anti-cancer drugs. Hypertension and cardiovascular diseases Activities area focus on the development of 3D heart models that can be used to test how a new drug affects the regularity of the heart rhythm. Work is performed to develop detailed models of the mechanisms by which the individual nephron of the kidney regulates the incoming blood flow and how neighboring nephrons interact. Mental disorders and neuronal systems Work includes application of mathematical models to develop less invasive and demand-controlled electrical stimulation techniques for the treatment of Parkinson's disease. Modelling studies are performed to examine the effect of sleep deprivation in the treatment of depression, and bioinformatic approaches are applied to try to identify forms of depression on the basis of the information available from blood samples. Methodological issues The area encompasses description of complex networks of oscillating biological units, studies of the mechanisms of temperature stabilization in biological feedback regulations, application of new methods of data analysis, and development of modeling software and biomedical search machines. The area includes application of new experimental techniques such as interference microscopy and surface enhanced Raman spectroscopy to study cellular processes. Regulatory issues and dialogue with the public Testing in animal and human subjects is a necessary part of the development of new drugs. Such experiments clearly raises a number of complicated ethical issues that the use of simulation models may reduce. This requires that the regulatory authorities can evaluate computer models and accept them as part of the required documentation.  During the last five years the BioSim Network has published nine books and 800 scientific publications. The network has organized or co-organized 30 conferences and workshops, edited four issues of international journals, and trained about 130 PhD students. New National Centres in Systems Biology have been established in relation to the BioSim partners in Manchester, Warwick, and Edinburgh.",
            "score": 90.52952575683594
        },
        {
            "docid": "24963841_2",
            "document": "Cognitive models of information retrieval . Cognitive models of information retrieval rest on the mix of areas such as cognitive science, human-computer interaction, information retrieval, and library science. They describe the relationship between a person's cognitive model of the information sought and the organization of this information in an information system. These models attempt to understand how a person is searching for information so that the database and the search of this database can be designed in such a way as to best serve the user. Information retrieval may incorporate multiple tasks and cognitive problems, particularly because different people may have different methods for attempting to find this information and expect the information to be in different forms. Cognitive models of information retrieval may be attempts at something as apparently prosaic as improving search results or may be something more complex, such as attempting to create a database which can be queried with natural language search.",
            "score": 90.51107788085938
        },
        {
            "docid": "57508587_3",
            "document": "Pseudomonas teessidea . Rhamnolipids are predominantly produced by the microbe \"Pseudomonas aeruginosa\". However, \"Pseudomonas putida\" is a model organism with greater metabolic versatility and potential for industrial applications. Computational methods for metabolic engineering are able to model and optimise such biological models, leading to the improvement of a given biotechnological pipeline.The engineered genome-scale model of \"Pseudomonas putida\" built during a BBSRC Research project can already be used to predict and maximise rhamnolipid production and transport through the cell membrane. The promising results found during this project have strengthened the collaboration between TeeGene and the Computational Biology group at Teesside University. The resulting pipeline will finally be used to build a genome-scale model of \"Pseudomonas teessidea\" for which a model is unavailable. The resulting project will elucidate the metabolic engineering steps for overproduction of rhamnolipids and their transport out of the cell membrane.",
            "score": 89.70330810546875
        },
        {
            "docid": "21468960_19",
            "document": "Domain-specific multimodeling . The example illustrates some of the advantages of using multiple languages in development. There are, however, also difficulties associated with this kind of development. These difficulties stem from the observation that the more kinds of artifacts we introduce into our process, the more coordination between developer efforts is needed. We will refer to these difficulties as the \"Coordination Problem\". The Coordination Problem has a conceptual and a technical aspect. Conceptually, the main problem is to understand the different languages and their interaction. To properly design and coordinate models in multiple languages, developers must have a sufficient understanding of how languages interact. Technically, the main problem is to enforce consistency. Tools must be provided to detect inconsistencies early, i.e., at modeling time, and assist developers in resolving these inconsistencies. In the following, we will examine these two aspects in greater detail.",
            "score": 89.6122055053711
        },
        {
            "docid": "19374_11",
            "document": "Model organism . Models are those organisms with a wealth of biological data that make them attractive to study as examples for other species and/or natural phenomena that are more difficult to study directly. Continual research on these organisms focus on a wide variety of experimental techniques and goals from many different levels of biology\u2014from ecology, behavior and biomechanics, down to the tiny functional scale of individual tissues, organelles and proteins. Inquiries about the DNA of organisms are classed as genetic models (with short generation times, such as the fruitfly and nematode worm), experimental models, and genomic parsimony models, investigating pivotal position in the evolutionary tree. Historically, model organisms include a handful of species with extensive genomic research data, such as the NIH model organisms.",
            "score": 89.0418701171875
        },
        {
            "docid": "24574814_3",
            "document": "Models of collaborative tagging . Just like any social phenomena, behavioral patterns in social tagging systems can be characterized by either a descriptive or predictive model. While descriptive models ask the question of \"what\", predictive models go deeper to also ask the question of \"why\" by attempting to provide explanations to the aggregate behavioral patterns. While there may be no general agreement on what an acceptable explanation should be like, many believe that a good explanation should have certain level of predictive accuracy. Descriptive models of social tagging typically are not concerned with explaining the actions of single individuals but describing the patterns that emerge as individual behavior is aggregated in a large social information system. Predictive models, however, attempt to explain aggregate patterns by analyzing how individuals interact and link to each other in ways that bring about similar or different emergent patterns of social behavior. In particular, a mechanism-based predictive model assumes a certain set of rule that individuals interact with each other, and understand how these interactions could produce aggregate patterns as observed and characterized by descriptive models. Predictive models can therefore provide explanations to why different system characteristics may lead to different aggregate patterns, and can therefore potentially provide information on how systems should be designed to achieve different social purposes.",
            "score": 88.91728210449219
        },
        {
            "docid": "33980770_31",
            "document": "Organ-on-a-chip . Mathematical pharmacokinetic (PK) models aim to estimate concentration-time profiles within each organ on the basis of the initial drug dose. Such mathematical models can be relatively simple, treating the body as a single compartment in which the drug distribution reaches a rapid equilibrium after administration. Mathematical models can be highly accurate when all parameters involved are known. Models that combine PK or PBPK models with PD models can predict the time-dependent pharmacological effects of a drug. We can nowadays predict with PBPK models the PK of about any chemical in humans, almost from first principles. These models can be either very simple, like statistical dose-response models, or sophisticated and based on systems biology, according to the goal pursued and the data available. All we need for those models are good parameter values for the molecule of interest.",
            "score": 88.91205596923828
        },
        {
            "docid": "6040399_4",
            "document": "Generative Modelling Language . Generative modelling gains efficiency through the possibility of creating high-level shape operators from low-level shape operators. Any sequence of processing steps can be grouped together to create a new \"combined operator\". It may use elementary operators as well as other combined operators. Concrete values can easily be replaced by parameters, which makes it possible to separate data from operations: The same processing sequence can be applied to different input data sets. The same data can be used to produce different shapes by applying different combined operators from, e.g., a library of domain-dependent modelling operators. This makes it possible to create very complex objects from only a few high-level input parameters, such as for instance a style library.",
            "score": 88.6602783203125
        },
        {
            "docid": "21468960_35",
            "document": "Domain-specific multimodeling . The goal of the application step is to take advantage of the coordination model. The coordination model allows tools to derive three layers of useful information. First, the coordination model can be used to enforce consistency across multiple languages. The coordination model specifies consistency relations such as how elements from different languages can refer to each other. Tools can enforce referential integrity and perform static checks of the final system before deployment. Second, the consistency relations are used to navigate, visualize and map the web of different languages in a development setup. This information is used to quickly link and relate elements from different languages and to provide traceability among different models. Third, based on consistency relations and navigational information about how elements are related, tools can provide guidance, specifically completion or assistance. Model completion can for instance be provided in a generic manner across domain-specific tools.",
            "score": 88.5643539428711
        },
        {
            "docid": "44248347_18",
            "document": "Gene Disease Database . This one of the largest resources available for all genomic and genetic studies, it provides a centralized resource for geneticists, molecular biologists and other researchers studying the genomes of our own species and other vertebrates and model disease organisms. Ensembl is one of several well-known genome browsers for the retrieval of genomic-disease information. Ensembl imports variation data from a variety of different sources, Ensembl predicts the effects of variants. For each variation that is mapped to the reference genome, each Ensembl transcript is identified that overlap the variation. Then it uses a rule-based approach to predict the effects that each allele of the variation may have on the transcript. The set of consequence terms, defined by the Sequence Ontology (SO) can be currently assigned to each combination of an allele and a transcript. Each allele of each variation may have a different effect in different transcripts. A variety of different tools are used to predict human mutations in the Ensembl database, one of the most widely used is SIFT, that predicts whether an amino acid substitution is likely to affect protein function based on sequence homology and the physic-chemical similarity between the alternate amino acids. The data provided for each amino acid substitution is a score and a qualitative prediction (either 'tolerated' or 'deleterious'). The score is the normalized probability that the amino acid change is tolerated so scores near 0 are more likely to be deleterious. The qualitative prediction is derived from this score such that substitutions with a score < 0.05 are called 'deleterious' and all others are called 'tolerated'.SIFT can be applied to naturally occurring nonsynonymous polymorphisms and laboratory-induced missense mutations, that will lead to build relationships in phenotype characteristics, proteomics and genomics",
            "score": 88.37193298339844
        },
        {
            "docid": "19374_34",
            "document": "Model organism . Many animal models serving as test subjects in biomedical research, such as rats and mice, may be selectively sedentary, obese and glucose intolerant. This may confound their use to model human metabolic processes and diseases as these can be affected by dietary energy intake and exercise. Similarly, there are differences between the immune systems of model organisms and humans that lead to significantly altered responses to stimuli, although the underlying principles of genome function may be the same.",
            "score": 88.3082275390625
        },
        {
            "docid": "46638993_2",
            "document": "Microbiome in the Drosophila gut . The microbiota describes the sum of all symbiotic microorganisms (mutualism, commensalism or pathogenic) living on or in an organism. The fruit fly \"Drosophila melanogaster\" is a model organism and known as one of the most investigated organisms worldwide. The microbiota in flies is less complex than that found in humans. It still has an influence on the fitness of the fly, and it affects different life-history characteristics such as lifespan (life expectancy), resistance against pathogens (immunity) and metabolic processes (digestion). Considering the comprehensive toolkit available for research in \"Drosophila\", analysis of its microbiome could enhance our understanding of similar processes in other types of host-microbiota interactions, including those involving humans.",
            "score": 88.0710220336914
        },
        {
            "docid": "34913748_5",
            "document": "Swiss-model . The SWISS-MODEL Workspace integrates programs and databases required for protein structure modelling in a web-based workspace. Depending on the complexity of the modelling task, different modes of usage can be applied, in which the user has different levels of control over individual modelling steps: automated mode, alignment mode, and project mode. A fully automated mode is used when a sufficiently high sequence identity between target and template (>50%) allows for no human intervention at all. In this case only the sequence or UniProt accession code of the protein is required as input. The alignment mode enables the user to input their own target-template alignments from which the modelling procedure starts (i.e. search for templates step is skipped and rarely only minor changes in the provided alignment are made). The project mode is used in more difficult cases, when manual corrections of target-template alignments are needed to improve the quality of the resulting model. In this mode the input is a project file that can be generated by the DeepView (Swiss Pdb Viewer) visualization and structural analysis tool, to allow the user to examine and manipulate the target-template alignment in its structural context. In all three cases the output is a pdb file with atom coordinates of the model or a DeepView project file. The four main steps of homology modelling may be repeated iteratively until a satisfactory model is achieved.",
            "score": 87.90921020507812
        },
        {
            "docid": "7637273_3",
            "document": "Generic Model Organism Database . The GMOD project was started in the early 2000s as a collaboration between several model organism databases (MODs) who shared a need to create similar software tools for processing data from sequencing projects. MODs, or organism-specific databases, describe genome and other information about important experimental organisms in the life sciences and capture the large volumes of data and information being generated by modern biology. Rather than each group designing their own software, four major MODs--FlyBase, Saccharomyces Genome Database, Mouse Genome Database, and WormBase\u2014worked together to create applications that provide functionality needed by all MODs, such as software to help manage the data within the MOD, and to help users access and query the data.",
            "score": 87.82789611816406
        },
        {
            "docid": "8377_51",
            "document": "Database . The first task of a database designer is to produce a conceptual data model that reflects the structure of the information to be held in the database. A common approach to this is to develop an entity-relationship model, often with the aid of drawing tools. Another popular approach is the Unified Modeling Language. A successful data model will accurately reflect the possible state of the external world being modeled: for example, if people can have more than one phone number, it will allow this information to be captured. Designing a good conceptual data model requires a good understanding of the application domain; it typically involves asking deep questions about the things of interest to an organization, like \"can a customer also be a supplier?\", or \"if a product is sold with two different forms of packaging, are those the same product or different products?\", or \"if a plane flies from New York to Dubai via Frankfurt, is that one flight or two (or maybe even three)?\". The answers to these questions establish definitions of the terminology used for entities (customers, products, flights, flight segments) and their relationships and attributes.",
            "score": 87.8261947631836
        },
        {
            "docid": "35840461_3",
            "document": "PhytoPath . PhytoPath is a bioinformatics resource launched in 2012, which integrates genome scale data from important plant pathogenic species with literature-curated information about the phenotypes of host infection available from the Pathogen-Host Interaction database (PHI-base). It provides access to complete genome assembly and gene models from priority crop and model phytopathogenic species of fungi and oomycetes through the Ensembl Genomes Browser interface. Phytopath also links directly from individual gene sequence models within the Ensembl genome browser to the peer reviewed phenotype information curated within PHI-base. The Phytopath resource aims to provide tools for comparative analysis of fungal and oomycete genomes. In 2015 the database makes accessible 135 genomic sequences in genome browsers from 87 plant pathogen species. For 1364 genes phenotypic annotation regarding their role in pathogenicity or as targets for chemical intervention is displayed directly in the pathogen genome browser. Support for community annotation for gene models is provided using the WebApollo online gene editor for some species.",
            "score": 87.45359802246094
        },
        {
            "docid": "3408308_23",
            "document": "Metabolic network modelling . Metabolic network reconstructions and models are used to understand how an organism or parasite functions inside of the host cell. For example, if the parasite serves to compromise the immune system by lysing macrophages, then the goal of metabolic reconstruction/simulation would be to determine the metabolites that are essential to the organism's proliferation inside of macrophages. If the proliferation cycle is inhibited, then the parasite would not continue to evade the host's immune system. A reconstruction model serves as a first step to deciphering the complicated mechanisms surrounding disease. These models can also look at the minimal genes necessary for a cell to maintain virulence. The next step would be to use the predictions and postulates generated from a reconstruction model and apply it to discover novel biological functions such as drug-engineering and drug delivery techniques.",
            "score": 86.85028076171875
        },
        {
            "docid": "36307309_2",
            "document": "Virtual Physiological Rat . sysThe Virtual Physiological Rat (VPR) Project is an international collaboration aimed simulating the integrated cardiovascular function of the rat and supported by the National Institute of General Medical Sciences as a National Center for Systems Biology. The project is motivated by the fact that, although there exist both a depth of knowledge of basic cardiovascular physiology and a host of physiological and genomic data from animal models of disease, there is a lack of understanding of how multiple genes and environmental factors interact to determine cardiovascular phenotype. The Virtual Physiological Rat Project is focused on developing computational tools to capture the underlying systems physiology as well as the pathophysiological perturbations associated with disease. These tools are being developed and validated based on experimental characterization of physiological function across a number of organ systems in rat strains engineered to show relevant disease phenotypes. Computer simulation is used to integrate disparate data (genomic, anatomic, physiological, etc.) to explain and predict function, and to translate the findings from animal models to yield new information on specific interrelated complex diseases in humans, including hypertension, kidney disease, heart failure, and metabolic syndrome.",
            "score": 86.83953857421875
        },
        {
            "docid": "20374_50",
            "document": "Metabolism . An idea of the complexity of the metabolic networks in cells that contain thousands of different enzymes is given by the figure showing the interactions between just 43 proteins and 40 metabolites to the right: the sequences of genomes provide lists containing anything up to 45,000 genes. However, it is now possible to use this genomic data to reconstruct complete networks of biochemical reactions and produce more holistic mathematical models that may explain and predict their behavior. These models are especially powerful when used to integrate the pathway and metabolite data obtained through classical methods with data on gene expression from proteomic and DNA microarray studies. Using these techniques, a model of human metabolism has now been produced, which will guide future drug discovery and biochemical research. These models are now used in network analysis, to classify human diseases into groups that share common proteins or metabolites.",
            "score": 86.79090881347656
        },
        {
            "docid": "42022633_3",
            "document": "Popgenie . PopGenie is a model organism database (MOD) which brings together the increasingly extensive collection of genetics and genomics data created by the scientific community in a central resource. Such MODs offer a single entry point to the collection of resources available within a model system, typically including tools for exploring and querying those resources. PopGenIE contains an integrated set of tools including genome, synteny and quantitative trait locus (QTL) browsers for exploring genetic data. Expression tools include an electronic fluorescent pictograph (eFP) browser, expression profile plots, co-regulation within collated transcriptomics data sets, and identification of over-represented functional categories and genomic hotspot locations. A number of collated transcriptomics data sets are available in the eFP browser to facilitate functional exploration of gene function. Additional homology and data extraction tools are provided. PopGenIE significantly increases accessibility to \"Populus\" genomics resources and allows exploration of transcriptomics data without the need to learn or understand complex statistical analysis methods.",
            "score": 86.75349426269531
        },
        {
            "docid": "45346_21",
            "document": "Theories of urban planning . The communicative approach to planning is perhaps the most difficult to explain. It focuses on using communication to help different interests in the process understand each other. The idea is that each individual will approach a conversation with his or her own subjective experience in mind and that from that conservation shared goals and possibilities will emerge. Again, participation plays a central role under this model. The model seeks to include as a broad range of voice to enhance the debate and negotiation that is supposed to form the core of actual plan making. In this model, participation is actually fundamental to the planning process happening. Without the involvement of concerned interests there is no planning. Bent Flyvbjerg and Tim Richardson have developed a critique of the communicative approach and an alternative theory based on an understanding of power and how it works in planning. Looking at each of these models it becomes clear that participation is not only shaped by the public in a given area or by the attitude of the planning organization or planners that work for it. In fact, public participation is largely influenced by how planning is defined, how planning problems are defined, the kinds of knowledge that planners choose to employ and how the planning context is set. Though some might argue that is too difficult to involve the public through transactive, advocacy, bargaining and communicative models because transportation is some ways more technical than other fields, it is important to note that transportation is perhaps unique among planning fields in that its systems depend on the interaction of a number of individuals and organizations.",
            "score": 86.35062408447266
        },
        {
            "docid": "129126_11",
            "document": "Antoni K\u0119pi\u0144ski . Information metabolism is a psychological theory of interaction between biological organisms and their environment based on information processing. The most detailed description of information metabolism concept was given by K\u0119pi\u0144ski in his book \"Melancholy\" (1974). In this model, the living organism is considered an open system as understood by von Bertalanffy. Living beings are characterized by ability to increase and maintain their own negentropy - an idea popularized in Schr\u00f6dinger's book \"What is life?\". This ability makes the difference between them and inanimate objects which obey the increase of entropy principle. The body retains the same basic structure, although its building elements (molecules) are replaced quite frequently in anabolic and catabolic processes. The energy derived from food and oxygen is spent on securing the integrity of the organism. To refer to anabolic and catabolic processes in cells K\u0119pi\u0144ski used the term \"energy metabolism\". Any activity of an organism is an informational sign to other beings. Activities in the physical realm are reactions to changes perceived in the external or internal reality of the organism. Bearing that in mind, the psyche can be seen as the information-processing unit. As emhpasized by K\u0119pi\u0144ski, psychological structure of an individual remains relatively stable despite an ongoing exchange of information, analogically to the physical structure subject to energy metabolism. In his books, K\u0119pi\u0144ski explained various mental conditions as disorders and imbalances of the information metabolism in general and its inherent value structure in particular. During his life, K\u0119pi\u0144ski mentioned that his model of information metabolism is not complete. The work upon it was interrupted by his illness and death.",
            "score": 86.2694320678711
        }
    ]
}