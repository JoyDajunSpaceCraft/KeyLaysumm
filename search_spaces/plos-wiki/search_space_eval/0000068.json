{
    "q": [
        {
            "docid": "52085_16",
            "document": "Protein folding . The protein folding phenomenon was largely an experimental endeavor until the formulation of an energy landscape theory of proteins by Joseph Bryngelson and Peter Wolynes in the late 1980s and early 1990s. This approach introduced the \"principle of minimal frustration.\" This principle says that nature has chosen amino acid sequences so that the folded state of the protein is very stable. In addition, the undesired interactions between amino acids along the folding pathway are reduced, making the acquisition of the folded state a very fast process. Even though nature has reduced the level of \"frustration\" in proteins, some degree of it remains up to now as can be observed in the presence of local minima in the energy landscape of proteins.  A consequence of these evolutionarily selected sequences is that proteins are generally thought to have globally \"funneled energy landscapes\" (coined by Jos\u00e9 Onuchic) that are largely directed toward the native state. This \"folding funnel\" landscape allows the protein to fold to the native state through any of a large number of pathways and intermediates, rather than being restricted to a single mechanism. The theory is supported by both computational simulations of model proteins and experimental studies, and it has been used to improve methods for protein structure prediction and design. The description of protein folding by the leveling free-energy landscape is also consistent with the 2nd law of thermodynamics. Physically, thinking of landscapes in terms of visualizable potential or total energy surfaces simply with maxima, saddle points, minima, and funnels, rather like geographic landscapes, is perhaps a little misleading. The relevant description is really a high-dimensional phase space in which manifolds might take a variety of more complicated topological forms.",
            "score": 73.76610946655273
        },
        {
            "docid": "11044599_4",
            "document": "Searching the conformational space for docking . In this approach, proteins are typically held rigid, and the ligand is allowed to freely explore their conformational space. The generated conformations are then docked successively into the protein, and an MD simulation consisting of a simulated annealing protocol is performed. This is usually supplemented with short MD energy minimization steps, and the energies determined from the MD runs are used for ranking the overall scoring. Although this is a computer-expensive method (involving potentially hundreds of MD runs), it has some advantages: for example, no specialized energy/scoring functions are required. MD force-fields can typically be used to find poses that are reasonable and can be compared with experimental structures.",
            "score": 84.26213479042053
        },
        {
            "docid": "413102_21",
            "document": "Folding@home . Drugs function by binding to specific locations on target molecules and causing some desired change, such as disabling a target or causing a conformational change. Ideally, a drug should act very specifically, and bind only to its target without interfering with other biological functions. However, it is difficult to precisely determine where and how tightly two molecules will bind. Due to limits in computing power, current \"in silico\" methods usually must trade speed for accuracy; e.g., use rapid protein docking methods instead of computationally costly free energy calculations. Folding@home's computing performance allows researchers to use both methods, and evaluate their efficiency and reliability. Computer-assisted drug design has the potential to expedite and lower the costs of drug discovery. In 2010, Folding@home used MSMs and free energy calculations to predict the native state of the villin protein to within 1.8 angstrom (\u00c5) root mean square deviation (RMSD) from the crystalline structure experimentally determined through X-ray crystallography. This accuracy has implications to future protein structure prediction methods, including for intrinsically unstructured proteins. Scientists have used Folding@home to research drug resistance by studying vancomycin, an antibiotic drug of last resort, and beta-lactamase, a protein that can break down antibiotics like penicillin.",
            "score": 83.35692536830902
        },
        {
            "docid": "6893544_3",
            "document": "Folding funnel . The folding funnel hypothesis is closely related to the hydrophobic collapse hypothesis, under which the driving force for protein folding is the stabilization associated with the sequestration of hydrophobic amino acid side chains in the interior of the folded protein. This allows the water solvent to maximize its entropy, lowering the total free energy. On the side of the protein, free energy is further lowered by favorable energetic contacts: isolation of electrostatically charged side chains on the solvent-accessible protein surface and neutralization of salt bridges within the protein's core. The molten globule state predicted by the folding funnel theory as an ensemble of folding intermediates thus corresponds to a protein in which hydrophobic collapse has occurred but many native contacts, or close residue-residue interactions represented in the native state, have yet to form.",
            "score": 46.31211018562317
        },
        {
            "docid": "547400_16",
            "document": "Molecular mechanics . Another application of molecular mechanics is energy minimization, whereby the force field is used as an optimization criterion. This method uses an appropriate algorithm (e.g. steepest descent) to find the molecular structure of a local energy minimum. These minima correspond to stable conformers of the molecule (in the chosen force field) and molecular motion can be modelled as vibrations around and interconversions between these stable conformers. It is thus common to find local energy minimization methods combined with global energy optimization, to find the global energy minimum (and other low energy states). At finite temperature, the molecule spends most of its time in these low-lying states, which thus dominate the molecular properties. Global optimization can be accomplished using simulated annealing, the Metropolis algorithm and other Monte Carlo methods, or using different deterministic methods of discrete or continuous optimization. While the force field represents only the enthalpic component of free energy (and only this component is included during energy minimization), it is possible to include the entropic component through the use of additional methods, such as normal mode analysis.",
            "score": 53.34350609779358
        },
        {
            "docid": "306769_38",
            "document": "Protein structure prediction . Accurate packing of the amino acid side chains represents a separate problem in protein structure prediction. Methods that specifically address the problem of predicting side-chain geometry include dead-end elimination and the self-consistent mean field methods. The side chain conformations with low energy are usually determined on the rigid polypeptide backbone and using a set of discrete side chain conformations known as \"rotamers.\" The methods attempt to identify the set of rotamers that minimize the model's overall energy.",
            "score": 67.32577276229858
        },
        {
            "docid": "11044599_6",
            "document": "Searching the conformational space for docking . The most common technique used in many docking programs, shape-complementarity methods focus on the match between the receptor and the ligand in order to find an optimal pose. Programs include DOCK, FRED, GLIDE, SURFLEX, eHiTS and many more. Most methods describe the molecules in terms of a finite number of descriptors that include structural complementarity and binding complementarity. Structural complementarity is mostly a geometric description of the molecules, including solvent-accessible surface area, overall shape and geometric constraints between atoms in the protein and ligand. Binding complementarity takes into account features like hydrogen bonding interactions, hydrophobic contacts and van der Waals interactions to describe how well a particular ligand will bind to the protein. Both kinds of descriptors are conveniently represented in the form of structural templates which are then used to quickly match potential compounds (either from a database or from the user-given inputs) that will bind well at the active site of the protein. Compared to the all-atom molecular dynamics approaches, these methods are very efficient in finding optimal binding poses for the protein and ligand.",
            "score": 96.47671222686768
        },
        {
            "docid": "6893544_2",
            "document": "Folding funnel . The folding funnel hypothesis is a specific version of the energy landscape theory of protein folding, which assumes that a protein's native state corresponds to its free energy minimum under the solution conditions usually encountered in cells. Although energy landscapes may be \"rough\", with many non-native local minima in which partially folded proteins can become trapped, the folding funnel hypothesis assumes that the native state is a deep free energy minimum with steep walls, corresponding to a single well-defined tertiary structure. The term was coined by Jos\u00e9 Onuchic in a 1992 article.",
            "score": 43.92853093147278
        },
        {
            "docid": "7026278_25",
            "document": "Homology modeling . The assessment of homology models' accuracy is straightforward when the experimental structure is known. The most common method of comparing two protein structures uses the root-mean-square deviation (RMSD) metric to measure the mean distance between the corresponding atoms in the two structures after they have been superimposed. However, RMSD does underestimate the accuracy of models in which the core is essentially correctly modeled, but some flexible loop regions are inaccurate. A method introduced for the modeling assessment experiment CASP is known as the global distance test (GDT) and measures the total number of atoms whose distance from the model to the experimental structure lies under a certain distance cutoff. Both methods can be used for any subset of atoms in the structure, but are often applied to only the alpha carbon or protein backbone atoms to minimize the noise created by poorly modeled side chain rotameric states, which most modeling methods are not optimized to predict.",
            "score": 75.54140448570251
        },
        {
            "docid": "11044599_8",
            "document": "Searching the conformational space for docking . Although genetic algorithms are quite successful in sampling the large conformational space, many docking programs require the protein to remain fixed, while allowing only the ligand to flex and adjust to the active site of the protein. Genetic algorithms also require multiple runs to obtain reliable answers regarding ligands that may bind to the protein. The time it takes to typically run a genetic algorithm in order to allow a proper pose may be longer, hence these methods may not be as efficient as shape complementarity-based approaches in screening large databases of compounds. Recent improvements in using grid-based evaluation of energies, limiting the exploration of the conformational changes at only local areas (active sites) of interest, and improved tabling methods have significantly enhanced the performance of genetic algorithms and made them suitable for virtual screening applications.",
            "score": 88.17229580879211
        },
        {
            "docid": "31881102_5",
            "document": "Lead Finder . Extra precise representation of protein-ligand interactions implemented in Lead-Finder scoring function is the second (in addition to docking algorithm) component of successful ligand docking. Lead-Finder scoring function is based on a semi-empiric molecular mechanical functional, which explicitly accounts for different types of molecular interactions. Individual energy contributions are scaled with empiric coefficients to fit particular purposes: accurate binding energy predictions, correct energy-ranking of docked ligand poses, correct rank-ordering of active and inactive compounds during virtual screening experiments. For these reasons three distinct types of scoring functions based on the same set of energy contributions but different sets of energy-scaling coefficients are used by Lead-Finder.",
            "score": 58.201579332351685
        },
        {
            "docid": "14149235_4",
            "document": "Energy profile (chemistry) . In simplest terms, a potential energy surface or PES is a mathematical or graphical representation of the relation between energy of a molecule and its geometry. The methods for describing the potential energy are broken down into a classical mechanics interpretation (molecular mechanics) and a quantum mechanical interpretation. In the quantum mechanical interpretation an exact expression for energy can be obtained for any molecule derived from quantum principles (although an infinite basis set may be required) but ab initio calculations/methods will often use approximations to reduce computational cost. Molecular mechanics is empirically based and potential energy is described as a function of component terms that correspond to individual potential functions such as torsion, stretches,bends, Van der Waals energies,electrostatics and cross terms. Each component potential function is fit to experimental data or properties predicted by ab initio calculations. Molecular mechanics is useful in predicting equilibrium geometries and transition states as well as relative conformational stability. As a reaction occurs the atoms of the molecules involved will generally undergo some change in spatial orientation through internal motion as well as its electronic environment. Distortions in the geometric parameters result in a deviation from the equilibrium geometry (local energy minima). These changes in geometry of a molecule or interactions between molecules are dynamic processes which call for understanding all the forces operating within the system. Since these forces can be mathematically derived as first derivative of potential energy with respect to a displacement, it makes sense to map the potential energy E of the system as a function of geometric parameters q, q, q and so on. The potential energy at given values of the geometric parameters (q, q,\u2026, q) is represented as a hyper-surface (when n >2 or a surface when n \u2264 2). Mathematically, it can be written as-",
            "score": 49.30990433692932
        },
        {
            "docid": "3255539_23",
            "document": "Rosetta@home . In October 2006, RosettaDock was integrated into Rosetta@home. The method used a fast, crude docking model phase using only the protein backbone. This was followed by a slow full-atom refinement phase in which the orientation of the two interacting proteins relative to each other, and side-chain interactions at the protein\u2013protein interface, were simultaneously optimized to find the lowest energy conformation. The vastly increased computing power afforded by the Rosetta@home network, combined with revised \"fold-tree\" representations for backbone flexibility and loop modeling, made RosettaDock sixth out of 63 prediction groups in the third CAPRI assessment.",
            "score": 91.92366027832031
        },
        {
            "docid": "11044649_11",
            "document": "Scoring functions for docking . A perfect scoring function would be able to predict the binding free energy between the ligand and its target. But in reality both the computational methods and the computational resources put restraints to this goal. So most often methods are selected that minimize the number of false positive and false negative ligands. In cases where an experimental training set of data of binding constants and structures are available a simple method has been developed to refine the scoring function used in molecular docking.",
            "score": 60.53407406806946
        },
        {
            "docid": "2292623_8",
            "document": "Docking (molecular) . Geometric matching/ shape complementarity methods describe the protein and ligand as a set of features that make them dockable. These features may include molecular surface / complementary surface descriptors. In this case, the receptor\u2019s molecular surface is described in terms of its solvent-accessible surface area and the ligand\u2019s molecular surface is described in terms of its matching surface description. The complementarity between the two surfaces amounts to the shape matching description that may help finding the complementary pose of docking the target and the ligand molecules. Another approach is to describe the hydrophobic features of the protein using turns in the main-chain atoms. Yet another approach is to use a Fourier shape descriptor technique. Whereas the shape complementarity based approaches are typically fast and robust, they cannot usually model the movements or dynamic changes in the ligand/ protein conformations accurately, although recent developments allow these methods to investigate ligand flexibility. Shape complementarity methods can quickly scan through several thousand ligands in a matter of seconds and actually figure out whether they can bind at the protein\u2019s active site, and are usually scalable to even protein-protein interactions. They are also much more amenable to pharmacophore based approaches, since they use geometric descriptions of the ligands to find optimal binding.",
            "score": 85.54718816280365
        },
        {
            "docid": "216104_14",
            "document": "Protein engineering . These methods involve free modeling without using any structural information about the template. \"Ab initio\" methods are aimed at prediction of the native structures of proteins corresponding to the global minimum of its free energy. some examples of \"ab initio\" methods are AMBER, GROMOS, GROMACS, CHARMM, OPLS, and ENCEPP12. General steps for \"ab initio\" methods begin with the geometric representation of the protein of interest. Next, a potential energy function model for the protein is developed. This model can be created using either molecular mechanics potentials or protein structure derived potential functions. Following the development of a potential model, energy search techniques including molecular dynamic simulations, Monte Carlo simulations and genetic algorithms are applied to the protein.",
            "score": 87.42034864425659
        },
        {
            "docid": "10130725_28",
            "document": "Protein domain . Advances in experimental and theoretical studies have shown that folding can be viewed in terms of energy landscapes, where folding kinetics is considered as a progressive organisation of an ensemble of partially folded structures through which a protein passes on its way to the folded structure. This has been described in terms of a folding funnel, in which an unfolded protein has a large number of conformational states available and there are fewer states available to the folded protein. A funnel implies that for protein folding there is a decrease in energy and loss of entropy with increasing tertiary structure formation. The local roughness of the funnel reflects kinetic traps, corresponding to the accumulation of misfolded intermediates. A folding chain progresses toward lower intra-chain free-energies by increasing its compactness. The chain's conformational options become increasingly narrowed ultimately toward one native structure.",
            "score": 68.89265751838684
        },
        {
            "docid": "31881102_3",
            "document": "Lead Finder . Lead-Finder software is an integrated solution for simulating structure and binding affinity of protein-ligand complexes. The software combines automatic processing of protein structures, extra precision protein-ligand docking and calculation of free energy of ligand binding. Original docking algorithm provides a fast rate of calculations, which can be easily adjusted from more rapid (for virtual screening applications) to slightly more slow and robust, while unique scoring function implemented in Lead-Finder provides unsurpassed accuracy of calculations.  Lead-Finder is intended to meet the requirements of computational and medicinal chemists involved in drug discovery, pharmacologists and toxicologists involved in the evaluation of ADMET properties in silico, and biochemists and enzymologists working on modeling protein-ligand interactions, enzyme specificity and rational enzyme design. Efficiency of ligand docking and binding energy estimations achieved by Lead-Finder are due to docking algorithm and extra precision representation of protein-ligand interactions.",
            "score": 100.90541982650757
        },
        {
            "docid": "3255539_5",
            "document": "Rosetta@home . The Rosetta@home application and the BOINC distributed computing platform are available for the operating systems Windows, Linux, and macOS; BOINC also runs on several others, e.g., FreeBSD. Participation in Rosetta@home requires a central processing unit (CPU) with a clock speed of at least 500\u00a0MHz, 200\u00a0megabytes of free disk space, 512\u00a0megabytes of physical memory, and Internet connectivity. As of July 20, 2016, the current version of the Rosetta Mini application is 3.73. The current recommended BOINC program version is 7.6.22. Standard Hypertext Transfer Protocol (HTTP) (port 80) is used for communication between the user's BOINC client and the Rosetta@home servers at the University of Washington; HTTPS (port 443) is used during password exchange. Remote and local control of the BOINC client use port 31416 and port 1043, which might need to be specifically unblocked if they are behind a firewall. Workunits containing data on individual proteins are distributed from servers located in the Baker lab at the University of Washington to volunteers' computers, which then calculate a structure prediction for the assigned protein. To avoid duplicate structure predictions on a given protein, each workunit is initialized with a random seed number. This gives each prediction a unique trajectory of descent along the protein's energy landscape. Protein structure predictions from Rosetta@home are approximations of a global minimum in a given protein's energy landscape. That global minimum represents the most energetically favorable conformation of the protein, i.e., its native state. A primary feature of the Rosetta@home graphical user interface (GUI) is a screensaver which shows a current workunit's progress during the simulated protein folding process. In the upper-left of the current screensaver, the target protein is shown adopting different shapes (conformations) in its search for the lowest energy structure. Depicted immediately to the right is the structure of the most recently accepted. On the upper right the lowest energy conformation of the current decoy is shown; below that is the true, or native, structure of the protein if it has already been determined. Three graphs are included in the screensaver. Near the middle, a graph for the accepted model's thermodynamic free energy is displayed, which fluctuates as the accepted model changes. A graph of the accepted model's root-mean-square deviation (RMSD), which measures how structurally similar the accepted model is to the native model, is shown far right. On the right of the accepted energy graph and below the RMSD graph, the results from these two functions are used to produce an energy vs. RMSD plot as the model is progressively refined.",
            "score": 81.50424194335938
        },
        {
            "docid": "16706608_18",
            "document": "Phase field models . The choice of free energy function, formula_13, can have a significant effect on the physical behaviour of the interface, and should be selected with care. The double-well function represents an approximation of the Van der Waals EOS near the critical point, and has historically been used for its simplicity of implementation when the phase field model is employed solely for interface tracking purposes. However, this has led to the frequently observed spontaneous drop shrinkage phenomenon, whereby the high phase miscibility predicted by an Equation of State near the critical point allows significant interpenetration of the phases and can eventually lead to the complete disappearance of a droplet whose radius is below some critical value. Minimizing perceived continuity losses over the duration of a simulation requires limits on the Mobility parameter, resulting in a delicate balance between interfacial smearing due to convection, interfacial reconstruction due to free energy minimization (i.e. mobility-based diffusion), and phase interpenetration, also dependent on the mobility. A recent review of alternative energy density functions for interface tracking applications has proposed a modified form of the double-obstacle function which avoids the spontaneous drop shrinkage phenomena and limits on mobility, with comparative results provide for a number of benchmark simulations using the double-well function and the VOF sharp interface technique. The proposed implementation has a computational complexity only slightly greater than that of the double-well function, and may prove useful for interface tracking applications of the phase field model where the duration/nature of the simulated phenomena introduces phase continuity concerns (i.e. small droplets, extended simulations, multiple interfaces, etc.).",
            "score": 31.89310908317566
        },
        {
            "docid": "7026278_22",
            "document": "Homology modeling . Physics-based energy calculations aim to capture the interatomic interactions that are physically responsible for protein stability in solution, especially van der Waals and electrostatic interactions. These calculations are performed using a molecular mechanics force field; proteins are normally too large even for semi-empirical quantum mechanics-based calculations. The use of these methods is based on the energy landscape hypothesis of protein folding, which predicts that a protein's native state is also its energy minimum. Such methods usually employ implicit solvation, which provides a continuous approximation of a solvent bath for a single protein molecule without necessitating the explicit representation of individual solvent molecules. A force field specifically constructed for model assessment is known as the Effective Force Field (EFF) and is based on atomic parameters from CHARMM.",
            "score": 75.24732232093811
        },
        {
            "docid": "31881102_4",
            "document": "Lead Finder . From mathematical point of view ligand docking represents a search for global minimum on the multidimensional surface describing the free energy of protein-ligand binding. With ligands having up to 15-20 degrees of freedom (freely rotatable bonds) and complex nature of energy surface, global optimum search represents generally unsolved scientific task. To tackle this computationally challenging problem Lead-Finder applies unique approach combining genetic algorithm search, local optimization procedures, and a smart exploitation of the knowledge generated during the search run. Rational combination of different optimization strategies makes Lead Finder efficient in terms of coarse sampling of ligand's phase space and refinement of promising solutions.",
            "score": 55.28588390350342
        },
        {
            "docid": "11044599_7",
            "document": "Searching the conformational space for docking . Two of the most used docking programs belong to this class: GOLD and AutoDock. Genetic algorithms allow the exploration of a large conformational space \u2013 which is basically spanned by the protein and ligand jointly in this case \u2013 by representing each spatial arrangement of the pair as a \u201cgene\u201d with a particular energy. The entire genome thus represents the complete energy landscape which is to be explored. The simulation of the evolution of the genome is carried out by cross-over techniques similar to biological evolution, where random pairs of individuals (conformations) are \u201cmated\u201d with the possibility for a random mutation in the offspring. These methods have proven very useful in sampling the vast state-space while maintaining closeness to the actual process involved.",
            "score": 73.42817449569702
        },
        {
            "docid": "13967547_5",
            "document": "Dry lab . As a means of surpassing the limitations of these techniques, projects such as Folding@home and Rosetta@home are aimed at resolving this problem using computational analysis, this means of resolving protein structure is referred to as protein structure prediction. Although many labs have a slightly different approach, the main concept is to find, from a myriad of protein conformations, which conformation has the lowest energy or, in the case of Folding@Home, to find relatively low energies of proteins that could cause the protein to misfold and aggregate other proteins to itself\u2014like in the case of sickle cell anemia. The general scheme in these projects is that a small number of computations are parsed to, or sent to be calculated on, a computer, generally a home computer, and then that computer analyzes the likelihood that a specific protein will take a certain shape or conformation based on the amount of energy required for that protein to stay in that shape, this way of processing data is what is generally referred to as distributed computing. This analysis is done on an extraordinarily large number of different conformations, owing to the support of hundreds of thousands of home-based computers, in hopes to find the conformation of lowest possible energy or set of conformations of lowest possible energy relative to any conformations that are just slightly different. Although doing so is quite difficult, one can, by observing the energy distribution of a large number of conformations, despite the almost infinite number of different protein conformations possible for any given protein (see Levinthal Paradox), with a reasonably large number of protein energy samplings, predict relatively closely what conformation, within a range of conformations, has the expected lowest energy using methods in statistical inference. There are other factors such as salt concentration, pH, ambient temperature or chaperonins, which are proteins that assist in the folding process of other proteins, that can greatly affect how a protein folds. However, if the given protein is shown to fold on its own, especially in vitro, these findings can be further supported. Once we can see how a protein folds then we can see how it works as a catalyst, or in intracellular communication, e.g. neuroreceptor-neurotransmitter interaction. How certain compounds may be used to enhance or prevent the function of these proteins and how an elucidated protein overall plays a role in diseases such as Alzheimer's Disease or Huntington's Disease can also be much better understood.",
            "score": 97.6320686340332
        },
        {
            "docid": "7479239_3",
            "document": "Implicit solvation . The implicit solvation model is justified in liquids, where the potential of mean force can be applied to approximate the averaged behavior of many highly dynamic solvent molecules. However, the interfaces and the interiors of biological membranes or proteins can also be considered as media with specific solvation or dielectric properties. These media are not necessarily uniform, since their properties can be described by different analytical functions, such as \u201cpolarity profiles\u201d of lipid bilayers. There are two basic types of implicit solvent methods: models based on accessible surface areas (ASA) that were historically the first, and more recent continuum electrostatics models, although various modifications and combinations of the different methods are possible.  The accessible surface area (ASA) method is based on experimental linear relations between Gibbs free energy of transfer and the surface area of a solute molecule. This method operates directly with free energy of solvation, unlike molecular mechanics or electrostatic methods that include only the enthalpic component of free energy. The continuum representation of solvent also significantly improves the computational speed and reduces errors in statistical averaging that arise from incomplete sampling of solvent conformations, so that the energy landscapes obtained with implicit and explicit solvent are different. Although the implicit solvent model is useful for simulations of biomolecules, this is an approximate method with certain limitations and problems related to parameterization and treatment of ionization effects.",
            "score": 66.09316337108612
        },
        {
            "docid": "413102_6",
            "document": "Folding@home . Due to the complexity of proteins' conformation or configuration space (the set of possible shapes a protein can take), and limits in computing power, all-atom molecular dynamics simulations have been severely limited in the timescales which they can study. While most proteins typically fold in the order of milliseconds, before 2010 simulations could only reach nanosecond to microsecond timescales. General-purpose supercomputers have been used to simulate protein folding, but such systems are intrinsically costly and typically shared among many research groups. Further, because the computations in kinetic models occur serially, strong scaling of traditional molecular simulations to these architectures is exceptionally difficult. Moreover, as protein folding is a stochastic process and can statistically vary over time, it is challenging computationally to use long simulations for comprehensive views of the folding process. Protein folding does not occur in one step. Instead, proteins spend most of their folding time, nearly 96% in some cases, \"waiting\" in various intermediate conformational states, each a local thermodynamic free energy minimum in the protein's energy landscape. Through a process known as adaptive sampling, these conformations are used by Folding@home as starting points for a set of simulation trajectories. As the simulations discover more conformations, the trajectories are restarted from them, and a Markov state model (MSM) is gradually created from this cyclic process. MSMs are discrete-time master equation models which describe a biomolecule's conformational and energy landscape as a set of distinct structures and the short transitions between them. The adaptive sampling Markov state model method significantly increases the efficiency of simulation as it avoids computation inside the local energy minimum itself, and is amenable to distributed computing (including on GPUGRID) as it allows for the statistical aggregation of short, independent simulation trajectories. The amount of time it takes to construct a Markov state model is inversely proportional to the number of parallel simulations run, i.e., the number of processors available. In other words, it achieves linear parallelization, leading to an approximately four orders of magnitude reduction in overall serial calculation time. A completed MSM may contain tens of thousands of sample states from the protein's phase space (all the conformations a protein can take on) and the transitions between them. The model illustrates folding events and pathways (i.e., routes) and researchers can later use kinetic clustering to view a coarse-grained representation of the otherwise highly detailed model. They can use these MSMs to reveal how proteins misfold and to quantitatively compare simulations with experiments.",
            "score": 90.46015334129333
        },
        {
            "docid": "5310739_5",
            "document": "Dead-end elimination . Dead-end elimination has been used effectively to predict the structure of side chains on a given protein backbone structure by minimizing an energy function formula_1. The dihedral angle search space of the side chains is restricted to a discrete set of rotamers for each amino acid position in the protein (which is, obviously, of fixed length). The original DEE description included criteria for the elimination of single rotamers and of rotamer pairs, although this can be expanded. In the following discussion, let formula_2 be the length of the protein and let formula_3 represent the rotamer of the formula_4 side chain. Since atoms in proteins are assumed to interact only by two-body potentials, the energy may be written",
            "score": 60.33199381828308
        },
        {
            "docid": "2292623_6",
            "document": "Docking (molecular) . Molecular docking research focusses on computationally simulating the molecular recognition process. It aims to achieve an optimized conformation for both the protein and ligand and relative orientation between protein and ligand such that the free energy of the overall system is minimized.",
            "score": 55.30556917190552
        },
        {
            "docid": "4566642_3",
            "document": "Energy landscape . The term is useful when examining protein folding; while a protein can theoretically exist in a nearly infinite number of conformations along its energy landscape, in reality proteins fold (or \"relax\") into secondary and tertiary structures that possess the lowest possible free energy. The key concept in the energy landscape approach to protein folding is the \"folding funnel\" hypothesis.",
            "score": 51.216874837875366
        },
        {
            "docid": "9378673_12",
            "document": "De novo protein structure prediction . De novo programs will search three dimensional space and, in the process, produce candidate protein conformations. As a protein approaches its correctly folded, native state, entropy and free energy will decrease. Using this information, de novo predictors can discriminate amongst decoys. Specifically, de novo programs will select possible confirmations with lower free energies \u2013 which are more likely to be correct than those structures with higher free energies. As stated by David A. Baker in regards to how his de novo Rosetta predictor works, \u201cduring folding, each local segment of the chain flickers between a different subset of local conformations\u2026folding to the native structure occurs when the conformations adopted by the local segments and their relative orientations allow\u2026low energy features of native protein structures. In the Rosetta algorithm\u2026the program then searches for the combination of these local conformations that has the lowest overall energy.\u201d",
            "score": 70.64306282997131
        },
        {
            "docid": "32002467_21",
            "document": "Protein adsorption . Water has as much propensity to form hydrogen bonds as any group in a polypeptide. During a folding and association process, peptide and amino acid groups exchange hydrogen bonds with water. Thus, hydrogen bonding does not have a strong stabilizing effect on protein adsorption in an aqueous medium. Hydrophobic interactions are essentially entropic interactions basically due to order/disorder phenomena in an aqueous medium. The free energy associated with minimizing interfacial areas is responsible for minimizing the surface area of water droplets and air bubbles in water. This same principle is the reason that hydrophobic amino acid side chains are oriented away from water, minimizing their interaction with water. The hydrophilic groups on the outside of the molecule result in protein water solubility. Characterizing this phenomenon can be done by treating these hydrophobic relationships with interfacial free energy concepts. Accordingly, one can think of the driving force of these interactions as the minimization of total interfacial free energy, i.e. minimization of surface area. Charge-transfer interactions are also important in protein stabilization and surface interaction. In general donor-acceptor processes, one can think of excess electron density being present which can be donated to an electrophilic species. In aqueous media, these solute interactions are primarily due to pi orbital electron effects.",
            "score": 53.29391837120056
        },
        {
            "docid": "43677277_10",
            "document": "Mean field particle methods . In computational physics and more specifically in quantum mechanics, the ground state energies of quantum systems is associated with the top of the spectrum of Schr\u00f6dinger's operators. The Schr\u00f6dinger equation is the quantum mechanics version of the Newton's second law of motion of classical mechanics (the mass times the acceleration is the sum of the forces). This equation represents the wave function (a.k.a. the quantum state) evolution of some physical system, including molecular, atomic of subatomic systems, as well as macroscopic systems like the universe. The solution of the imaginary time Schr\u00f6dinger equation (a.k.a. the heat equation) is given by a Feynman-Kac distribution associated with a free evolution Markov process (often represented by Brownian motions) in the set of electronic or macromolecular configurations and some potential energy function. The long time behavior of these nonlinear semigroups is related to top eigenvalues and ground state energies of Schr\u00f6dinger's operators. The genetic type mean field interpretation of these Feynman-Kac models are termed Resample Monte Carlo, or Diffusion Monte Carlo methods. These branching type evolutionary algorithms are based on mutation and selection transitions. During the mutation transition, the walkers evolve randomly and independently in a potential energy landscape on particle configurations. The mean field selection process (a.k.a. quantum teleportation, population reconfiguration, resampled transition) is associated with a fitness function that reflects the particle absorption in an energy well. Configurations with low relative energy are more likely to duplicate. In molecular chemistry, and statistical physics Mean field particle methods are also used to sample Boltzmann-Gibbs measures associated with some cooling schedule, and to compute their normalizing constants (a.k.a. free energies, or partition functions).",
            "score": 36.92222189903259
        }
    ],
    "r": [
        {
            "docid": "4350008_2",
            "document": "Protein\u2013protein interaction prediction . Protein\u2013protein interaction prediction is a field combining bioinformatics and structural biology in an attempt to identify and catalog physical interactions between pairs or groups of proteins. Understanding protein\u2013protein interactions is important for the investigation of intracellular signaling pathways, modelling of protein complex structures and for gaining insights into various biochemical processes. Experimentally, physical interactions between pairs of proteins can be inferred from a variety of experimental techniques, including yeast two-hybrid systems, protein-fragment complementation assays (PCA), affinity purification/mass spectrometry, protein microarrays, fluorescence resonance energy transfer (FRET), and Microscale Thermophoresis (MST). Efforts to experimentally determine the interactome of numerous species are ongoing, and a number of computational methods for interaction prediction have been developed in recent years.",
            "score": 103.64025115966797
        },
        {
            "docid": "31881102_3",
            "document": "Lead Finder . Lead-Finder software is an integrated solution for simulating structure and binding affinity of protein-ligand complexes. The software combines automatic processing of protein structures, extra precision protein-ligand docking and calculation of free energy of ligand binding. Original docking algorithm provides a fast rate of calculations, which can be easily adjusted from more rapid (for virtual screening applications) to slightly more slow and robust, while unique scoring function implemented in Lead-Finder provides unsurpassed accuracy of calculations.  Lead-Finder is intended to meet the requirements of computational and medicinal chemists involved in drug discovery, pharmacologists and toxicologists involved in the evaluation of ADMET properties in silico, and biochemists and enzymologists working on modeling protein-ligand interactions, enzyme specificity and rational enzyme design. Efficiency of ligand docking and binding energy estimations achieved by Lead-Finder are due to docking algorithm and extra precision representation of protein-ligand interactions.",
            "score": 100.9054183959961
        },
        {
            "docid": "2916615_19",
            "document": "Force field (chemistry) . Another round of criticism came from practical applications, such as protein structure refinement. It was noted that \"Critical Assessment of protein Structure Prediction\" (CASP) participants did not try to refine their models to avoid \"\"a central embarrassment of molecular mechanics, namely that energy minimization or molecular dynamics generally leads to a model that is less like the experimental structure\"\". The force fields have been applied successfully for protein structure refinement in different X-ray crystallography and NMR spectroscopy applications, especially using program XPLOR. However, such refinement is driven mainly by a set of experimental constraints, whereas the interatomic potentials serve merely to remove interatomic hindrances. The results of calculations are practically the same with rigid sphere potentials implemented in program DYANA (calculations from NMR data), or with programs for crystallographic refinement that do not use any energy functions. The deficiencies of the interatomic potentials remain a major bottleneck in homology modeling of proteins. Such situation gave rise to development of alternative empirical scoring functions specifically for ligand docking, protein folding, homology model refinement, computational protein design, and modeling of proteins in membranes.",
            "score": 99.47463989257812
        },
        {
            "docid": "4350008_8",
            "document": "Protein\u2013protein interaction prediction . This group of methods makes use of known protein complex structures to predict and structurally model interactions between query protein sequences. The prediction process generally starts by employing a sequence based method (e.g. Interolog) to search for protein complex structures that are homologous to the query sequences. These known complex structures are then used as templates to structurally model the interaction between query sequences. This method has the advantage of not only inferring protein interactions but also suggests models of how proteins interact structurally, which can provide some insights into the atomic level mechanism of that interaction. On the other hand, the ability for these methods to make a prediction is constrained by a limited number of known protein complex structures.",
            "score": 98.70536804199219
        },
        {
            "docid": "13967547_5",
            "document": "Dry lab . As a means of surpassing the limitations of these techniques, projects such as Folding@home and Rosetta@home are aimed at resolving this problem using computational analysis, this means of resolving protein structure is referred to as protein structure prediction. Although many labs have a slightly different approach, the main concept is to find, from a myriad of protein conformations, which conformation has the lowest energy or, in the case of Folding@Home, to find relatively low energies of proteins that could cause the protein to misfold and aggregate other proteins to itself\u2014like in the case of sickle cell anemia. The general scheme in these projects is that a small number of computations are parsed to, or sent to be calculated on, a computer, generally a home computer, and then that computer analyzes the likelihood that a specific protein will take a certain shape or conformation based on the amount of energy required for that protein to stay in that shape, this way of processing data is what is generally referred to as distributed computing. This analysis is done on an extraordinarily large number of different conformations, owing to the support of hundreds of thousands of home-based computers, in hopes to find the conformation of lowest possible energy or set of conformations of lowest possible energy relative to any conformations that are just slightly different. Although doing so is quite difficult, one can, by observing the energy distribution of a large number of conformations, despite the almost infinite number of different protein conformations possible for any given protein (see Levinthal Paradox), with a reasonably large number of protein energy samplings, predict relatively closely what conformation, within a range of conformations, has the expected lowest energy using methods in statistical inference. There are other factors such as salt concentration, pH, ambient temperature or chaperonins, which are proteins that assist in the folding process of other proteins, that can greatly affect how a protein folds. However, if the given protein is shown to fold on its own, especially in vitro, these findings can be further supported. Once we can see how a protein folds then we can see how it works as a catalyst, or in intracellular communication, e.g. neuroreceptor-neurotransmitter interaction. How certain compounds may be used to enhance or prevent the function of these proteins and how an elucidated protein overall plays a role in diseases such as Alzheimer's Disease or Huntington's Disease can also be much better understood.",
            "score": 97.63206481933594
        },
        {
            "docid": "11044599_6",
            "document": "Searching the conformational space for docking . The most common technique used in many docking programs, shape-complementarity methods focus on the match between the receptor and the ligand in order to find an optimal pose. Programs include DOCK, FRED, GLIDE, SURFLEX, eHiTS and many more. Most methods describe the molecules in terms of a finite number of descriptors that include structural complementarity and binding complementarity. Structural complementarity is mostly a geometric description of the molecules, including solvent-accessible surface area, overall shape and geometric constraints between atoms in the protein and ligand. Binding complementarity takes into account features like hydrogen bonding interactions, hydrophobic contacts and van der Waals interactions to describe how well a particular ligand will bind to the protein. Both kinds of descriptors are conveniently represented in the form of structural templates which are then used to quickly match potential compounds (either from a database or from the user-given inputs) that will bind well at the active site of the protein. Compared to the all-atom molecular dynamics approaches, these methods are very efficient in finding optimal binding poses for the protein and ligand.",
            "score": 96.47671508789062
        },
        {
            "docid": "55172_54",
            "document": "Proteomics . A number of emerging concepts have the potential to improve current features of proteomics. Obtaining absolute quantification of proteins and monitoring post-translational modifications are the two tasks that impact the understanding of protein function in healthy and diseased cells. For many cellular events, the protein concentrations do not change; rather, their function is modulated by post-translational modifications (PTM). Methods of monitoring PTM are an underdeveloped area in proteomics. Selecting a particular subset of protein for analysis substantially reduces protein complexity, making it advantageous for diagnostic purposes where blood is the starting material. Another important aspect of proteomics, yet not addressed, is that proteomics methods should focus on studying proteins in the context of the environment. The increasing use of chemical cross linkers, introduced into living cells to fix protein-protein, protein-DNA and other interactions, may ameliorate this problem partially. The challenge is to identify suitable methods of preserving relevant interactions. Another goal for studying protein is to develop more sophisticated methods to image proteins and other molecules in living cells and real time.",
            "score": 96.0002212524414
        },
        {
            "docid": "7026278_33",
            "document": "Homology modeling . Uses of the structural models include protein\u2013protein interaction prediction, protein\u2013protein docking, molecular docking, and functional annotation of genes identified in an organism's genome. Even low-accuracy homology models can be useful for these purposes, because their inaccuracies tend to be located in the loops on the protein surface, which are normally more variable even between closely related proteins. The functional regions of the protein, especially its active site, tend to be more highly conserved and thus more accurately modeled.",
            "score": 95.21491241455078
        },
        {
            "docid": "9378673_6",
            "document": "De novo protein structure prediction . A general paradigm for \"de novo\" prediction involves sampling conformation space, guided by scoring functions and other sequence-dependent biases such that a large set of candidate (\u201cdecoy\") structures are generated. Native-like conformations are then selected from these decoys using scoring functions as well as conformer clustering. High-resolution refinement is sometimes used as a final step to fine-tune native-like structures. There are two major classes of scoring functions. Physics-based functions are based on mathematical models describing aspects of the known physics of molecular interaction. Knowledge-based functions are formed with statistical models capturing aspects of the properties of native protein conformations.",
            "score": 94.06533813476562
        },
        {
            "docid": "306769_32",
            "document": "Protein structure prediction . \"Ab initio\"- or \"de novo\"- protein modelling methods seek to build three-dimensional protein models \"from scratch\", i.e., based on physical principles rather than (directly) on previously solved structures. There are many possible procedures that either attempt to mimic protein folding or apply some stochastic method to search possible solutions (i.e., global optimization of a suitable energy function). These procedures tend to require vast computational resources, and have thus only been carried out for tiny proteins. To predict protein structure \"de novo\" for larger proteins will require better algorithms and larger computational resources like those afforded by either powerful supercomputers (such as Blue Gene or MDGRAPE-3) or distributed computing (such as Folding@home, the Human Proteome Folding Project and Rosetta@Home). Although these computational barriers are vast, the potential benefits of structural genomics (by predicted or experimental methods) make \"ab initio\" structure prediction an active research field.",
            "score": 92.98018646240234
        },
        {
            "docid": "3255539_23",
            "document": "Rosetta@home . In October 2006, RosettaDock was integrated into Rosetta@home. The method used a fast, crude docking model phase using only the protein backbone. This was followed by a slow full-atom refinement phase in which the orientation of the two interacting proteins relative to each other, and side-chain interactions at the protein\u2013protein interface, were simultaneously optimized to find the lowest energy conformation. The vastly increased computing power afforded by the Rosetta@home network, combined with revised \"fold-tree\" representations for backbone flexibility and loop modeling, made RosettaDock sixth out of 63 prediction groups in the third CAPRI assessment.",
            "score": 91.92366027832031
        },
        {
            "docid": "55172_50",
            "document": "Proteomics . The biomolecular structure forms the 3D configuration of the protein. Understanding the protein's structure aids in identification of the protein's interactions and function. It used to be that the 3D structure of proteins could only be determined using X-ray crystallography and NMR spectroscopy. As of 2017, Cryo-electron microscopy is a leading technique, solving difficulties with crystallization (in X-ray crystallography) and conformational ambiguity (in NMR); resolution was 2.2\u00c5 as of 2015. Now, through bioinformatics, there are computer programs that can in some cases predict and model the structure of proteins. These programs use the chemical properties of amino acids and structural properties of known proteins to predict the 3D model of sample proteins. This also allows scientists to model protein interactions on a larger scale. In addition, biomedical engineers are developing methods to factor in the flexibility of protein structures to make comparisons and predictions.",
            "score": 90.53177642822266
        },
        {
            "docid": "413102_6",
            "document": "Folding@home . Due to the complexity of proteins' conformation or configuration space (the set of possible shapes a protein can take), and limits in computing power, all-atom molecular dynamics simulations have been severely limited in the timescales which they can study. While most proteins typically fold in the order of milliseconds, before 2010 simulations could only reach nanosecond to microsecond timescales. General-purpose supercomputers have been used to simulate protein folding, but such systems are intrinsically costly and typically shared among many research groups. Further, because the computations in kinetic models occur serially, strong scaling of traditional molecular simulations to these architectures is exceptionally difficult. Moreover, as protein folding is a stochastic process and can statistically vary over time, it is challenging computationally to use long simulations for comprehensive views of the folding process. Protein folding does not occur in one step. Instead, proteins spend most of their folding time, nearly 96% in some cases, \"waiting\" in various intermediate conformational states, each a local thermodynamic free energy minimum in the protein's energy landscape. Through a process known as adaptive sampling, these conformations are used by Folding@home as starting points for a set of simulation trajectories. As the simulations discover more conformations, the trajectories are restarted from them, and a Markov state model (MSM) is gradually created from this cyclic process. MSMs are discrete-time master equation models which describe a biomolecule's conformational and energy landscape as a set of distinct structures and the short transitions between them. The adaptive sampling Markov state model method significantly increases the efficiency of simulation as it avoids computation inside the local energy minimum itself, and is amenable to distributed computing (including on GPUGRID) as it allows for the statistical aggregation of short, independent simulation trajectories. The amount of time it takes to construct a Markov state model is inversely proportional to the number of parallel simulations run, i.e., the number of processors available. In other words, it achieves linear parallelization, leading to an approximately four orders of magnitude reduction in overall serial calculation time. A completed MSM may contain tens of thousands of sample states from the protein's phase space (all the conformations a protein can take on) and the transitions between them. The model illustrates folding events and pathways (i.e., routes) and researchers can later use kinetic clustering to view a coarse-grained representation of the otherwise highly detailed model. They can use these MSMs to reveal how proteins misfold and to quantitatively compare simulations with experiments.",
            "score": 90.46015167236328
        },
        {
            "docid": "23634_47",
            "document": "Protein . Complementary to the field of structural genomics, \"protein structure prediction\" develops efficient mathematical models of proteins to computationally predict the molecular formations in theory, instead of detecting structures with laboratory observation. The most successful type of structure prediction, known as homology modeling, relies on the existence of a \"template\" structure with sequence similarity to the protein being modeled; structural genomics' goal is to provide sufficient representation in solved structures to model most of those that remain. Although producing accurate models remains a challenge when only distantly related template structures are available, it has been suggested that sequence alignment is the bottleneck in this process, as quite accurate models can be produced if a \"perfect\" sequence alignment is known. Many structure prediction methods have served to inform the emerging field of protein engineering, in which novel protein folds have already been designed. A more complex computational problem is the prediction of intermolecular interactions, such as in molecular docking and protein\u2013protein interaction prediction.",
            "score": 90.14612579345703
        },
        {
            "docid": "413102_5",
            "document": "Folding@home . Proteins are an essential component to many biological functions and participate in virtually all processes within biological cells. They often act as enzymes, performing biochemical reactions including cell signaling, molecular transportation, and cellular regulation. As structural elements, some proteins act as a type of skeleton for cells, and as antibodies, while other proteins participate in the immune system. Before a protein can take on these roles, it must fold into a functional three-dimensional structure, a process that often occurs spontaneously and is dependent on interactions within its amino acid sequence and interactions of the amino acids with their surroundings. Protein folding is driven by the search to find the most energetically favorable conformation of the protein, i.e., its native state. Thus, understanding protein folding is critical to understanding what a protein does and how it works, and is considered a \"holy grail\" of computational biology. Despite folding occurring within a crowded cellular environment, it typically proceeds smoothly. However, due to a protein's chemical properties or other factors, proteins may misfold, that is, fold down the wrong pathway and end up misshapen. Unless cellular mechanisms can destroy or refold misfolded proteins, they can subsequently aggregate and cause a variety of debilitating diseases. Laboratory experiments studying these processes can be limited in scope and atomic detail, leading scientists to use physics-based computing models that, when complementing experiments, seek to provide a more complete picture of protein folding, misfolding, and aggregation.",
            "score": 90.06771087646484
        },
        {
            "docid": "46581687_2",
            "document": "Pathway analysis . In bioinformatics research, pathway analysis software is used to identify related proteins within a pathway or building pathway de novo from the proteins of interest. This is helpful when studying differential expression of a gene in a disease or analyzing any omics dataset with a large number of proteins. By examining the changes in gene expression in a pathway, its biological causes can be explored. Pathway is the term from molecular biology which depicts an artificial simplified model of a process within a cell or tissue. Typical pathway model starts with extracellular signaling molecule that activates a specific protein. Thus triggers a chain of protein-protein or protein-small molecule interactions. Pathway analysis helps to understand or interpret omics data from the point of view of canonical prior knowledge structured in the form of pathways diagrams. It allows finding distinct cell processes (), diseases or signaling pathways that are statistically associated with selection of differentially expressed genes between two samples. Often but erroneously pathway analysis is used as synonym for network analysis (functional enrichment analysis and gene set analysis).",
            "score": 88.69470977783203
        },
        {
            "docid": "11044599_8",
            "document": "Searching the conformational space for docking . Although genetic algorithms are quite successful in sampling the large conformational space, many docking programs require the protein to remain fixed, while allowing only the ligand to flex and adjust to the active site of the protein. Genetic algorithms also require multiple runs to obtain reliable answers regarding ligands that may bind to the protein. The time it takes to typically run a genetic algorithm in order to allow a proper pose may be longer, hence these methods may not be as efficient as shape complementarity-based approaches in screening large databases of compounds. Recent improvements in using grid-based evaluation of energies, limiting the exploration of the conformational changes at only local areas (active sites) of interest, and improved tabling methods have significantly enhanced the performance of genetic algorithms and made them suitable for virtual screening applications.",
            "score": 88.17229461669922
        },
        {
            "docid": "23634_24",
            "document": "Protein . Proteins can bind to other proteins as well as to small-molecule substrates. When proteins bind specifically to other copies of the same molecule, they can oligomerize to form fibrils; this process occurs often in structural proteins that consist of globular monomers that self-associate to form rigid fibers. Protein\u2013protein interactions also regulate enzymatic activity, control progression through the cell cycle, and allow the assembly of large protein complexes that carry out many closely related reactions with a common biological function. Proteins can also bind to, or even be integrated into, cell membranes. The ability of binding partners to induce conformational changes in proteins allows the construction of enormously complex signaling networks. As interactions between proteins are reversible, and depend heavily on the availability of different groups of partner proteins to form aggregates that are capable to carry out discrete sets of function, study of the interactions between specific proteins is a key to understand important aspects of cellular function, and ultimately the properties that distinguish particular cell types.",
            "score": 87.62521362304688
        },
        {
            "docid": "20358421_2",
            "document": "Target protein . Target proteins are functional biomolecules that are addressed and controlled by biologically active compounds. They are used in the processes of transduction, transformation and conjugation. The identification of target proteins, the investigation of signal transduction processes and the understanding of their interaction with ligands are key elements of modern biomedical research. Since the interaction with target proteins is the molecular origin of most drugs, their particular importance for molecular biology, molecular pharmacy and pharmaceutical sciences is obvious. Target proteins control the action and the kinetic behavior of drugs within the organism. The elucidation of structure, conformational signaling and catalytic properties of particular target proteins facilitates a rational design of drugs and biotechnological processes. Known as biologicals, target proteins can also be drugs by themselves when their modification and formulation is emphasized within the pharmaceutical sciences. Finally, target protein - inducer interactions can be exploited for biomolecular transcription regulating systems in order to control for example gene therapeutic approaches.",
            "score": 87.6126480102539
        },
        {
            "docid": "216104_14",
            "document": "Protein engineering . These methods involve free modeling without using any structural information about the template. \"Ab initio\" methods are aimed at prediction of the native structures of proteins corresponding to the global minimum of its free energy. some examples of \"ab initio\" methods are AMBER, GROMOS, GROMACS, CHARMM, OPLS, and ENCEPP12. General steps for \"ab initio\" methods begin with the geometric representation of the protein of interest. Next, a potential energy function model for the protein is developed. This model can be created using either molecular mechanics potentials or protein structure derived potential functions. Following the development of a potential model, energy search techniques including molecular dynamic simulations, Monte Carlo simulations and genetic algorithms are applied to the protein.",
            "score": 87.42034912109375
        },
        {
            "docid": "26480660_6",
            "document": "Ram Samudrala . Samudrala's research has focused on understanding how the genome of an organism specifies its behaviour and characteristics, and applying that information to improve health and quality of life. His vision is to produce a computing model of life focused on atomic level detail, organisation, and arrangements of all the components involved, which he calls the \"structeome\". The structeome, which is the actual structural organization of components at the atomic level, by its very nature includes single molecules such as DNA, RNA, proteins, and metabolites, as well larger groupings such genomes, proteome, interactomes, connectomes, and so on. Since the vision is of a large collection of atoms with subgroupings of atoms that work together in a complex dynamic manner, a protein would be a collection of atoms, many of which are covalently bonded, that interact together to perform a specific biological function. Samudrala's work has thus focussed on proteins, which is the fundamental unit of biological function within the structeome. Atoms in a structeome interact with the environment which may include other structeomes (or components thereof) thereby causing a strange loop or a tangled hierarchy of interactions. Thus a structeome would include not only all atoms and their interactions within that structeome, but also all interactions to other structeomes. Samudrala has extended this theoretical framework to explain how evolution works by recursion of existing information and has used it to solve research problems with practical applications in medicine, such as therapeutic discovery based on docking with dynamics, multitargeting, and drug repurposing in a shotgun manner, as well as in nanobiotechnology, such as engineering tooth tissue by designing novel peptides that bind to various inorganic substrates.",
            "score": 87.36273193359375
        },
        {
            "docid": "2606518_26",
            "document": "Macromolecular docking . A benchmark of 84 protein\u2013protein interactions with known complexed structures has been developed for testing docking methods. The set is chosen to cover a wide range of interaction types, and to avoid repeated features, such as the profile of interactors' structural families according to the SCOP database. Benchmark elements are classified into three levels of difficulty (the most difficult containing the largest change in backbone conformation). The protein\u2013protein docking benchmark contains examples of enzyme-inhibitor, antigen-antibody and homomultimeric complexes.",
            "score": 85.69048309326172
        },
        {
            "docid": "6987160_2",
            "document": "Discrete optimized protein energy . DOPE, or Discrete Optimized Protein Energy, is a statistical potential used to assess homology models in protein structure prediction. DOPE is based on an improved reference state that corresponds to noninteracting atoms in a homogeneous sphere with the radius dependent on a sample native structure; it thus accounts for the finite and spherical shape of the native structures. It is implemented in the popular homology modeling program MODELLER and used to assess the energy of the protein model generated through many iterations by MODELLER, which produces homology models by the satisfaction of spatial restraints. The models returning the minimum molpdfs can be chosen as best probable structures and can be further used for evaluating with the DOPE score. Like the current version of the MODELLER software, DOPE is implemented in Python and is run within the MODELLER environment. The DOPE method is generally used to assess the quality of a structure model as a whole. Alternatively, DOPE can also generate a residue-by-residue energy profile for the input model, making it possible for the user to spot the problematic region in the structure model.",
            "score": 85.60983276367188
        },
        {
            "docid": "542598_14",
            "document": "Protein complex . The molecular structure of protein complexes can be determined by experimental techniques such as X-ray crystallography, Single particle analysis or nuclear magnetic resonance. Increasingly the theoretical option of protein\u2013protein docking is also becoming available. One method that is commonly used for identifying the meomplexes immunoprecipitation. Recently, Raicu and coworkers developed a method to determine the quaternary structure of protein complexes in living cells. This method is based on the determination of pixel-level F\u00f6rster resonance energy transfer (FRET) efficiency in conjunction with spectrally resolved two-photon microscope. The distribution of FRET efficiencies are simulated against different models to get the geometry and stoichiometry of the complexes.",
            "score": 85.5943832397461
        },
        {
            "docid": "2292623_8",
            "document": "Docking (molecular) . Geometric matching/ shape complementarity methods describe the protein and ligand as a set of features that make them dockable. These features may include molecular surface / complementary surface descriptors. In this case, the receptor\u2019s molecular surface is described in terms of its solvent-accessible surface area and the ligand\u2019s molecular surface is described in terms of its matching surface description. The complementarity between the two surfaces amounts to the shape matching description that may help finding the complementary pose of docking the target and the ligand molecules. Another approach is to describe the hydrophobic features of the protein using turns in the main-chain atoms. Yet another approach is to use a Fourier shape descriptor technique. Whereas the shape complementarity based approaches are typically fast and robust, they cannot usually model the movements or dynamic changes in the ligand/ protein conformations accurately, although recent developments allow these methods to investigate ligand flexibility. Shape complementarity methods can quickly scan through several thousand ligands in a matter of seconds and actually figure out whether they can bind at the protein\u2019s active site, and are usually scalable to even protein-protein interactions. They are also much more amenable to pharmacophore based approaches, since they use geometric descriptions of the ligands to find optimal binding.",
            "score": 85.54718780517578
        },
        {
            "docid": "2606518_13",
            "document": "Macromolecular docking . In the early 1990s, more structures of complexes were determined, and available computational power had increased substantially. With the emergence of bioinformatics, the focus moved towards developing generalized techniques which could be applied to an arbitrary set of complexes at acceptable computational cost. The new methods were envisaged to apply even in the absence of phylogenetic or experimental clues; any specific prior knowledge could still be introduced at the stage of choosing between the highest ranking output models, or be framed as input if the algorithm catered for it. 1992 saw the publication of the correlation method, an algorithm which used the fast Fourier transform to give a vastly improved scalability for evaluating coarse shape complementarity on rigid-body models. This was extended in 1997 to cover coarse electrostatics.",
            "score": 85.2772445678711
        },
        {
            "docid": "23890524_11",
            "document": "Eukaryotic ribosome (80S) . Protein synthesis is primarily regulated at the stage of translation initiation. In eukaryotes, the canonical initiation pathway requires at least 12 protein initiation factors, some of which are themselves large complexes. The structures of the 40S:eIF1 and 60S:eIF6 complexes provide first detailed insights into the atomic interactions between the eukaryotic ribosome and regulatory factors. eIF1 is involved in start codon selection, and eIF6 sterically precludes the joining of subunits. However, structural information on the eukaryotic initiation factors and their interactions with the ribosome is limited and largely derived from homology models or low-resolution analyses. Elucidation of the interactions between the eukaryotic ribosome and initiation factors at an atomic level is essential for a mechanistic understanding of the regulatory processes, but represents a significant technical challenge, because of the inherent dynamics and flexibility of the initiation complexes. The first structure of the mammalian pre initiation complex was done by cryo-electron microscopy. Other structures of initiation complexes followed soon, driven by cryo-EM technical improvements. Those structures will help better understand the process of translation initiation in eukaryotes.",
            "score": 84.79341888427734
        },
        {
            "docid": "2606518_2",
            "document": "Macromolecular docking . Macromolecular docking is the computational modelling of the quaternary structure of complexes formed by two or more interacting biological macromolecules. Protein\u2013protein complexes are the most commonly attempted targets of such modelling, followed by protein\u2013nucleic acid complexes.",
            "score": 84.49601745605469
        },
        {
            "docid": "11044599_4",
            "document": "Searching the conformational space for docking . In this approach, proteins are typically held rigid, and the ligand is allowed to freely explore their conformational space. The generated conformations are then docked successively into the protein, and an MD simulation consisting of a simulated annealing protocol is performed. This is usually supplemented with short MD energy minimization steps, and the energies determined from the MD runs are used for ranking the overall scoring. Although this is a computer-expensive method (involving potentially hundreds of MD runs), it has some advantages: for example, no specialized energy/scoring functions are required. MD force-fields can typically be used to find poses that are reasonable and can be compared with experimental structures.",
            "score": 84.26213836669922
        },
        {
            "docid": "303101_3",
            "document": "Structural genomics . Because protein structure is closely linked with protein function, the structural genomics has the potential to inform knowledge of protein function. In addition to elucidating protein functions, structural genomics can be used to identify novel protein folds and potential targets for drug discovery. Structural genomics involves taking a large number of approaches to structure determination, including experimental methods using genomic sequences or modeling-based approaches based on sequence or structural homology to a protein of known structure or based on chemical and physical principles for a protein with no homology to any known structure.",
            "score": 84.14517211914062
        },
        {
            "docid": "9705082_7",
            "document": "Robert J. LeRoy . In almost any area of science today, the experimental work runs parallel to the theoretical work and there is constant interplay between the two areas. In Canada there are several theorists whose research teams examine the forces between atoms and molecules to increase our understanding of physical and chemical properties. One such individual is Dr. Robert LeRoy, currently working in theoretical chemical physics at the University of Waterloo. Dr. LeRoy\u2019s interest is intermolecular forces. He uses quantum mechanics and computer models to define and analyze the basic forces between atoms and molecules. Early in his career, Dr. LeRoy developed a technique for mathematically defining a radius of a small molecule, now known as the LeRoy radius. This established a boundary.Within the boundary, intramolecular bonding is important, and beyond the boundary, intermolecular forces predominate. In his work, the study of atomic and molecular spectra (called spectroscopy) plays a crucial role. Measurements from spectroscopy help theoreticians develop better models and theories for explaining molecular structure.Computer programs that Dr. LeRoy has developed for the purpose of converting experimental evidence to information on forces, shape, and structure are free, and are now routinely used around the world. It is important not to assume that forces and structures are well established. Our knowledge of bonding and structure becomes more and more scanty and unreliable for larger structures. A huge amount of research remains to be done if we are ever to be able to describe bonding and structure very accurately for even microscopic amounts of complex substances. Dr. LeRoy states \u201c... except for the simplest systems, our knowledge of (interactions between molecules) is fairly primitive... .\u201d A classic example is our understanding of the structure and activity of proteins\u2014the stuff of life.We know the composition of many proteins quite precisely and the structure can be experimentally determined, but the structure of these large molecules depends on how bonding folds and shapes the chains and branches. How a protein behaves and what it does depends specifically on its precise shape and structure, and that is something scientists often state is \u201cnot well understood.\u201d",
            "score": 83.99783325195312
        },
        {
            "docid": "524466_18",
            "document": "Clique (graph theory) . Many different problems from bioinformatics have been modeled using cliques. For instance, model the problem of clustering gene expression data as one of finding the minimum number of changes needed to transform a graph describing the data into a graph formed as the disjoint union of cliques; discuss a similar biclustering problem for expression data in which the clusters are required to be cliques. uses cliques to model ecological niches in food webs. describe the problem of inferring evolutionary trees as one of finding maximum cliques in a graph that has as its vertices characteristics of the species, where two vertices share an edge if there exists a perfect phylogeny combining those two characters. model protein structure prediction as a problem of finding cliques in a graph whose vertices represent positions of subunits of the protein. And by searching for cliques in a protein-protein interaction network, found clusters of proteins that interact closely with each other and have few interactions with proteins outside the cluster. Power graph analysis is a method for simplifying complex biological networks by finding cliques and related structures in these networks.",
            "score": 83.77193450927734
        }
    ]
}